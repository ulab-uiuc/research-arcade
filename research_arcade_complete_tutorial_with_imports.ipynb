{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# ResearchArcade Complete Tutorial\n",
    "\n",
    "This tutorial demonstrates how to work with the ResearchArcade database, covering all node types and edge relationships.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup](#setup)\n",
    "2. [OpenReview Data](#openreview)\n",
    "3. [ArXiv Papers](#arxiv-papers)\n",
    "4. [ArXiv Authors](#arxiv-authors)\n",
    "5. [ArXiv Categories](#arxiv-categories)\n",
    "6. [ArXiv Figures](#arxiv-figures)\n",
    "7. [ArXiv Tables](#arxiv-tables)\n",
    "8. [ArXiv Sections](#arxiv-sections)\n",
    "9. [ArXiv Paragraphs](#arxiv-paragraphs)\n",
    "10. [Relationships/Edges](#relationships)\n",
    "11. [Advanced Queries](#advanced-queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": [
    "## 1. Setup <a name=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05b9b352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from research_arcade.research_arcade import ResearchArcade\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f1a1e4",
   "metadata": {},
   "source": [
    "### Choose Database Backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9672a27",
   "metadata": {},
   "source": [
    "#### CSV Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "169f7a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_type = \"csv\"\n",
    "config = {\n",
    "    \"csv_dir\": \"../data/my_research_arcade_data/\"\n",
    "}\n",
    "\n",
    "research_arcade = ResearchArcade(db_type=db_type, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-papers-section",
   "metadata": {},
   "source": [
    "## 3. ArXiv Papers <a name=\"arxiv-papers\"></a>\n",
    "\n",
    "### Table Schema\n",
    "- `id` (SERIAL PK)\n",
    "- `arxiv_id` (VARCHAR, unique) - e.g., 1802.08773v3\n",
    "- `base_arxiv_id` (VARCHAR) - e.g., 1802.08773\n",
    "- `version` (INT) - e.g., 3\n",
    "- `title` (TEXT)\n",
    "- `abstract` (TEXT)\n",
    "- `submit_date` (DATE)\n",
    "- `metadata` (JSONB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b8e215",
   "metadata": {},
   "source": [
    "### Construct Table from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccaeefb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"arxiv_ids\": [\"1806.08804v4\", \"1903.03894v4\"], \"dest_dir\": \"./download\"}\n",
    "research_arcade.construct_table_from_api(\"arxiv_papers\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Table from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported 1 papers from ./examples/csv_data/csv_arxiv_papers_example.csv\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"./examples/csv_data/csv_arxiv_papers_example.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"arxiv_papers\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Table from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new papers to import (all papers already exist)\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"./examples/json_data/json_arxiv_papers_example.json\"}\n",
    "research_arcade.construct_table_from_json(\"arxiv_papers\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-papers-insert",
   "metadata": {},
   "source": [
    "### Insert a Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "insert-paper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Insert the famous \"Attention is All You Need\" paper\n",
    "new_paper = {\n",
    "    'arxiv_id': '1706.03762v7',\n",
    "    'base_arxiv_id': '1706.03762',\n",
    "    'version': 7,\n",
    "    'title': 'Attention Is All You Need',\n",
    "    'abstract': 'The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.',\n",
    "    'submit_date': '2017-06-12',\n",
    "    'metadata': {'venue': 'NeurIPS 2017', 'pdf_url': 'https://arxiv.org/pdf/1706.03762.pdf'}\n",
    "}\n",
    "\n",
    "research_arcade.insert_node(\"arxiv_papers\", node_features=new_paper)\n",
    "print(\"Paper inserted successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "insert-paper-bert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT paper inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Insert BERT paper\n",
    "bert_paper = {\n",
    "    'arxiv_id': '1810.04805v2',\n",
    "    'base_arxiv_id': '1810.04805',\n",
    "    'version': 2,\n",
    "    'title': 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding',\n",
    "    'abstract': 'We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications.',\n",
    "    'submit_date': '2018-10-11',\n",
    "    'metadata': {'venue': 'NAACL 2019', 'citations': 50000}\n",
    "}\n",
    "\n",
    "research_arcade.insert_node(\"arxiv_papers\", node_features=bert_paper)\n",
    "print(\"BERT paper inserted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-papers-get-all",
   "metadata": {},
   "source": [
    "### Get All Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "get-all-papers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total papers in database: 7\n",
      "\n",
      "First 5 papers:\n",
      "   id      arxiv_id  base_arxiv_id  version  \\\n",
      "0   2  1810.04805v2     1810.04805        2   \n",
      "1   3   1409.0473v7     1409.04730        7   \n",
      "2   4  1512.03385v1     1512.03385        1   \n",
      "3   5  2010.11929v2     2010.11929        2   \n",
      "4   6  1806.08804v4     1806.08804        4   \n",
      "\n",
      "                                               title  \\\n",
      "0  BERT: Pre-training of Deep Bidirectional Trans...   \n",
      "1  Neural Machine Translation by Jointly Learning...   \n",
      "2       Deep Residual Learning for Image Recognition   \n",
      "3  An Image is Worth 16x16 Words: Transformers fo...   \n",
      "4  Hierarchical Graph Representation Learning wit...   \n",
      "\n",
      "                                            abstract  \\\n",
      "0  We introduce a new language representation mod...   \n",
      "1  Neural machine translation is a recently propo...   \n",
      "2  Deeper neural networks are more difficult to t...   \n",
      "3  We show that a pure transformer applied direct...   \n",
      "4  Recently, graph neural networks (GNNs) have re...   \n",
      "\n",
      "                 submit_date  \\\n",
      "0                 2018-10-11   \n",
      "1                 2014-09-01   \n",
      "2                 2015-12-10   \n",
      "3                 2020-10-22   \n",
      "4  2018-06-22 18:04:46+00:00   \n",
      "\n",
      "                                            metadata  \n",
      "0        {\"venue\": \"NAACL 2019\", \"citations\": 60000}  \n",
      "1         {\"venue\": \"ICLR 2015\", \"citations\": 30000}  \n",
      "2         {\"venue\": \"CVPR 2016\", \"citations\": 70000}  \n",
      "3         {\"venue\": \"ICLR 2021\", \"citations\": 15000}  \n",
      "4  {\"id\": \"1806.08804v4\", \"title\": \"Hierarchical ...  \n"
     ]
    }
   ],
   "source": [
    "arxiv_papers_df = research_arcade.get_all_node_features(\"arxiv_papers\")\n",
    "print(f\"Total papers in database: {len(arxiv_papers_df)}\")\n",
    "print(\"\\nFirst 5 papers:\")\n",
    "print(arxiv_papers_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-papers-get-by-id",
   "metadata": {},
   "source": [
    "### Get Specific Paper by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "get-paper-by-id",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper details:\n",
      "{'id': 2, 'arxiv_id': '1810.04805v2', 'base_arxiv_id': 1810.04805, 'version': 2, 'title': 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding', 'abstract': 'We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers.', 'submit_date': '2018-10-11', 'metadata': '{\"venue\": \"NAACL 2019\", \"citations\": 60000}'}\n"
     ]
    }
   ],
   "source": [
    "paper_id = {\"arxiv_id\": \"1810.04805v2\"}\n",
    "paper_features = research_arcade.get_node_features_by_id(\"arxiv_papers\", paper_id)\n",
    "print(\"Paper details:\")\n",
    "print(paper_features.to_dict(orient=\"records\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-papers-update",
   "metadata": {},
   "source": [
    "### Update a Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "update-paper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper updated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Update metadata for a paper\n",
    "updated_paper = {\n",
    "    'arxiv_id': '1706.03762v7',\n",
    "    'metadata': {\n",
    "        'venue': 'NeurIPS 2017',\n",
    "        'pdf_url': 'https://arxiv.org/pdf/1706.03762.pdf',\n",
    "        'citations': 75000,\n",
    "        'influential': True\n",
    "    }\n",
    "}\n",
    "\n",
    "research_arcade.update_node(\"arxiv_papers\", node_features=updated_paper)\n",
    "print(\"Paper updated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-papers-delete",
   "metadata": {},
   "source": [
    "### Delete a Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "delete-paper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted paper:\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Delete a paper by ID\n",
    "paper_id = {\"arxiv_id\": \"1706.03762v7\"}\n",
    "deleted_paper = research_arcade.delete_node_by_id(\"arxiv_papers\", paper_id)\n",
    "print(\"Deleted paper:\")\n",
    "print(deleted_paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-authors-section",
   "metadata": {},
   "source": [
    "## 4. ArXiv Authors <a name=\"arxiv-authors\"></a>\n",
    "\n",
    "### Table Schema\n",
    "- `id` (SERIAL PK)\n",
    "- `semantic_scholar_id` (VARCHAR, unique)\n",
    "- `name` (VARCHAR)\n",
    "- `homepage` (VARCHAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e14ad06",
   "metadata": {},
   "source": [
    "### Construct Table from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c18c7737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = {\"arxiv_ids\": [\"1903.03894v4\", \"1806.08804v4\"], \"dest_dir\": \"./download\"}\n",
    "# research_arcade.construct_table_from_api(\"arxiv_authors\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Table from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported 10 authors from ./examples/csv_data/csv_arxiv_authors_example.csv\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"./examples/csv_data/csv_arxiv_authors_example.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"arxiv_authors\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Table from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new authors to import (all authors already exist)\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"./examples/json_data/json_arxiv_authors_example.json\"}\n",
    "research_arcade.construct_table_from_json(\"arxiv_authors\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-authors-insert",
   "metadata": {},
   "source": [
    "### Insert Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "insert-authors",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted author: Ashish Vaswani\n",
      "Inserted author: Noam Shazeer\n",
      "Inserted author: Niki Parmar\n",
      "Inserted author: Jakob Uszkoreit\n",
      "Inserted author: Llion Jones\n"
     ]
    }
   ],
   "source": [
    "# Insert authors from the Transformer paper\n",
    "authors = [\n",
    "    {\n",
    "        'semantic_scholar_id': 'ss_ashish_vaswani',\n",
    "        'name': 'Ashish Vaswani',\n",
    "        'homepage': 'https://scholar.google.com/citations?user=oR9sCGYAAAAJ'\n",
    "    },\n",
    "    {\n",
    "        'semantic_scholar_id': 'ss_noam_shazeer',\n",
    "        'name': 'Noam Shazeer',\n",
    "        'homepage': 'https://scholar.google.com/citations?user=oR9sCGYAAAAJ'\n",
    "    },\n",
    "    {\n",
    "        'semantic_scholar_id': 'ss_niki_parmar',\n",
    "        'name': 'Niki Parmar',\n",
    "        'homepage': 'https://scholar.google.com/citations?user=oR9sCGYAAAAJ'\n",
    "    },\n",
    "    {\n",
    "        'semantic_scholar_id': 'ss_jakob_uszkoreit',\n",
    "        'name': 'Jakob Uszkoreit',\n",
    "        'homepage': 'https://scholar.google.com/citations?user=oR9sCGYAAAAJ'\n",
    "    },\n",
    "    {\n",
    "        'semantic_scholar_id': 'ss_llion_jones',\n",
    "        'name': 'Llion Jones',\n",
    "        'homepage': 'https://scholar.google.com/citations?user=oR9sCGYAAAAJ'\n",
    "    }\n",
    "]\n",
    "\n",
    "for author in authors:\n",
    "    research_arcade.insert_node(\"arxiv_authors\", node_features=author)\n",
    "    print(f\"Inserted author: {author['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-authors-get-all",
   "metadata": {},
   "source": [
    "### Get All Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "get-all-authors",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total authors in database: 55\n",
      "\n",
      "All authors:\n",
      "    id semantic_scholar_id              name  \\\n",
      "0    1             1234567    Ashish Vaswani   \n",
      "1    2             2345678      Noam Shazeer   \n",
      "2    3             3456789       Niki Parmar   \n",
      "3    4             4567890   Jakob Uszkoreit   \n",
      "4    5             5678901       Llion Jones   \n",
      "5    6             6789012    Aidan N. Gomez   \n",
      "6    7             7890123     Lukasz Kaiser   \n",
      "7    8             8901234  Illia Polosukhin   \n",
      "8    9             9012345      Jacob Devlin   \n",
      "9   10             1234098    Ming-Wei Chang   \n",
      "10  11             1234567    Ashish Vaswani   \n",
      "11  12             2345678      Noam Shazeer   \n",
      "12  13             3456789       Niki Parmar   \n",
      "13  14             4567890   Jakob Uszkoreit   \n",
      "14  15             5678901       Llion Jones   \n",
      "15  16             6789012    Aidan N. Gomez   \n",
      "16  17             7890123     Lukasz Kaiser   \n",
      "17  18             8901234  Illia Polosukhin   \n",
      "18  19             9012345      Jacob Devlin   \n",
      "19  20             1234098    Ming-Wei Chang   \n",
      "20  21             1234567    Ashish Vaswani   \n",
      "21  22             2345678      Noam Shazeer   \n",
      "22  23             3456789       Niki Parmar   \n",
      "23  24             4567890   Jakob Uszkoreit   \n",
      "24  25             5678901       Llion Jones   \n",
      "25  26             6789012    Aidan N. Gomez   \n",
      "26  27             7890123     Lukasz Kaiser   \n",
      "27  28             8901234  Illia Polosukhin   \n",
      "28  29             9012345      Jacob Devlin   \n",
      "29  30             1234098    Ming-Wei Chang   \n",
      "30  31   ss_ashish_vaswani    Ashish Vaswani   \n",
      "31  32     ss_noam_shazeer      Noam Shazeer   \n",
      "32  33      ss_niki_parmar       Niki Parmar   \n",
      "33  34  ss_jakob_uszkoreit   Jakob Uszkoreit   \n",
      "34  35      ss_llion_jones       Llion Jones   \n",
      "35  36             1234567    Ashish Vaswani   \n",
      "36  37             2345678      Noam Shazeer   \n",
      "37  38             3456789       Niki Parmar   \n",
      "38  39             4567890   Jakob Uszkoreit   \n",
      "39  40             5678901       Llion Jones   \n",
      "40  41             6789012    Aidan N. Gomez   \n",
      "41  42             7890123     Lukasz Kaiser   \n",
      "42  43             8901234  Illia Polosukhin   \n",
      "43  44             9012345      Jacob Devlin   \n",
      "44  45             1234098    Ming-Wei Chang   \n",
      "45  46             1234567    Ashish Vaswani   \n",
      "46  47             2345678      Noam Shazeer   \n",
      "47  48             3456789       Niki Parmar   \n",
      "48  49             4567890   Jakob Uszkoreit   \n",
      "49  50             5678901       Llion Jones   \n",
      "50  51             6789012    Aidan N. Gomez   \n",
      "51  52             7890123     Lukasz Kaiser   \n",
      "52  53             8901234  Illia Polosukhin   \n",
      "53  54             9012345      Jacob Devlin   \n",
      "54  55             1234098    Ming-Wei Chang   \n",
      "\n",
      "                                             homepage  \n",
      "0   https://scholar.google.com/citations?user=Pu55...  \n",
      "1   https://scholar.google.com/citations?user=8VY4...  \n",
      "2   https://scholar.google.com/citations?user=rK3M...  \n",
      "3   https://scholar.google.com/citations?user=UYZj...  \n",
      "4   https://scholar.google.com/citations?user=exam...  \n",
      "5   https://scholar.google.com/citations?user=exam...  \n",
      "6   https://scholar.google.com/citations?user=ZmBQ...  \n",
      "7   https://scholar.google.com/citations?user=exam...  \n",
      "8   https://scholar.google.com/citations?user=exam...  \n",
      "9   https://scholar.google.com/citations?user=exam...  \n",
      "10  https://scholar.google.com/citations?user=Pu55...  \n",
      "11  https://scholar.google.com/citations?user=8VY4...  \n",
      "12  https://scholar.google.com/citations?user=rK3M...  \n",
      "13  https://scholar.google.com/citations?user=UYZj...  \n",
      "14  https://scholar.google.com/citations?user=exam...  \n",
      "15  https://scholar.google.com/citations?user=exam...  \n",
      "16  https://scholar.google.com/citations?user=ZmBQ...  \n",
      "17  https://scholar.google.com/citations?user=exam...  \n",
      "18  https://scholar.google.com/citations?user=exam...  \n",
      "19  https://scholar.google.com/citations?user=exam...  \n",
      "20  https://scholar.google.com/citations?user=Pu55...  \n",
      "21  https://scholar.google.com/citations?user=8VY4...  \n",
      "22  https://scholar.google.com/citations?user=rK3M...  \n",
      "23  https://scholar.google.com/citations?user=UYZj...  \n",
      "24  https://scholar.google.com/citations?user=exam...  \n",
      "25  https://scholar.google.com/citations?user=exam...  \n",
      "26  https://scholar.google.com/citations?user=ZmBQ...  \n",
      "27  https://scholar.google.com/citations?user=exam...  \n",
      "28  https://scholar.google.com/citations?user=exam...  \n",
      "29  https://scholar.google.com/citations?user=exam...  \n",
      "30                          https://ashishvaswani.com  \n",
      "31  https://scholar.google.com/citations?user=oR9s...  \n",
      "32  https://scholar.google.com/citations?user=oR9s...  \n",
      "33  https://scholar.google.com/citations?user=oR9s...  \n",
      "34  https://scholar.google.com/citations?user=oR9s...  \n",
      "35  https://scholar.google.com/citations?user=Pu55...  \n",
      "36  https://scholar.google.com/citations?user=8VY4...  \n",
      "37  https://scholar.google.com/citations?user=rK3M...  \n",
      "38  https://scholar.google.com/citations?user=UYZj...  \n",
      "39  https://scholar.google.com/citations?user=exam...  \n",
      "40  https://scholar.google.com/citations?user=exam...  \n",
      "41  https://scholar.google.com/citations?user=ZmBQ...  \n",
      "42  https://scholar.google.com/citations?user=exam...  \n",
      "43  https://scholar.google.com/citations?user=exam...  \n",
      "44  https://scholar.google.com/citations?user=exam...  \n",
      "45  https://scholar.google.com/citations?user=Pu55...  \n",
      "46  https://scholar.google.com/citations?user=8VY4...  \n",
      "47  https://scholar.google.com/citations?user=rK3M...  \n",
      "48  https://scholar.google.com/citations?user=UYZj...  \n",
      "49  https://scholar.google.com/citations?user=exam...  \n",
      "50  https://scholar.google.com/citations?user=exam...  \n",
      "51  https://scholar.google.com/citations?user=ZmBQ...  \n",
      "52  https://scholar.google.com/citations?user=exam...  \n",
      "53  https://scholar.google.com/citations?user=exam...  \n",
      "54  https://scholar.google.com/citations?user=exam...  \n"
     ]
    }
   ],
   "source": [
    "authors_df = research_arcade.get_all_node_features(\"arxiv_authors\")\n",
    "print(f\"Total authors in database: {len(authors_df)}\")\n",
    "print(\"\\nAll authors:\")\n",
    "print(authors_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-authors-get-by-id",
   "metadata": {},
   "source": [
    "### Get Specific Author by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "get-author-by-id",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author details:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "author_id = {\"semantic_scholar_id\": 8901234}\n",
    "author_features = research_arcade.get_node_features_by_id(\"arxiv_authors\", author_id)\n",
    "print(\"Author details:\")\n",
    "print(author_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-authors-update",
   "metadata": {},
   "source": [
    "### Update an Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "update-author",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author updated successfully!\n"
     ]
    }
   ],
   "source": [
    "updated_author = {\n",
    "    'semantic_scholar_id': 'ss_ashish_vaswani',\n",
    "    'homepage': 'https://ashishvaswani.com'\n",
    "}\n",
    "\n",
    "research_arcade.update_node(\"arxiv_authors\", node_features=updated_author)\n",
    "print(\"Author updated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-categories-section",
   "metadata": {},
   "source": [
    "## 5. ArXiv Categories <a name=\"arxiv-categories\"></a>\n",
    "\n",
    "### Table Schema\n",
    "- `id` (SERIAL PK)\n",
    "- `name` (VARCHAR, unique)\n",
    "- `description` (TEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9eeea6",
   "metadata": {},
   "source": [
    "### Insert From API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "168633f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '1903.03894v4', 'title': 'GNNExplainer: Generating Explanations for Graph Neural Networks', 'abstract': \"Graph Neural Networks (GNNs) are a powerful tool for machine learning on\\ngraphs.GNNs combine node feature information with the graph structure by\\nrecursively passing neural messages along edges of the input graph. However,\\nincorporating both graph structure and feature information leads to complex\\nmodels, and explaining predictions made by GNNs remains unsolved. Here we\\npropose GNNExplainer, the first general, model-agnostic approach for providing\\ninterpretable explanations for predictions of any GNN-based model on any\\ngraph-based machine learning task. Given an instance, GNNExplainer identifies a\\ncompact subgraph structure and a small subset of node features that have a\\ncrucial role in GNN's prediction. Further, GNNExplainer can generate consistent\\nand concise explanations for an entire class of instances. We formulate\\nGNNExplainer as an optimization task that maximizes the mutual information\\nbetween a GNN's prediction and distribution of possible subgraph structures.\\nExperiments on synthetic and real-world graphs show that our approach can\\nidentify important graph structures as well as node features, and outperforms\\nbaselines by 17.1% on average. GNNExplainer provides a variety of benefits,\\nfrom the ability to visualize semantically relevant structures to\\ninterpretability, to giving insights into errors of faulty GNNs.\", 'authors': ['Rex Ying', 'Dylan Bourgeois', 'Jiaxuan You', 'Marinka Zitnik', 'Jure Leskovec'], 'published': '2019-03-10 00:56:26+00:00', 'categories': ['cs.LG', 'stat.ML'], 'url': 'http://arxiv.org/abs/1903.03894v4'}\n",
      "{'id': '1806.08804v4', 'title': 'Hierarchical Graph Representation Learning with Differentiable Pooling', 'abstract': 'Recently, graph neural networks (GNNs) have revolutionized the field of graph\\nrepresentation learning through effectively learned node embeddings, and\\nachieved state-of-the-art results in tasks such as node classification and link\\nprediction. However, current GNN methods are inherently flat and do not learn\\nhierarchical representations of graphs---a limitation that is especially\\nproblematic for the task of graph classification, where the goal is to predict\\nthe label associated with an entire graph. Here we propose DiffPool, a\\ndifferentiable graph pooling module that can generate hierarchical\\nrepresentations of graphs and can be combined with various graph neural network\\narchitectures in an end-to-end fashion. DiffPool learns a differentiable soft\\ncluster assignment for nodes at each layer of a deep GNN, mapping nodes to a\\nset of clusters, which then form the coarsened input for the next GNN layer.\\nOur experimental results show that combining existing GNN methods with DiffPool\\nyields an average improvement of 5-10% accuracy on graph classification\\nbenchmarks, compared to all existing pooling approaches, achieving a new\\nstate-of-the-art on four out of five benchmark data sets.', 'authors': ['Rex Ying', 'Jiaxuan You', 'Christopher Morris', 'Xiang Ren', 'William L. Hamilton', 'Jure Leskovec'], 'published': '2018-06-22 18:04:46+00:00', 'categories': ['cs.LG', 'cs.NE', 'cs.SI', 'stat.ML'], 'url': 'http://arxiv.org/abs/1806.08804v4'}\n"
     ]
    }
   ],
   "source": [
    "config = {\"arxiv_ids\": [\"1903.03894v4\", \"1806.08804v4\"], \"dest_dir\": \"./download\"}\n",
    "research_arcade.construct_table_from_api(\"arxiv_categories\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Table from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new categories to import (all categories already exist)\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"./examples/csv_data/csv_arxiv_categories_example.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"arxiv_categories\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Table from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new categories to import (all categories already exist)\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"./examples/json_data/json_arxiv_categories_example.json\"}\n",
    "research_arcade.construct_table_from_json(\"arxiv_categories\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-categories-insert",
   "metadata": {},
   "source": [
    "### Insert Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "insert-categories",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted category: cs.CL\n",
      "Inserted category: cs.LG\n",
      "Inserted category: cs.AI\n",
      "Inserted category: cs.CV\n",
      "Inserted category: stat.ML\n"
     ]
    }
   ],
   "source": [
    "categories = [\n",
    "    {\n",
    "        'name': 'cs.CL',\n",
    "        'description': 'Computation and Language (Natural Language Processing)'\n",
    "    },\n",
    "    {\n",
    "        'name': 'cs.LG',\n",
    "        'description': 'Machine Learning'\n",
    "    },\n",
    "    {\n",
    "        'name': 'cs.AI',\n",
    "        'description': 'Artificial Intelligence'\n",
    "    },\n",
    "    {\n",
    "        'name': 'cs.CV',\n",
    "        'description': 'Computer Vision and Pattern Recognition'\n",
    "    },\n",
    "    {\n",
    "        'name': 'stat.ML',\n",
    "        'description': 'Machine Learning (Statistics)'\n",
    "    }\n",
    "]\n",
    "\n",
    "for category in categories:\n",
    "    research_arcade.insert_node(\"arxiv_categories\", node_features=category)\n",
    "    print(f\"Inserted category: {category['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-categories-get-all",
   "metadata": {},
   "source": [
    "### Get All Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "get-all-categories",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total categories: 11\n",
      "\n",
      "All categories:\n",
      "    id     name                              description\n",
      "0    1    cs.LG                                      NaN\n",
      "1    2  stat.ML                                      NaN\n",
      "2    3    cs.NE                                      NaN\n",
      "3    4    cs.SI                                      NaN\n",
      "4    5    cs.AI                  Artificial Intelligence\n",
      "5    7    cs.CL                 Computation and Language\n",
      "6    8    cs.CV  Computer Vision and Pattern Recognition\n",
      "7   11    cs.CR                Cryptography and Security\n",
      "8   12    cs.DS           Data Structures and Algorithms\n",
      "9   13    cs.IT                       Information Theory\n",
      "10  14  math.IT                Information Theory (Math)\n"
     ]
    }
   ],
   "source": [
    "categories_df = research_arcade.get_all_node_features(\"arxiv_categories\")\n",
    "print(f\"Total categories: {len(categories_df)}\")\n",
    "print(\"\\nAll categories:\")\n",
    "print(categories_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-figures-section",
   "metadata": {},
   "source": [
    "## 6. ArXiv Figures <a name=\"arxiv-figures\"></a>\n",
    "\n",
    "### Table Schema\n",
    "- `id` (SERIAL PK)\n",
    "- `paper_arxiv_id` (VARCHAR FK → papers.arxiv_id)\n",
    "- `path` (VARCHAR)\n",
    "- `caption` (TEXT)\n",
    "- `label` (TEXT)\n",
    "- `name` (TEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-figures-insert",
   "metadata": {},
   "source": [
    "### Insert Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "insert-figures",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted Figure 1\n",
      "Inserted Figure 2\n",
      "Inserted Figure 3\n"
     ]
    }
   ],
   "source": [
    "# Insert figures for the Transformer paper\n",
    "figures = [\n",
    "    {\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'path': '/figures/transformer_architecture.png',\n",
    "        'caption': 'The Transformer model architecture. The left side shows the encoder stack and the right side shows the decoder stack.',\n",
    "        'label': 'fig:architecture',\n",
    "        'name': 'Figure 1'\n",
    "    },\n",
    "    {\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'path': '/figures/scaled_dot_product_attention.png',\n",
    "        'caption': 'Scaled Dot-Product Attention and Multi-Head Attention mechanisms.',\n",
    "        'label': 'fig:attention',\n",
    "        'name': 'Figure 2'\n",
    "    },\n",
    "    {\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'path': '/figures/positional_encoding.png',\n",
    "        'caption': 'Positional encoding visualization showing sine and cosine functions of different frequencies.',\n",
    "        'label': 'fig:positional',\n",
    "        'name': 'Figure 3'\n",
    "    }\n",
    "]\n",
    "\n",
    "for figure in figures:\n",
    "    research_arcade.insert_node(\"arxiv_figures\", node_features=figure)\n",
    "    print(f\"Inserted {figure['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-figures-get-all",
   "metadata": {},
   "source": [
    "### Get All Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "get-all-figures",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total figures: 11\n",
      "\n",
      "All figures:\n",
      "        name                                            caption  \\\n",
      "0   Figure 1  The Transformer model architecture. The left s...   \n",
      "1   Figure 2  Scaled Dot-Product Attention and Multi-Head At...   \n",
      "2   Figure 3  Positional encoding visualization showing sine...   \n",
      "3    figure1                 The Transformer model architecture   \n",
      "4    figure2       Multi-head attention mechanism visualization   \n",
      "5    figure3         Variations on the Transformer architecture   \n",
      "6    figure4     BERT model architecture and pre-training tasks   \n",
      "7    figure5               Fine-tuning BERT for different tasks   \n",
      "8    figure6                Residual learning: a building block   \n",
      "9    figure7                  ResNet architectures for ImageNet   \n",
      "10   figure8            Vision Transformer (ViT) model overview   \n",
      "\n",
      "               label  \n",
      "0   fig:architecture  \n",
      "1      fig:attention  \n",
      "2     fig:positional  \n",
      "3   fig:architecture  \n",
      "4      fig:attention  \n",
      "5     fig:variations  \n",
      "6      fig:bert_arch  \n",
      "7      fig:fine_tune  \n",
      "8       fig:residual  \n",
      "9    fig:resnet_arch  \n",
      "10           fig:vit  \n"
     ]
    }
   ],
   "source": [
    "figures_df = research_arcade.get_all_node_features(\"arxiv_figures\")\n",
    "print(f\"Total figures: {len(figures_df)}\")\n",
    "print(\"\\nAll figures:\")\n",
    "print(figures_df[['name', 'caption', 'label']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-tables-section",
   "metadata": {},
   "source": [
    "## 7. ArXiv Tables <a name=\"arxiv-tables\"></a>\n",
    "\n",
    "### Table Schema\n",
    "- `id` (SERIAL PK)\n",
    "- `paper_arxiv_id` (VARCHAR FK → papers.arxiv_id)\n",
    "- `path` (VARCHAR)\n",
    "- `caption` (TEXT)\n",
    "- `label` (TEXT)\n",
    "- `table_text` (TEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c240602b",
   "metadata": {},
   "source": [
    "### Insert From API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54a13d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: ['1903.03894v4']\n",
      "BFS_que.qsize(): 1\n",
      "current paper: 1903.03894v4\n",
      "Thread 13079867392 Processing 1903.03894v4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x 000abstract.tex\n",
      "x 010intro.tex\n",
      "x 020related.tex\n",
      "x 030background.tex\n",
      "x 030formulation.tex\n",
      "x 030proposed.tex\n",
      "x 040experiments.tex\n",
      "x 050conclusion.tex\n",
      "x 060supplement.tex\n",
      "x acmart.bib\n",
      "x acmart.cls\n",
      "x acmart.dtx\n",
      "x acmart.ins\n",
      "x ACM-Reference-Format.bbx\n",
      "x ACM-Reference-Format.bst\n",
      "x ACM-Reference-Format.cbx\n",
      "x ACM-Reference-Format.dbx\n",
      "x figs/\n",
      "x figs/explainer-introduction_v2.pdf\n",
      "x figs/explainer-motivation.pdf\n",
      "x figs/explainer.pdf\n",
      "x figs/feature_importance_v2.pdf\n",
      "x figs/fig3-graph-cls-v2.pdf\n",
      "x figs/fig3-graph-cls.pdf\n",
      "x figs/fig3-node-cls-v3.pdf\n",
      "x figs/fig3-node-cls.pdf\n",
      "x figs/fig3-v4.pdf\n",
      "x figs/fig3-v5.pdf\n",
      "x figs/including-node-features.pdf\n",
      "x figs/local_subgraph.png\n",
      "x figs/motivation-node-features.pdf\n",
      "x figs/prototype.png\n",
      "x figs/prototype1.png\n",
      "x figs/single-instance-explanation-final.pdf\n",
      "x figs/single-instance-explanation2.pdf\n",
      "x figs/single-instance-explanations.pdf: truncated gzip input\n",
      "tar: Error exit delayed from previous errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 13079867392 Finished processing 1903.03894v4 (1/999999999) Time elapsed: 0.70s\n",
      "'NoneType' object is not subscriptable\n",
      "Thread 13079867392 Failed to process 1903.03894v4\n",
      "Thread 8614781504 Finished processing 1 papers\n",
      "Error: The file at path './download/output/1903.03894v4.json' was not found.\n"
     ]
    }
   ],
   "source": [
    "config = {\"arxiv_ids\": [\"1903.03894v4\", \"1806.08804v4\"], \"dest_dir\": \"./download\"}\n",
    "research_arcade.construct_table_from_api(\"arxiv_tables\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Table from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported 6 tables from ./examples/csv_data/csv_arxiv_tables_example.csv\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"./examples/csv_data/csv_arxiv_tables_example.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"arxiv_tables\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7002162",
   "metadata": {},
   "source": [
    "### Insert Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b809fdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted category: cs.CL\n",
      "Inserted category: cs.LG\n",
      "Inserted category: cs.AI\n",
      "Inserted category: cs.CV\n",
      "Inserted category: stat.ML\n"
     ]
    }
   ],
   "source": [
    "categories = [\n",
    "    {\n",
    "        'name': 'cs.CL',\n",
    "        'description': 'Computation and Language (Natural Language Processing)'\n",
    "    },\n",
    "    {\n",
    "        'name': 'cs.LG',\n",
    "        'description': 'Machine Learning'\n",
    "    },\n",
    "    {\n",
    "        'name': 'cs.AI',\n",
    "        'description': 'Artificial Intelligence'\n",
    "    },\n",
    "    {\n",
    "        'name': 'cs.CV',\n",
    "        'description': 'Computer Vision and Pattern Recognition'\n",
    "    },\n",
    "    {\n",
    "        'name': 'stat.ML',\n",
    "        'description': 'Machine Learning (Statistics)'\n",
    "    }\n",
    "]\n",
    "\n",
    "for category in categories:\n",
    "    research_arcade.insert_node(\"arxiv_categories\", node_features=category)\n",
    "    print(f\"Inserted category: {category['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3771de83",
   "metadata": {},
   "source": [
    "### Get All Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f1357fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total categories: 11\n",
      "\n",
      "All categories:\n",
      "    id     name                              description\n",
      "0    1    cs.LG                                      NaN\n",
      "1    2  stat.ML                                      NaN\n",
      "2    3    cs.NE                                      NaN\n",
      "3    4    cs.SI                                      NaN\n",
      "4    5    cs.AI                  Artificial Intelligence\n",
      "5    7    cs.CL                 Computation and Language\n",
      "6    8    cs.CV  Computer Vision and Pattern Recognition\n",
      "7   11    cs.CR                Cryptography and Security\n",
      "8   12    cs.DS           Data Structures and Algorithms\n",
      "9   13    cs.IT                       Information Theory\n",
      "10  14  math.IT                Information Theory (Math)\n"
     ]
    }
   ],
   "source": [
    "categories_df = research_arcade.get_all_node_features(\"arxiv_categories\")\n",
    "print(f\"Total categories: {len(categories_df)}\")\n",
    "print(\"\\nAll categories:\")\n",
    "print(categories_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827d6714",
   "metadata": {},
   "source": [
    "## 6. ArXiv Figures <a name=\"arxiv-figures\"></a>\n",
    "\n",
    "### Table Schema\n",
    "- `id` (SERIAL PK)\n",
    "- `paper_arxiv_id` (VARCHAR FK → papers.arxiv_id)\n",
    "- `path` (VARCHAR)\n",
    "- `caption` (TEXT)\n",
    "- `label` (TEXT)\n",
    "- `name` (TEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7d33eb",
   "metadata": {},
   "source": [
    "### Insert From API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "195e218d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: ['1903.03894v4']\n",
      "BFS_que.qsize(): 1\n",
      "current paper: 1903.03894v4\n",
      "Thread 13079867392 Processing 1903.03894v4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x 000abstract.tex\n",
      "x 010intro.tex\n",
      "x 020related.tex\n",
      "x 030background.tex\n",
      "x 030formulation.tex\n",
      "x 030proposed.tex\n",
      "x 040experiments.tex\n",
      "x 050conclusion.tex\n",
      "x 060supplement.tex\n",
      "x acmart.bib\n",
      "x acmart.cls\n",
      "x acmart.dtx\n",
      "x acmart.ins\n",
      "x ACM-Reference-Format.bbx\n",
      "x ACM-Reference-Format.bst\n",
      "x ACM-Reference-Format.cbx\n",
      "x ACM-Reference-Format.dbx\n",
      "x figs/\n",
      "x figs/explainer-introduction_v2.pdf\n",
      "x figs/explainer-motivation.pdf\n",
      "x figs/explainer.pdf\n",
      "x figs/feature_importance_v2.pdf\n",
      "x figs/fig3-graph-cls-v2.pdf\n",
      "x figs/fig3-graph-cls.pdf\n",
      "x figs/fig3-node-cls-v3.pdf\n",
      "x figs/fig3-node-cls.pdf\n",
      "x figs/fig3-v4.pdf\n",
      "x figs/fig3-v5.pdf\n",
      "x figs/including-node-features.pdf\n",
      "x figs/local_subgraph.png\n",
      "x figs/motivation-node-features.pdf\n",
      "x figs/prototype.png\n",
      "x figs/prototype1.png\n",
      "x figs/single-instance-explanation-final.pdf\n",
      "x figs/single-instance-explanation2.pdf\n",
      "x figs/single-instance-explanations.pdf: truncated gzip input\n",
      "tar: Error exit delayed from previous errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 13079867392 Finished processing 1903.03894v4 (1/999999999) Time elapsed: 0.71s\n",
      "'NoneType' object is not subscriptable\n",
      "Thread 13079867392 Failed to process 1903.03894v4\n",
      "Thread 8614781504 Finished processing 1 papers\n",
      "Error: The file with path './download/output/1903.03894v4.json' was not found.\n"
     ]
    }
   ],
   "source": [
    "config = {\"arxiv_ids\": [\"1903.03894v4\", \"1806.08804v4\"], \"dest_dir\": \"./download\"}\n",
    "research_arcade.construct_table_from_api(\"arxiv_figures\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Table from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new figures to import\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"./examples/csv_data/csv_arxiv_figures_example.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"arxiv_figures\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Table from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new figures to import\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"./examples/json_data/json_arxiv_figures_example.json\"}\n",
    "research_arcade.construct_table_from_json(\"arxiv_figures\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-tables-insert",
   "metadata": {},
   "source": [
    "### Insert Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "insert-tables",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted table: tab:variations\n",
      "Inserted table: tab:wmt\n",
      "Inserted table: tab:parsing\n"
     ]
    }
   ],
   "source": [
    "# Insert tables for the Transformer paper\n",
    "tables = [\n",
    "    {\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'path': '/tables/model_variations.tex',\n",
    "        'caption': 'Variations on the Transformer architecture with different hyperparameters.',\n",
    "        'label': 'tab:variations',\n",
    "        'table_text': 'Model | N | d_model | d_ff | h | d_k | d_v | P_drop | train time\\nbase | 6 | 512 | 2048 | 8 | 64 | 64 | 0.1 | 12 hrs'\n",
    "    },\n",
    "    {\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'path': '/tables/wmt_results.tex',\n",
    "        'caption': 'Performance of the Transformer on WMT 2014 English-German and English-French translation tasks.',\n",
    "        'label': 'tab:wmt',\n",
    "        'table_text': 'Model | EN-DE BLEU | EN-FR BLEU\\nTransformer (base) | 27.3 | 38.1\\nTransformer (big) | 28.4 | 41.8'\n",
    "    },\n",
    "    {\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'path': '/tables/parsing_results.tex',\n",
    "        'caption': 'English constituency parsing results on WSJ test set.',\n",
    "        'label': 'tab:parsing',\n",
    "        'table_text': 'Model | WSJ 23 F1\\nTransformer | 91.3'\n",
    "    }\n",
    "]\n",
    "\n",
    "for table in tables:\n",
    "    research_arcade.insert_node(\"arxiv_tables\", node_features=table)\n",
    "    print(f\"Inserted table: {table['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-tables-get-all",
   "metadata": {},
   "source": [
    "### Get All Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "get-all-tables",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tables: 34\n",
      "\n",
      "All tables:\n",
      "                   label                                            caption\n",
      "0        tab:wmt_results    Machine translation performance on WMT datasets\n",
      "1         tab:variations         Variations on the Transformer architecture\n",
      "2               tab:glue           BERT performance on GLUE benchmark tasks\n",
      "3              tab:squad                Results on SQuAD question answering\n",
      "4           tab:imagenet    Classification error on ImageNet validation set\n",
      "5           tab:vit_perf          Vision Transformer performance comparison\n",
      "6        tab:wmt_results    Machine translation performance on WMT datasets\n",
      "7         tab:variations         Variations on the Transformer architecture\n",
      "8               tab:glue           BERT performance on GLUE benchmark tasks\n",
      "9              tab:squad                Results on SQuAD question answering\n",
      "10          tab:imagenet    Classification error on ImageNet validation set\n",
      "11          tab:vit_perf          Vision Transformer performance comparison\n",
      "12        tab:variations  Variations on the Transformer architecture wit...\n",
      "13               tab:wmt  Performance of the Transformer on WMT 2014 Eng...\n",
      "14           tab:parsing  English constituency parsing results on WSJ te...\n",
      "15   \\label{tab:results}  \\caption{Classification accuracies in percent....\n",
      "16  \\label{tab:results2}  \\caption{Accuracy results of applying \\name to...\n",
      "17       tab:wmt_results    Machine translation performance on WMT datasets\n",
      "18        tab:variations         Variations on the Transformer architecture\n",
      "19              tab:glue           BERT performance on GLUE benchmark tasks\n",
      "20             tab:squad                Results on SQuAD question answering\n",
      "21          tab:imagenet    Classification error on ImageNet validation set\n",
      "22          tab:vit_perf          Vision Transformer performance comparison\n",
      "23   \\label{tab:results}  \\caption{Classification accuracies in percent....\n",
      "24  \\label{tab:results2}  \\caption{Accuracy results of applying \\name to...\n",
      "25       tab:wmt_results    Machine translation performance on WMT datasets\n",
      "26        tab:variations         Variations on the Transformer architecture\n",
      "27              tab:glue           BERT performance on GLUE benchmark tasks\n",
      "28             tab:squad                Results on SQuAD question answering\n",
      "29          tab:imagenet    Classification error on ImageNet validation set\n",
      "30          tab:vit_perf          Vision Transformer performance comparison\n",
      "31        tab:variations  Variations on the Transformer architecture wit...\n",
      "32               tab:wmt  Performance of the Transformer on WMT 2014 Eng...\n",
      "33           tab:parsing  English constituency parsing results on WSJ te...\n"
     ]
    }
   ],
   "source": [
    "tables_df = research_arcade.get_all_node_features(\"arxiv_tables\")\n",
    "print(f\"Total tables: {len(tables_df)}\")\n",
    "print(\"\\nAll tables:\")\n",
    "print(tables_df[['label', 'caption']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-sections-section",
   "metadata": {},
   "source": [
    "## 8. ArXiv Sections <a name=\"arxiv-sections\"></a>\n",
    "\n",
    "### Table Schema\n",
    "- `id` (SERIAL PK)\n",
    "- `content` (TEXT)\n",
    "- `title` (TEXT)\n",
    "- `appendix` (BOOLEAN)\n",
    "- `paper_arxiv_id` (VARCHAR FK → papers.arxiv_id)\n",
    "- `section_in_paper_id` (INT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9890560",
   "metadata": {},
   "source": [
    "### Insert From API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1735fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: ['1903.03894v4']\n",
      "BFS_que.qsize(): 1\n",
      "current paper: 1903.03894v4\n",
      "Thread 13079867392 Processing 1903.03894v4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x 000abstract.tex\n",
      "x 010intro.tex\n",
      "x 020related.tex\n",
      "x 030background.tex\n",
      "x 030formulation.tex\n",
      "x 030proposed.tex\n",
      "x 040experiments.tex\n",
      "x 050conclusion.tex\n",
      "x 060supplement.tex\n",
      "x acmart.bib\n",
      "x acmart.cls\n",
      "x acmart.dtx\n",
      "x acmart.ins\n",
      "x ACM-Reference-Format.bbx\n",
      "x ACM-Reference-Format.bst\n",
      "x ACM-Reference-Format.cbx\n",
      "x ACM-Reference-Format.dbx\n",
      "x figs/\n",
      "x figs/explainer-introduction_v2.pdf\n",
      "x figs/explainer-motivation.pdf\n",
      "x figs/explainer.pdf\n",
      "x figs/feature_importance_v2.pdf\n",
      "x figs/fig3-graph-cls-v2.pdf\n",
      "x figs/fig3-graph-cls.pdf\n",
      "x figs/fig3-node-cls-v3.pdf\n",
      "x figs/fig3-node-cls.pdf\n",
      "x figs/fig3-v4.pdf\n",
      "x figs/fig3-v5.pdf\n",
      "x figs/including-node-features.pdf\n",
      "x figs/local_subgraph.png\n",
      "x figs/motivation-node-features.pdf\n",
      "x figs/prototype.png\n",
      "x figs/prototype1.png\n",
      "x figs/single-instance-explanation-final.pdf\n",
      "x figs/single-instance-explanation2.pdf\n",
      "x figs/single-instance-explanations.pdf: truncated gzip input\n",
      "tar: Error exit delayed from previous errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 13079867392 Finished processing 1903.03894v4 (1/999999999) Time elapsed: 0.65s\n",
      "'NoneType' object is not subscriptable\n",
      "Thread 13079867392 Failed to process 1903.03894v4\n",
      "Thread 8614781504 Finished processing 1 papers\n",
      "Error: The file at path './download/output/1903.03894v4.json' was not found.\n"
     ]
    }
   ],
   "source": [
    "config = {\"arxiv_ids\": [\"1903.03894v4\", \"1806.08804v4\"], \"dest_dir\": \"./download\"}\n",
    "research_arcade.construct_table_from_api(\"arxiv_sections\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Table from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported 8 sections from ./examples/csv_data/csv_arxiv_sections_example.csv\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"./examples/csv_data/csv_arxiv_sections_example.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"arxiv_sections\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Table from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported 8 sections from ./examples/json_data/json_arxiv_sections_example.json\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"./examples/json_data/json_arxiv_sections_example.json\"}\n",
    "research_arcade.construct_table_from_json(\"arxiv_sections\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-sections-insert",
   "metadata": {},
   "source": [
    "### Insert Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "insert-sections",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted section: Introduction\n",
      "Inserted section: Background\n",
      "Inserted section: Model Architecture\n",
      "Inserted section: Training\n",
      "Inserted section: Results\n",
      "Inserted section: Conclusion\n"
     ]
    }
   ],
   "source": [
    "# Insert sections for the Transformer paper\n",
    "sections = [\n",
    "    {\n",
    "        'content': 'The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder...',\n",
    "        'title': 'Introduction',\n",
    "        'appendix': False,\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'section_in_paper_id': 1\n",
    "    },\n",
    "    {\n",
    "        'content': 'Most competitive neural sequence transduction models have an encoder-decoder structure. Here, the encoder maps an input sequence of symbol representations...',\n",
    "        'title': 'Background',\n",
    "        'appendix': False,\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'section_in_paper_id': 2\n",
    "    },\n",
    "    {\n",
    "        'content': 'Most neural sequence transduction models have an encoder-decoder structure. The Transformer follows this overall architecture using stacked self-attention and point-wise, fully connected layers...',\n",
    "        'title': 'Model Architecture',\n",
    "        'appendix': False,\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'section_in_paper_id': 3\n",
    "    },\n",
    "    {\n",
    "        'content': 'In this section we describe the training regime for our models...',\n",
    "        'title': 'Training',\n",
    "        'appendix': False,\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'section_in_paper_id': 4\n",
    "    },\n",
    "    {\n",
    "        'content': 'On the WMT 2014 English-to-German translation task, the big transformer model outperforms the best previously reported models...',\n",
    "        'title': 'Results',\n",
    "        'appendix': False,\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'section_in_paper_id': 5\n",
    "    },\n",
    "    {\n",
    "        'content': 'In this work, we presented the Transformer, the first sequence transduction model based entirely on attention, replacing the recurrent layers...',\n",
    "        'title': 'Conclusion',\n",
    "        'appendix': False,\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'section_in_paper_id': 6\n",
    "    }\n",
    "]\n",
    "\n",
    "for section in sections:\n",
    "    research_arcade.insert_node(\"arxiv_sections\", node_features=section)\n",
    "    print(f\"Inserted section: {section['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-sections-get-all",
   "metadata": {},
   "source": [
    "### Get All Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "get-all-sections",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sections:     id                                            content               title  \\\n",
      "0    1  The dominant sequence transduction models are ...        Introduction   \n",
      "1    2  The goal of reducing sequential computation al...          Background   \n",
      "2    3  The Transformer follows this overall architect...  Model Architecture   \n",
      "3    4  We trained on the standard WMT 2014 English-Ge...            Training   \n",
      "4    5  In this work we presented the Transformer, the...          Conclusion   \n",
      "5    6  We introduce a new language representation mod...        Introduction   \n",
      "6    7  Unlike recent language representation models, ...        Related Work   \n",
      "7    8  BERT uses a multi-layer bidirectional Transfor...  Model Architecture   \n",
      "8    9  The dominant sequence transduction models are ...        Introduction   \n",
      "9   10  The goal of reducing sequential computation al...          Background   \n",
      "10  11  The Transformer follows this overall architect...  Model Architecture   \n",
      "11  12  We trained on the standard WMT 2014 English-Ge...            Training   \n",
      "12  13  In this work we presented the Transformer, the...          Conclusion   \n",
      "13  14  We introduce a new language representation mod...        Introduction   \n",
      "14  15  Unlike recent language representation models, ...        Related Work   \n",
      "15  16  BERT uses a multi-layer bidirectional Transfor...  Model Architecture   \n",
      "16  17  The dominant sequence transduction models are ...        Introduction   \n",
      "17  18  Most competitive neural sequence transduction ...          Background   \n",
      "18  19  Most neural sequence transduction models have ...  Model Architecture   \n",
      "19  20  In this section we describe the training regim...            Training   \n",
      "20  21  On the WMT 2014 English-to-German translation ...             Results   \n",
      "21  22  In this work, we presented the Transformer, th...          Conclusion   \n",
      "22  23  \\n\\label{sec:intro}\\nIn recent years there has...        Introduction   \n",
      "23  24  \\n\\nOur work builds upon a rich line of recent...        Related Work   \n",
      "24  25  \\n\\label{sec:proposed}\\n\\nThe key idea of \\nam...     Proposed Method   \n",
      "25  26  \\n\\label{sec:ex}\\n\\nWe evaluate the benefits o...         Experiments   \n",
      "26  27  \\n\\nWe introduced a differentiable pooling met...          Conclusion   \n",
      "27  28  \\nThis research has been supported in part by ...     Acknowledgement   \n",
      "28  29  The dominant sequence transduction models are ...        Introduction   \n",
      "29  30  The goal of reducing sequential computation al...          Background   \n",
      "30  31  The Transformer follows this overall architect...  Model Architecture   \n",
      "31  32  We trained on the standard WMT 2014 English-Ge...            Training   \n",
      "32  33  In this work we presented the Transformer, the...          Conclusion   \n",
      "33  34  We introduce a new language representation mod...        Introduction   \n",
      "34  35  Unlike recent language representation models, ...        Related Work   \n",
      "35  36  BERT uses a multi-layer bidirectional Transfor...  Model Architecture   \n",
      "36  37  The dominant sequence transduction models are ...        Introduction   \n",
      "37  38  The goal of reducing sequential computation al...          Background   \n",
      "38  39  The Transformer follows this overall architect...  Model Architecture   \n",
      "39  40  We trained on the standard WMT 2014 English-Ge...            Training   \n",
      "40  41  In this work we presented the Transformer, the...          Conclusion   \n",
      "41  42  We introduce a new language representation mod...        Introduction   \n",
      "42  43  Unlike recent language representation models, ...        Related Work   \n",
      "43  44  BERT uses a multi-layer bidirectional Transfor...  Model Architecture   \n",
      "44  45  The dominant sequence transduction models are ...        Introduction   \n",
      "45  46  Most competitive neural sequence transduction ...          Background   \n",
      "46  47  Most neural sequence transduction models have ...  Model Architecture   \n",
      "47  48  In this section we describe the training regim...            Training   \n",
      "48  49  On the WMT 2014 English-to-German translation ...             Results   \n",
      "49  50  In this work, we presented the Transformer, th...          Conclusion   \n",
      "\n",
      "    appendix paper_arxiv_id  section_in_paper_id  \n",
      "0      False   1706.03762v7                  1.0  \n",
      "1      False   1706.03762v7                  2.0  \n",
      "2      False   1706.03762v7                  3.0  \n",
      "3      False   1706.03762v7                  4.0  \n",
      "4      False   1706.03762v7                  5.0  \n",
      "5      False   1810.04805v2                  1.0  \n",
      "6      False   1810.04805v2                  2.0  \n",
      "7      False   1810.04805v2                  3.0  \n",
      "8      False   1706.03762v7                  1.0  \n",
      "9      False   1706.03762v7                  2.0  \n",
      "10     False   1706.03762v7                  3.0  \n",
      "11     False   1706.03762v7                  4.0  \n",
      "12     False   1706.03762v7                  5.0  \n",
      "13     False   1810.04805v2                  1.0  \n",
      "14     False   1810.04805v2                  2.0  \n",
      "15     False   1810.04805v2                  3.0  \n",
      "16     False   1706.03762v7                  1.0  \n",
      "17     False   1706.03762v7                  2.0  \n",
      "18     False   1706.03762v7                  3.0  \n",
      "19     False   1706.03762v7                  4.0  \n",
      "20     False   1706.03762v7                  5.0  \n",
      "21     False   1706.03762v7                  6.0  \n",
      "22     False   1806.08804v4                  1.0  \n",
      "23     False   1806.08804v4                  2.0  \n",
      "24     False   1806.08804v4                  3.0  \n",
      "25     False   1806.08804v4                  4.0  \n",
      "26     False   1806.08804v4                  5.0  \n",
      "27     False   1806.08804v4                  6.0  \n",
      "28     False   1706.03762v7                  1.0  \n",
      "29     False   1706.03762v7                  2.0  \n",
      "30     False   1706.03762v7                  3.0  \n",
      "31     False   1706.03762v7                  4.0  \n",
      "32     False   1706.03762v7                  5.0  \n",
      "33     False   1810.04805v2                  1.0  \n",
      "34     False   1810.04805v2                  2.0  \n",
      "35     False   1810.04805v2                  3.0  \n",
      "36     False   1706.03762v7                  1.0  \n",
      "37     False   1706.03762v7                  2.0  \n",
      "38     False   1706.03762v7                  3.0  \n",
      "39     False   1706.03762v7                  4.0  \n",
      "40     False   1706.03762v7                  5.0  \n",
      "41     False   1810.04805v2                  1.0  \n",
      "42     False   1810.04805v2                  2.0  \n",
      "43     False   1810.04805v2                  3.0  \n",
      "44     False   1706.03762v7                  1.0  \n",
      "45     False   1706.03762v7                  2.0  \n",
      "46     False   1706.03762v7                  3.0  \n",
      "47     False   1706.03762v7                  4.0  \n",
      "48     False   1706.03762v7                  5.0  \n",
      "49     False   1706.03762v7                  6.0  \n",
      "\n",
      "All sections:\n",
      "                 title  section_in_paper_id  appendix\n",
      "0         Introduction                  1.0     False\n",
      "1           Background                  2.0     False\n",
      "2   Model Architecture                  3.0     False\n",
      "3             Training                  4.0     False\n",
      "4           Conclusion                  5.0     False\n",
      "5         Introduction                  1.0     False\n",
      "6         Related Work                  2.0     False\n",
      "7   Model Architecture                  3.0     False\n",
      "8         Introduction                  1.0     False\n",
      "9           Background                  2.0     False\n",
      "10  Model Architecture                  3.0     False\n",
      "11            Training                  4.0     False\n",
      "12          Conclusion                  5.0     False\n",
      "13        Introduction                  1.0     False\n",
      "14        Related Work                  2.0     False\n",
      "15  Model Architecture                  3.0     False\n",
      "16        Introduction                  1.0     False\n",
      "17          Background                  2.0     False\n",
      "18  Model Architecture                  3.0     False\n",
      "19            Training                  4.0     False\n",
      "20             Results                  5.0     False\n",
      "21          Conclusion                  6.0     False\n",
      "22        Introduction                  1.0     False\n",
      "23        Related Work                  2.0     False\n",
      "24     Proposed Method                  3.0     False\n",
      "25         Experiments                  4.0     False\n",
      "26          Conclusion                  5.0     False\n",
      "27     Acknowledgement                  6.0     False\n",
      "28        Introduction                  1.0     False\n",
      "29          Background                  2.0     False\n",
      "30  Model Architecture                  3.0     False\n",
      "31            Training                  4.0     False\n",
      "32          Conclusion                  5.0     False\n",
      "33        Introduction                  1.0     False\n",
      "34        Related Work                  2.0     False\n",
      "35  Model Architecture                  3.0     False\n",
      "36        Introduction                  1.0     False\n",
      "37          Background                  2.0     False\n",
      "38  Model Architecture                  3.0     False\n",
      "39            Training                  4.0     False\n",
      "40          Conclusion                  5.0     False\n",
      "41        Introduction                  1.0     False\n",
      "42        Related Work                  2.0     False\n",
      "43  Model Architecture                  3.0     False\n",
      "44        Introduction                  1.0     False\n",
      "45          Background                  2.0     False\n",
      "46  Model Architecture                  3.0     False\n",
      "47            Training                  4.0     False\n",
      "48             Results                  5.0     False\n",
      "49          Conclusion                  6.0     False\n"
     ]
    }
   ],
   "source": [
    "sections_df = research_arcade.get_all_node_features(\"arxiv_sections\")\n",
    "print(f\"Total sections: {sections_df}\")\n",
    "print(\"\\nAll sections:\")\n",
    "print(sections_df[['title', 'section_in_paper_id', 'appendix']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-paragraphs-section",
   "metadata": {},
   "source": [
    "## 9. ArXiv Paragraphs <a name=\"arxiv-paragraphs\"></a>\n",
    "\n",
    "### Table Schema\n",
    "- `id` (SERIAL PK)\n",
    "- `paragraph_id` (INT)\n",
    "- `content` (TEXT)\n",
    "- `paper_arxiv_id` (VARCHAR FK → papers.arxiv_id)\n",
    "- `paper_section` (TEXT)\n",
    "- `section_id` (INT)\n",
    "- `paragraph_in_paper_id` (INT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3fd1cc",
   "metadata": {},
   "source": [
    "### Insert From API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "480dabdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: ['1903.03894v4']\n",
      "BFS_que.qsize(): 1\n",
      "current paper: 1903.03894v4\n",
      "Thread 13079867392 Processing 1903.03894v4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x 000abstract.tex\n",
      "x 010intro.tex\n",
      "x 020related.tex\n",
      "x 030background.tex\n",
      "x 030formulation.tex\n",
      "x 030proposed.tex\n",
      "x 040experiments.tex\n",
      "x 050conclusion.tex\n",
      "x 060supplement.tex\n",
      "x acmart.bib\n",
      "x acmart.cls\n",
      "x acmart.dtx\n",
      "x acmart.ins\n",
      "x ACM-Reference-Format.bbx\n",
      "x ACM-Reference-Format.bst\n",
      "x ACM-Reference-Format.cbx\n",
      "x ACM-Reference-Format.dbx\n",
      "x figs/\n",
      "x figs/explainer-introduction_v2.pdf\n",
      "x figs/explainer-motivation.pdf\n",
      "x figs/explainer.pdf\n",
      "x figs/feature_importance_v2.pdf\n",
      "x figs/fig3-graph-cls-v2.pdf\n",
      "x figs/fig3-graph-cls.pdf\n",
      "x figs/fig3-node-cls-v3.pdf\n",
      "x figs/fig3-node-cls.pdf\n",
      "x figs/fig3-v4.pdf\n",
      "x figs/fig3-v5.pdf\n",
      "x figs/including-node-features.pdf\n",
      "x figs/local_subgraph.png\n",
      "x figs/motivation-node-features.pdf\n",
      "x figs/prototype.png\n",
      "x figs/prototype1.png\n",
      "x figs/single-instance-explanation-final.pdf\n",
      "x figs/single-instance-explanation2.pdf\n",
      "x figs/single-instance-explanations.pdf: truncated gzip input\n",
      "tar: Error exit delayed from previous errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread 13079867392 Finished processing 1903.03894v4 (1/999999999) Time elapsed: 0.65s\n",
      "'NoneType' object is not subscriptable\n",
      "Thread 13079867392 Failed to process 1903.03894v4\n",
      "Thread 8614781504 Finished processing 1 papers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 922.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading ./download/output/1903.03894v4.json: [Errno 2] No such file or directory: './download/output/1903.03894v4.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 281.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading ./download/output/1903.03894v4.json: [Errno 2] No such file or directory: './download/output/1903.03894v4.json'\n",
      "1806.08804v4\n",
      "Key to References: {'fig:assignment_vis': 'figures_3', 'tab:results': 'table_4', 'tab:results2': 'table_5'}\n",
      "tab:results\n",
      "tab:results2\n",
      "Paper count:  1\n",
      "Total nodes:  113\n",
      "Total edges:  210\n",
      "Paper nodes:  1\n",
      "Figure nodes:  0\n",
      "Table nodes:  2\n",
      "Text nodes:  110\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\"arxiv_ids\": [\"1903.03894v4\", \"1806.08804v4\"], \"dest_dir\": \"./download\"}\n",
    "research_arcade.construct_table_from_api(\"arxiv_paragraphs\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Table from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new paragraphs to import (all paragraphs already exist)\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"./examples/csv_data/csv_arxiv_paragraphs_example.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"arxiv_paragraphs\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Table from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new paragraphs to import (all paragraphs already exist)\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"./examples/json_data/json_arxiv_paragraphs_example.json\"}\n",
    "research_arcade.construct_table_from_json(\"arxiv_paragraphs\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-paragraphs-insert",
   "metadata": {},
   "source": [
    "### Insert Paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "insert-paragraphs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted paragraph 1 from Introduction\n",
      "Inserted paragraph 2 from Introduction\n",
      "Inserted paragraph 3 from Introduction\n",
      "Inserted paragraph 4 from Introduction\n",
      "Inserted paragraph 5 from Introduction\n"
     ]
    }
   ],
   "source": [
    "# Insert paragraphs from the Introduction section\n",
    "paragraphs = [\n",
    "    {\n",
    "        'paragraph_id': 1,\n",
    "        'content': 'Recurrent neural networks, long short-term memory and gated recurrent neural networks in particular, have been firmly established as state of the art approaches in sequence modeling and transduction problems such as language modeling and machine translation.',\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'paper_section': 'Introduction',\n",
    "        'section_id': 1,\n",
    "        'paragraph_in_paper_id': 1\n",
    "    },\n",
    "    {\n",
    "        'paragraph_id': 2,\n",
    "        'content': 'Numerous efforts have since continued to push the boundaries of recurrent language models and encoder-decoder architectures. Recurrent models typically factor computation along the symbol positions of the input and output sequences.',\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'paper_section': 'Introduction',\n",
    "        'section_id': 1,\n",
    "        'paragraph_in_paper_id': 2\n",
    "    },\n",
    "    {\n",
    "        'paragraph_id': 3,\n",
    "        'content': 'Aligning the positions to steps in computation time, they generate a sequence of hidden states h_t, as a function of the previous hidden state h_{t-1} and the input for position t. This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples.',\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'paper_section': 'Introduction',\n",
    "        'section_id': 1,\n",
    "        'paragraph_in_paper_id': 3\n",
    "    },\n",
    "    {\n",
    "        'paragraph_id': 4,\n",
    "        'content': 'Attention mechanisms have become an integral part of compelling sequence modeling and transduction models in various tasks, allowing modeling of dependencies without regard to their distance in the input or output sequences.',\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'paper_section': 'Introduction',\n",
    "        'section_id': 1,\n",
    "        'paragraph_in_paper_id': 4\n",
    "    },\n",
    "    {\n",
    "        'paragraph_id': 5,\n",
    "        'content': 'In this work we propose the Transformer, a model architecture eschewing recurrence and instead relying entirely on an attention mechanism to draw global dependencies between input and output. The Transformer allows for significantly more parallelization and can reach a new state of the art in translation quality after being trained for as little as twelve hours on eight P100 GPUs.',\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'paper_section': 'Introduction',\n",
    "        'section_id': 1,\n",
    "        'paragraph_in_paper_id': 5\n",
    "    }\n",
    "]\n",
    "\n",
    "for paragraph in paragraphs:\n",
    "    research_arcade.insert_node(\"arxiv_paragraphs\", node_features=paragraph)\n",
    "    print(f\"Inserted paragraph {paragraph['paragraph_id']} from {paragraph['paper_section']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-paragraphs-get-all",
   "metadata": {},
   "source": [
    "### Get All Paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "get-all-paragraphs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total paragraphs: 123\n",
      "\n",
      "First 3 paragraphs:\n",
      "   paragraph_id paper_section  \\\n",
      "0             0  Introduction   \n",
      "1             1  Introduction   \n",
      "2             2  Introduction   \n",
      "\n",
      "                                             content  \n",
      "0  \\label{sec:intro}\\nIn recent years there has b...  \n",
      "1  However, a major limitation of current GNN arc...  \n",
      "2  Here we propose \\name, a differentiable graph ...  \n"
     ]
    }
   ],
   "source": [
    "paragraphs_df = research_arcade.get_all_node_features(\"arxiv_paragraphs\")\n",
    "print(f\"Total paragraphs: {len(paragraphs_df)}\")\n",
    "print(\"\\nFirst 3 paragraphs:\")\n",
    "print(paragraphs_df[['paragraph_id', 'paper_section', 'content']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Relationships/Edges <a name=\"relationships\"></a>\n",
    "\n",
    "This section demonstrates how to create and manage relationships between different entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 ArXiv Citations (arxiv_citation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert Citation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citation created!\n"
     ]
    }
   ],
   "source": [
    "citation = {\n",
    "    'citing_arxiv_id': '1810.04805v2',\n",
    "    'cited_arxiv_id': '1706.03762v7',\n",
    "    'bib_title': 'attention is all you need',\n",
    "    'bib_key': 'something',\n",
    "    'citing_sections': 'citing_sections',\n",
    "}\n",
    "research_arcade.insert_edge(\"arxiv_citation\", edge_features=citation)\n",
    "print(\"Citation created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Table from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new citations to import (all citations already exist)\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"./examples/csv_data/csv_arxiv_paper_citation_example.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"arxiv_paper_citation\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Table from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new citations to import (all citations already exist)\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"./examples/json_data/json_arxiv_paper_citation_example.json\"}\n",
    "research_arcade.construct_table_from_json(\"arxiv_paper_citation\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get All Citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total citations: 8\n",
      "   id citing_arxiv_id cited_arxiv_id  \\\n",
      "0   2    1706.03762v7    1409.0473v7   \n",
      "1   3    1706.03762v7   1508.04025v5   \n",
      "2   5    1810.04805v2   1802.05365v2   \n",
      "3   6    2010.11929v2   1706.03762v7   \n",
      "4   7    2010.11929v2   1810.04805v2   \n",
      "\n",
      "                                           bib_title               bib_key  \\\n",
      "0  Neural Machine Translation by Jointly Learning...    bahdanau2014neural   \n",
      "1  Effective Approaches to Attention-based Neural...    luong2015effective   \n",
      "2           Deep contextualized word representations        peters2018deep   \n",
      "3                          Attention Is All You Need  vaswani2017attention   \n",
      "4  BERT: Pre-training of Deep Bidirectional Trans...        devlin2018bert   \n",
      "\n",
      "                    citing_sections citing_paragraphs  \n",
      "0  [\"introduction\", \"related_work\"]                []  \n",
      "1                  [\"related_work\"]                []  \n",
      "2                  [\"related_work\"]                []  \n",
      "3         [\"introduction\", \"model\"]                []  \n",
      "4                  [\"related_work\"]                []  \n"
     ]
    }
   ],
   "source": [
    "all_citations = research_arcade.get_all_edge_features(\"arxiv_citation\")\n",
    "print(f\"Total citations: {len(all_citations)}\")\n",
    "print(all_citations.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Cited Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers cited:\n",
      "   id citing_arxiv_id cited_arxiv_id  \\\n",
      "2   5    1810.04805v2   1802.05365v2   \n",
      "7  10    1810.04805v2   1706.03762v7   \n",
      "\n",
      "                                  bib_title         bib_key  \\\n",
      "2  Deep contextualized word representations  peters2018deep   \n",
      "7                 attention is all you need       something   \n",
      "\n",
      "     citing_sections citing_paragraphs  \n",
      "2   [\"related_work\"]                []  \n",
      "7  \"citing_sections\"                []  \n"
     ]
    }
   ],
   "source": [
    "citing_paper = {'citing_paper_id': '1810.04805v2'}\n",
    "cited_papers = research_arcade.get_neighborhood(\"arxiv_citation\", primary_key=citing_paper)\n",
    "print(\"Papers cited:\")\n",
    "print(cited_papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Citing Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers that cite:\n",
      "   id citing_arxiv_id cited_arxiv_id                  bib_title  \\\n",
      "3   6    2010.11929v2   1706.03762v7  Attention Is All You Need   \n",
      "7  10    1810.04805v2   1706.03762v7  attention is all you need   \n",
      "\n",
      "                bib_key            citing_sections citing_paragraphs  \n",
      "3  vaswani2017attention  [\"introduction\", \"model\"]                []  \n",
      "7             something          \"citing_sections\"                []  \n"
     ]
    }
   ],
   "source": [
    "cited_paper = {'cited_paper_id': '1706.03762v7'}\n",
    "citing_papers = research_arcade.get_neighborhood(\"arxiv_citation\", primary_key=cited_paper)\n",
    "print(\"Papers that cite:\")\n",
    "print(citing_papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete Citation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted citation: 1810.04805v2 -> 1706.03762v7\n",
      "Citation deleted!\n"
     ]
    }
   ],
   "source": [
    "citation_id = {\n",
    "    'citing_paper_id': '1810.04805v2',\n",
    "    'cited_paper_id': '1706.03762v7'\n",
    "}\n",
    "research_arcade.delete_edge_by_id(\"arxiv_citation\", primary_key=citation_id)\n",
    "print(\"Citation deleted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 ArXiv Paper-Author (arxiv_paper_author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert Paper-Author Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linked author ss_ashish_vaswani (position 1)\n",
      "Linked author ss_noam_shazeer (position 2)\n",
      "Linked author ss_niki_parmar (position 3)\n"
     ]
    }
   ],
   "source": [
    "paper_authors = [\n",
    "    {'paper_arxiv_id': '1706.03762v7', 'author_id': 'ss_ashish_vaswani', 'author_sequence': 1},\n",
    "    {'paper_arxiv_id': '1706.03762v7', 'author_id': 'ss_noam_shazeer', 'author_sequence': 2},\n",
    "    {'paper_arxiv_id': '1706.03762v7', 'author_id': 'ss_niki_parmar', 'author_sequence': 3}\n",
    "]\n",
    "for relation in paper_authors:\n",
    "    research_arcade.insert_edge(\"arxiv_paper_author\", edge_features=relation)\n",
    "    print(f\"Linked author {relation['author_id']} (position {relation['author_sequence']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Table from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported 16 paper-author relationships from ./examples/csv_data/csv_arxiv_paper_author_example.csv\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"./examples/csv_data/csv_arxiv_paper_author_example.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"arxiv_paper_author\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Table from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new paper-author relationships to import\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"./examples/json_data/json_arxiv_paper_author_example.json\"}\n",
    "research_arcade.construct_table_from_json(\"arxiv_paper_author\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get All Paper-Author Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total relationships: 35\n",
      "  paper_arxiv_id        author_id  author_sequence\n",
      "0   1706.03762v7  ss_noam_shazeer                2\n",
      "1   1706.03762v7   ss_niki_parmar                3\n",
      "2   1706.03762v7          1234567                1\n",
      "3   1706.03762v7          2345678                2\n",
      "4   1706.03762v7          3456789                3\n",
      "5   1706.03762v7          4567890                4\n",
      "6   1706.03762v7          5678901                5\n",
      "7   1706.03762v7          6789012                6\n",
      "8   1706.03762v7          7890123                7\n",
      "9   1706.03762v7          8901234                8\n"
     ]
    }
   ],
   "source": [
    "all_relations = research_arcade.get_all_edge_features(\"arxiv_paper_author\")\n",
    "print(f\"Total relationships: {len(all_relations)}\")\n",
    "print(all_relations.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Authors for a Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authors:\n",
      "   paper_arxiv_id          author_id  author_sequence\n",
      "0    1706.03762v7            1234567                1\n",
      "1    1706.03762v7  ss_ashish_vaswani                1\n",
      "2    1706.03762v7            1234567                1\n",
      "3    1706.03762v7    ss_noam_shazeer                2\n",
      "4    1706.03762v7            2345678                2\n",
      "5    1706.03762v7            2345678                2\n",
      "6    1706.03762v7     ss_niki_parmar                3\n",
      "7    1706.03762v7            3456789                3\n",
      "8    1706.03762v7            3456789                3\n",
      "10   1706.03762v7            4567890                4\n",
      "9    1706.03762v7            4567890                4\n",
      "11   1706.03762v7            5678901                5\n",
      "12   1706.03762v7            5678901                5\n",
      "13   1706.03762v7            6789012                6\n",
      "14   1706.03762v7            6789012                6\n",
      "15   1706.03762v7            7890123                7\n",
      "16   1706.03762v7            7890123                7\n",
      "17   1706.03762v7            8901234                8\n",
      "18   1706.03762v7            8901234                8\n"
     ]
    }
   ],
   "source": [
    "paper_id = {'paper_arxiv_id': '1706.03762v7'}\n",
    "authors = research_arcade.get_neighborhood(\"arxiv_paper_author\", primary_key=paper_id)\n",
    "print(\"Authors:\")\n",
    "print(authors.sort_values('author_sequence'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Papers by Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers by author:\n",
      "  paper_arxiv_id          author_id  author_sequence\n",
      "0   1706.03762v7  ss_ashish_vaswani                1\n"
     ]
    }
   ],
   "source": [
    "author_id = {'author_id': 'ss_ashish_vaswani'}\n",
    "papers = research_arcade.get_neighborhood(\"arxiv_paper_author\", primary_key=author_id)\n",
    "print(\"Papers by author:\")\n",
    "print(papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete Paper-Author Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relationship deleted!\n"
     ]
    }
   ],
   "source": [
    "relation_id = {'paper_arxiv_id': '1706.03762v7', 'author_id': 'ss_ashish_vaswani'}\n",
    "research_arcade.delete_edge_by_id(\"arxiv_paper_author\", primary_key=relation_id)\n",
    "print(\"Relationship deleted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4 ArXiv Paper-Category (arxiv_paper_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert Paper-Category Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linked 1\n",
      "Linked 1\n",
      "Linked 2\n"
     ]
    }
   ],
   "source": [
    "paper_categories = [\n",
    "    {'paper_arxiv_id': '1706.03762v7', 'category_id': '1'},\n",
    "    {'paper_arxiv_id': '1706.03762v7', 'category_id': '1'},\n",
    "    {'paper_arxiv_id': '1706.03762v7', 'category_id': '2'}\n",
    "]\n",
    "for relation in paper_categories:\n",
    "    research_arcade.insert_edge(\"arxiv_paper_category\", edge_features=relation)\n",
    "    print(f\"Linked {relation['category_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Table from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported 1 paper-category relationships from ./examples/csv_data/csv_arxiv_paper_category_example.csv\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"./examples/csv_data/csv_arxiv_paper_category_example.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"arxiv_paper_category\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Table from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new paper-category relationships to import\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"./examples/json_data/json_arxiv_paper_category_example.json\"}\n",
    "research_arcade.construct_table_from_json(\"arxiv_paper_category\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get All Paper-Category Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total relationships: 17\n",
      "  paper_arxiv_id category_id\n",
      "0   1706.03762v7           1\n",
      "1   1706.03762v7           1\n",
      "2   1706.03762v7           2\n",
      "3   1706.03762v7       cs.CL\n",
      "4   1706.03762v7       cs.LG\n"
     ]
    }
   ],
   "source": [
    "all_relations = research_arcade.get_all_edge_features(\"arxiv_paper_category\")\n",
    "print(f\"Total relationships: {len(all_relations)}\")\n",
    "print(all_relations.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Categories for Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories:\n",
      "  paper_arxiv_id category_id\n",
      "0   1706.03762v7           1\n",
      "1   1706.03762v7           1\n",
      "2   1706.03762v7           2\n",
      "3   1706.03762v7       cs.CL\n",
      "4   1706.03762v7       cs.LG\n",
      "5   1706.03762v7       cs.AI\n"
     ]
    }
   ],
   "source": [
    "paper_id = {'paper_arxiv_id': '1706.03762v7'}\n",
    "categories = research_arcade.get_neighborhood(\"arxiv_paper_category\", primary_key=paper_id)\n",
    "print(\"Categories:\")\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Papers in Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers in category:\n",
      "  paper_arxiv_id category_id\n",
      "0   1706.03762v7       cs.LG\n",
      "1   1810.04805v2       cs.LG\n",
      "2    1409.0473v7       cs.LG\n",
      "3   1512.03385v1       cs.LG\n",
      "4   2010.11929v2       cs.LG\n"
     ]
    }
   ],
   "source": [
    "category_id = {'category_id': 'cs.LG'}\n",
    "papers = research_arcade.get_neighborhood(\"arxiv_paper_category\", primary_key=category_id)\n",
    "print(\"Papers in category:\")\n",
    "print(papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete Paper-Category Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relationship deleted!\n"
     ]
    }
   ],
   "source": [
    "relation_id = {'paper_arxiv_id': '1706.03762v7', 'category_id': 'cs.AI'}\n",
    "research_arcade.delete_edge_by_id(\"arxiv_paper_category\", primary_key=relation_id)\n",
    "print(\"Relationship deleted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.5 ArXiv Paper-Figure (arxiv_paper_figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert Paper-Figure Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linked figure 1)\n",
      "Linked figure 2)\n"
     ]
    }
   ],
   "source": [
    "paper_figures = [\n",
    "    {'paper_arxiv_id': '1706.03762v7', 'figure_id': 1},\n",
    "    {'paper_arxiv_id': '1706.03762v7', 'figure_id': 2}\n",
    "]\n",
    "for relation in paper_figures:\n",
    "    research_arcade.insert_edge(\"arxiv_paper_figure\", edge_features=relation)\n",
    "    print(f\"Linked figure {relation['figure_id']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Table from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new paper-figure relationships to import\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"./examples/csv_data/csv_arxiv_paper_figure_example.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"arxiv_paper_figure\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Table from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new paper-figure relationships to import\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"./examples/json_data/json_arxiv_paper_figure_example.json\"}\n",
    "research_arcade.construct_table_from_json(\"arxiv_paper_figure\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Figures for Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figures:\n",
      "  paper_arxiv_id  figure_id\n",
      "0   1706.03762v7          1\n",
      "1   1706.03762v7          2\n",
      "2   1706.03762v7          3\n"
     ]
    }
   ],
   "source": [
    "paper_id = {'paper_arxiv_id': '1706.03762v7'}\n",
    "figures = research_arcade.get_neighborhood(\"arxiv_paper_figure\", primary_key=paper_id)\n",
    "print(\"Figures:\")\n",
    "print(figures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.6 ArXiv Paper-Table (arxiv_paper_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert Paper-Table Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linked table 1\n",
      "Linked table 2\n"
     ]
    }
   ],
   "source": [
    "paper_tables = [\n",
    "    {'paper_arxiv_id': '1706.03762v7', 'table_id': 1},\n",
    "    {'paper_arxiv_id': '1706.03762v7', 'table_id': 2}\n",
    "]\n",
    "for relation in paper_tables:\n",
    "    research_arcade.insert_edge(\"arxiv_paper_table\", edge_features=relation)\n",
    "    print(f\"Linked table {relation['table_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Table from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new paper-table relationships to import\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"./examples/csv_data/csv_arxiv_paper_table_example.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"arxiv_paper_table\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Table from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new paper-table relationships to import\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"./examples/json_data/json_arxiv_paper_table_example.json\"}\n",
    "research_arcade.construct_table_from_json(\"arxiv_paper_table\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Tables for Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables:\n"
     ]
    }
   ],
   "source": [
    "paper_id = {'paper_arxiv_id': '1706.03762v7'}\n",
    "tables = research_arcade.get_neighborhood(\"arxiv_paper_table\", primary_key=paper_id)\n",
    "print(\"Tables:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.7 ArXiv Paragraph-Reference (arxiv_paragraph_reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert Paragraph-Reference Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_references = [\n",
    "    {'paragraph_id': 1, 'paper_section': 'established approaches', 'paper_arxiv_id': '1706.03762v7', 'reference_label': \"{something}\", 'reference_type': 'figure'}\n",
    "]\n",
    "\n",
    "for relation in paragraph_references:\n",
    "    research_arcade.insert_edge(\"arxiv_paragraph_reference\", edge_features=relation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Table from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported 10 paragraph-reference relationships from ./examples/csv_data/csv_arxiv_paragraph_reference_example.csv\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"./examples/csv_data/csv_arxiv_paragraph_reference_example.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"arxiv_paragraph_reference\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Table from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: JSON file ./examples/json_data/json_arxiv_paragraph_reference_example.json does not exist.\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"./examples/json_data/json_arxiv_paragraph_reference_example.json\"}\n",
    "research_arcade.construct_table_from_json(\"arxiv_paragraph_reference\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get References in Paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "References:\n",
      "   id  paragraph_id           paper_section paper_arxiv_id  \\\n",
      "0   1             1  established approaches   1706.03762v7   \n",
      "1   3             1            introduction   1706.03762v7   \n",
      "2   6             1              background   1706.03762v7   \n",
      "3   8             1            introduction   1810.04805v2   \n",
      "4  11             1                   model   1810.04805v2   \n",
      "5  12             1  established approaches   1706.03762v7   \n",
      "6  14             1            introduction   1706.03762v7   \n",
      "7  17             1              background   1706.03762v7   \n",
      "8  19             1            introduction   1810.04805v2   \n",
      "9  22             1                   model   1810.04805v2   \n",
      "\n",
      "      reference_label reference_type  \n",
      "0         {something}         figure  \n",
      "1  bahdanau2014neural       citation  \n",
      "2       fig:attention         figure  \n",
      "3       fig:bert_arch         figure  \n",
      "4      peters2018deep       citation  \n",
      "5         {something}         figure  \n",
      "6  bahdanau2014neural       citation  \n",
      "7       fig:attention         figure  \n",
      "8       fig:bert_arch         figure  \n",
      "9      peters2018deep       citation  \n"
     ]
    }
   ],
   "source": [
    "paragraph_id = {'paragraph_id': 1}\n",
    "references = research_arcade.get_neighborhood(\"arxiv_paragraph_reference\", primary_key=paragraph_id)\n",
    "print(\"References:\")\n",
    "print(references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This tutorial has covered:\n",
    "\n",
    "1. Setting up the ResearchArcade database connection\n",
    "2. Working with OpenReview data\n",
    "3. CRUD operations for all ArXiv entity types:\n",
    "   - Papers\n",
    "   - Authors\n",
    "   - Categories\n",
    "   - Figures\n",
    "   - Tables\n",
    "   - Sections\n",
    "   - Paragraphs\n",
    "4. Creating relationships between entities:\n",
    "   - Authorship\n",
    "   - Citations\n",
    "   - Paper-Category links\n",
    "   - Paper-Figure/Table links\n",
    "   - Paragraph-level references\n",
    "\n",
    "For more information, refer to the ResearchArcade documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_arcade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
