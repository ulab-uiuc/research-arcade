{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07027768",
   "metadata": {},
   "source": [
    "## Retrieve PDF based on openreview_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604223de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_pdf(id, pdf_name):\n",
    "    # pdf url\n",
    "    pdf_url = \"https://openreview.net/notes/edits/attachment?id=\"+id+\"&name=pdf\"\n",
    "    \n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "    response = requests.get(pdf_url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        with open(pdf_name, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(\"✅ PDF is downloaded as \"+pdf_name)\n",
    "    else:\n",
    "        print(\"❌ Failure, Status Code: \", response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df750b42",
   "metadata": {},
   "source": [
    "## Compare the Differences between two PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6f7b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "import difflib\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    return extract_text(pdf_path)\n",
    "\n",
    "def compare_texts(text1, text2):\n",
    "    diff = difflib.unified_diff(\n",
    "        text1.splitlines(),\n",
    "        text2.splitlines(),\n",
    "        fromfile='Original',\n",
    "        tofile='Modified',\n",
    "        lineterm=''\n",
    "    )\n",
    "    return '\\n'.join(diff)\n",
    "\n",
    "def parse_diff(diff_text):\n",
    "    lines = diff_text.splitlines()\n",
    "    \n",
    "    all_diff = []\n",
    "    current_diff = None\n",
    "    for line in tqdm(lines[2:]):\n",
    "        # Check for diff change markers\n",
    "        if line.startswith('@@'):\n",
    "            if current_diff is not None:\n",
    "                # Add the previous diff to the corresponding list\n",
    "                all_diff.append(current_diff)\n",
    "            # Start a new diff block\n",
    "            current_diff = {\n",
    "                'context_before': \"\",\n",
    "                'context_after': \"\",\n",
    "                'original_lines': \"\",\n",
    "                'modified_lines': \"\",\n",
    "            }\n",
    "        elif line.startswith('-'):\n",
    "            current_diff['original_lines'] = current_diff['original_lines'] + line[1:].strip() + \" \"\n",
    "        elif line.startswith('+'):\n",
    "            current_diff['modified_lines'] = current_diff['modified_lines'] + line[1:].strip() + \" \"\n",
    "        elif line.strip() != \"\" and (current_diff['original_lines'] == \"\" and current_diff['modified_lines'] == \"\"):\n",
    "            current_diff['context_before'] = current_diff['context_before'] + line.strip() + \" \"\n",
    "        elif line.strip() != \"\" and (current_diff['original_lines'] != \"\" or current_diff['modified_lines'] != \"\"):\n",
    "            current_diff['context_after'] = current_diff['context_after'] + line.strip() + \" \"\n",
    "            \n",
    "    print(\"successfully build all_diff\")\n",
    "    \n",
    "    return all_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455add89",
   "metadata": {},
   "source": [
    "#### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a15fb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_original = \"original.pdf\"\n",
    "pdf_modified = \"modified.pdf\"\n",
    "\n",
    "# extract text\n",
    "original = extract_text_from_pdf(pdf_original)\n",
    "modified = extract_text_from_pdf(pdf_modified)\n",
    "\n",
    "# compare the differences\n",
    "diff_result = compare_texts(original, modified)\n",
    "\n",
    "# format the differences into dict\n",
    "all_diff_dict = parse_diff(diff_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2804d910",
   "metadata": {},
   "source": [
    "## Extract Figure from a PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95efdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pikepdf\n",
    "from pathlib import Path\n",
    "\n",
    "def find_items_with_prefix(obj, prefix):\n",
    "    results = []\n",
    "    try:\n",
    "        for k in obj:\n",
    "            key_str = str(k)\n",
    "            if key_str.startswith(prefix):\n",
    "                results.append((k, obj[k]))\n",
    "            results.extend(find_items_with_prefix(obj[k], prefix))\n",
    "    except:\n",
    "        pass\n",
    "    return results\n",
    "\n",
    "def extract_figures_from_pdf(page: pikepdf.Page, prefix_name: str, out_pdf_prefix: str = \"page_1_figure\"):\n",
    "    # 1) Grab the all the image item\n",
    "    xobjs = page.Resources.get(\"/XObject\", {})\n",
    "    all_form = find_items_with_prefix(xobjs, prefix_name)\n",
    "    \n",
    "    cnt = 0\n",
    "    for xobj_name, xobj_form in all_form:\n",
    "        cnt = cnt + 1\n",
    "        # 2) Create a new PDF\n",
    "        new_pdf = pikepdf.Pdf.new()\n",
    "        \n",
    "        # 3) Copy the form (and its dependencies) into new_pdf\n",
    "        form_copy = new_pdf.copy_foreign(xobj_form)\n",
    "        \n",
    "        # 4) Clone the page (to preserve MediaBox, etc.), then overwrite its Resources/Contents\n",
    "        new_pdf.pages.append(page)\n",
    "        new_page = new_pdf.pages[0]\n",
    "        \n",
    "        new_page.Resources = pikepdf.Dictionary({\n",
    "            \"/XObject\": pikepdf.Dictionary({ xobj_name: form_copy })\n",
    "        })\n",
    "        # 5) Save\n",
    "        draw_cmd = b\"q\\n1 0 0 1 0 0 cm \" + xobj_name.encode(\"utf-8\") + b\" Do\\nQ\"\n",
    "        content_stream = pikepdf.Stream(new_pdf, draw_cmd)\n",
    "        new_page.Contents = new_pdf.make_indirect(content_stream)\n",
    "        \n",
    "        output_pdf_path = Path(str(out_pdf_prefix)+\"_\"+str(cnt)+\".pdf\")\n",
    "        new_pdf.save(output_pdf_path)\n",
    "        print(\"Wrapped PDF written to\", output_pdf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7387e744",
   "metadata": {},
   "source": [
    "#### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642493d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_pdf_path = Path(\"paper.pdf\")\n",
    "\n",
    "src = pikepdf.Pdf.open(str(src_pdf_path))\n",
    "\n",
    "# save the image in each page into a pdf\n",
    "cnt = 0\n",
    "for page in src.pages:\n",
    "    cnt = cnt + 1\n",
    "    out_pdf_prefix = \"original_page_\"+str(cnt)+\"_figure\"\n",
    "    extract_figures_from_pdf(\n",
    "        page=page,\n",
    "        prefix_name=\"/Im\",\n",
    "        out_pdf_prefix=out_pdf_prefix\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f809bca",
   "metadata": {},
   "source": [
    "## Extract Paragraphs from a PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1831032",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "def check_str_regex(s: str) -> bool: # no more than 3 digits or at least 15 characters\n",
    "    has_3_digits = bool(re.search(r'(?:.*\\d){3,}', s))\n",
    "    letter_count = len(re.findall(r'[A-Za-z]', s))\n",
    "    return has_3_digits and (letter_count < 15)\n",
    "\n",
    "def extract_paragraphs_from_pdf(pdf_path: Path, up_form: str, output_json_file: Path):\n",
    "    # extract all the text from pdf\n",
    "    full_text = extract_text(pdf_path)\n",
    "    \n",
    "    # split the text into lines\n",
    "    lines = full_text.splitlines()\n",
    "    \n",
    "    # construct paragraphs based on the empty lines\n",
    "    formatted_lines = []\n",
    "    buffer = []\n",
    "    for line in lines:\n",
    "        if line.strip():          # Non-empty -> the same paragraph\n",
    "            if line[-1] == '-':\n",
    "                buffer.append(line[:-1])\n",
    "            else:\n",
    "                buffer.append(line)\n",
    "        else:                     # Empty -> Next paragraph\n",
    "            if buffer:            # Combine the content in buffer\n",
    "                formatted_lines.append(\"\".join(buffer))\n",
    "                buffer = []       # Clean buffer\n",
    "    if buffer:\n",
    "        formatted_lines.append(\"\".join(buffer))\n",
    "    \n",
    "    # only extract paragraphs between abstract and appendix\n",
    "    start = 0\n",
    "    try:\n",
    "        start = formatted_lines.index(\"Abstract\")\n",
    "    except:\n",
    "        try:\n",
    "            start = formatted_lines.index(\"ABSTRACT\")\n",
    "        except:\n",
    "            print(\"can not find abstract\")\n",
    "    end = len(formatted_lines)\n",
    "    try:\n",
    "        end = formatted_lines.index(\"Appendix\")\n",
    "    except:\n",
    "        try:\n",
    "            end = formatted_lines.index(\"APPENDIX\")\n",
    "        except:\n",
    "            print(\"can not find appendix\")\n",
    "\n",
    "    # the structured content and insert the title\n",
    "    structured_content = {\n",
    "        \"Title\": formatted_lines[1],\n",
    "    }\n",
    "    \n",
    "    # start constructing the structured content\n",
    "    before_context = \"\"\n",
    "    current_chapter = 0\n",
    "    current_sub_chapter = 0\n",
    "    current_section = \"\"\n",
    "    is_across_page = False\n",
    "    current_image_table = []\n",
    "    is_across_page = False\n",
    "    is_chapter = False\n",
    "    for line in formatted_lines[start:end]:\n",
    "        if check_str_regex(line): # no more than 3 digits or at least 15 characters\n",
    "            continue\n",
    "        \n",
    "        # before_context add into formatted context\n",
    "        if up_form in before_context:\n",
    "            pass\n",
    "        elif is_chapter:\n",
    "            is_chapter = False\n",
    "        elif before_context.isdigit() and len(line) > 20: # page changed\n",
    "            is_across_page = True\n",
    "        elif len(before_context) > 1 and before_context[0].isdigit() and before_context[1] != \".\":\n",
    "            pass\n",
    "        elif before_context.startswith(\"Figure\") or before_context.startswith(\"Table\"):\n",
    "            current_image_table.append(before_context)\n",
    "        elif before_context != \"\":\n",
    "            if len(structured_content[current_section]) == 0:\n",
    "                char_end = \".\"\n",
    "            else:\n",
    "                char_end = structured_content[current_section][-1][-1]\n",
    "            if not before_context.isdigit() and before_context != \"\": # get rid of pure digit\n",
    "                if char_end == \".\" and not (before_context[0].isdigit() and before_context[1] == \".\") and not before_context[0] == \"•\" and not before_context[0] == \"(\" and not before_context[0] == \")\": # combine itemize and enumerate into one paragraph\n",
    "                    structured_content[current_section].append(before_context)\n",
    "                else:\n",
    "                    structured_content[current_section][-1] = structured_content[current_section][-1] + \" \" + before_context\n",
    "            if char_end == \".\" and len(current_image_table) != 0: # insert the figure or table only when the paragraph is finished\n",
    "                structured_content[current_section].extend(current_image_table)\n",
    "                current_image_table = []\n",
    "        \n",
    "        # abstract\n",
    "        if line == \"Abstract\" or line == \"ABSTRACT\":\n",
    "            is_chapter = True\n",
    "            current_section = \"Abstract\"\n",
    "            structured_content[current_section] = []\n",
    "        # reference\n",
    "        if line == \"REFERENCES\" or line == \"References\":\n",
    "            is_chapter = True\n",
    "            current_section = \"References\"\n",
    "            structured_content[current_section] = []\n",
    "        # chapter\n",
    "        if before_context.isdigit() and len(line) <= 20:\n",
    "            is_chapter = True\n",
    "            current_section = before_context+\" \"+line\n",
    "            structured_content[current_section] = []\n",
    "            current_chapter = current_chapter + 1\n",
    "            current_sub_chapter = 0\n",
    "        if not line.isdigit() and line[0].isdigit() and line[1] == \" \":\n",
    "            is_chapter = True\n",
    "            current_section = line\n",
    "            structured_content[current_section] = []\n",
    "            current_chapter = current_chapter + 1\n",
    "            current_sub_chapter = 0\n",
    "        # sub-chapter\n",
    "        if not line.isdigit() and line[0] == str(current_chapter) and line[1] == \".\" and line[2] == str(current_sub_chapter+1):\n",
    "            is_chapter = True\n",
    "            current_section = line\n",
    "            structured_content[current_section] = []\n",
    "            current_sub_chapter = current_sub_chapter + 1\n",
    "\n",
    "        # combine the paragraph across two pages\n",
    "        if is_across_page:\n",
    "            before_context = before_context + \" \" + line\n",
    "            is_across_page = False\n",
    "        else:\n",
    "            before_context = line\n",
    "    \n",
    "    # output the structured content as json\n",
    "    with open(output_json_file, 'w') as json_file:\n",
    "        json.dump(structured_content, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5d3cd6",
   "metadata": {},
   "source": [
    "#### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0febfb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"original.pdf\"\n",
    "up_form = \"Under review as a conference paper at ICLR 2025\"\n",
    "output_json_file = 'data_original.json'\n",
    "\n",
    "extract_paragraphs_from_pdf(pdf_path, up_form, output_json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9424549",
   "metadata": {},
   "source": [
    "## Extract Tables from a PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7f7ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabula\n",
    "from pathlib import Path\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def extract_table_from_pdf(pdf_path: Path, output_csv_name: str):\n",
    "    # get the number of pages\n",
    "    pdf_reader = PdfReader(pdf_path)\n",
    "    num_page = len(pdf_reader.pages)\n",
    "    \n",
    "    # go through all pages\n",
    "    table_idx = 0\n",
    "    for page_idx in range(num_page):\n",
    "        page_idx = page_idx + 1\n",
    "        # read tables into a list\n",
    "        dfs = tabula.read_pdf(pdf_path, \n",
    "                     pages=str(page_idx), \n",
    "                     multiple_tables=True)\n",
    "        # save table into csv\n",
    "        for _, df in enumerate(dfs, start=1):\n",
    "            print(\"Page \"+str(page_idx)+\" Table \"+str(table_idx))\n",
    "            df.to_csv(f\"{output_csv_name}_{page_idx}_{table_idx}.csv\", index=False)\n",
    "            table_idx = table_idx + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445c9b6d",
   "metadata": {},
   "source": [
    "#### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b941ebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"paper.pdf\"\n",
    "output_csv_name = \"paper_table\"\n",
    "extract_table_from_pdf(pdf_path, output_csv_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openreview",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
