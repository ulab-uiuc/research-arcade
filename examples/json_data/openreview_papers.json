[
  {
    "venue": "ICLR.cc/2025/Conference",
    "paper_openreview_id": "vdUYa7N8Mt",
    "title": "The Rate-Distortion-Perception Trade-Off with Algorithmic Realism",
    "abstract": "Realism constraints (or constraints on perceptual quality) have received considerable recent attention within the context of lossy compression, particularly of images. Theoretical studies of lossy compression indicate that high-rate common randomness between the compressor and the decompressor is a valuable resource for achieving realism. On the other hand, the utility of significant amounts of common randomness at test time has not been noted in practice. We offer an explanation for this discrepancy by considering a realism constraint that requires satisfying a universal critic that inspects realizations of individual compressed images, or batches thereof. We characterize the optimal rate-distortion-perception trade-off under such a realism constraint, and show that it is asymptotically achievable without any common randomness, unless the batch size is impractically large.",
    "paper_decision": "Rejected_Submission",
    "paper_pdf_link": "/pdf/df5f78f3432f64cbaed51951fa2c15e246aaeee4.pdf"
  },
  {
    "venue": "ICLR.cc/2025/Conference",
    "paper_openreview_id": "PwxYoMvmvy",
    "title": "Beyond Random Masking: When Dropout meets Graph Convolutional Networks",
    "abstract": "Graph Convolutional Networks (GCNs) have emerged as powerful tools for learning on graph-structured data, yet the behavior of dropout in these models remains poorly understood. This paper presents a comprehensive theoretical analysis of dropout in GCNs, revealing that its primary role differs fundamentally from standard neural networks - preventing oversmoothing rather than co-adaptation. We demonstrate that dropout in GCNs creates dimension-specific stochastic sub-graphs, leading to a form of structural regularization not present in standard neural networks. Our analysis shows that dropout effects are inherently degree-dependent, resulting in adaptive regularization that considers the topological importance of nodes. We provide new insights into dropout's role in mitigating oversmoothing and derive novel generalization bounds that account for graph-specific dropout effects. Furthermore, we analyze the synergistic interaction between dropout and batch normalization in GCNs, uncovering a mechanism that enhances overall regularization. Our theoretical findings are validated through extensive experiments on both node-level and graph-level tasks across 14 datasets. Notably, GCN with dropout and batch normalization outperforms state-of-the-art methods on several benchmarks, demonstrating the practical impact of our theoretical insights.",
    "paper_decision": "ICLR 2025 Poster",
    "paper_pdf_link": "/pdf/2630e5206aeeb0a02cc48e38f5890bb07d7b7f77.pdf"
  },
  {
    "venue": "ICLR.cc/2025/Conference",
    "paper_openreview_id": "YaRzuMaubS",
    "title": "Defining Deception in Decision Making",
    "abstract": "With the growing capabilities of machine learning systems, particularly those that interact with humans, there is an increased risk of systems that can easily deceive and manipulate people. Preventing unintended behaviors therefore represents an important challenge for creating aligned AI systems. To approach this challenge in a principled way, we first need to define deception formally. In this work, we present a concrete definition of deception under the formalism of rational decision making in partially observed Markov decision processes. Specifically, we propose a general regret theory of deception under which the degree of deception can be quantified in terms of the actor's beliefs, actions, and utility. To evaluate our definition, we study the degree to which our definition aligns with human judgments about deception. We hope that our work will constitute a step toward both systems that aim to avoid deception, and detection mechanisms to identify deceptive agents.",
    "paper_decision": "Rejected_Submission",
    "paper_pdf_link": "/pdf/e30923c81d69302a4b47a0821e184e52b4d6d294.pdf"
  },
  {
    "venue": "ICLR.cc/2025/Conference",
    "paper_openreview_id": "ONfWFluZBI",
    "title": "Self-supervised contrastive learning performs non-linear system identification",
    "abstract": "Self-supervised learning (SSL) approaches have brought tremendous success across many tasks and domains. It has been argued that these successes can be attributed to a link between SSL and identifiable representation learning: Temporal structure and auxiliary variables ensure that latent representations are related to the true underlying generative factors of the data. Here, we deepen this connection and show that SSL can perform system identification in latent space. We propose dynamics contrastive learning, a framework to uncover linear, switching linear and non-linear dynamics under a non-linear observation model, give theoretical guarantees and validate them empirically.",
    "paper_decision": "ICLR 2025 Poster",
    "paper_pdf_link": "/pdf/a0e89f340d21f75df21f82b519f7eafed7b8ea88.pdf"
  },
  {
    "venue": "ICLR.cc/2025/Conference",
    "paper_openreview_id": "0vtftmYQGV",
    "title": "SNAP-TTA: Sparse Test-Time Adaptation for Latency-Sensitive Applications",
    "abstract": "Test-Time Adaptation (TTA) methods use unlabeled test data to dynamically adjust models in response to distribution changes. However, existing TTA methods are not tailored for practical use on edge devices with limited computational capacity, resulting in a latency-accuracy trade-off. To address this problem, we propose SNAP-TTA, a sparse TTA framework that significantly reduces adaptation frequency and data usage, delivering latency reductions proportional to adaptation rate. It achieves competitive accuracy even with an adaptation rate as low as 0.01, demonstrating its ability to adapt infrequently while utilizing only a small portion of the data relative to full adaptation. Our approach involves (i) Class and Domain Representative Memory (CnDRM), which identifies key samples that are both class-representative and domain-representative to facilitate adaptation with minimal data, and (ii) Inference-only Batch-aware Memory Normalization (IoBMN), which leverages representative samples to adjust normalization layers on-the-fly during inference, aligning the model effectively to changing domains. When combined with five state-of-the-art TTA algorithms, SNAP-TTA maintains the performances of these methods even with much-reduced adaptation rates from 0.01 to 0.5, making it suitable for edge devices serving latency-sensitive applications.",
    "paper_decision": "Rejected_Submission",
    "paper_pdf_link": "/pdf/15d5559569f030abafe634516791ac27749674bd.pdf"
  },
  {
    "venue": "ICLR.cc/2025/Conference",
    "paper_openreview_id": "cDdeTXOnAK",
    "title": "AutoCoder: Enhancing Code Large Language Model with AIEV-INSTRUCT",
    "abstract": "We introduce AutoCoder, an open-source Large Language Model to surpass GPT-4 Turbo and GPT-4o in pass@1 on the Human Eval benchmark test (90.9\\% vs. 90.2). In addition, AutoCoder offers a more versatile code interpreter compared to GPT-4 Turbo and GPT-4o. It's code interpreter can install external packages instead of limiting to built-in packages. AutoCoder's training data is a multi-turn dialogue dataset created by a system combining agent interaction and external code execution verification, a method we term AIEV-Instruct (Agent-Interaction Execution-Verified). Compared to previous large-scale code dataset annotation methods, AIEV-Instruct reduces dependence on proprietary large models and provides more accurate code annotation data.",
    "paper_decision": "Rejected_Submission",
    "paper_pdf_link": "/pdf/8258f5d5510a6bd7a70688f3dd8589659f3b8618.pdf"
  },
  {
    "venue": "ICLR.cc/2025/Conference",
    "paper_openreview_id": "9DrPvYCETp",
    "title": "Shared Memory for Multi-agent Lifelong Pathfinding",
    "abstract": "Multi-agent reinforcement learning (MARL) demonstrates significant progress in solving cooperative and competitive multi-agent problems in various environments. One of the main challenges in MARL is the need to explicitly predict other agents' behavior to achieve cooperation. As a solution to this problem, we propose the Shared Recurrent Memory Transformer (SRMT), which extends memory transformers to multi-agent settings by pooling and globally broadcasting individual working memories, enabling agents to implicitly exchange information and coordinate actions. We evaluate SRMT on the Partially Observable Multi-Agent Path Finding problem, both in a toy bottleneck navigation task requiring agents to pass through a narrow corridor and on a set of mazes from the POGEMA benchmark. In the bottleneck task, SRMT consistently outperforms a range of reinforcement learning baselines, especially under sparse rewards, and generalizes effectively to longer corridors than those seen during training. On POGEMA maps,  including Mazes, Random, and Warehouses, SRMT is competitive with a variety of recent MARL, hybrid, and planning-based algorithms. These results suggest that incorporating shared memory into transformer-based architectures can enhance coordination in decentralized multi-agent systems.",
    "paper_decision": "Rejected_Submission",
    "paper_pdf_link": "/pdf/aa602f8fb67bffa9115836c5a35ebd178662a3ac.pdf"
  },
  {
    "venue": "ICLR.cc/2025/Conference",
    "paper_openreview_id": "odjMSBSWRt",
    "title": "DarkBench: Benchmarking Dark Patterns in Large Language Models",
    "abstract": "We introduce DarkBench, a comprehensive benchmark for detecting dark design patterns—manipulative techniques that influence user behavior—in interactions with large language models (LLMs). Our benchmark comprises 660 prompts across six categories: brand bias, user retention, sycophancy, anthropomorphism, harmful generation, and sneaking. We evaluate models from five leading companies (OpenAI, Anthropic, Meta, Mistral, Google) and find that some LLMs are explicitly designed to favor their developers' products and exhibit untruthful communication, among other manipulative behaviors. Companies developing LLMs should recognize and mitigate the impact of dark design patterns to promote more ethical Al.",
    "paper_decision": "ICLR 2025 Oral",
    "paper_pdf_link": "/pdf/66d66215ed6e8821cf14e0c9c0e83be089660c40.pdf"
  },
  {
    "venue": "ICLR.cc/2025/Conference",
    "paper_openreview_id": "qK6U4Ahfms",
    "title": "OpenCity: A Scalable Platform to Simulate Urban Activities with Massive LLM Agents",
    "abstract": "Agent-based models (ABMs) have long been employed to explore how individual behaviors aggregate into complex societal phenomena in urban space. Unlike black-box predictive models, ABMs excel at explaining the micro-macro linkages that drive such emergent behaviors. The recent rise of Large Language Models (LLMs) has led to the development of LLM agents capable of simulating urban activities with unprecedented realism. However, scaling LLM agents to large city simulations presents significant challenges. Existing models are limited by the computational and communication costs of LLMs, compounded by the dynamic nature of urban environments that require continual updates to agent behavior. To address these limitations, we propose OpenCity, a scalable simulation platform optimized for both system and prompt efficiencies. Specifically, we propose a LLM request scheduler to reduce communication overhead by parallelizing requests through IO multiplexing. Besides, we deisgn a ``group-and-distill'' prompt optimization strategy minimizes redundancy by clustering agents with similar static attributes. Through experiments on six global cities, OpenCity achieves a 600-fold acceleration in simulation time per agent, a 70\\% reduction in LLM requests, and a 50\\% reduction in token usage. These improvements enable the simulation of 10,000 agents’ daily activities in 1 hour on commodity hardware. Additionally, OpenCity establishes a benchmark for LLM agents, comparing simulated mobility behaviors, origin-destination flows, and segregation indices against real-world data. We believe our OpenCity platform provides a critical infrastructure to harness the power of LLMs for interdisciplinary studies in urban space, fostering the collective efforts of broader research communities. Code repo is available at https://anonymous.4open.science/r/Anonymous-OpenCity-42BD.",
    "paper_decision": "Rejected_Submission",
    "paper_pdf_link": "/pdf/e4f2bbe9d411cd85f82f963fe7f97ac125c6f5e8.pdf"
  },
  {
    "venue": "ICLR.cc/2025/Conference",
    "paper_openreview_id": "f7VXdQTbyW",
    "title": "ThreadsGAN: Enhancing Coherence and Diversity in Discussion Thread Generation",
    "abstract": "Current research on generating discussion threads faces challenges in coherence, interactivity, and multi-topic handling, which are crucial for meaningful responses. This paper introduces threadsGAN, a model that enhances thread generation by incorporating multi-topic and social response intention tags. By leveraging BERT and Transformer, threadsGAN ensures contextual coherence and manages topic consistency. Additionally, it employs conditional generation to align responses with specific discussion contexts, and its CNN-based discriminator assesses response quality by evaluating similarity between generated and real responses, improving overall performance in generating realistic and contextually appropriate discussion threads.",
    "paper_decision": "Rejected_Submission",
    "paper_pdf_link": "/pdf/e00e9fce21e4a82589355263427aeefdfba2281f.pdf"
  }
]