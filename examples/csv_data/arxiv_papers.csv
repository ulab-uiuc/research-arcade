id,arxiv_id,base_arxiv_id,version,title,abstract,submit_date,metadata,research_question,method_description
24210,2506.22911,2506.22911,,Learning Truthful Mechanisms without Discretization,"This paper introduces TEDI (Truthful, Expressive, and Dimension-Insensitive
approach), a discretization-free algorithm to learn truthful and
utility-maximizing mechanisms. Existing learning-based approaches often rely on
discretization of outcome spaces to ensure truthfulness, which leads to
inefficiency with increasing problem size. To address this limitation, we
formalize the concept of pricing rules, defined as functions that map outcomes
to prices. Based on this concept, we propose a novel menu mechanism, which can
be equivalent to a truthful direct mechanism under specific conditions. The
core idea of TEDI lies in its parameterization of pricing rules using Partial
GroupMax Network, a new network architecture designed to universally
approximate partial convex functions. To learn optimal pricing rules, we
develop novel training techniques, including covariance trick and continuous
sampling, to derive unbiased gradient estimators compatible with first-order
optimization. Theoretical analysis establishes that TEDI guarantees
truthfulness, full expressiveness, and dimension-insensitivity. Experimental
evaluation in the studied auction setting demonstrates that TEDI achieves
strong performance, competitive with or exceeding state-of-the-art methods.
  This work presents the first approaches to learn truthful mechanisms without
outcome discretization, thereby enhancing algorithmic efficiency. The proposed
concepts, network architecture, and learning techniques might offer potential
value and provide new insights for automated mechanism design and
differentiable economics.",2025-06-28,"{'id': '2506.22911', 'title': 'Learning Truthful Mechanisms without Discretization', 'abstract': 'This paper introduces TEDI (Truthful, Expressive, and Dimension-Insensitive\napproach), a discretization-free algorithm to learn truthful and\nutility-maximizing mechanisms. Existing learning-based approaches often rely on\ndiscretization of outcome spaces to ensure truthfulness, which leads to\ninefficiency with increasing problem size. To address this limitation, we\nformalize the concept of pricing rules, defined as functions that map outcomes\nto prices. Based on this concept, we propose a novel menu mechanism, which can\nbe equivalent to a truthful direct mechanism under specific conditions. The\ncore idea of TEDI lies in its parameterization of pricing rules using Partial\nGroupMax Network, a new network architecture designed to universally\napproximate partial convex functions. To learn optimal pricing rules, we\ndevelop novel training techniques, including covariance trick and continuous\nsampling, to derive unbiased gradient estimators compatible with first-order\noptimization. Theoretical analysis establishes that TEDI guarantees\ntruthfulness, full expressiveness, and dimension-insensitivity. Experimental\nevaluation in the studied auction setting demonstrates that TEDI achieves\nstrong performance, competitive with or exceeding state-of-the-art methods.\n  This work presents the first approaches to learn truthful mechanisms without\noutcome discretization, thereby enhancing algorithmic efficiency. The proposed\nconcepts, network architecture, and learning techniques might offer potential\nvalue and provide new insights for automated mechanism design and\ndifferentiable economics.', 'authors': ['Yunxuan Ma', 'Siqiang Wang', 'Zhijian Duan', 'Yukun Cheng', 'Xiaotie Deng'], 'published': '2025-06-28 14:50:29+00:00', 'categories': ['cs.GT', 'cs.AI', 'cs.LG'], 'url': 'http://arxiv.org/abs/2506.22911v1'}",,
9519,2505.05183,2505.05183,,PaniCar: Securing the Perception of Advanced Driving Assistance Systems Against Emergency Vehicle Lighting,"The safety of autonomous cars has come under scrutiny in recent years,
especially after 16 documented incidents involving Teslas (with autopilot
engaged) crashing into parked emergency vehicles (police cars, ambulances, and
firetrucks). While previous studies have revealed that strong light sources
often introduce flare artifacts in the captured image, which degrade the image
quality, the impact of flare on object detection performance remains unclear.
In this research, we unveil PaniCar, a digital phenomenon that causes an object
detector's confidence score to fluctuate below detection thresholds when
exposed to activated emergency vehicle lighting. This vulnerability poses a
significant safety risk, and can cause autonomous vehicles to fail to detect
objects near emergency vehicles. In addition, this vulnerability could be
exploited by adversaries to compromise the security of advanced driving
assistance systems (ADASs). We assess seven commercial ADASs (Tesla Model 3,
""manufacturer C"", HP, Pelsee, AZDOME, Imagebon, Rexing), four object detectors
(YOLO, SSD, RetinaNet, Faster R-CNN), and 14 patterns of emergency vehicle
lighting to understand the influence of various technical and environmental
factors. We also evaluate four SOTA flare removal methods and show that their
performance and latency are insufficient for real-time driving constraints. To
mitigate this risk, we propose Caracetamol, a robust framework designed to
enhance the resilience of object detectors against the effects of activated
emergency vehicle lighting. Our evaluation shows that on YOLOv3 and Faster
RCNN, Caracetamol improves the models' average confidence of car detection by
0.20, the lower confidence bound by 0.33, and reduces the fluctuation range by
0.33. In addition, Caracetamol is capable of processing frames at a rate of
between 30-50 FPS, enabling real-time ADAS car detection.",2025-05-08,"{'id': '2505.05183', 'title': 'PaniCar: Securing the Perception of Advanced Driving Assistance Systems Against Emergency Vehicle Lighting', 'abstract': 'The safety of autonomous cars has come under scrutiny in recent years,\nespecially after 16 documented incidents involving Teslas (with autopilot\nengaged) crashing into parked emergency vehicles (police cars, ambulances, and\nfiretrucks). While previous studies have revealed that strong light sources\noften introduce flare artifacts in the captured image, which degrade the image\nquality, the impact of flare on object detection performance remains unclear.\nIn this research, we unveil PaniCar, a digital phenomenon that causes an object\ndetector\'s confidence score to fluctuate below detection thresholds when\nexposed to activated emergency vehicle lighting. This vulnerability poses a\nsignificant safety risk, and can cause autonomous vehicles to fail to detect\nobjects near emergency vehicles. In addition, this vulnerability could be\nexploited by adversaries to compromise the security of advanced driving\nassistance systems (ADASs). We assess seven commercial ADASs (Tesla Model 3,\n""manufacturer C"", HP, Pelsee, AZDOME, Imagebon, Rexing), four object detectors\n(YOLO, SSD, RetinaNet, Faster R-CNN), and 14 patterns of emergency vehicle\nlighting to understand the influence of various technical and environmental\nfactors. We also evaluate four SOTA flare removal methods and show that their\nperformance and latency are insufficient for real-time driving constraints. To\nmitigate this risk, we propose Caracetamol, a robust framework designed to\nenhance the resilience of object detectors against the effects of activated\nemergency vehicle lighting. Our evaluation shows that on YOLOv3 and Faster\nRCNN, Caracetamol improves the models\' average confidence of car detection by\n0.20, the lower confidence bound by 0.33, and reduces the fluctuation range by\n0.33. In addition, Caracetamol is capable of processing frames at a rate of\nbetween 30-50 FPS, enabling real-time ADAS car detection.', 'authors': ['Elad Feldman', 'Jacob Shams', 'Dudi Biton', 'Alfred Chen', 'Shaoyuan Xie', 'Satoru Koda', 'Yisroel Mirsky', 'Asaf Shabtai', 'Yuval Elovici', 'Ben Nassi'], 'published': '2025-05-08 12:33:48+00:00', 'categories': ['cs.CV', 'cs.LG'], 'url': 'http://arxiv.org/abs/2505.05183v1'}",,
63669,1812.04778,1812.04778,,Bridging the Generalization Gap: Training Robust Models on Confounded Biological Data,"Statistical learning on biological data can be challenging due to confounding variables in sample collection and processing. Confounders can cause models to generalize poorly and result in inaccurate prediction performance metrics if models are not validated thoroughly. In this paper, we propose methods to control for confounding factors and further improve prediction performance. We introduce OrthoNormal basis construction In cOnfounding factor Normalization (ONION) to remove confounding covariates and use the Domain-Adversarial Neural Network (DANN) to penalize models for encoding confounder information. We apply the proposed methods to simulated and empirical patient data and show significant improvements in generalization.",2018-12-12,"{'id': '1812.04778', 'title': 'Bridging the Generalization Gap: Training Robust Models on Confounded Biological Data', 'abstract': 'Statistical learning on biological data can be challenging due to confounding variables in sample collection and processing. Confounders can cause models to generalize poorly and result in inaccurate prediction performance metrics if models are not validated thoroughly. In this paper, we propose methods to control for confounding factors and further improve prediction performance. We introduce OrthoNormal basis construction In cOnfounding factor Normalization (ONION) to remove confounding covariates and use the Domain-Adversarial Neural Network (DANN) to penalize models for encoding confounder information. We apply the proposed methods to simulated and empirical patient data and show significant improvements in generalization.', 'authors': ['Tzu-Yu Liu', 'Ajay Kannan', 'Adam Drake', 'Marvin Bertin', 'Nathan Wan'], 'published': '2018-12-12 02:16:20+00:00', 'categories': ['cs.LG', 'stat.ML'], 'url': 'http://arxiv.org/abs/1812.04778v1'}",,
52547,2105.12277,2105.12277,,Learning Bipedal Robot Locomotion from Human Movement,"Teaching an anthropomorphic robot from human example offers the opportunity to impart humanlike qualities on its movement. In this work we present a reinforcement learning based method for teaching a real world bipedal robot to perform movements directly from human motion capture data. Our method seamlessly transitions from training in a simulation environment to executing on a physical robot without requiring any real world training iterations or offline steps. To overcome the disparity in joint configurations between the robot and the motion capture actor, our method incorporates motion re-targeting into the training process. Domain randomization techniques are used to compensate for the differences between the simulated and physical systems. We demonstrate our method on an internally developed humanoid robot with movements ranging from a dynamic walk cycle to complex balancing and waving. Our controller preserves the style imparted by the motion capture data and exhibits graceful failure modes resulting in safe operation for the robot. This work was performed for research purposes only.",2021-05-26,"{'id': '2105.12277', 'title': 'Learning Bipedal Robot Locomotion from Human Movement', 'abstract': 'Teaching an anthropomorphic robot from human example offers the opportunity to impart humanlike qualities on its movement. In this work we present a reinforcement learning based method for teaching a real world bipedal robot to perform movements directly from human motion capture data. Our method seamlessly transitions from training in a simulation environment to executing on a physical robot without requiring any real world training iterations or offline steps. To overcome the disparity in joint configurations between the robot and the motion capture actor, our method incorporates motion re-targeting into the training process. Domain randomization techniques are used to compensate for the differences between the simulated and physical systems. We demonstrate our method on an internally developed humanoid robot with movements ranging from a dynamic walk cycle to complex balancing and waving. Our controller preserves the style imparted by the motion capture data and exhibits graceful failure modes resulting in safe operation for the robot. This work was performed for research purposes only.', 'authors': ['Michael Taylor', 'Sergey Bashkirov', 'Javier Fernandez Rico', 'Ike Toriyama', 'Naoyuki Miyada', 'Hideki Yanagisawa', 'Kensaku Ishizuka'], 'published': '2021-05-26 00:49:37+00:00', 'categories': ['cs.RO', 'cs.AI', 'cs.LG'], 'url': 'http://arxiv.org/abs/2105.12277v1'}",,
64776,2408.07958,2408.07958,,"Simultaneous imaging of vibrational, rotational, and electronic wave packet dynamics in a triatomic molecule","Light-induced molecular dynamics often involve the excitation of several electronic, vibrational, and rotational states. Since the ensuing electronic and nuclear motion determines the pathways and outcomes of photoinduced reactions, our ability to monitor and understand these dynamics is crucial for molecular physics, physical chemistry, and photobiology. However, characterizing this complex motion represents a significant challenge when different degrees of freedom are strongly coupled. In this Letter, we demonstrate how the interplay between vibrational, rotational, and electronic degrees of freedom governs the evolution of molecular wave packets in the low-lying states of strong-field-ionized sulfur dioxide. Using time-resolved Coulomb explosion imaging (CEI) and quantum mechanical wave packet simulations, we directly map the bending vibrations of the molecule, show how the vibrational wave packet is influenced by molecular alignment, and elucidate the consequences of nuclear motion for the coupling between the two lowest electronic states of the cation. Our results demonstrate that multi-coincident CEI can be an efficient experimental tool for characterizing coupled electronic and nuclear motion in polyatomic molecules.",2024-08-15,"{'id': '2408.07958', 'title': 'Simultaneous imaging of vibrational, rotational, and electronic wave packet dynamics in a triatomic molecule', 'abstract': 'Light-induced molecular dynamics often involve the excitation of several electronic, vibrational, and rotational states. Since the ensuing electronic and nuclear motion determines the pathways and outcomes of photoinduced reactions, our ability to monitor and understand these dynamics is crucial for molecular physics, physical chemistry, and photobiology. However, characterizing this complex motion represents a significant challenge when different degrees of freedom are strongly coupled. In this Letter, we demonstrate how the interplay between vibrational, rotational, and electronic degrees of freedom governs the evolution of molecular wave packets in the low-lying states of strong-field-ionized sulfur dioxide. Using time-resolved Coulomb explosion imaging (CEI) and quantum mechanical wave packet simulations, we directly map the bending vibrations of the molecule, show how the vibrational wave packet is influenced by molecular alignment, and elucidate the consequences of nuclear motion for the coupling between the two lowest electronic states of the cation. Our results demonstrate that multi-coincident CEI can be an efficient experimental tool for characterizing coupled electronic and nuclear motion in polyatomic molecules.', 'authors': ['Huynh Van Sa Lam', 'Van-Hung Hoang', 'Anbu Selvam Venkatachalam', 'Surjendu Bhattacharyya', 'Keyu Chen', 'Sina Jacob', 'Sanduni Kudagama', 'Tu Thanh Nguyen', 'Daniel Rolles', 'Uwe Thumm', 'Artem Rudenko', 'Vinod Kumarappan'], 'published': '2024-08-15 06:13:04+00:00', 'categories': ['physics.chem-ph', 'physics.atm-clus', 'physics.optics', 'quant-ph'], 'url': 'http://arxiv.org/abs/2408.07958v3'}",,
2905,2501.15943,2501.15943,,Integral Transform Solution of Random Coupled Parabolic Partial Differential Models,"Random coupled parabolic partial differential models are solved numerically
using random cosine Fourier transform together with non Gaussian random
numerical integration that capture the highly oscillatory behavior of the
involved integrands. Sufficient condition of spectral type imposed on the
random matrices of the system are given so that the approximated stochastic
process solution and its statistical moments are numerically convergent.
Numerical experiments illustrate the results.",2025-01-27,"{'id': '2501.15943', 'title': 'Integral Transform Solution of Random Coupled Parabolic Partial Differential Models', 'abstract': 'Random coupled parabolic partial differential models are solved numerically\nusing random cosine Fourier transform together with non Gaussian random\nnumerical integration that capture the highly oscillatory behavior of the\ninvolved integrands. Sufficient condition of spectral type imposed on the\nrandom matrices of the system are given so that the approximated stochastic\nprocess solution and its statistical moments are numerically convergent.\nNumerical experiments illustrate the results.', 'authors': ['M. -C. Casabán', 'R. Company', 'V. N. Egorova', 'L. Jódar'], 'published': '2025-01-27 10:42:06+00:00', 'categories': ['math.NA', 'cs.NA', '35R60, 60H15, 60H35, 62M15, 65D30, 65R10, 68U20'], 'url': 'http://arxiv.org/abs/2501.15943v1'}","Here is a concise summary of the main research question(s) or objective(s):

This paper addresses the problem of solving random coupled partial differential equations (PDEs) in unbounded domains, where the parameters and coefficients are subject to uncertainties. The goal is to develop an efficient method for approximating the stochastic solution process and computing its statistical moments, overcoming the limitations of existing methods that struggle with highly oscillatory integrands. The paper aims to provide a more general and accurate approach for solving random coupled parabolic problems, which is crucial in various engineering disciplines such as geomechanics, geotechnics, and optics.","Here is a concise summary of the main methodology or approach used:

The approach involves solving a random coupled parabolic problem using Fourier integral transforms. The method builds upon previous work that used Fourier transforms and random Gaussian quadrature rules, but overcomes the limitation of decreased accuracy for highly oscillatory Fourier kernels in large domains. The new approach uses an appropriate truncation of the infinite integral and employs quadrature rules that can handle highly oscillatory integrands. The solution involves algebraic manipulations, including the use of matrix exponential and logarithmic operator norms, and the application of Ostrowski's theorem to establish bounds on the eigenvalues of certain matrices."
63230,2405.13424,2405.13424,,Metabolic coordination and phase transitions in spatially distributed multi-cellular systems,"During overflow metabolism, cells excrete glycolytic byproducts when growing under aerobic conditions in a seemingly wasteful fashion. While potentially advantageous for microbes with finite oxidative capacity, its role in higher organisms is harder to assess. Recent single-cell experiments suggest overflow metabolism arises due to imbalances in inter-cellular exchange networks. We quantitatively characterize this scenario by integrating spatial metabolic modeling with tools from statistical physics and experimental single-cell flux data. Our results provide a theoretical demonstration of how diffusion-limited exchanges shape the space of accessible multi-cellular metabolic states. Specifically, a phase transition from a balanced network of exchanges to an unbalanced, overflow regime occurs as mean glucose and oxygen uptake rates vary. Heterogeneous single-cell metabolic phenotypes occur near this transition. Time-resolved tumor-stroma co-culture data support the idea that overflow metabolism stems from failure of inter-cellular metabolic coordination. In summary, environmental control is an emergent multi-cellular property, rather than a cell-autonomous effect.",2024-05-22,"{'id': '2405.13424', 'title': 'Metabolic coordination and phase transitions in spatially distributed multi-cellular systems', 'abstract': 'During overflow metabolism, cells excrete glycolytic byproducts when growing under aerobic conditions in a seemingly wasteful fashion. While potentially advantageous for microbes with finite oxidative capacity, its role in higher organisms is harder to assess. Recent single-cell experiments suggest overflow metabolism arises due to imbalances in inter-cellular exchange networks. We quantitatively characterize this scenario by integrating spatial metabolic modeling with tools from statistical physics and experimental single-cell flux data. Our results provide a theoretical demonstration of how diffusion-limited exchanges shape the space of accessible multi-cellular metabolic states. Specifically, a phase transition from a balanced network of exchanges to an unbalanced, overflow regime occurs as mean glucose and oxygen uptake rates vary. Heterogeneous single-cell metabolic phenotypes occur near this transition. Time-resolved tumor-stroma co-culture data support the idea that overflow metabolism stems from failure of inter-cellular metabolic coordination. In summary, environmental control is an emergent multi-cellular property, rather than a cell-autonomous effect.', 'authors': ['Krishnadev Narayanankutty', 'José Antonio Pereiro-Morejon', 'Arián Ferrero-Fernández', 'Valentina Onesto', 'Stefania Forciniti', 'Loretta L. del Mercato', 'Roberto Mulet', 'Andrea De Martino', 'David S. Tourigny', 'Daniele De Martino'], 'published': '2024-05-22 08:12:56+00:00', 'categories': ['cond-mat.stat-mech', 'physics.bio-ph', 'q-bio.CB'], 'url': 'http://arxiv.org/abs/2405.13424v2'}",,
57982,2404.06400,2404.06400,,Dynamic Deep Learning Based Super-Resolution For The Shallow Water Equations,"Using the nonlinear shallow water equations as benchmark, we demonstrate that a simulation with the ICON-O ocean model with a 20km resolution that is frequently corrected by a U-net-type neural network can achieve discretization errors of a simulation with 10km resolution. The network, originally developed for image-based super-resolution in post-processing, is trained to compute the difference between solutions on both meshes and is used to correct the coarse mesh every 12h. Our setup is the Galewsky test case, modeling transition of a barotropic instability into turbulent flow. We show that the ML-corrected coarse resolution run correctly maintains a balance flow and captures the transition to turbulence in line with the higher resolution simulation. After 8 day of simulation, the $L_2$-error of the corrected run is similar to a simulation run on the finer mesh. While mass is conserved in the corrected runs, we observe some spurious generation of kinetic energy.",2024-04-09,"{'id': '2404.06400', 'title': 'Dynamic Deep Learning Based Super-Resolution For The Shallow Water Equations', 'abstract': 'Using the nonlinear shallow water equations as benchmark, we demonstrate that a simulation with the ICON-O ocean model with a 20km resolution that is frequently corrected by a U-net-type neural network can achieve discretization errors of a simulation with 10km resolution. The network, originally developed for image-based super-resolution in post-processing, is trained to compute the difference between solutions on both meshes and is used to correct the coarse mesh every 12h. Our setup is the Galewsky test case, modeling transition of a barotropic instability into turbulent flow. We show that the ML-corrected coarse resolution run correctly maintains a balance flow and captures the transition to turbulence in line with the higher resolution simulation. After 8 day of simulation, the $L_2$-error of the corrected run is similar to a simulation run on the finer mesh. While mass is conserved in the corrected runs, we observe some spurious generation of kinetic energy.', 'authors': ['Maximilian Witte', 'Fabricio Rodrigues Lapolli', 'Philip Freese', 'Sebastian Götschel', 'Daniel Ruprecht', 'Peter Korn', 'Christopher Kadow'], 'published': '2024-04-09 15:46:00+00:00', 'categories': ['cs.LG', 'physics.comp-ph', 'physics.flu-dyn'], 'url': 'http://arxiv.org/abs/2404.06400v2'}","Unfortunately, the provided sections do not contain any information about the research question or objective of the paper. The sections appear to be a part of a LaTeX template or a guide for authors submitting papers to IOP Publishing journals, providing instructions on how to prepare and submit articles.

There is no research question or objective mentioned in the provided sections. If you could provide the actual content of the research paper, I would be happy to help you summarize the main research question or objective.","This is not a research paper, but rather a document providing guidelines for authors submitting papers to IOP Publishing journals. The text describes the LaTeX template and formatting requirements for submissions, including the use of the ""iopart.cls"" style file and the ""cjk.sty"" package for including Chinese, Japanese, and Korean characters in author names. There is no methodology or approach to summarize."
15396,2504.10653,2504.10653,,On the Contractivity of Stochastic Interpolation Flow,"We investigate stochastic interpolation, a recently introduced framework for
high dimensional sampling which bears many similarities to diffusion modeling.
Stochastic interpolation generates a data sample by first randomly initializing
a particle drawn from a simple base distribution, then simulating deterministic
or stochastic dynamics such that in finite time the particle's distribution
converges to the target. We show that for a Gaussian base distribution and a
strongly log-concave target distribution, the stochastic interpolation flow map
is Lipschitz with a sharp constant which matches that of Caffarelli's theorem
for optimal transport maps. We are further able to construct Lipschitz
transport maps between non-Gaussian distributions, generalizing some recent
constructions in the literature on transport methods for establishing
functional inequalities. We discuss the practical implications of our theorem
for the sampling and estimation problems required by stochastic interpolation.",2025-04-14,"{'id': '2504.10653', 'title': 'On the Contractivity of Stochastic Interpolation Flow', 'abstract': ""We investigate stochastic interpolation, a recently introduced framework for\nhigh dimensional sampling which bears many similarities to diffusion modeling.\nStochastic interpolation generates a data sample by first randomly initializing\na particle drawn from a simple base distribution, then simulating deterministic\nor stochastic dynamics such that in finite time the particle's distribution\nconverges to the target. We show that for a Gaussian base distribution and a\nstrongly log-concave target distribution, the stochastic interpolation flow map\nis Lipschitz with a sharp constant which matches that of Caffarelli's theorem\nfor optimal transport maps. We are further able to construct Lipschitz\ntransport maps between non-Gaussian distributions, generalizing some recent\nconstructions in the literature on transport methods for establishing\nfunctional inequalities. We discuss the practical implications of our theorem\nfor the sampling and estimation problems required by stochastic interpolation."", 'authors': ['Max Daniels'], 'published': '2025-04-14 19:10:22+00:00', 'categories': ['math.ST', 'cs.LG', 'stat.ML', 'stat.TH'], 'url': 'http://arxiv.org/abs/2504.10653v1'}",,
52605,2402.10058,2402.10058,,Towards Safer Large Language Models through Machine Unlearning,"The rapid advancement of Large Language Models (LLMs) has demonstrated their vast potential across various domains, attributed to their extensive pretraining knowledge and exceptional generalizability. However, LLMs often encounter challenges in generating harmful content when faced with problematic prompts. To address this problem, existing work attempted to implement a gradient ascent based approach to prevent LLMs from producing harmful output. While these methods can be effective, they frequently impact the model utility in responding to normal prompts. To address this gap, we introduce Selective Knowledge negation Unlearning (SKU), a novel unlearning framework for LLMs, designed to eliminate harmful knowledge while preserving utility on normal prompts. Specifically, SKU is consisted of two stages: harmful knowledge acquisition stage and knowledge negation stage. The first stage aims to identify and acquire harmful knowledge within the model, whereas the second is dedicated to remove this knowledge. SKU selectively isolates and removes harmful knowledge in model parameters, ensuring the model's performance remains robust on normal prompts. Our experiments conducted across various LLM architectures demonstrate that SKU identifies a good balance point between removing harmful information and preserving utility.",2024-02-15,"{'id': '2402.10058', 'title': 'Towards Safer Large Language Models through Machine Unlearning', 'abstract': ""The rapid advancement of Large Language Models (LLMs) has demonstrated their vast potential across various domains, attributed to their extensive pretraining knowledge and exceptional generalizability. However, LLMs often encounter challenges in generating harmful content when faced with problematic prompts. To address this problem, existing work attempted to implement a gradient ascent based approach to prevent LLMs from producing harmful output. While these methods can be effective, they frequently impact the model utility in responding to normal prompts. To address this gap, we introduce Selective Knowledge negation Unlearning (SKU), a novel unlearning framework for LLMs, designed to eliminate harmful knowledge while preserving utility on normal prompts. Specifically, SKU is consisted of two stages: harmful knowledge acquisition stage and knowledge negation stage. The first stage aims to identify and acquire harmful knowledge within the model, whereas the second is dedicated to remove this knowledge. SKU selectively isolates and removes harmful knowledge in model parameters, ensuring the model's performance remains robust on normal prompts. Our experiments conducted across various LLM architectures demonstrate that SKU identifies a good balance point between removing harmful information and preserving utility."", 'authors': ['Zheyuan Liu', 'Guangyao Dou', 'Zhaoxuan Tan', 'Yijun Tian', 'Meng Jiang'], 'published': '2024-02-15 16:28:34+00:00', 'categories': ['cs.CL'], 'url': 'http://arxiv.org/abs/2402.10058v2'}","Here is a concise summary of the main research question(s) or objective(s):

This paper addresses the problem of Large Language Models (LLMs) generating undesired outputs with harmful prompts, which can be problematic and misaligned with human values. The goal is to develop an efficient and effective method to ""unlearn"" or remove harmful knowledge from LLMs while maintaining their performance on normal prompts. The paper aims to improve upon existing approaches, such as reinforcement learning from human feedback (RLHF) and machine unlearning (MU), which have limitations in terms of computational efficiency and effectiveness.","Here is a concise summary of the main methodology or approach used in the research paper:

The proposed method, \method, is a two-stage unlearning framework designed to selectively remove harmful information from Large Language Models (LLMs) while maintaining utility performance. The first stage involves identifying and learning harmful knowledge through three modules: Guided Distortion, Random Disassociation, and Preservation Divergence. The second stage negates the learned harmful knowledge from the pretrained model to form a safe yet useful LLM. The approach is novel in its use of a multi-module framework to acquire and negate harmful knowledge. The experimental setup involves fine-tuning the model on non-harmful samples and evaluating the performance on test data using metrics such as perplexity score and BLEURT score."
