id,paper_arxiv_id,path,caption,label,table_text
299023,2407.05308,,\caption{Frequency of Key Physics Terms Across AI Models},\label{tab:frequency_keywords},"\begin{tabular}{lcccccc}
		\toprule
		Keyword & ChatGPT3.5 & ChatGPT4.0 & Coral & Gemini-1.0-pro & Gemini-1.5-flash & Gemini-1.5-pro \\
		\midrule
		Vector concept & 4 & 48 & 27 & 19 & 36 & 44 \\
		Momentum  & 0 & 0 & 0 & 0 & 2 & 9 \\
		Time invariance & 3 & 31 & 42 & 42 & 6 & 5 \\
		Net force & 4 & 14 & 6 & 0 & 2 & 0 \\
		Derivation & 0 & 4 & 16 & 4 & 9 & 3 \\
		Conservation of energy & 3 & 9 & 8 & 6 & 2 & 5 \\
		Inelastic collision & 0 & 15 & 34 & 8 & 0 & 1 \\
		Quantum mechanics & 2 & 7 & 21 & 3 & 1 & 4 \\
		\bottomrule
	\end{tabular}"
105405,2008.02265v5,,\caption{The AUCCESS scores for each of evaluated fold.},\label{tab:phyre_detail},"\begin{tabular}{c|c|cccccccccc}
\multirow{2}{*}{setting} & \multirow{2}{*}{method} & \multicolumn{10}{c}{fold id} \\
& & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 \\
\hline
\hline
\multirow{3}{*}{B (within)} & RAND & 13.44 & 14.01 & 13.79 & 13.80 & 12.75 & 13.34 & 13.95 & 14.30 & 13.36 & 14.33 \\
 & DQN & 76.82 & 79.72 & 78.22 & 75.86 & 77.03 & 78.42 & 78.01 & 77.34 & 78.04 & 76.87 \\
 & \textbf{Ours} & 85.49 & 86.57 & 85.58 & 84.11 & 85.30 & 85.18 & 84.78 & 84.32 & 85.71 & 85.17 \\
\hline
\multirow{3}{*}{B (cross)}  & RAND & 11.78 & 12.42 & 18.18 & 12.42 & 3.81 & 22.50 & 11.73 & 13.29 & 8.94 & 14.60\\
& DQN & 43.69 & 30.96 & 43.05 & 43.91 & 22.77 & 44.40 & 34.53 & 39.20 & 18.98 & 46.46 \\
& \textbf{Ours} & 50.86 & 36.58 & 55.44 & 38.34 & 37.11 & 47.23 & 38.23 & 47.19 & 32.23 & 38.76 \\
\end{tabular}"
1546,2508.00454,,"\caption{Multi-dimensional evaluation results on the Daily-MTD-Dim dataset. The best result among non-SOTA LLMs is bolded, and the second best is underlined. Boxes highlight cases where our method outperforms all SOTA LLMs.}",\label{tab:Fine_Grained_Dim},"\begin{tabular}{lccccccccccccc}
\toprule
\textbf{Evaluator} & Acc. & Log. & Conv. & Rel. & Pers. & Crea. & Inter. & Emo. & Info. & Safe. & Average \\
\midrule
GPT-4o                   & 85.67 & 79.67 & 58.67 & 85.67 & 63.00 & 67.67 & 59.00 & 54.00 & 67.67 & 92.00 & 71.30 \\
Grok-3                   & 75.33 & 72.00 & 57.33 & 74.67 & 51.33 & 56.00 & 55.67 & 50.33 & 63.67 & 92.33 & 64.87 \\
Claude-3.7-Sonnet        & 76.33 & 69.00 & 63.33 & 73.00 & 56.33 & 60.33 & 60.00 & 58.33 & 67.00 & 91.33 & 67.50 \\
Deepseek-R1              & 76.67 & 77.73 & 61.00 & 80.67 & 59.67 & 64.00 & 62.00 & 57.67 & 70.00 & 97.00 & 70.64 \\                      
\midrule
Llama-3-8B-Instruct      & 36.67 & 32.00 & 47.33 & 32.00 & 74.67 & 45.33 & 40.00 & 61.33 & 26.00 & 17.67 & 41.30 \\ 
Llama-3.1-8B-Instruct    & 43.67 & 52.33 & 60.33 & 52.67 & 71.67 & 48.00 & 45.00 & 60.00 & 37.00 & 64.67 & 53.53 \\
Qwen2-7B-Instruct        & 28.62 & 27.24 & 30.69 & 27.24 & \underline{74.90} & 36.21 & 31.03 & 65.86 & 24.14 & 14.83 & 36.08 \\
Qwen2.5-7B-Instruct      & \textbf{76.67} & \underline{72.33} & 68.67 & \underline{77.67} & 74.00 & \underline{61.00} & \textbf{61.33} & 64.00 & 63.33 & 64.67 & 68.37 \\
AutoJ-13B                & 34.67 & 29.67 & 43.00 & 39.67 & 62.67 & 55.67 & 35.33 & 57.00 & 33.67 & 22.33 & 41.37 \\
Prometheus-7B            & 21.14 & 24.07 & 33.44 & 26.50 & 44.03 & 32.44 & 29.76 & 42.03 & 22.44 & 10.41 & 28.63 \\
Prometheus-2-7B          & 68.33 & \textbf{73.67} & \underline{69.92} & \textbf{82.33} & 64.00 & 48.67 & \underline{58.72} & \underline{66.00} & \underline{63.67} & \underline{70.33} & \underline{66.56} \\
\midrule
\textbf{\OURS{} (8B)}    & \underline{72.33} & 68.33 & \boxed{\textbf{79.00}} & 67.67 & \boxed{\textbf{75.67}} & \boxed{\textbf{74.67}} & 52.33 & \boxed{\textbf{66.33}} & \boxed{\textbf{74.67}} & \boxed{\textbf{97.67}} & \boxed{\textbf{72.87}} \\
% \textbf{\OURS{}}(train with only 10 fine dim)     & \underline{72.33} & 68.33 & \textbf{79.00} & 67.67 & \textbf{75.67} & \textbf{74.67} & 52.33 & \textbf{66.33} & \textbf{74.67} & \textbf{97.67} & \textbf{65.83} \\
% \textbf{\OURS{}}(train with 10 fine dim + overall rating)     & 74.67 & 64.33 & 73.33 & 62.67 & 72.67 & 81.67 & 42.33 & 65.00 & 67.67 & 96.67 & 59.83 \\
\bottomrule
\end{tabular}"
138874,2507.00761,,"\caption{Information of the study areas used in this research, including details on fire incidents, their geographic coordinates, affected area, duration, start date, and average wind speed.}",\label{tab:fire-info},"\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\textbf{Fire} & \textbf{Latitude} & \textbf{Longitude} & \textbf{Area} & \textbf{Duration} & \textbf{Start} & \textbf{Wind} \\ \hline
Chimney & 37.6230 & -119.8247 & $\approx246$ km$^2$ & 23 days & 13 August 2016 & 23.56 mph \\ \hline
Ferguson & 35.7386 & -121.0743 & $\approx185$ km$^2$ & 36 days & 13 July 2018 & 18.54 mph \\ \hline
\end{tabular}"
273966,2410.05298,,\caption{The accuracy of extracted frequent subgraphs},\label{frequency_table},"\begin{tabular}{l|l|ccc|ccc|ccc|ccc|ccc|ccc|ccc}
    \toprule
\multicolumn{2}{c}{\multirow{2}{*}{ }} & \multicolumn{3}{c}{GPT-4} & \multicolumn{3}{c}{GPT-4o} & \multicolumn{3}{c}{Mixtral} & \multicolumn{3}{c}{Llama} & \multicolumn{3}{c}{Gemini} & \multicolumn{3}{c}{Claude} & \multicolumn{3}{c}{O1-mini} \\
\multicolumn{2}{c}{} & S. & M. & L. & S. & M. & L. & S. & M. & L. & S. & M. & L. & S. & M. & L. & S. & M. & L. & S. & M. & L. \\
\midrule
\multirow{2}{*}{ Triangle } & A.L. & 1.00 & 1.00 & 1.00 & 0.84 & 0.88 & 0.88 & 0.86 & 0.88 & 1.00 & 0.62 & 0.68 & 0.87 & 1.00 & 1.00 & 0.59 & 0.43 & 0.26 & 0.09 & 1.00 & 1.00 & 1.00 \\
& E.L & 1.00 & 1.00 & 1.00 & 0.94 & 1.00 & 0.81 & 1.00 & 1.00 & 1.00 & 0.94 & 0.95 & 1.00 & 1.00 & 0.57 & 0.29 & 0.84 & 0.58 & 0.32 & 1.00 & 1.00 & 1.00 \\
\multirow{2}{*}{ Square } & A.L. & 1.00 & 1.00 & 1.00 & 1.00 & 0.86 & 1.00 & 0.69 & 0.95 & 1.00 & 0.61 & 0.94 & 1.00 & 0.75 & 0.47 & 0.40 & 0.30 & 0.37 & 0.07 & 1.00 & 1.00 & 1.00 \\
& E.L & 1.00 & 1.00 & 1.00 & 0.97 & 0.71 & 0.98 & 1.00 & 1.00 & 1.00 & 0.94 & 0.93 & 0.91 & 0.80 & 1.00 & 0.17 & 0.93 & 0.67 & 0.21 & 1.00 & 1.00 & 1.00 \\
\multirow{2}{*}{ Diamond } & A.L. & 1.00 & 1.00 & 1.00 & 0.89 & 1.00 & 0.50 & 0.92 & 1.00 & 1.00 & 0.43 & 0.52 & 0.96 & 1.00 & 1.00 & 0.83 & 0.34 & 0.33 & 0.14 & 1.00 & 1.00 & 1.00 \\
& E.L & 1.00 & 1.00 & 1.00 & 1.00 & 0.87 & 0.93 & 1.00 & 1.00 & 1.00 & 0.99 & 0.93 & 0.91 & 1.00 & 0.38 & 0.52 & 0.99 & 0.68 & 0.32 & 1.00 & 1.00 & 1.00 \\
\multirow{2}{*}{ House } & A.L. & 1.00 & 1.00 & 1.00 & 1.00 & 1.00 & 0.98 & 0.73 & 1.00 & 1.00 & 0.53 & 0.66 & 0.93 & 1.00 & 0.78 & 0.10 & 0.31 & 0.32 & 0.22 & 1.00 & 1.00 & 1.00 \\
& E.L & 1.00 & 1.00 & 1.00 & 1.00 & 1.00 & 0.76 & 1.00 & 1.00 & 1.00 & 1.00 & 0.74 & 0.95 & 1.00 & 0.33 & 0.18 & 1.00 & 0.55 & 0.44 & 1.00 & 1.00 & 1.00 \\
\midrule
\multirow{2}{*}{ FFL } & A.L. & 1.00 & 1.00 & 1.00 & 0.91 & 0.64 & 1.00 & 0.89 & 1.00 & 0.86 & 0.67 & 0.68 & 0.93 & 0.89 & 0.00 & 1.00 & 0.33 & 0.32 & 0.26 & 1.00 & 1.00 & 1.00 \\
& E.L & 1.00 & 1.00 & 1.00 & 0.96 & 0.67 & 0.92 & 1.00 & 1.00 & 1.00 & 0.92 & 1.00 & 1.00 & 1.00 & 1.00 & 1.00 & 0.68 & 0.52 & 0.34 & 1.00 & 1.00 & 1.00 \\
\multirow{2}{*}{ FBL } & A.L. & 1.00 & 1.00 & 1.00 & 0.78 & 0.89 & 0.90 & 1.00 & 1.00 & 0.59 & 0.77 & 0.67 & 0.87 & 1.00 & 1.00 & 1.00 & 0.46 & 0.22 & 0.40 & 1.00 & 1.00 & 0.85 \\
& E.L & 1.00 & 1.00 & 1.00 & 0.98 & 0.75 & 0.83 & 1.00 & 1.00 & 1.00 & 0.96 & 1.00 & 1.00 & 1.00 & 1.00 & 1.00 & 0.84 & 0.45 & 0.31 & 1.00 & 1.00 & 1.00 \\
\multirow{2}{*}{ D-Diamond } & A.L. & 1.00 & 1.00 & 1.00 & 0.81 & 0.95 & 1.00 & 1.00 & 1.00 & 0.67 & 0.54 & 0.73 & 0.91 & 0.67 & 0.00 & 1.00 & 0.41 & 0.42 & 0.35 & 1.00 & 1.00 & 1.00 \\
& E.L & 1.00 & 1.00 & 1.00 & 0.85 & 0.88 & 0.66 & 1.00 & 0.60 & 1.00 & 0.78 & 1.00 & 1.00 & 1.00 & 0.75 & 1.00 & 0.61 & 0.46 & 0.28 & 1.00 & 1.00 & 1.00 \\
\bottomrule
\end{tabular}"
63292,2506.17163,,,\label{tab:alignment-breakdown},"\begin{tabular}{llccc}
\toprule
\textbf{Dataset} & \textbf{Perturbation} & \textbf{MANAGE} & \textbf{VISIT} & \textbf{RESOURCE} \\
\midrule
r/AskaDocs        & Baseline & \textbf{54} & 70 & \textbf{52} \\
r/AskaDocs         & Gender-Swapped & \textbf{50} & 66 & \textbf{50} \\
r/AskaDocs         & Gender-Removed & \textbf{42} & 70 & 66 \\
r/AskaDocs         & Uncertain & 62 & 74 & \textbf{58} \\
r/AskaDocs         & Colorful & 84* & 92* & 84* \\
\midrule
OncQA           & Baseline & \textbf{38} & 82 & 68 \\
OncQA           & Gender-Swapped & \textbf{44} & 66* & 78 \\
OncQA           & Gender-Removed & \textbf{44} & 78 & 78 \\
OncQA           & Uncertain & \textbf{54} & 90 & 66 \\
OncQA           & Colorful & 94* & 92 & 98* \\
\midrule
USMLE  & Vignette & 90 & 79 & 95 \\
USMLE  & Multiturn & 76* & 88 & 73* \\
USMLE  & Summarized & 64* & 84 & 78* \\
\bottomrule
\end{tabular}"
98245,2411.05000v2,,\caption{Multi-Threading overall results.},\label{tab:multi_threading_table},"\begin{tabular}{lllllllllllll}
            \textbf{Model} & \multicolumn{12}{c}{\textbf{Accuracy (\%)}}                                                    \\
                  & 1.2k  & 2.5k  & 5k    & 10k   & 20k   & 32k   & 64k   & 128k  & 180k  & 250k & 500k & 630k \\
\toprule       
Gemini 1.5 Pro    & 82.2 & 65.1 & 53.2 & 57.9 & 50.7 & 44.9 & 34.6 & 24.6 & -    & -    & -    & -    \\
Gemini 1.5 Flash  & 60.5 & 36.9 & 30.4 & 25.1 & 21.9 & 18.5 & 10.5 & 7.8  & 4.0  & 2.2  & 0.3  & 0.5  \\
Jamba 1.5 Large   & 32.5 & 13.5 & 8.0  & 13.0 & 3.8  & 1.2  & 0.6  & 1.2  & -    & -    & -    & -    \\
Jamba 1.5 Mini    & 18.9 & 10.8 & 13.6 & 7.9  & 2.5  & 1.0  & 0.0  & 0.0  & -    & -    & -    & -    \\
Claude 3.5 Sonnet & 90.1 & 79.1 & 72.8 & 62.8 & 58.2 & 48.5 & 33.9 & 13.8 & 11.1 & -    & -    & -    \\
Claude 3 Sonnet   & 69.9 & 42.1 & 24.2 & 7.6  & 1.0  & 5.1  & 1.5  & 0.0  & 1.6  & -    & -    & -    \\
Claude 3 Haiku    & 34.1 & 24.2 & 17.4 & 8.7  & 7.4  & 4.0  & 2.3  & 1.6  & 1.6  & -    & -    & -    \\
GPT-4o            & 90.9 & 69.5 & 57.5 & 42.9 & 44.9 & 34.1 & 19.9 & 15.2 & -    & -    & -    & -    \\
GPT-4o mini       & 43.0 & 18.6 & 17.3 & 13.1 & 9.3  & 10.3 & 0.0  & 0.0  & -    & -    & -    & -    \\
Reka Core         & 16.8 & 2.9  & 3.5  & 1.5  & 1.3  & 0.0  & 0.2  & -    & -    & -    & -    & -    \\
Reka Flash        & 11.1 & 1.7  & 2.0  & 0.7  & 0.2  & 0.6  & 0.8  & 0.0  & -    & -    & -    & -    \\
LLaMA 3.1 8b      & 14.0 & 3.3  & 3.5  & 0.9  & 1.1  & 1.5  & 1.6  & 0.6  & -    & -    & -    & -    \\
LLaMA 3.1 70b     & 55.1 & 28.3 & 21.6 & 6.7  & 4.1  & 1.8  & 0.3  & 0.4  & -    & -    & -    & -    \\
LLaMA 3.1 405b    & 91.6 & 71.5 & 43.7 & 22.7 & 14.5 & 2.2  & 2.4  & 0.3  & -    & -    & -    & -    \\
Gemini 1.0 Pro    & 21.6 & 8.2  & 1.3  & 0.3  & 1.9  & -    & -    & -    & -    & -    & -    & -    \\
Mistral Large     & 71.3 & 49.2 & 34.9 & 14.4 & 8.7  & -    & -    & -    & -    & -    & -    & -    \\
Mistral Nemo      & 19.0 & 14.4 & 9.7  & 7.7  & 3.1  & -    & -    & -    & -    & -    & -    & -    \\
\bottomrule
\end{tabular}"
60057,2505.07425,,\caption{Task characteristic summary of neural code translation in terms of programming language pairs},\label{sec:plpairs},"\begin{tabular}{|c|c|c|l|}
\hline
\textbf{Translation Type} & \textbf{Categories of PL Pair} & \textbf{PL Pair} & \textbf{Related Studies} \\
\hline
\multirow{24}{*}{Bidirectional Translation} 
& \multirow{15}{*}{Statically Typed $\leftrightarrow$ Statically Typed} 
& Java $\leftrightarrow$ C\# & \cite{guo2020graphcodebert, wang2022no, zhu2022multilingual, liu2023contrabert, jha2023codeattack, chen2023exploring, huang2023program, li2024few, tipirneni2024structcoder, zhu2024grammart5, agarwal2021using, ahmad2021unified, lin2022xcode, chakraborty2022natgen,kumar2025can,du2024joint} \\
 & & Java $\leftrightarrow$ C++ & \cite{roziere2020unsupervised, agarwal2021using, roziere2021leveraging, jiao2023evaluation, szafraniec2022code, lin2022xcode, zheng2023codegeex, liu2023syntax, liu2024mftcoder, yang2024exploring, di2024codefuse, zhu2024semi, yin2024rectifier, macedo2024intertrans, yuan2024transagent,xue2025classeval,du2025post,pan2024lost,du2024joint} \\
  & &Java $\leftrightarrow$ Go & \cite{szafraniec2022code, zheng2023codegeex, macedo2024intertrans,pan2024lost} \\
   & & Java $\leftrightarrow$ Rust & \cite{szafraniec2022code, macedo2024intertrans} \\
 & & Java $\leftrightarrow$ C & \cite{zhu2024semi,pan2024lost,du2024joint} \\
 & & C++ $\leftrightarrow$ C\# & \cite{lin2022xcode,pan2024lost,du2024joint} \\
  & & C $\leftrightarrow$ C\# & \cite{du2024joint} \\
 & & C++ $\leftrightarrow$ C & \cite{zhu2024semi,du2024joint} \\
  & & C++ $\leftrightarrow$ Rust & \cite{szafraniec2022code, macedo2024intertrans} \\
 & & C++ $\leftrightarrow$ Go & \cite{szafraniec2022code, zheng2023codegeex, macedo2024intertrans,pan2024lost} \\
  & & C $\leftrightarrow$ Go & \cite{pan2024lost} \\
 & & Swift $\leftrightarrow$ Java & \cite{muhammad2020trans} \\
& & C++ $\leftrightarrow$ CUDA& \cite{tehrani2024coderosetta} \\
& & Fortran $\leftrightarrow$ C++ & \cite{tehrani2024coderosetta} \\
& & Rust $\leftrightarrow$ Go & \cite{szafraniec2022code, macedo2024intertrans} \\
\cline{2-4}
& \multirow{3}{*}{Dynamically Typed $\leftrightarrow$ Dynamically Typed} 
&  Python $\leftrightarrow$ JavaScript & \cite{zheng2023codegeex, macedo2024intertrans,du2024joint} \\
&&  PHP $\leftrightarrow$ JavaScript & \cite{du2024joint} \\
&&  PHP $\leftrightarrow$ Python & \cite{du2024joint} \\
\cline{2-4}
& \multirow{15}{*}{Statically Typed $\leftrightarrow$ Dynamically Typed} 
& Python $\leftrightarrow$ C++ & \cite{roziere2020unsupervised, agarwal2021using, roziere2021leveraging, lin2022xcode, zheng2023codegeex, liu2023syntax, liu2024mftcoder, yang2024exploring, di2024codefuse, zhu2024semi, yin2024rectifier, macedo2024intertrans, yuan2024transagent,xue2025classeval,du2025post,pan2024lost,du2024joint} \\
& & Python $\leftrightarrow$ Go & \cite{zheng2023codegeex, macedo2024intertrans,pan2024lost} \\
 & & Python $\leftrightarrow$ Rust & \cite{macedo2024intertrans} \\
 & & JavaScript $\leftrightarrow$ Rust & \cite{macedo2024intertrans} \\

& & Java $\leftrightarrow$ Python & \cite{malyala2023ml, ahmad2023summarize, li2024few, jana2024cotran, roziere2020unsupervised, agarwal2021using, roziere2021leveraging, jiao2023evaluation, lin2022xcode, zheng2023codegeex, liu2023syntax, liu2024mftcoder, yang2024exploring, di2024codefuse, zhu2024semi, yin2024rectifier, macedo2024intertrans, yang2025assessing, yuan2024transagent,liu2024hmcodetrans,xue2025classeval,du2025post,pan2024lost,du2024joint} \\
 & & Python $\leftrightarrow$ C & \cite{zhu2024semi,pan2024lost,du2024joint} \\
 & & C++ $\leftrightarrow$ JavaScript & \cite{zheng2023codegeex, macedo2024intertrans,du2024joint} \\
 & & Java $\leftrightarrow$ JavaScript & \cite{zheng2023codegeex, macedo2024intertrans,jiao2023evaluation,du2024joint} \\
 & & C $\leftrightarrow$ JavaScript & \cite{du2024joint} \\
  & & C\# $\leftrightarrow$ JavaScript & \cite{du2024joint} \\
& & C $\leftrightarrow$ PHP & \cite{du2024joint} \\
& & C\# $\leftrightarrow$ PHP & \cite{du2024joint} \\
& & C\# $\leftrightarrow$ Python & \cite{du2024joint} \\
& & C++ $\leftrightarrow$ PHP & \cite{du2024joint} \\
& & Java $\leftrightarrow$ PHP & \cite{du2024joint} \\
\hline
\multirow{12}{*}{Unidirectional Translation} 
& \multirow{7}{*}{Statically Typed → Statically Typed} 
&  C\# → Java & \cite{liu2023improving, shao2025unigencoder} \\
& & Java → C\# & \cite{li2024extracting, chen2024data} \\
& & Java → C++ & \cite{eniser2024automatically} \\
& & Java → Rust & \cite{ou2025enhancing} \\
& &C → Rust & \cite{hong2025type, shiraishi2024context,ou2025enhancing} \\
& & Fortran → C++ & \cite{bhattarai2024enhancing} \\
& & Solidity → Move & \cite{karanjai2024solmover} \\
\cline{2-4}
& \multirow{3}{*}{Dynamically Typed → Dynamically Typed} 
&  JavaScript → Python & \cite{pan2023stelocoder} \\
& &Python → JavaScript & \cite{wang2023transmap} \\
& &PHP → Python & \cite{pan2023stelocoder} \\
\cline{2-4}
& \multirow{3}{*}{Statically Typed →Dynamically Typed} 
& Java → Python & \cite{weisz2022better, xue2024interpretable, pan2023stelocoder, eniser2024automatically, ibrahimzada2025repository} \\
& & C++ → Python & \cite{pan2023stelocoder} \\
& & C\# → Python & \cite{pan2023stelocoder} \\
\cline{2-4}
& \multirow{2}{*}{Dynamically Typed →Statically Typed} 
& Python → Java & \cite{jin2021algorithm} 
\\
&& Python → Rust & \cite{ou2025enhancing} 
\\
\hline
\end{tabular}"
15621,2501.17486,,"\caption{Model configurations for different sizes, including hidden dimension, number of layers, and number of attention heads. Each model was trained with a sequence length of 2048 and a batch size of 0.25 million tokens, for a total of 40K training steps.}",\label{tab:model_configs},"\begin{tabular}{|l|c|c|c|}
        \hline
        \textbf{Size} & \textbf{Hidden Dim.} & \textbf{\#Layers} & \textbf{\#Heads} \\ \hline
        830M & 1536 & 24 & 8 \\ 
        1.4B & 2048 & 24 & 8 \\ 
        2.8B & 2560 & 32 & 10 \\ 
        6.8B & 4096 & 32 & 16 \\ 
        13.1B & 5120 & 40 & 20 \\ \hline
    \end{tabular}"
191755,2503.21200v1,,"\caption{
% \textcolor{blue}{
Average test win rates in the \textit{Stalker-Zealot} task set with different data qualities.
}",\label{app:stalker_mean},"\begin{tabular}{lcccc}
\toprule
\multicolumn{1}{l|}{Data Qualities}  
% & \multicolumn{1}{c}{w/o Task-Emb} 
& \multicolumn{1}{c}{BC-best} &\multicolumn{1}{c}{UPDeT-m} &\multicolumn{1}{c}{ODIS} &\multicolumn{1}{c}{HiSSD} \\
\midrule
\multicolumn{5}{c}{Source Tasks} \\
\midrule
\multicolumn{1}{l|}{Expert}         
% &85.9$\pm$16.4
&87.9$\pm$\ \ 5.6 &30.2$\pm$26.6  &82.0$\pm$\ \ 6.3 &\textbf{89.3$\pm$\ \ 4.0} \\
\multicolumn{1}{l|}{Medium}         
% &53.1$\pm$20.0
&28.6$\pm$10.1 &26.5$\pm$19.2 &\textbf{37.0$\pm$\ \ 9.1} &24.6$\pm$\ \ 7.3 \\
\multicolumn{1}{l|}{Medium-Expert}  
% &63.5$\pm$26.1
&52.9$\pm$17.9 &48.5$\pm$25.1 &47.1$\pm$13.9 &\textbf{55.9$\pm$\ \ 9.7} \\
\multicolumn{1}{l|}{Medium-Replay}  
% &47.7$\pm$25.1
&13.2$\pm$\ \ 5.4 &\textbf{15.6$\pm$13.2}  &14.1$\pm$\ \ 8.8 &10.8$\pm$\ \ 1.6 \\
\midrule
\multicolumn{5}{c}{Target Tasks} \\
\midrule
\multicolumn{1}{l|}{Expert}         
% &55.0$\pm$37.4
&60.9$\pm$19.0 &13.8$\pm$13.2 &62.8$\pm$\ \ 7.5 &\textbf{69.2$\pm$\ \ 8.7} \\
\multicolumn{1}{l|}{Medium}         
% &37.6$\pm$34.2
&19.8$\pm$14.1 &10.1$\pm$11.8 &\textbf{24.7$\pm$\ \ 8.4} &16.6$\pm$\ \ 7.4 \\
\multicolumn{1}{l|}{Medium-Expert}  
% &51.2$\pm$34.3
&37.5$\pm$17.4 &18.6$\pm$14.1 &38.2$\pm$11.9 &\textbf{40.3$\pm$12.8} \\
\multicolumn{1}{l|}{Medium-Replay}  
% &42.8$\pm$36.2
&13.6$\pm$7.6 &10.7$\pm$11.8 &11.0$\pm$10.8    &\textbf{13.6$\pm$\ \ 4.8} \\
\bottomrule"
299024,1706.03762v7,,Performance comparison,label,Table content here
