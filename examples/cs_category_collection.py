import psycopg2
import pandas as pd

class DatabaseAnalyzer:
    def __init__(self):
        self.conn = psycopg2.connect(
            host="localhost",
            port="5433",
            dbname="postgres",
            user="cl195"
        )
        self.conn.autocommit = True
        self.cur = self.conn.cursor()
        
        # å®šä¹‰åˆ†ç±»å’ŒæŸ¥è¯¢
        self.categories = ["cs.AI", "cs.LG", "cs.CV", "cs.RO", "cs.CR", 
                          "cs.DB", "cs.DC", "cs.PF", "cs.MA", "cs.OS"]
        
        self.statements = [
            """
            SELECT COUNT(*) FROM papers p
            JOIN paper_category pc ON p.arxiv_id = pc.paper_arxiv_id
            JOIN categories c ON pc.category_id = c.id
            WHERE c.name = %s;
            """,
            """
            SELECT COUNT(*) FROM sections s
            JOIN papers p ON s.paper_arxiv_id = p.arxiv_id
            JOIN paper_category pc ON p.arxiv_id = pc.paper_arxiv_id
            JOIN categories c ON pc.category_id = c.id
            WHERE c.name = %s;
            """,
            """
            SELECT COUNT(*) FROM paragraphs s
            JOIN papers p ON s.paper_arxiv_id = p.arxiv_id
            JOIN paper_category pc ON p.arxiv_id = pc.paper_arxiv_id
            JOIN categories c ON pc.category_id = c.id
            WHERE c.name = %s;
            """,
            """
            SELECT COUNT(*) FROM figures s
            JOIN papers p ON s.paper_arxiv_id = p.arxiv_id
            JOIN paper_category pc ON p.arxiv_id = pc.paper_arxiv_id
            JOIN categories c ON pc.category_id = c.id
            WHERE c.name = %s;
            """,
            """
            SELECT COUNT(*) FROM tables s
            JOIN papers p ON s.paper_arxiv_id = p.arxiv_id
            JOIN paper_category pc ON p.arxiv_id = pc.paper_arxiv_id
            JOIN categories c ON pc.category_id = c.id
            WHERE c.name = %s;
            """,
            """
            SELECT COUNT(DISTINCT a.semantic_scholar_id) FROM authors a
            JOIN paper_authors pa ON a.semantic_scholar_id = pa.author_id
            JOIN papers p ON pa.paper_arxiv_id = p.arxiv_id
            JOIN paper_category pc ON p.arxiv_id = pc.paper_arxiv_id
            JOIN categories c ON pc.category_id = c.id
            WHERE c.name = %s;
            """
        ]
        
        # åˆ—å
        self.column_names = ["paper", "section", "paragraph", "figure", "table", "author"]
    
    def execute_queries(self):
        """æ‰§è¡Œæ‰€æœ‰æŸ¥è¯¢å¹¶è¿”å›ç»“æœçŸ©é˜µ"""
        results = []
        
        for category in self.categories:
            row = [category]  # ç¬¬ä¸€åˆ—æ˜¯åˆ†ç±»å
            
            for statement in self.statements:
                try:
                    self.cur.execute(statement, (category,))
                    count = self.cur.fetchone()[0]
                    row.append(count)
                    print(f"âœ“ {category} - {self.column_names[len(row)-2]}: {count}")
                except Exception as e:
                    print(f"âœ— Error for {category}: {e}")
                    row.append(0)  # å‡ºé”™æ—¶å¡«0
            
            results.append(row)
        
        return results
    
    def create_dataframe(self, results):
        """åˆ›å»ºpandas DataFrame"""
        columns = ["category"] + self.column_names
        df = pd.DataFrame(results, columns=columns)
        return df
    
    def print_table(self, df):
        """æ‰“å°æ ¼å¼åŒ–çš„è¡¨æ ¼"""
        print("\n" + "="*80)
        print("Database Analysis Results")
        print("="*80)
        
        # æ‰“å°è¡¨å¤´
        header = f"{'Category':<10}"
        for col in self.column_names:
            header += f"{col.capitalize():<12}"
        print(header)
        print("-" * 80)
        
        # æ‰“å°æ•°æ®è¡Œ
        for _, row in df.iterrows():
            line = f"{row['category']:<10}"
            for col in self.column_names:
                line += f"{row[col]:<12}"
            print(line)
    
    def save_to_csv(self, df, filename="./csv/database_analysis.csv"):
        """ä¿å­˜åˆ°CSVæ–‡ä»¶"""
        df.to_csv(filename, index=False, encoding='utf-8')
        print(f"\nâœ“ Results saved to {filename}")
    
    def run_analysis(self):
        """è¿è¡Œå®Œæ•´çš„åˆ†ææµç¨‹"""
        try:
            print("Starting database analysis...")
            
            # æ‰§è¡ŒæŸ¥è¯¢
            results = self.execute_queries()
            
            # åˆ›å»ºDataFrame
            df = self.create_dataframe(results)
            
            # æ‰“å°è¡¨æ ¼
            self.print_table(df)
            
            # ä¿å­˜åˆ°CSV
            self.save_to_csv(df)
            
            # æ˜¾ç¤ºä¸€äº›ç»Ÿè®¡ä¿¡æ¯
            print(f"\nğŸ“Š Summary:")
            print(f"Total categories analyzed: {len(self.categories)}")
            print(f"Total papers across all categories: {df['paper'].sum():,}")
            print(f"Total authors across all categories: {df['author'].sum():,}")
            
            return df
            
        except Exception as e:
            print(f"Error during analysis: {e}")
            return None
        finally:
            self.close_connection()
    
    def close_connection(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.cur:
            self.cur.close()
        if self.conn:
            self.conn.close()
        print("âœ“ Database connection closed")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    analyzer = DatabaseAnalyzer()
    df = analyzer.run_analysis()
    
    # # å¦‚æœéœ€è¦è¿›ä¸€æ­¥å¤„ç†æ•°æ®
    # if df is not None:
    #     # ä¾‹å¦‚ï¼šæ‰¾åˆ°è®ºæ–‡æ•°é‡æœ€å¤šçš„åˆ†ç±»
    #     max_papers = df.loc[df['paper'].idxmax()]
    #     print(f"\nğŸ† Category with most papers: {max_papers['category']} ({max_papers['paper']} papers)")