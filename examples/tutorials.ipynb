{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17cb2429",
   "metadata": {},
   "source": [
    "# ResearchArcade Complete Tutorial\n",
    "\n",
    "This tutorial demonstrates how to work with the ResearchArcade database, covering all node types and edge relationships.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup](#Setup)\n",
    "2. [Node Table Operations](#NodeTableOperations)\n",
    "\n",
    "    2.1. [openreview_authors](#openreview_authors)\n",
    "\n",
    "    2.2. [openreview_papers](#openreview_papers)\n",
    "\n",
    "    2.3. [openreview_reviews](#openreview_reviews)\n",
    "\n",
    "    2.4. [openreview_revisions](#openreview_revisions)\n",
    "\n",
    "    2.5. [openreview_paragraphs](#openreview_paragraphs)\n",
    "\n",
    "    2.6. [arxiv_papers](#arxiv_papers)\n",
    "\n",
    "    2.7. [arxiv_authors](#arxiv_authors)\n",
    "\n",
    "    2.8. [arxiv_categories](#arxiv_categories)\n",
    "\n",
    "    2.9. [arxiv_figures](#arxiv_figures)\n",
    "\n",
    "    2.10. [arxiv_tables](#arxiv_tables)\n",
    "\n",
    "    2.11. [arxiv_sections](#arxiv_sections)\n",
    "\n",
    "    2.12. [arxiv_paragraphs](#arxiv_paragraphs)\n",
    "\n",
    "3. [Edge Table Operations](#EdgeTableOperations)\n",
    "\n",
    "    3.1. [openreview_arxiv](#openreview_arxiv)\n",
    "\n",
    "    3.2. [openreview_papers_authors](#openreview_papers_authors)\n",
    "\n",
    "    3.3. [openreview_papers_reviews](#openreview_papers_reviews)\n",
    "\n",
    "    3.4. [openreview_papers_revisions](#openreview_papers_revisions)\n",
    "\n",
    "    3.5. [openreview_revisions_reviews](#openreview_revisions_reviews)\n",
    "\n",
    "    3.6. [arxiv_citations](#arxiv_citations)\n",
    "\n",
    "    3.7. [arxiv_papers_authors](#arxiv_papers_authors)\n",
    "\n",
    "    3.8. [arxiv_papers_categories](#arxiv_papers_categories)\n",
    "\n",
    "    3.9. [arxiv_papers_figures](#arxiv_papers_figures)\n",
    "\n",
    "    3.10. [arxiv_papers_tables](#arxiv_papers_tables)\n",
    "\n",
    "    3.11. [arxiv_paragraphs_references](#arxiv_paragraphs_references)\n",
    "\n",
    "    3.12. [arxiv_paragraphs_citations](#arxiv_paragraphs_citations)\n",
    "\n",
    "4. [Batch Processing](#BatchProcessing)\n",
    "\n",
    "    4.1 [openreview conference](#batch_openreview_conference)\n",
    "\n",
    "    4.2 [openreview conference](#batch_arxiv_papers)\n",
    "\n",
    "5. [Continuous Crawling](#ContinuousCrawling)\n",
    "\n",
    "    5.1 [arxiv continuous crawling](#arxiv_continuous_crawling)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecef1ce",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8875af46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:paperscraper.load_dumps: No dump found for biorxiv. Skipping entry.\n",
      "WARNING:paperscraper.load_dumps: No dump found for chemrxiv. Skipping entry.\n",
      "WARNING:paperscraper.load_dumps: No dump found for medrxiv. Skipping entry.\n",
      "WARNING:paperscraper.load_dumps: No dumps found for either biorxiv, medrxiv and chemrxiv. Consider using paperscraper.get_dumps.* to fetch the dumps.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from research_arcade.research_arcade import ResearchArcade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baebeae7",
   "metadata": {},
   "source": [
    "### Choose Database Backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2760f392",
   "metadata": {},
   "source": [
    "#### CSV Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "633ed4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_type = \"csv\"\n",
    "config = {\n",
    "    \"csv_dir\": \"./csv3\",\n",
    "}\n",
    "\n",
    "research_arcade = ResearchArcade(db_type=db_type, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0516ba6f",
   "metadata": {},
   "source": [
    "#### SQL Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14a280a",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_type = \"sql\"\n",
    "config = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"dbname\": \"DATABASE_NAME\",\n",
    "    \"user\": \"USER_NAME\",\n",
    "    \"password\": \"PASSWORD\",\n",
    "    \"port\": \"5432\"\n",
    "}\n",
    "\n",
    "research_arcade = ResearchArcade(db_type=db_type, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635d46e5",
   "metadata": {},
   "source": [
    "## NodeTableOperations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06116fab",
   "metadata": {},
   "source": [
    "### openreview_authors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df912e97",
   "metadata": {},
   "source": [
    "#### construct table from api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b23cd76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling author data from OpenReview API...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m config = {\u001b[33m\"\u001b[39m\u001b[33mvenue\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mICLR.cc/2025/Conference\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mresearch_arcade\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstruct_table_from_api\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mopenreview_authors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/uiuc/research-arcade/research_arcade/research_arcade.py:638\u001b[39m, in \u001b[36mResearchArcade.construct_table_from_api\u001b[39m\u001b[34m(self, table, config)\u001b[39m\n\u001b[32m    636\u001b[39m     \u001b[38;5;28mself\u001b[39m.openreview_papers.construct_papers_table_from_api(**config)\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m table == \u001b[33m\"\u001b[39m\u001b[33mopenreview_authors\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m638\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopenreview_authors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstruct_authors_table_from_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m table == \u001b[33m\"\u001b[39m\u001b[33mopenreview_reviews\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    640\u001b[39m     \u001b[38;5;28mself\u001b[39m.openreview_reviews.construct_reviews_table_from_api(**config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/uiuc/research-arcade/research_arcade/csv_database/csv_openreview_authors.py:173\u001b[39m, in \u001b[36mCSVOpenReviewAuthors.construct_authors_table_from_api\u001b[39m\u001b[34m(self, venue)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconstruct_authors_table_from_api\u001b[39m(\u001b[38;5;28mself\u001b[39m, venue: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    171\u001b[39m     \u001b[38;5;66;03m# 从API爬取数据\u001b[39;00m\n\u001b[32m    172\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCrawling author data from OpenReview API...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m     author_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopenreview_crawler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcrawl_author_data_from_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvenue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m     \u001b[38;5;66;03m# 插入数据\u001b[39;00m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(author_data) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/uiuc/research-arcade/research_arcade/openreview_utils/openreview_crawler.py:156\u001b[39m, in \u001b[36mOpenReviewCrawler.crawl_author_data_from_api\u001b[39m\u001b[34m(self, venue)\u001b[39m\n\u001b[32m    154\u001b[39m         author_profiles = openreview.tools.get_profiles(\u001b[38;5;28mself\u001b[39m.client_v1, author_set)\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     submissions = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient_v2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_all_notes\u001b[49m\u001b[43m(\u001b[49m\u001b[43minvitation\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mvenue\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m/-/Submission\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m submissions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    158\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNo submissions found for venue: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvenue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/site-packages/openreview/api/client.py:1555\u001b[39m, in \u001b[36mOpenReviewClient.get_all_notes\u001b[39m\u001b[34m(self, id, paperhash, forum, invitation, replyto, signature, transitive_members, signatures, writer, trash, number, content, mintcdate, details, select, sort, with_count)\u001b[39m\n\u001b[32m   1552\u001b[39m         reverse = direction == \u001b[33m'\u001b[39m\u001b[33mdesc\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1553\u001b[39m         params[\u001b[33m'\u001b[39m\u001b[33msort\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Remove for API call, sort locally            \u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1555\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_notes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1556\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sort_key:\n\u001b[32m   1557\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(results, key=sort_key, reverse=reverse)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/site-packages/openreview/api/client.py:1424\u001b[39m, in \u001b[36mOpenReviewClient.get_notes\u001b[39m\u001b[34m(self, id, external_id, paperhash, forum, invitation, parent_invitations, replyto, tauthor, signature, transitive_members, signatures, writer, trash, number, content, limit, offset, after, mintcdate, domain, paper_hash, details, sort, with_count, stream)\u001b[39m\n\u001b[32m   1421\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1422\u001b[39m     params[\u001b[33m'\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m'\u001b[39m] = stream\n\u001b[32m-> \u001b[39m\u001b[32m1424\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnotes_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1425\u001b[39m response = \u001b[38;5;28mself\u001b[39m.__handle_response(response)\n\u001b[32m   1427\u001b[39m notes = [Note.from_json(n) \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m response.json()[\u001b[33m'\u001b[39m\u001b[33mnotes\u001b[39m\u001b[33m'\u001b[39m]]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/site-packages/requests/sessions.py:602\u001b[39m, in \u001b[36mSession.get\u001b[39m\u001b[34m(self, url, **kwargs)\u001b[39m\n\u001b[32m    594\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[32m    595\u001b[39m \n\u001b[32m    596\u001b[39m \u001b[33;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m    597\u001b[39m \u001b[33;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[32m    598\u001b[39m \u001b[33;03m:rtype: requests.Response\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    601\u001b[39m kwargs.setdefault(\u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/site-packages/requests/sessions.py:746\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    743\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    745\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m746\u001b[39m     \u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/site-packages/requests/models.py:902\u001b[39m, in \u001b[36mResponse.content\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    900\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    901\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m902\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[33;43mb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    904\u001b[39m \u001b[38;5;28mself\u001b[39m._content_consumed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    905\u001b[39m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[32m    906\u001b[39m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/site-packages/requests/models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/site-packages/urllib3/response.py:1246\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1230\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1231\u001b[39m \u001b[33;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[32m   1232\u001b[39m \u001b[33;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1243\u001b[39m \u001b[33;03m    'content-encoding' header.\u001b[39;00m\n\u001b[32m   1244\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.supports_chunked_reads():\n\u001b[32m-> \u001b[39m\u001b[32m1246\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.read_chunked(amt, decode_content=decode_content)\n\u001b[32m   1247\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1248\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m (\n\u001b[32m   1249\u001b[39m         \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp)\n\u001b[32m   1250\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m\n\u001b[32m   1251\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoder.has_unconsumed_tail)\n\u001b[32m   1252\u001b[39m     ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/site-packages/urllib3/response.py:1417\u001b[39m, in \u001b[36mHTTPResponse.read_chunked\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1415\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunk_left == \u001b[32m0\u001b[39m:\n\u001b[32m   1416\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1417\u001b[39m     chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1418\u001b[39m decoded = \u001b[38;5;28mself\u001b[39m._decode(\n\u001b[32m   1419\u001b[39m     chunk,\n\u001b[32m   1420\u001b[39m     decode_content=decode_content,\n\u001b[32m   1421\u001b[39m     flush_decoder=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1422\u001b[39m     max_length=amt,\n\u001b[32m   1423\u001b[39m )\n\u001b[32m   1424\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m decoded:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/site-packages/urllib3/response.py:1354\u001b[39m, in \u001b[36mHTTPResponse._handle_chunk\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m   1352\u001b[39m     returned_chunk = value\n\u001b[32m   1353\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m amt == \u001b[38;5;28mself\u001b[39m.chunk_left:\n\u001b[32m-> \u001b[39m\u001b[32m1354\u001b[39m     value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_safe_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m   1355\u001b[39m     \u001b[38;5;28mself\u001b[39m._fp._safe_read(\u001b[32m2\u001b[39m)  \u001b[38;5;66;03m# type: ignore[union-attr] # Toss the CRLF at the end of the chunk.\u001b[39;00m\n\u001b[32m   1356\u001b[39m     \u001b[38;5;28mself\u001b[39m.chunk_left = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/http/client.py:642\u001b[39m, in \u001b[36mHTTPResponse._safe_read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_safe_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, amt):\n\u001b[32m    636\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[32m    637\u001b[39m \n\u001b[32m    638\u001b[39m \u001b[33;03m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[32m    639\u001b[39m \u001b[33;03m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[32m    640\u001b[39m \u001b[33;03m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[32m    641\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m642\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    643\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) < amt:\n\u001b[32m    644\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt-\u001b[38;5;28mlen\u001b[39m(data))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/socket.py:720\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    722\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/ssl.py:1251\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1247\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1248\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1249\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1250\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/ssl.py:1103\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "config = {\"venue\": \"ICLR.cc/2025/Conference\"}\n",
    "research_arcade.construct_table_from_api(\"openreview_authors\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cfa6cc",
   "metadata": {},
   "source": [
    "#### construct table from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a3ebdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading authors data from /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/csv_data/openreview_authors.csv...\n",
      "Inserting data into CSV file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 929.30it/s]\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"/home/jingjunx/openreview_benchmark/Code/research-arcade/examples/csv_data/openreview_authors.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"openreview_authors\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411b2026",
   "metadata": {},
   "source": [
    "#### construct table from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b660cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading authors data from /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/json_data/openreview_authors.json...\n",
      "Inserting data into CSV file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 348.01it/s]\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"/home/jingjunx/openreview_benchmark/Code/research-arcade/examples/json_data/openreview_authors.json\"}\n",
    "research_arcade.construct_table_from_json(\"openreview_authors\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a627c1d",
   "metadata": {},
   "source": [
    "#### insert node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf3806a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ICLR.cc/2025/Conference', '~ishmam_zabir1')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_author = {'venue': 'ICLR.cc/2025/Conference', \n",
    "              'author_openreview_id': '~ishmam_zabir1', \n",
    "              'author_full_name': 'ishmam zabir', \n",
    "              'email': '****@microsoft.com', \n",
    "              'affiliation': 'Microsoft', \n",
    "              'homepage': 'https://scholar.google.com/citations?user=X7bjzrUAAAAJ&hl=en&oi=ao', \n",
    "              'dblp': ''}\n",
    "research_arcade.insert_node(\"openreview_authors\", node_features=new_author)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64cf4c2",
   "metadata": {},
   "source": [
    "#### delete specific node by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b9affa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author with author_openreview_id ~ishmam_zabir1 deleted successfully.\n",
      "{'venue': 'ICLR.cc/2025/Conference', 'author_openreview_id': '~ishmam_zabir1', 'author_full_name': 'ishmam zabir', 'email': '****@microsoft.com', 'affiliation': 'Microsoft', 'homepage': 'https://scholar.google.com/citations?user=X7bjzrUAAAAJ&hl=en&oi=ao', 'dblp': nan}\n"
     ]
    }
   ],
   "source": [
    "author_id = {\"author_openreview_id\": \"~ishmam_zabir1\"}\n",
    "author_features = research_arcade.delete_node_by_id(\"openreview_authors\", author_id)\n",
    "print(author_features.to_dict(orient=\"records\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df28da83",
   "metadata": {},
   "source": [
    "#### get all nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf7cf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "openreview_authors_df = research_arcade.get_all_node_features(\"openreview_authors\")\n",
    "print(len(openreview_authors_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893300f4",
   "metadata": {},
   "source": [
    "#### get specific node by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3fe84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'venue': 'ICLR.cc/2025/Conference', 'author_openreview_id': '~ishmam_zabir1', 'author_full_name': 'ishmam zabir', 'email': '****@microsoft.com', 'affiliation': 'Microsoft', 'homepage': 'https://scholar.google.com/citations?user=X7bjzrUAAAAJ&hl=en&oi=ao', 'dblp': nan}\n"
     ]
    }
   ],
   "source": [
    "author_id = {\"author_openreview_id\": \"~ishmam_zabir1\"}\n",
    "author_features = research_arcade.get_node_features_by_id(\"openreview_authors\", author_id)\n",
    "print(author_features.to_dict(orient=\"records\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a604a55",
   "metadata": {},
   "source": [
    "#### update specific node by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f18161c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author with author_openreview_id ~ishmam_zabir1 updated successfully.\n",
      "{'venue': 'ICLR.cc/2025/Conference', 'author_openreview_id': '~ishmam_zabir1', 'author_full_name': 'hii', 'email': '****@microsoft.com', 'affiliation': 'Microsoft', 'homepage': 'https://scholar.google.com/citations?user=X7bjzrUAAAAJ&hl=en&oi=ao', 'dblp': nan}\n"
     ]
    }
   ],
   "source": [
    "new_author = {'venue': 'ICLR.cc/2025/Conference', \n",
    "              'author_openreview_id': '~ishmam_zabir1', \n",
    "              'author_full_name': 'test', \n",
    "              'email': '****@microsoft.com', \n",
    "              'affiliation': 'Microsoft', \n",
    "              'homepage': 'https://scholar.google.com/citations?user=X7bjzrUAAAAJ&hl=en&oi=ao', \n",
    "              'dblp': ''}\n",
    "\n",
    "research_arcade.update_node(\"openreview_authors\", node_features=new_author)\n",
    "author_id = {\"author_openreview_id\": \"~ishmam_zabir1\"}\n",
    "author_features = research_arcade.get_node_features_by_id(\"openreview_authors\", author_id)\n",
    "print(author_features.to_dict(orient=\"records\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d64840",
   "metadata": {},
   "source": [
    "### openreview_papers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0d9e86",
   "metadata": {},
   "source": [
    "#### construct table from api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c4ac22",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"venue\": \"ICLR.cc/2025/Conference\"}\n",
    "research_arcade.construct_table_from_api(\"openreview_papers\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51bb022",
   "metadata": {},
   "source": [
    "#### construct table from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9403d630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading paper data from /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/csv_data/openreview_papers.csv...\n",
      "Inserting data into CSV file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 18/508 [00:00<00:05, 88.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 508/508 [00:05<00:00, 96.62it/s] \n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"/home/jingjunx/openreview_benchmark/Code/research-arcade/examples/csv_data/openreview_papers.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"openreview_papers\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98231ecf",
   "metadata": {},
   "source": [
    "#### construct table from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30114a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading paper data from /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/json_data/openreview_papers.json...\n",
      "Inserting data into CSV file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 77.70it/s]\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"/home/jingjunx/openreview_benchmark/Code/research-arcade/examples/json_data/openreview_papers.json\"}\n",
    "research_arcade.construct_table_from_json(\"openreview_papers\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c265e0",
   "metadata": {},
   "source": [
    "#### insert node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d11550d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ICLR.cc/2025/Conference', 'zGej22CBnS')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_features = {'venue': 'ICLR.cc/2025/Conference', \n",
    "                  'paper_openreview_id': 'zGej22CBnS', \n",
    "                  'title': 'Exact Byte-Level Probabilities from Tokenized Language Models for FIM-Tasks and Model Ensembles', \n",
    "                  'abstract': \"Tokenization is associated with many poorly understood shortcomings in language models (LMs), yet remains an important component for long sequence scaling purposes. This work studies  how tokenization impacts  model performance by analyzing and comparing the stochastic behavior of tokenized models with their byte-level, or token-free, counterparts. We discover that, even when the two models are statistically equivalent, their predictive distributions over the next byte can be substantially different, a phenomenon we term as ``tokenization bias''. To fully characterize this phenomenon, we  introduce the Byte-Token Representation Lemma, a framework that establishes a mapping between the learned token distribution and its equivalent byte-level distribution.  From this result, we develop a next-byte sampling algorithm  that eliminates tokenization bias without requiring further training or optimization. In other words, this enables zero-shot conversion of tokenized LMs into statistically equivalent token-free ones. We demonstrate its broad applicability with two use cases: fill-in-the-middle (FIM) tasks and model ensembles. In FIM tasks where input prompts may terminate mid-token, leading to out-of-distribution tokenization, our method mitigates performance degradation and achieves 18\\\\% improvement in FIM coding benchmarks, while consistently outperforming the standard token healing fix. For model ensembles where each model employs a distinct vocabulary, our approach enables seamless integration, resulting in improved performance up to 3.7\\\\% over individual models across various standard baselines in reasoning, knowledge, and coding. Code is available at:https: //github.com/facebookresearch/Exact-Byte-Level-Probabilities-from-Tokenized-LMs.\", \n",
    "                  'paper_decision': 'ICLR 2025 Poster', \n",
    "                  'paper_pdf_link': '/pdf/cdd2212a20c4034029874cba11a05e081bfdb83e.pdf'}\n",
    "research_arcade.insert_node(\"openreview_papers\", node_features=paper_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eb27a5",
   "metadata": {},
   "source": [
    "#### delete specific node by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e71395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper with paper_openreview_id zGej22CBnS deleted successfully.\n",
      "{'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': 'zGej22CBnS', 'title': 'Exact Byte-Level Probabilities from Tokenized Language Models for FIM-Tasks and Model Ensembles', 'abstract': \"Tokenization is associated with many poorly understood shortcomings in language models (LMs), yet remains an important component for long sequence scaling purposes. This work studies  how tokenization impacts  model performance by analyzing and comparing the stochastic behavior of tokenized models with their byte-level, or token-free, counterparts. We discover that, even when the two models are statistically equivalent, their predictive distributions over the next byte can be substantially different, a phenomenon we term as ``tokenization bias''. To fully characterize this phenomenon, we  introduce the Byte-Token Representation Lemma, a framework that establishes a mapping between the learned token distribution and its equivalent byte-level distribution.  From this result, we develop a next-byte sampling algorithm  that eliminates tokenization bias without requiring further training or optimization. In other words, this enables zero-shot conversion of tokenized LMs into statistically equivalent token-free ones. We demonstrate its broad applicability with two use cases: fill-in-the-middle (FIM) tasks and model ensembles. In FIM tasks where input prompts may terminate mid-token, leading to out-of-distribution tokenization, our method mitigates performance degradation and achieves 18\\\\% improvement in FIM coding benchmarks, while consistently outperforming the standard token healing fix. For model ensembles where each model employs a distinct vocabulary, our approach enables seamless integration, resulting in improved performance up to 3.7\\\\% over individual models across various standard baselines in reasoning, knowledge, and coding. Code is available at:https: //github.com/facebookresearch/Exact-Byte-Level-Probabilities-from-Tokenized-LMs.\", 'paper_decision': 'ICLR 2025 Poster', 'paper_pdf_link': '/pdf/cdd2212a20c4034029874cba11a05e081bfdb83e.pdf'}\n"
     ]
    }
   ],
   "source": [
    "paper_id = {\"paper_openreview_id\": \"zGej22CBnS\"}\n",
    "paper_features = research_arcade.delete_node_by_id(\"openreview_papers\", paper_id)\n",
    "print(paper_features.to_dict(orient=\"records\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d38a80",
   "metadata": {},
   "source": [
    "#### get all nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3b0a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "openreview_papers_df = research_arcade.get_all_node_features(\"openreview_papers\")\n",
    "print(len(openreview_papers_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b46ea2",
   "metadata": {},
   "source": [
    "#### get specific node by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bec63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': 'zGej22CBnS', 'title': 'Exact Byte-Level Probabilities from Tokenized Language Models for FIM-Tasks and Model Ensembles', 'abstract': \"Tokenization is associated with many poorly understood shortcomings in language models (LMs), yet remains an important component for long sequence scaling purposes. This work studies  how tokenization impacts  model performance by analyzing and comparing the stochastic behavior of tokenized models with their byte-level, or token-free, counterparts. We discover that, even when the two models are statistically equivalent, their predictive distributions over the next byte can be substantially different, a phenomenon we term as ``tokenization bias''. To fully characterize this phenomenon, we  introduce the Byte-Token Representation Lemma, a framework that establishes a mapping between the learned token distribution and its equivalent byte-level distribution.  From this result, we develop a next-byte sampling algorithm  that eliminates tokenization bias without requiring further training or optimization. In other words, this enables zero-shot conversion of tokenized LMs into statistically equivalent token-free ones. We demonstrate its broad applicability with two use cases: fill-in-the-middle (FIM) tasks and model ensembles. In FIM tasks where input prompts may terminate mid-token, leading to out-of-distribution tokenization, our method mitigates performance degradation and achieves 18\\\\% improvement in FIM coding benchmarks, while consistently outperforming the standard token healing fix. For model ensembles where each model employs a distinct vocabulary, our approach enables seamless integration, resulting in improved performance up to 3.7\\\\% over individual models across various standard baselines in reasoning, knowledge, and coding. Code is available at:https: //github.com/facebookresearch/Exact-Byte-Level-Probabilities-from-Tokenized-LMs.\", 'paper_decision': 'ICLR 2025 Poster', 'paper_pdf_link': '/pdf/cdd2212a20c4034029874cba11a05e081bfdb83e.pdf'}\n"
     ]
    }
   ],
   "source": [
    "paper_id = {\"paper_openreview_id\": \"zGej22CBnS\"}\n",
    "paper_features = research_arcade.get_node_features_by_id(\"openreview_papers\", paper_id)\n",
    "print(paper_features.to_dict(orient=\"records\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ca432c",
   "metadata": {},
   "source": [
    "#### update specific node by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ee5f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper with paper_openreview_id zGej22CBnS updated successfully.\n",
      "{'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': 'zGej22CBnS', 'title': 'Exact Byte-Level Probabilities from Tokenized Language Models for FIM-Tasks and Model Ensembles', 'abstract': \"Tokenization is associated with many poorly understood shortcomings in language models (LMs), yet remains an important component for long sequence scaling purposes. This work studies  how tokenization impacts  model performance by analyzing and comparing the stochastic behavior of tokenized models with their byte-level, or token-free, counterparts. We discover that, even when the two models are statistically equivalent, their predictive distributions over the next byte can be substantially different, a phenomenon we term as ``tokenization bias''. To fully characterize this phenomenon, we  introduce the Byte-Token Representation Lemma, a framework that establishes a mapping between the learned token distribution and its equivalent byte-level distribution.  From this result, we develop a next-byte sampling algorithm  that eliminates tokenization bias without requiring further training or optimization. In other words, this enables zero-shot conversion of tokenized LMs into statistically equivalent token-free ones. We demonstrate its broad applicability with two use cases: fill-in-the-middle (FIM) tasks and model ensembles. In FIM tasks where input prompts may terminate mid-token, leading to out-of-distribution tokenization, our method mitigates performance degradation and achieves 18\\\\% improvement in FIM coding benchmarks, while consistently outperforming the standard token healing fix. For model ensembles where each model employs a distinct vocabulary, our approach enables seamless integration, resulting in improved performance up to 3.7\\\\% over individual models across various standard baselines in reasoning, knowledge, and coding. Code is available at:https: //github.com/facebookresearch/Exact-Byte-Level-Probabilities-from-Tokenized-LMs.\", 'paper_decision': 'test', 'paper_pdf_link': '/pdf/cdd2212a20c4034029874cba11a05e081bfdb83e.pdf'}\n"
     ]
    }
   ],
   "source": [
    "new_paper_features = {'venue': 'ICLR.cc/2025/Conference', \n",
    "                  'paper_openreview_id': 'zGej22CBnS', \n",
    "                  'title': 'Exact Byte-Level Probabilities from Tokenized Language Models for FIM-Tasks and Model Ensembles', \n",
    "                  'abstract': \"Tokenization is associated with many poorly understood shortcomings in language models (LMs), yet remains an important component for long sequence scaling purposes. This work studies  how tokenization impacts  model performance by analyzing and comparing the stochastic behavior of tokenized models with their byte-level, or token-free, counterparts. We discover that, even when the two models are statistically equivalent, their predictive distributions over the next byte can be substantially different, a phenomenon we term as ``tokenization bias''. To fully characterize this phenomenon, we  introduce the Byte-Token Representation Lemma, a framework that establishes a mapping between the learned token distribution and its equivalent byte-level distribution.  From this result, we develop a next-byte sampling algorithm  that eliminates tokenization bias without requiring further training or optimization. In other words, this enables zero-shot conversion of tokenized LMs into statistically equivalent token-free ones. We demonstrate its broad applicability with two use cases: fill-in-the-middle (FIM) tasks and model ensembles. In FIM tasks where input prompts may terminate mid-token, leading to out-of-distribution tokenization, our method mitigates performance degradation and achieves 18\\\\% improvement in FIM coding benchmarks, while consistently outperforming the standard token healing fix. For model ensembles where each model employs a distinct vocabulary, our approach enables seamless integration, resulting in improved performance up to 3.7\\\\% over individual models across various standard baselines in reasoning, knowledge, and coding. Code is available at:https: //github.com/facebookresearch/Exact-Byte-Level-Probabilities-from-Tokenized-LMs.\", \n",
    "                  'paper_decision': 'test', \n",
    "                  'paper_pdf_link': '/pdf/cdd2212a20c4034029874cba11a05e081bfdb83e.pdf'}\n",
    "research_arcade.update_node(\"openreview_papers\", node_features=new_paper_features)\n",
    "paper_id = {\"paper_openreview_id\": \"zGej22CBnS\"}\n",
    "paper_features = research_arcade.get_node_features_by_id(\"openreview_papers\", paper_id)\n",
    "print(paper_features.to_dict(orient=\"records\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f3c2a6",
   "metadata": {},
   "source": [
    "### openreview_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82412cd",
   "metadata": {},
   "source": [
    "#### construct table from api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f01ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"venue\": \"ICLR.cc/2013/conference\"}\n",
    "research_arcade.construct_table_from_api(\"openreview_reviews\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1814923a",
   "metadata": {},
   "source": [
    "#### construct table from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce125b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading review data from /home/jingjunx/openreview_benchmark/Code/paper-crawler/examples/csv_data/csv_openreview_review_example.csv...\n",
      "Inserting data into CSV file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 69.43it/s]\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"/home/jingjunx/openreview_benchmark/Code/paper-crawler/examples/csv_data/csv_openreview_review_example.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"openreview_reviews\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dff25f",
   "metadata": {},
   "source": [
    "#### construct table from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884c5ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading review data from /home/jingjunx/openreview_benchmark/Code/paper-crawler/examples/json_data/json_openreview_review_example.json...\n",
      "Inserting data into CSV file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 139.39it/s]\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"/home/jingjunx/openreview_benchmark/Code/paper-crawler/examples/json_data/json_openreview_review_example.json\"}\n",
    "research_arcade.construct_table_from_json(\"openreview_reviews\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c59c8e",
   "metadata": {},
   "source": [
    "#### insert node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b36504a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ICLR.cc/2025/Conference', 'DHwZxFryth')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_features = {'venue': 'ICLR.cc/2025/Conference', \n",
    "                   'review_openreview_id': 'DHwZxFryth', \n",
    "                   'replyto_openreview_id': 'Yqbllggrmw', \n",
    "                   'writer': 'Authors', \n",
    "                   'title': 'Response by Authors', \n",
    "                   'content': {'Title': 'Response to Reviewer 7i95 (1/2)', 'Comment': '> The method does not improve much in the AlpacaEval 2.0 Score. The author should give a detailed explanation. And why not use metrics like length-controlled win rate?**Response:** Thank you for your careful observation and question. We would like to clarify that we are already using the length-controlled (LC) AlpacaEval 2.0 win-rate metric in our evaluations. We will make this clearer in the table header of Table 3.Regarding the fact that the AlpacaEval 2.0 scores on LLama-3 (8B) do not improve compared to the baselines, we believe this is because our base model, the instruction-finetuned LLama-3 (8B), is already trained to perform exceptionally well in terms of helpfulness, which is the focus of the AlpacaEval benchmark. Additionally, the preference dataset we used, UltraFeedback, may not provide significant further enhancement in the helpfulness aspect. This is supported by the slight decrease observed in the AlpacaEval score for the standard DPO baseline as well (see Table 3, results on LLama-3). Therefore, we think these AlpacaEval 2.0 results on LLama-3 (8B) may not indicate that SAIL is ineffective; it may be simply caused by an ill-suited combination of base model, finetuning dataset, and evaluation benchmark.We also further conducted experiments on the Zephyr (7B) model as the backbone, whose AlpacaEval 2.0 win-rate is lower. We still train on the UltraFeedback preference dataset and the other experiment setups are unchanged. In this experiment, we see a larger improvement of the SAIL method compared to the standard DPO baseline (Zephyr-7B-Beta).|             | AlpacaEval 2.0 (LC) Win-Rate ||--------------------|------------------------------|| Base (Zephyr-7B-SFT-Full) | 6.4 %                        || DPO (Zephyr-7B-Beta)   | 13.2 %                       || SAIL-PP  | 15.9 %                       |> Authors should compare more advanced preference optimization algorithms like ORPO and SimPO. And current results are not impressive for the alignment community.**Response:** Thank you for raising this insightful point. We see ORPO and SimPO are two recent work which propose a different objective than the standard RLHF, and achieve remarkable improvements in terms of alignment performance and efficiency.Our work focus more on bringing standard RLHF to a bilevel optimization framework and propose an effective and efficient approximate algorithm on top of it. We can see some new preference optimization methods including ORPO and SimPO have one fundamental difference from our approach: they do not explicitly incorporate the KL regularization term. The absence of the KL regularization term allows these methods to optimize more aggressively for the reward function by deviating significantly from the reference model. In contrast, our approach is specifically grounded in the standard RLHF, where the KL regularization term ensures that the model remains aligned with the reference distribution while optimizing for the reward function. This distinction makes direct comparisons with ORPO or SimPO less meaningful theoretically, as those methods omit the KL regularization and adopt a fundamentally different optimization objective design.However, we think our work, although developed adhering to the standard RLHF setup, can be compatible and combined with some recent advanced preference optimization algorithms, despite their differences in optimization setups and objectives. This is because we can reformulate their alignment problem as bilevel optimization, and go through the derivation as done in the paper. Taking SimPO as an example, we can treat their reward model definition (Equation (4) in '\n",
    "                   'the SimPO paper) as the solution of the upper level optimization (replacing Equation (4) in our manuscript), and adopt their modified Bradley-Terry objective with reward margin (Equation (5) in the SimPO paper) to replace the standard one (Equation (10) in our manuscript). By applying these changes and rederiving the extra gradient terms, we can formulate an adaptation of our method to the SimPO objective. We will implement this combined algorithm, which adapt our methodology to the SimPO objective, and compare with the SimPO as a baseline.Recently many different alignment objectives and algorithms have emerged; it is an interesting question to discuss the compatibility and combination of our method with each objective. We will add more relevant discussions to the appendices, but due to the fact that the compatibility problem with each design is a non-trivial question, this process may incur considerably more work, and we hope the reviewer understands that this effort cannot be fully reflected by the rebuttal period. But we will continue to expand the discussion as the wide compatibility to other designs also strengthens our contribution to the community. We thank the reviewer for raising this insightful point.'}, \n",
    "                   'time': '2024-11-26 15:27:26'\n",
    "}\n",
    "research_arcade.insert_node(\"openreview_reviews\", node_features=review_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f442d7",
   "metadata": {},
   "source": [
    "#### delete specific node by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7ca23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review with review_openreview_id DHwZxFryth deleted successfully.\n",
      "{'venue': 'ICLR.cc/2025/Conference', 'review_openreview_id': 'DHwZxFryth', 'replyto_openreview_id': 'Yqbllggrmw', 'writer': 'Authors', 'title': 'Response by Authors', 'content': {'Title': 'Response to Reviewer 7i95 (1/2)', 'Comment': '> The method does not improve much in the AlpacaEval 2.0 Score. The author should give a detailed explanation. And why not use metrics like length-controlled win rate?**Response:** Thank you for your careful observation and question. We would like to clarify that we are already using the length-controlled (LC) AlpacaEval 2.0 win-rate metric in our evaluations. We will make this clearer in the table header of Table 3.Regarding the fact that the AlpacaEval 2.0 scores on LLama-3 (8B) do not improve compared to the baselines, we believe this is because our base model, the instruction-finetuned LLama-3 (8B), is already trained to perform exceptionally well in terms of helpfulness, which is the focus of the AlpacaEval benchmark. Additionally, the preference dataset we used, UltraFeedback, may not provide significant further enhancement in the helpfulness aspect. This is supported by the slight decrease observed in the AlpacaEval score for the standard DPO baseline as well (see Table 3, results on LLama-3). Therefore, we think these AlpacaEval 2.0 results on LLama-3 (8B) may not indicate that SAIL is ineffective; it may be simply caused by an ill-suited combination of base model, finetuning dataset, and evaluation benchmark.We also further conducted experiments on the Zephyr (7B) model as the backbone, whose AlpacaEval 2.0 win-rate is lower. We still train on the UltraFeedback preference dataset and the other experiment setups are unchanged. In this experiment, we see a larger improvement of the SAIL method compared to the standard DPO baseline (Zephyr-7B-Beta).|             | AlpacaEval 2.0 (LC) Win-Rate ||--------------------|------------------------------|| Base (Zephyr-7B-SFT-Full) | 6.4 %                        || DPO (Zephyr-7B-Beta)   | 13.2 %                       || SAIL-PP  | 15.9 %                       |> Authors should compare more advanced preference optimization algorithms like ORPO and SimPO. And current results are not impressive for the alignment community.**Response:** Thank you for raising this insightful point. We see ORPO and SimPO are two recent work which propose a different objective than the standard RLHF, and achieve remarkable improvements in terms of alignment performance and efficiency.Our work focus more on bringing standard RLHF to a bilevel optimization framework and propose an effective and efficient approximate algorithm on top of it. We can see some new preference optimization methods including ORPO and SimPO have one fundamental difference from our approach: they do not explicitly incorporate the KL regularization term. The absence of the KL regularization term allows these methods to optimize more aggressively for the reward function by deviating significantly from the reference model. In contrast, our approach is specifically grounded in the standard RLHF, where the KL regularization term ensures that the model remains aligned with the reference distribution while optimizing for the reward function. This distinction makes direct comparisons with ORPO or SimPO less meaningful theoretically, as those methods omit the KL regularization and adopt a fundamentally different optimization objective design.However, we think our work, although developed adhering to the standard RLHF setup, can be compatible and combined with some recent advanced preference optimization algorithms, despite their differences in optimization setups and objectives. This is because we can reformulate their alignment problem as bilevel optimization, and go through the derivation as done in the paper. Taking SimPO as an example, we can treat their reward model definition (Equation (4) in the SimPO paper) as the solution of the upper level optimization (replacing Equation (4) in our manuscript), and adopt their modified Bradley-Terry objective with reward margin (Equation (5) in the SimPO paper) to replace the standard one (Equation (10) in our manuscript). By applying these changes and rederiving the extra gradient terms, we can formulate an adaptation of our method to the SimPO objective. We will implement this combined algorithm, which adapt our methodology to the SimPO objective, and compare with the SimPO as a baseline.Recently many different alignment objectives and algorithms have emerged; it is an interesting question to discuss the compatibility and combination of our method with each objective. We will add more relevant discussions to the appendices, but due to the fact that the compatibility problem with each design is a non-trivial question, this process may incur considerably more work, and we hope the reviewer understands that this effort cannot be fully reflected by the rebuttal period. But we will continue to expand the discussion as the wide compatibility to other designs also strengthens our contribution to the community. We thank the reviewer for raising this insightful point.'}, 'time': '2024-11-26 15:27:26'}\n"
     ]
    }
   ],
   "source": [
    "review_id = {\"review_openreview_id\": \"DHwZxFryth\"}\n",
    "review_features = research_arcade.delete_node_by_id(\"openreview_reviews\", review_id)\n",
    "print(review_features.to_dict(orient=\"records\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957f92ce",
   "metadata": {},
   "source": [
    "#### get all nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c314d180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "openreview_reviews_df = research_arcade.get_all_node_features(\"openreview_reviews\")\n",
    "print(len(openreview_reviews_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d21d2f8",
   "metadata": {},
   "source": [
    "#### get specific node by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b3b2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'venue': 'ICLR.cc/2025/Conference', 'review_openreview_id': 'DHwZxFryth', 'replyto_openreview_id': 'Yqbllggrmw', 'writer': 'Authors', 'title': 'Response by Authors', 'content': {'Title': 'Response to Reviewer 7i95 (1/2)', 'Comment': '> The method does not improve much in the AlpacaEval 2.0 Score. The author should give a detailed explanation. And why not use metrics like length-controlled win rate?**Response:** Thank you for your careful observation and question. We would like to clarify that we are already using the length-controlled (LC) AlpacaEval 2.0 win-rate metric in our evaluations. We will make this clearer in the table header of Table 3.Regarding the fact that the AlpacaEval 2.0 scores on LLama-3 (8B) do not improve compared to the baselines, we believe this is because our base model, the instruction-finetuned LLama-3 (8B), is already trained to perform exceptionally well in terms of helpfulness, which is the focus of the AlpacaEval benchmark. Additionally, the preference dataset we used, UltraFeedback, may not provide significant further enhancement in the helpfulness aspect. This is supported by the slight decrease observed in the AlpacaEval score for the standard DPO baseline as well (see Table 3, results on LLama-3). Therefore, we think these AlpacaEval 2.0 results on LLama-3 (8B) may not indicate that SAIL is ineffective; it may be simply caused by an ill-suited combination of base model, finetuning dataset, and evaluation benchmark.We also further conducted experiments on the Zephyr (7B) model as the backbone, whose AlpacaEval 2.0 win-rate is lower. We still train on the UltraFeedback preference dataset and the other experiment setups are unchanged. In this experiment, we see a larger improvement of the SAIL method compared to the standard DPO baseline (Zephyr-7B-Beta).|             | AlpacaEval 2.0 (LC) Win-Rate ||--------------------|------------------------------|| Base (Zephyr-7B-SFT-Full) | 6.4 %                        || DPO (Zephyr-7B-Beta)   | 13.2 %                       || SAIL-PP  | 15.9 %                       |> Authors should compare more advanced preference optimization algorithms like ORPO and SimPO. And current results are not impressive for the alignment community.**Response:** Thank you for raising this insightful point. We see ORPO and SimPO are two recent work which propose a different objective than the standard RLHF, and achieve remarkable improvements in terms of alignment performance and efficiency.Our work focus more on bringing standard RLHF to a bilevel optimization framework and propose an effective and efficient approximate algorithm on top of it. We can see some new preference optimization methods including ORPO and SimPO have one fundamental difference from our approach: they do not explicitly incorporate the KL regularization term. The absence of the KL regularization term allows these methods to optimize more aggressively for the reward function by deviating significantly from the reference model. In contrast, our approach is specifically grounded in the standard RLHF, where the KL regularization term ensures that the model remains aligned with the reference distribution while optimizing for the reward function. This distinction makes direct comparisons with ORPO or SimPO less meaningful theoretically, as those methods omit the KL regularization and adopt a fundamentally different optimization objective design.However, we think our work, although developed adhering to the standard RLHF setup, can be compatible and combined with some recent advanced preference optimization algorithms, despite their differences in optimization setups and objectives. This is because we can reformulate their alignment problem as bilevel optimization, and go through the derivation as done in the paper. Taking SimPO as an example, we can treat their reward model definition (Equation (4) in the SimPO paper) as the solution of the upper level optimization (replacing Equation (4) in our manuscript), and adopt their modified Bradley-Terry objective with reward margin (Equation (5) in the SimPO paper) to replace the standard one (Equation (10) in our manuscript). By applying these changes and rederiving the extra gradient terms, we can formulate an adaptation of our method to the SimPO objective. We will implement this combined algorithm, which adapt our methodology to the SimPO objective, and compare with the SimPO as a baseline.Recently many different alignment objectives and algorithms have emerged; it is an interesting question to discuss the compatibility and combination of our method with each objective. We will add more relevant discussions to the appendices, but due to the fact that the compatibility problem with each design is a non-trivial question, this process may incur considerably more work, and we hope the reviewer understands that this effort cannot be fully reflected by the rebuttal period. But we will continue to expand the discussion as the wide compatibility to other designs also strengthens our contribution to the community. We thank the reviewer for raising this insightful point.'}, 'time': '2024-11-26 15:27:26'}\n"
     ]
    }
   ],
   "source": [
    "review_id = {\"review_openreview_id\": \"DHwZxFryth\"}\n",
    "review_features = research_arcade.get_node_features_by_id(\"openreview_reviews\", review_id)\n",
    "print(review_features.to_dict(orient=\"records\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49146a7e",
   "metadata": {},
   "source": [
    "#### update specific node by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7672f177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review with review_openreview_id DHwZxFryth updated successfully.\n",
      "{'venue': 'ICLR.cc/2025/Conference', 'review_openreview_id': 'DHwZxFryth', 'replyto_openreview_id': 'Yqbllggrmw', 'writer': 'test', 'title': 'Response by Authors', 'content': {'Title': 'Response to Reviewer 7i95 (1/2)', 'Comment': '> The method does not improve much in the AlpacaEval 2.0 Score. The author should give a detailed explanation. And why not use metrics like length-controlled win rate?**Response:** Thank you for your careful observation and question. We would like to clarify that we are already using the length-controlled (LC) AlpacaEval 2.0 win-rate metric in our evaluations. We will make this clearer in the table header of Table 3.Regarding the fact that the AlpacaEval 2.0 scores on LLama-3 (8B) do not improve compared to the baselines, we believe this is because our base model, the instruction-finetuned LLama-3 (8B), is already trained to perform exceptionally well in terms of helpfulness, which is the focus of the AlpacaEval benchmark. Additionally, the preference dataset we used, UltraFeedback, may not provide significant further enhancement in the helpfulness aspect. This is supported by the slight decrease observed in the AlpacaEval score for the standard DPO baseline as well (see Table 3, results on LLama-3). Therefore, we think these AlpacaEval 2.0 results on LLama-3 (8B) may not indicate that SAIL is ineffective; it may be simply caused by an ill-suited combination of base model, finetuning dataset, and evaluation benchmark.We also further conducted experiments on the Zephyr (7B) model as the backbone, whose AlpacaEval 2.0 win-rate is lower. We still train on the UltraFeedback preference dataset and the other experiment setups are unchanged. In this experiment, we see a larger improvement of the SAIL method compared to the standard DPO baseline (Zephyr-7B-Beta).|             | AlpacaEval 2.0 (LC) Win-Rate ||--------------------|------------------------------|| Base (Zephyr-7B-SFT-Full) | 6.4 %                        || DPO (Zephyr-7B-Beta)   | 13.2 %                       || SAIL-PP  | 15.9 %                       |> Authors should compare more advanced preference optimization algorithms like ORPO and SimPO. And current results are not impressive for the alignment community.**Response:** Thank you for raising this insightful point. We see ORPO and SimPO are two recent work which propose a different objective than the standard RLHF, and achieve remarkable improvements in terms of alignment performance and efficiency.Our work focus more on bringing standard RLHF to a bilevel optimization framework and propose an effective and efficient approximate algorithm on top of it. We can see some new preference optimization methods including ORPO and SimPO have one fundamental difference from our approach: they do not explicitly incorporate the KL regularization term. The absence of the KL regularization term allows these methods to optimize more aggressively for the reward function by deviating significantly from the reference model. In contrast, our approach is specifically grounded in the standard RLHF, where the KL regularization term ensures that the model remains aligned with the reference distribution while optimizing for the reward function. This distinction makes direct comparisons with ORPO or SimPO less meaningful theoretically, as those methods omit the KL regularization and adopt a fundamentally different optimization objective design.However, we think our work, although developed adhering to the standard RLHF setup, can be compatible and combined with some recent advanced preference optimization algorithms, despite their differences in optimization setups and objectives. This is because we can reformulate their alignment problem as bilevel optimization, and go through the derivation as done in the paper. Taking SimPO as an example, we can treat their reward model definition (Equation (4) in the SimPO paper) as the solution of the upper level optimization (replacing Equation (4) in our manuscript), and adopt their modified Bradley-Terry objective with reward margin (Equation (5) in the SimPO paper) to replace the standard one (Equation (10) in our manuscript). By applying these changes and rederiving the extra gradient terms, we can formulate an adaptation of our method to the SimPO objective. We will implement this combined algorithm, which adapt our methodology to the SimPO objective, and compare with the SimPO as a baseline.Recently many different alignment objectives and algorithms have emerged; it is an interesting question to discuss the compatibility and combination of our method with each objective. We will add more relevant discussions to the appendices, but due to the fact that the compatibility problem with each design is a non-trivial question, this process may incur considerably more work, and we hope the reviewer understands that this effort cannot be fully reflected by the rebuttal period. But we will continue to expand the discussion as the wide compatibility to other designs also strengthens our contribution to the community. We thank the reviewer for raising this insightful point.'}, 'time': '2024-11-26 15:27:26'}\n"
     ]
    }
   ],
   "source": [
    "new_review_features = {'venue': 'ICLR.cc/2025/Conference', \n",
    "                   'review_openreview_id': 'DHwZxFryth', \n",
    "                   'replyto_openreview_id': 'Yqbllggrmw', \n",
    "                   'writer': 'test', \n",
    "                   'title': 'Response by Authors', \n",
    "                   'content': {'Title': 'Response to Reviewer 7i95 (1/2)', 'Comment': '> The method does not improve much in the AlpacaEval 2.0 Score. The author should give a detailed explanation. And why not use metrics like length-controlled win rate?**Response:** Thank you for your careful observation and question. We would like to clarify that we are already using the length-controlled (LC) AlpacaEval 2.0 win-rate metric in our evaluations. We will make this clearer in the table header of Table 3.Regarding the fact that the AlpacaEval 2.0 scores on LLama-3 (8B) do not improve compared to the baselines, we believe this is because our base model, the instruction-finetuned LLama-3 (8B), is already trained to perform exceptionally well in terms of helpfulness, which is the focus of the AlpacaEval benchmark. Additionally, the preference dataset we used, UltraFeedback, may not provide significant further enhancement in the helpfulness aspect. This is supported by the slight decrease observed in the AlpacaEval score for the standard DPO baseline as well (see Table 3, results on LLama-3). Therefore, we think these AlpacaEval 2.0 results on LLama-3 (8B) may not indicate that SAIL is ineffective; it may be simply caused by an ill-suited combination of base model, finetuning dataset, and evaluation benchmark.We also further conducted experiments on the Zephyr (7B) model as the backbone, whose AlpacaEval 2.0 win-rate is lower. We still train on the UltraFeedback preference dataset and the other experiment setups are unchanged. In this experiment, we see a larger improvement of the SAIL method compared to the standard DPO baseline (Zephyr-7B-Beta).|             | AlpacaEval 2.0 (LC) Win-Rate ||--------------------|------------------------------|| Base (Zephyr-7B-SFT-Full) | 6.4 %                        || DPO (Zephyr-7B-Beta)   | 13.2 %                       || SAIL-PP  | 15.9 %                       |> Authors should compare more advanced preference optimization algorithms like ORPO and SimPO. And current results are not impressive for the alignment community.**Response:** Thank you for raising this insightful point. We see ORPO and SimPO are two recent work which propose a different objective than the standard RLHF, and achieve remarkable improvements in terms of alignment performance and efficiency.Our work focus more on bringing standard RLHF to a bilevel optimization framework and propose an effective and efficient approximate algorithm on top of it. We can see some new preference optimization methods including ORPO and SimPO have one fundamental difference from our approach: they do not explicitly incorporate the KL regularization term. The absence of the KL regularization term allows these methods to optimize more aggressively for the reward function by deviating significantly from the reference model. In contrast, our approach is specifically grounded in the standard RLHF, where the KL regularization term ensures that the model remains aligned with the reference distribution while optimizing for the reward function. This distinction makes direct comparisons with ORPO or SimPO less meaningful theoretically, as those methods omit the KL regularization and adopt a fundamentally different optimization objective design.However, we think our work, although developed adhering to the standard RLHF setup, can be compatible and combined with some recent advanced preference optimization algorithms, despite their differences in optimization setups and objectives. This is because we can reformulate their alignment problem as bilevel optimization, and go through the derivation as done in the paper. Taking SimPO as an example, we can treat their reward model definition (Equation (4) in the SimPO paper) as the solution of the upper level optimization (replacing Equation (4) in our manuscript), and adopt their modified Bradley-Terry objective with reward margin (Equation (5) in the SimPO paper) to replace the standard one (Equation (10) in our manuscript). By applying these changes and rederiving the extra gradient terms, we can formulate an adaptation of our method to the SimPO objective. We will implement this combined algorithm, which adapt our methodology to the SimPO objective, and compare with the SimPO as a baseline.Recently many different alignment objectives and algorithms have emerged; it is an interesting question to discuss the compatibility and combination of our method with each objective. We will add more relevant discussions to the appendices, but due to the fact that the compatibility problem with each design is a non-trivial question, this process may incur considerably more work, and we hope the reviewer understands that this effort cannot be fully reflected by the rebuttal period. But we will continue to expand the discussion as the wide compatibility to other designs also strengthens our contribution to the community. We thank the reviewer for raising this insightful point.'}, \n",
    "                   'time': '2024-11-26 15:27:26'\n",
    "}\n",
    "research_arcade.update_node(\"openreview_reviews\", node_features=new_review_features)\n",
    "review_id = {\"review_openreview_id\": \"DHwZxFryth\"}\n",
    "review_features = research_arcade.get_node_features_by_id(\"openreview_reviews\", review_id)\n",
    "print(review_features.to_dict(orient=\"records\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4aa46e",
   "metadata": {},
   "source": [
    "### openreview_revisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c96137a",
   "metadata": {},
   "source": [
    "#### construct table from api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e64ac97",
   "metadata": {},
   "source": [
    "##### get pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd8eeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import openreview\n",
    "import time\n",
    "\n",
    "def get_paper_pdf(link, pdf_path, log_file):\n",
    "    pdf_url = \"https://openreview.net\"+link\n",
    "    \n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(pdf_url, headers=headers, timeout=15)\n",
    "        if response.status_code == 200:\n",
    "            with open(pdf_path, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"✅ PDF downloaded: {pdf_path}\")\n",
    "        else:\n",
    "            print(f\"❌ Download failed ({response.status_code}) for ID: {id}\")\n",
    "            with open(log_file, \"a\") as log:\n",
    "                log.write(f\"{link}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Exception for ID {link}: {e}\")\n",
    "        with open(log_file, \"a\") as log:\n",
    "            log.write(f\"{link}\\n\")\n",
    "            \n",
    "def get_revision_pdf(venue, id, pdf_path, log_file):\n",
    "    if \"2024\" in venue or \"2025\" in venue:\n",
    "        pdf_url = \"https://openreview.net/notes/edits/attachment?id=\"+id+\"&name=pdf\"\n",
    "    elif  \"EMNLP\" in venue:\n",
    "        pdf_url = \"https://openreview.net/attachment?id=\"+id+\"&name=pdf\"\n",
    "    elif \"2023\" in venue or \"2022\" in venue or \"2021\" in venue or \"2020\" in venue or \"2019\" in venue or \"2018\" in venue or \"2017\" in venue or \"2014\" in venue or \"2013\" in venue:\n",
    "        pdf_url = \"https://openreview.net/references/pdf?id=\"+id\n",
    "    \n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(pdf_url, headers=headers, timeout=15)\n",
    "        if response.status_code == 200:\n",
    "            with open(pdf_path, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"✅ PDF downloaded: {pdf_path}\")\n",
    "        else:\n",
    "            print(f\"❌ Download failed ({response.status_code}) for ID: {id}\")\n",
    "            with open(log_file, \"a\") as log:\n",
    "                log.write(f\"{id}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Exception for ID {id}: {e}\")\n",
    "        with open(log_file, \"a\") as log:\n",
    "            log.write(f\"{id}\\n\")\n",
    "\n",
    "client_v1 = openreview.Client(baseurl='https://api.openreview.net')\n",
    "client_v2 = openreview.api.OpenReviewClient(baseurl='https://api2.openreview.net')\n",
    "\n",
    "venue = 'ICLR.cc/2017/conference'\n",
    "pdf_dir = \"/home/jingjunx/openreview_benchmark/Code/research-arcade/examples/pdfs/\"\n",
    "log_file = \"/home/jingjunx/openreview_benchmark/Code/research-arcade/examples/log/download_failed_ids_2017.log\"\n",
    "start_idx = 0\n",
    "end_idx = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91115c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PDF downloaded: /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/pdfs/ryxB0Rtxx.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [00:01<00:05,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PDF downloaded: /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/pdfs/rywUcQogx.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:02<00:03,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PDF downloaded: /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/pdfs/ryuxYmvel.pdf\n",
      "✅ PDF downloaded: /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/pdfs/BJRNV4wue.pdf\n",
      "✅ PDF downloaded: /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/pdfs/S1PHr1IIx.pdf\n",
      "✅ PDF downloaded: /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/pdfs/SJdZSdr7e.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [00:07<00:06,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PDF downloaded: /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/pdfs/ryrGawqex.pdf\n",
      "✅ PDF downloaded: /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/pdfs/HkzJI95Yl.pdf\n",
      "✅ PDF downloaded: /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/pdfs/S1nIl5DOx.pdf\n",
      "✅ PDF downloaded: /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/pdfs/BJKAta8Ue.pdf\n",
      "✅ PDF downloaded: /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/pdfs/r1Z7SpDWx.pdf\n",
      "✅ PDF downloaded: /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/pdfs/SyvPXTwWx.pdf\n",
      "✅ PDF downloaded: /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/pdfs/S1SO2N8Wx.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:16<00:05,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PDF downloaded: /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/pdfs/ryjp1c9xg.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:17<00:00,  3.55s/it]\n"
     ]
    }
   ],
   "source": [
    "if \"2023\" in venue or \"2022\" in venue or \"2021\" in venue or \"2020\" in venue or \"2019\" in venue or \"2018\" in venue or \"2017\" in venue or \"2014\" in venue or \"2013\" in venue:\n",
    "    if \"2023\" in venue or \"2022\" in venue or \"2021\" in venue or \"2020\" in venue or \"2019\" in venue or \"2018\" in venue:\n",
    "        submissions = client_v1.get_all_notes(invitation=f'{venue}/-/Blind_Submission', details='revisions')\n",
    "    elif \"2017\" in venue or \"2014\" in venue or \"2013\" in venue:\n",
    "        submissions = client_v1.get_all_notes(invitation=f'{venue}/-/submission', details='revisions')\n",
    "        \n",
    "    if submissions is None:\n",
    "        print(f\"No submissions found for venue: {venue}\")\n",
    "    else:\n",
    "        for submission in tqdm(submissions[start_idx:end_idx]):\n",
    "            # get paper openreview id\n",
    "            paper_id = submission.id\n",
    "            if \"pdf\" in submission.content:\n",
    "                pdf_link = submission.content[\"pdf\"]\n",
    "                pdf_path = str(pdf_dir)+str(paper_id)+\".pdf\"\n",
    "                if os.path.isfile(pdf_path):\n",
    "                    continue\n",
    "                else:\n",
    "                    get_paper_pdf(pdf_link, pdf_path, log_file)\n",
    "            \n",
    "            revisions = client_v1.get_references(referent=paper_id, original=True)\n",
    "            time.sleep(1)\n",
    "            \n",
    "            pdf_revisions_ids = []\n",
    "            for revision in revisions:\n",
    "                if \"pdf\" in revision.content:\n",
    "                    pdf_revisions_ids.append(revision.id)\n",
    "            \n",
    "            if len(pdf_revisions_ids) <= 1:\n",
    "                continue\n",
    "            else:\n",
    "                for pdf_revision_id in pdf_revisions_ids:\n",
    "                    pdf_path = str(pdf_dir)+str(pdf_revision_id)+\".pdf\"\n",
    "                    if os.path.isfile(pdf_path):\n",
    "                        continue\n",
    "                    else:\n",
    "                        get_revision_pdf(venue, pdf_revision_id, pdf_path, log_file)\n",
    "                        time.sleep(1)\n",
    "else:\n",
    "    submissions = client_v2.get_all_notes(invitation=f'{venue}/-/Submission', details='revisions')\n",
    "    if submissions is None:\n",
    "        print(f\"No submissions found for venue: {venue}\")\n",
    "    else:\n",
    "        for submission in tqdm(submissions[start_idx:end_idx]):\n",
    "            decision = submission.content[\"venueid\"][\"value\"].split('/')[-1]\n",
    "            if decision == \"Withdrawn_Submission\":\n",
    "                continue\n",
    "            else:\n",
    "                # get paper openreview id\n",
    "                paper_id = submission.id\n",
    "                if \"pdf\" in submission.content:\n",
    "                    pdf_link = submission.content[\"pdf\"][\"value\"]\n",
    "                    pdf_path = str(pdf_dir)+str(paper_id)+\".pdf\"\n",
    "                    if os.path.isfile(pdf_path):\n",
    "                        continue\n",
    "                    else:\n",
    "                        get_paper_pdf(pdf_link, pdf_path, log_file)\n",
    "                        \n",
    "                revisions = client_v2.get_note_edits(note_id=paper_id)\n",
    "                if len(revisions) <= 1:\n",
    "                    continue\n",
    "                else:\n",
    "                    for revision in revisions:\n",
    "                        pdf_revision_id = revision.id\n",
    "                        pdf_path = str(pdf_dir)+str(pdf_revision_id)+\".pdf\"\n",
    "                        if os.path.isfile(pdf_path):\n",
    "                            continue\n",
    "                        else:\n",
    "                            time.sleep(1)\n",
    "                            get_revision_pdf(venue, pdf_revision_id, pdf_path, log_file)\n",
    "                            time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d04643",
   "metadata": {},
   "source": [
    "#### construct the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248804cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "venue = \"ICLR.cc/2017/conference\"\n",
    "filter_list = [\"Under review as a conference paper at ICLR 2017\", \"Published as a conference paper at ICLR 2017\"]\n",
    "pdf_dir = \"/home/jingjunx/openreview_benchmark/Code/research-arcade/examples/pdfs/\"\n",
    "log_file = \"/home/jingjunx/openreview_benchmark/Code/research-arcade/examples/log/failed_ids_2017.log\"\n",
    "config = {\"venue\": venue, \"filter_list\": filter_list, \"pdf_dir\": pdf_dir, \"log_file\": log_file}\n",
    "research_arcade.construct_table_from_api(\"openreview_revisions\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6f9cbe",
   "metadata": {},
   "source": [
    "#### construct table from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084bc08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading revisions data from /home/jingjunx/openreview_benchmark/Code/paper-crawler/examples/csv_data/csv_openreview_revision_example.csv...\n",
      "Inserting data into CSV file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 63.16it/s]\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"/home/jingjunx/openreview_benchmark/Code/paper-crawler/examples/csv_data/csv_openreview_revision_example.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"openreview_revisions\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890f7bfd",
   "metadata": {},
   "source": [
    "#### construct table from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6f1b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading revisions data from /home/jingjunx/openreview_benchmark/Code/paper-crawler/examples/json_data/json_openreview_revision_example.json...\n",
      "Inserting data into CSV file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 46.79it/s]\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"/home/jingjunx/openreview_benchmark/Code/paper-crawler/examples/json_data/json_openreview_revision_example.json\"}\n",
    "research_arcade.construct_table_from_json(\"openreview_revisions\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0531e93",
   "metadata": {},
   "source": [
    "#### insert node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae283786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ICLR.cc/2025/Conference', 'yfHQOp5zWc')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revision_feature = {'venue': 'ICLR.cc/2025/Conference', \n",
    "                    'original_openreview_id': 'pbTVNlX8Ig', \n",
    "                    'revision_openreview_id': 'yfHQOp5zWc', \n",
    "                    'content': [{'section': '1 INTRODUCTION', \n",
    "                                 'after_section': None, \n",
    "                                 'context_after': '2 RELATED WORK ', \n",
    "                                 'paragraph_idx': 9, \n",
    "                                 'before_section': None, \n",
    "                                 'context_before': 'Published as a conference paper at ICLR 2025 tograd system in PyTorch, specifically tailored for our experimental setup, which is available at ', \n",
    "                                 'modified_lines': 'https://github.com/stephane-rivaud/PETRA. ', \n",
    "                                 'original_lines': 'https://github.com/streethagore/PETRA. ', \n",
    "                                 'after_paragraph_idx': None, \n",
    "                                 'before_paragraph_idx': None}], \n",
    "                    'time': '2025-03-14 15:35:37'}\n",
    "research_arcade.insert_node(\"openreview_revisions\", node_features=revision_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80cc6d0",
   "metadata": {},
   "source": [
    "#### delete specific node by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeb6e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revision with revision_openreview_id yfHQOp5zWc deleted successfully.\n",
      "{'venue': 'ICLR.cc/2025/Conference', 'original_openreview_id': 'pbTVNlX8Ig', 'revision_openreview_id': 'yfHQOp5zWc', 'content': [{'section': '1 INTRODUCTION', 'after_section': None, 'context_after': '2 RELATED WORK ', 'paragraph_idx': 9, 'before_section': None, 'context_before': 'Published as a conference paper at ICLR 2025 tograd system in PyTorch, specifically tailored for our experimental setup, which is available at ', 'modified_lines': 'https://github.com/stephane-rivaud/PETRA. ', 'original_lines': 'https://github.com/streethagore/PETRA. ', 'after_paragraph_idx': None, 'before_paragraph_idx': None}], 'time': '2025-03-14 15:35:37'}\n"
     ]
    }
   ],
   "source": [
    "revision_id = {\"revision_openreview_id\": \"yfHQOp5zWc\"}\n",
    "revision_feature = research_arcade.delete_node_by_id(\"openreview_revisions\", revision_id)\n",
    "print(revision_feature.to_dict(orient=\"records\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b80557",
   "metadata": {},
   "source": [
    "#### get all nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0632da9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "openreview_revisions_df = research_arcade.get_all_node_features(\"openreview_revisions\")\n",
    "print(len(openreview_revisions_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6a8f5e",
   "metadata": {},
   "source": [
    "#### get specific node by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a0f2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'venue': 'ICLR.cc/2025/Conference', 'original_openreview_id': 'pbTVNlX8Ig', 'revision_openreview_id': 'yfHQOp5zWc', 'content': [{'section': '1 INTRODUCTION', 'after_section': None, 'context_after': '2 RELATED WORK ', 'paragraph_idx': 9, 'before_section': None, 'context_before': 'Published as a conference paper at ICLR 2025 tograd system in PyTorch, specifically tailored for our experimental setup, which is available at ', 'modified_lines': 'https://github.com/stephane-rivaud/PETRA. ', 'original_lines': 'https://github.com/streethagore/PETRA. ', 'after_paragraph_idx': None, 'before_paragraph_idx': None}], 'time': '2025-03-14 15:35:37'}\n"
     ]
    }
   ],
   "source": [
    "revision_id = {\"revision_openreview_id\": \"yfHQOp5zWc\"}\n",
    "revision_feature = research_arcade.get_node_features_by_id(\"openreview_revisions\", revision_id)\n",
    "print(revision_feature.to_dict(orient=\"records\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d20b6a6",
   "metadata": {},
   "source": [
    "#### update specific node by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601349d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revision with revision_openreview_id yfHQOp5zWc updated successfully.\n",
      "{'venue': 'ICLR.cc/2025/Conference', 'original_openreview_id': 'pbTVNlX8Ig', 'revision_openreview_id': 'yfHQOp5zWc', 'content': [{'section': '1 INTRODUCTION', 'after_section': None, 'context_after': '2 RELATED WORK ', 'paragraph_idx': 9, 'before_section': None, 'context_before': 'Published as a conference paper at ICLR 2025 tograd system in PyTorch, specifically tailored for our experimental setup, which is available at ', 'modified_lines': 'https://github.com/stephane-rivaud/PETRA. ', 'original_lines': 'https://github.com/streethagore/PETRA. ', 'after_paragraph_idx': None, 'before_paragraph_idx': None}], 'time': 'test'}\n"
     ]
    }
   ],
   "source": [
    "new_revision_features = {'venue': 'ICLR.cc/2025/Conference', \n",
    "                    'original_openreview_id': 'pbTVNlX8Ig', \n",
    "                    'revision_openreview_id': 'yfHQOp5zWc', \n",
    "                    'content': [{'section': '1 INTRODUCTION', \n",
    "                                 'after_section': None, \n",
    "                                 'context_after': '2 RELATED WORK ', \n",
    "                                 'paragraph_idx': 9, \n",
    "                                 'before_section': None, \n",
    "                                 'context_before': 'Published as a conference paper at ICLR 2025 tograd system in PyTorch, specifically tailored for our experimental setup, which is available at ', \n",
    "                                 'modified_lines': 'https://github.com/stephane-rivaud/PETRA. ', \n",
    "                                 'original_lines': 'https://github.com/streethagore/PETRA. ', \n",
    "                                 'after_paragraph_idx': None, \n",
    "                                 'before_paragraph_idx': None}], \n",
    "                    'time': 'test'}\n",
    "research_arcade.update_node(\"openreview_revisions\", node_features=new_revision_features)\n",
    "revision_id = {\"revision_openreview_id\": \"yfHQOp5zWc\"}\n",
    "revision_feature = research_arcade.get_node_features_by_id(\"openreview_revisions\", revision_id)\n",
    "print(revision_feature.to_dict(orient=\"records\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c376fca",
   "metadata": {},
   "source": [
    "### openreview_paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366c2122",
   "metadata": {},
   "source": [
    "#### construct table from api"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06a9f4b",
   "metadata": {},
   "source": [
    "##### get pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6de2025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import openreview\n",
    "import time\n",
    "\n",
    "def get_paper_pdf(link, pdf_path, log_file):\n",
    "    pdf_url = \"https://openreview.net\"+link\n",
    "    \n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(pdf_url, headers=headers, timeout=15)\n",
    "        if response.status_code == 200:\n",
    "            with open(pdf_path, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"✅ PDF downloaded: {pdf_path}\")\n",
    "        else:\n",
    "            print(f\"❌ Download failed ({response.status_code}) for ID: {id}\")\n",
    "            with open(log_file, \"a\") as log:\n",
    "                log.write(f\"{link}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Exception for ID {link}: {e}\")\n",
    "        with open(log_file, \"a\") as log:\n",
    "            log.write(f\"{link}\\n\")\n",
    "            \n",
    "def get_revision_pdf(venue, id, pdf_path, log_file):\n",
    "    if \"2024\" in venue or \"2025\" in venue:\n",
    "        pdf_url = \"https://openreview.net/notes/edits/attachment?id=\"+id+\"&name=pdf\"\n",
    "    elif  \"EMNLP\" in venue:\n",
    "        pdf_url = \"https://openreview.net/attachment?id=\"+id+\"&name=pdf\"\n",
    "    elif \"2023\" in venue or \"2022\" in venue or \"2021\" in venue or \"2020\" in venue or \"2019\" in venue or \"2018\" in venue or \"2017\" in venue or \"2014\" in venue or \"2013\" in venue:\n",
    "        pdf_url = \"https://openreview.net/references/pdf?id=\"+id\n",
    "    \n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(pdf_url, headers=headers, timeout=15)\n",
    "        if response.status_code == 200:\n",
    "            with open(pdf_path, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"✅ PDF downloaded: {pdf_path}\")\n",
    "        else:\n",
    "            print(f\"❌ Download failed ({response.status_code}) for ID: {id}\")\n",
    "            with open(log_file, \"a\") as log:\n",
    "                log.write(f\"{id}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Exception for ID {id}: {e}\")\n",
    "        with open(log_file, \"a\") as log:\n",
    "            log.write(f\"{id}\\n\")\n",
    "\n",
    "client_v1 = openreview.Client(baseurl='https://api.openreview.net')\n",
    "client_v2 = openreview.api.OpenReviewClient(baseurl='https://api2.openreview.net')\n",
    "\n",
    "venue = 'ICLR.cc/2017/conference'\n",
    "pdf_dir = \"/home/jingjunx/openreview_benchmark/Code/research-arcade/examples/pdfs/\"\n",
    "log_file = \"/home/jingjunx/openreview_benchmark/Code/research-arcade/examples/log/download_failed_ids_2017.log\"\n",
    "start_idx = 0\n",
    "end_idx = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879c7d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"2023\" in venue or \"2022\" in venue or \"2021\" in venue or \"2020\" in venue or \"2019\" in venue or \"2018\" in venue or \"2017\" in venue or \"2014\" in venue or \"2013\" in venue:\n",
    "    if \"2023\" in venue or \"2022\" in venue or \"2021\" in venue or \"2020\" in venue or \"2019\" in venue or \"2018\" in venue:\n",
    "        submissions = client_v1.get_all_notes(invitation=f'{venue}/-/Blind_Submission', details='revisions')\n",
    "    elif \"2017\" in venue or \"2014\" in venue or \"2013\" in venue:\n",
    "        submissions = client_v1.get_all_notes(invitation=f'{venue}/-/submission', details='revisions')\n",
    "        \n",
    "    if submissions is None:\n",
    "        print(f\"No submissions found for venue: {venue}\")\n",
    "    else:\n",
    "        for submission in tqdm(submissions[start_idx:end_idx]):\n",
    "            # get paper openreview id\n",
    "            paper_id = submission.id\n",
    "            if \"pdf\" in submission.content:\n",
    "                pdf_link = submission.content[\"pdf\"]\n",
    "                pdf_path = str(pdf_dir)+str(paper_id)+\".pdf\"\n",
    "                if os.path.isfile(pdf_path):\n",
    "                    continue\n",
    "                else:\n",
    "                    get_paper_pdf(pdf_link, pdf_path, log_file)\n",
    "            \n",
    "            revisions = client_v1.get_references(referent=paper_id, original=True)\n",
    "            time.sleep(1)\n",
    "            \n",
    "            pdf_revisions_ids = []\n",
    "            for revision in revisions:\n",
    "                if \"pdf\" in revision.content:\n",
    "                    pdf_revisions_ids.append(revision.id)\n",
    "            \n",
    "            if len(pdf_revisions_ids) <= 1:\n",
    "                continue\n",
    "            else:\n",
    "                for pdf_revision_id in pdf_revisions_ids:\n",
    "                    pdf_path = str(pdf_dir)+str(pdf_revision_id)+\".pdf\"\n",
    "                    if os.path.isfile(pdf_path):\n",
    "                        continue\n",
    "                    else:\n",
    "                        get_revision_pdf(venue, pdf_revision_id, pdf_path, log_file)\n",
    "                        time.sleep(1)\n",
    "else:\n",
    "    submissions = client_v2.get_all_notes(invitation=f'{venue}/-/Submission', details='revisions')\n",
    "    if submissions is None:\n",
    "        print(f\"No submissions found for venue: {venue}\")\n",
    "    else:\n",
    "        for submission in tqdm(submissions[start_idx:end_idx]):\n",
    "            decision = submission.content[\"venueid\"][\"value\"].split('/')[-1]\n",
    "            if decision == \"Withdrawn_Submission\":\n",
    "                continue\n",
    "            else:\n",
    "                # get paper openreview id\n",
    "                paper_id = submission.id\n",
    "                if \"pdf\" in submission.content:\n",
    "                    pdf_link = submission.content[\"pdf\"][\"value\"]\n",
    "                    pdf_path = str(pdf_dir)+str(paper_id)+\".pdf\"\n",
    "                    if os.path.isfile(pdf_path):\n",
    "                        continue\n",
    "                    else:\n",
    "                        get_paper_pdf(pdf_link, pdf_path, log_file)\n",
    "                        \n",
    "                revisions = client_v2.get_note_edits(note_id=paper_id)\n",
    "                if len(revisions) <= 1:\n",
    "                    continue\n",
    "                else:\n",
    "                    for revision in revisions:\n",
    "                        pdf_revision_id = revision.id\n",
    "                        pdf_path = str(pdf_dir)+str(pdf_revision_id)+\".pdf\"\n",
    "                        if os.path.isfile(pdf_path):\n",
    "                            continue\n",
    "                        else:\n",
    "                            time.sleep(1)\n",
    "                            get_revision_pdf(venue, pdf_revision_id, pdf_path, log_file)\n",
    "                            time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5087e583",
   "metadata": {},
   "source": [
    "##### construct the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8c57df",
   "metadata": {},
   "outputs": [],
   "source": [
    "venue = \"ICLR.cc/2017/conference\"\n",
    "filter_list = [\"Under review as a conference paper at ICLR 2017\", \"Published as a conference paper at ICLR 2017\"]\n",
    "pdf_dir = \"/home/jingjunx/openreview_benchmark/Code/research-arcade/examples/pdfs/\"\n",
    "log_file = \"/home/jingjunx/openreview_benchmark/Code/research-arcade/examples/log/failed_ids_2017.log\"\n",
    "config = {\"venue\": venue, \"filter_list\": filter_list, \"pdf_dir\": pdf_dir, \"log_file\": log_file, \"is_paper\": True, \"is_revision\": True, \"is_pdf_delete\": False}\n",
    "research_arcade.construct_table_from_api(\"openreview_paragraphs\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5065603e",
   "metadata": {},
   "source": [
    "#### construct table from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dca0bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading paragraph data from /home/jingjunx/openreview_benchmark/Code/paper-crawler/examples/csv_data/csv_openreview_paragraphs_example.csv...\n",
      "Inserting data into CSV file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 107.64it/s]\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"/home/jingjunx/openreview_benchmark/Code/paper-crawler/examples/csv_data/csv_openreview_paragraphs_example.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"openreview_paragraphs\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d65474",
   "metadata": {},
   "source": [
    "#### construct table from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550b7a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading paper data from /home/jingjunx/openreview_benchmark/Code/paper-crawler/examples/json_data/json_openreview_paragraphs_example.json...\n",
      "Inserting data into CSV file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 183.69it/s]\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"/home/jingjunx/openreview_benchmark/Code/paper-crawler/examples/json_data/json_openreview_paragraphs_example.json\"}\n",
    "research_arcade.construct_table_from_json(\"openreview_paragraphs\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492c338e",
   "metadata": {},
   "source": [
    "#### insert node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf2b2d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('xujj_test', 'xujj_test', 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_feature = {'venue': 'xujj_test', \n",
    "                    'paper_openreview_id': 'xujj_test', \n",
    "                    'paragraph_idx': 1, \n",
    "                    'section': \"xujj_test\", \n",
    "                    'content': \"xujj_test\"}\n",
    "research_arcade.insert_node(\"openreview_paragraphs\", node_features=paragraph_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f98834d",
   "metadata": {},
   "source": [
    "#### delete specific node by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ffee4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraphs with paper_openreview_id xujj_test deleted successfully.\n",
      "1\n",
      "{'venue': 'xujj_test', 'paper_openreview_id': 'xujj_test', 'paragraph_idx': 1, 'section': 'xujj_test', 'content': 'xujj_test'}\n"
     ]
    }
   ],
   "source": [
    "paper_id = {\"paper_openreview_id\": \"xujj_test\"}\n",
    "paragraph_feature = research_arcade.delete_node_by_id(\"openreview_paragraphs\", paper_id)\n",
    "print(len(paragraph_feature))\n",
    "print(paragraph_feature.to_dict(orient=\"records\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ffe9d4",
   "metadata": {},
   "source": [
    "#### get all nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d6287a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "openreview_paragraphs_df = research_arcade.get_all_node_features(\"openreview_paragraphs\")\n",
    "print(len(openreview_paragraphs_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a782915b",
   "metadata": {},
   "source": [
    "#### get specific node by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01611f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'venue': 'xujj_test', 'paper_openreview_id': 'xujj_test', 'paragraph_idx': 1, 'section': 'xujj_test', 'content': 'xujj_test'}\n"
     ]
    }
   ],
   "source": [
    "paper_id = {\"paper_openreview_id\": \"xujj_test\"}\n",
    "paragraph_feature = research_arcade.get_node_features_by_id(\"openreview_paragraphs\", paper_id)\n",
    "print(paragraph_feature.to_dict(orient=\"records\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725a8e36",
   "metadata": {},
   "source": [
    "### arxiv_papers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044e676c",
   "metadata": {},
   "source": [
    "#### Table Schema\n",
    "\n",
    "- `id` (SERIAL PK)\n",
    "- `arxiv_id` (VARCHAR, unique) - e.g., 1802.08773v3\n",
    "- `base_arxiv_id` (VARCHAR) - e.g., 1802.08773\n",
    "- `version` (INT) - e.g., 3\n",
    "- `title` (TEXT)\n",
    "- `abstract` (TEXT)\n",
    "- `submit_date` (DATE)\n",
    "- `metadata` (JSONB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01382b6a",
   "metadata": {},
   "source": [
    "#### Construct Table from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5951867e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded\n",
      "Downloaded\n"
     ]
    }
   ],
   "source": [
    "config = {\"arxiv_ids\": [\"1806.08804v4\", \"1903.03894v4\"], \"dest_dir\": \"./download\"}\n",
    "research_arcade.construct_table_from_api(\"arxiv_papers\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae47a10",
   "metadata": {},
   "source": [
    "#### Construct Table from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e88e171d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: CSV file /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/csv_data/arxiv_papers.csv does not exist.\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"/home/jingjunx/openreview_benchmark/Code/research-arcade/examples/csv_data/arxiv_papers.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"arxiv_papers\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73bc485",
   "metadata": {},
   "source": [
    "#### Construct Table from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f5e711d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: JSON file /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/json_data/arxiv_papers.json does not exist.\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"/home/jingjunx/openreview_benchmark/Code/research-arcade/examples/json_data/arxiv_papers.json\"}\n",
    "research_arcade.construct_table_from_json(\"arxiv_papers\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc4ad18",
   "metadata": {},
   "source": [
    "#### Insert a Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fc3c231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Insert the famous \"Attention is All You Need\" paper\n",
    "new_paper = {\n",
    "    'arxiv_id': '1706.03762v7',\n",
    "    'base_arxiv_id': '1706.03762',\n",
    "    'version': 7,\n",
    "    'title': 'Attention Is All You Need',\n",
    "    'abstract': 'The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.',\n",
    "    'submit_date': '2017-06-12',\n",
    "    'metadata': {'venue': 'NeurIPS 2017', 'pdf_url': 'https://arxiv.org/pdf/1706.03762.pdf'}\n",
    "}\n",
    "\n",
    "research_arcade.insert_node(\"arxiv_papers\", node_features=new_paper)\n",
    "print(\"Paper inserted successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ce67f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT paper inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Insert BERT paper\n",
    "bert_paper = {\n",
    "    'arxiv_id': '1810.04805v2',\n",
    "    'base_arxiv_id': '1810.04805',\n",
    "    'version': 2,\n",
    "    'title': 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding',\n",
    "    'abstract': 'We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications.',\n",
    "    'submit_date': '2018-10-11',\n",
    "    'metadata': {'venue': 'NAACL 2019', 'citations': 50000}\n",
    "}\n",
    "\n",
    "research_arcade.insert_node(\"arxiv_papers\", node_features=bert_paper)\n",
    "print(\"BERT paper inserted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac124e08",
   "metadata": {},
   "source": [
    "#### Get All Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07a95736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total papers in database: 4\n",
      "\n",
      "First 5 papers:\n",
      "   id      arxiv_id base_arxiv_id  version  \\\n",
      "0   1  1806.08804v4    1806.08804        4   \n",
      "1   2  1903.03894v4    1903.03894        4   \n",
      "2   4  1810.04805v2    1810.04805        2   \n",
      "3   5  1706.03762v7    1706.03762        7   \n",
      "\n",
      "                                               title  \\\n",
      "0  Hierarchical Graph Representation Learning wit...   \n",
      "1  GNNExplainer: Generating Explanations for Grap...   \n",
      "2  BERT: Pre-training of Deep Bidirectional Trans...   \n",
      "3                          Attention Is All You Need   \n",
      "\n",
      "                                            abstract  \\\n",
      "0  Recently, graph neural networks (GNNs) have re...   \n",
      "1  Graph Neural Networks (GNNs) are a powerful to...   \n",
      "2  We introduce a new language representation mod...   \n",
      "3  The dominant sequence transduction models are ...   \n",
      "\n",
      "                 submit_date  \\\n",
      "0  2018-06-22 18:04:46+00:00   \n",
      "1  2019-03-10 00:56:26+00:00   \n",
      "2                 2018-10-11   \n",
      "3                 2017-06-12   \n",
      "\n",
      "                                            metadata  \n",
      "0  {\"id\": \"1806.08804v4\", \"title\": \"Hierarchical ...  \n",
      "1  {\"id\": \"1903.03894v4\", \"title\": \"GNNExplainer:...  \n",
      "2        {\"venue\": \"NAACL 2019\", \"citations\": 50000}  \n",
      "3  {\"venue\": \"NeurIPS 2017\", \"pdf_url\": \"https://...  \n"
     ]
    }
   ],
   "source": [
    "arxiv_papers_df = research_arcade.get_all_node_features(\"arxiv_papers\")\n",
    "print(f\"Total papers in database: {len(arxiv_papers_df)}\")\n",
    "print(\"\\nFirst 5 papers:\")\n",
    "print(arxiv_papers_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612ed642",
   "metadata": {},
   "source": [
    "#### Get Specific Paper by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0ad00fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper details:\n",
      "{'id': 4, 'arxiv_id': '1810.04805v2', 'base_arxiv_id': '1810.04805', 'version': 2, 'title': 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding', 'abstract': 'We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications.', 'submit_date': '2018-10-11', 'metadata': '{\"venue\": \"NAACL 2019\", \"citations\": 50000}'}\n"
     ]
    }
   ],
   "source": [
    "paper_id = {\"arxiv_id\": \"1810.04805v2\"}\n",
    "paper_features = research_arcade.get_node_features_by_id(\"arxiv_papers\", paper_id)\n",
    "print(\"Paper details:\")\n",
    "print(paper_features.to_dict(orient=\"records\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d23c11",
   "metadata": {},
   "source": [
    "#### Update a Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0111989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paper updated successfully!\n"
     ]
    }
   ],
   "source": [
    "# Update metadata for a paper\n",
    "updated_paper = {\n",
    "    'arxiv_id': '1706.03762v7',\n",
    "    'metadata': {\n",
    "        'venue': 'NeurIPS 2017',\n",
    "        'pdf_url': 'https://arxiv.org/pdf/1706.03762.pdf',\n",
    "        'citations': 75000,\n",
    "        'influential': True\n",
    "    }\n",
    "}\n",
    "\n",
    "research_arcade.update_node(\"arxiv_papers\", node_features=updated_paper)\n",
    "print(\"Paper updated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f78ad70",
   "metadata": {},
   "source": [
    "#### Delete a Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9082548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted paper:\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Delete a paper by ID\n",
    "paper_id = {\"arxiv_id\": \"1706.03762v7\"}\n",
    "deleted_paper = research_arcade.delete_node_by_id(\"arxiv_papers\", paper_id)\n",
    "print(\"Deleted paper:\")\n",
    "print(deleted_paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357e4ac9",
   "metadata": {},
   "source": [
    "### arxiv_authors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8627385",
   "metadata": {},
   "source": [
    "#### Table Schema\n",
    "\n",
    "- `id` (SERIAL PK)\n",
    "- `semantic_scholar_id` (VARCHAR, unique)\n",
    "- `name` (VARCHAR)\n",
    "- `homepage` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef9038a",
   "metadata": {},
   "source": [
    "#### Construct Table from API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "580474c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_arxiv_id: 1903.03894\n",
      "INFO:httpx:HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/ARXIV:1903.03894?fields=abstract%2Cauthors%2Cauthors.affiliations%2Cauthors.authorId%2Cauthors.citationCount%2Cauthors.externalIds%2Cauthors.hIndex%2Cauthors.homepage%2Cauthors.name%2Cauthors.paperCount%2Cauthors.url%2CcitationCount%2CcitationStyles%2Ccitations%2Ccitations.abstract%2Ccitations.authors%2Ccitations.citationCount%2Ccitations.citationStyles%2Ccitations.corpusId%2Ccitations.externalIds%2Ccitations.fieldsOfStudy%2Ccitations.influentialCitationCount%2Ccitations.isOpenAccess%2Ccitations.journal%2Ccitations.openAccessPdf%2Ccitations.paperId%2Ccitations.publicationDate%2Ccitations.publicationTypes%2Ccitations.publicationVenue%2Ccitations.referenceCount%2Ccitations.s2FieldsOfStudy%2Ccitations.title%2Ccitations.url%2Ccitations.venue%2Ccitations.year%2CcorpusId%2Cembedding%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Creferences%2Creferences.abstract%2Creferences.authors%2Creferences.citationCount%2Creferences.citationStyles%2Creferences.corpusId%2Creferences.externalIds%2Creferences.fieldsOfStudy%2Creferences.influentialCitationCount%2Creferences.isOpenAccess%2Creferences.journal%2Creferences.openAccessPdf%2Creferences.paperId%2Creferences.publicationDate%2Creferences.publicationTypes%2Creferences.publicationVenue%2Creferences.referenceCount%2Creferences.s2FieldsOfStudy%2Creferences.title%2Creferences.url%2Creferences.venue%2Creferences.year%2Cs2FieldsOfStudy%2Ctitle%2Ctldr%2Curl%2Cvenue%2Cyear \"HTTP/1.1 429 \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m config = {\u001b[33m\"\u001b[39m\u001b[33marxiv_ids\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33m1903.03894v4\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m1806.08804v4\u001b[39m\u001b[33m\"\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mdest_dir\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m./download\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mresearch_arcade\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstruct_table_from_api\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43marxiv_authors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/uiuc/research-arcade/research_arcade/research_arcade.py:662\u001b[39m, in \u001b[36mResearchArcade.construct_table_from_api\u001b[39m\u001b[34m(self, table, config)\u001b[39m\n\u001b[32m    660\u001b[39m     \u001b[38;5;28mself\u001b[39m.arxiv_papers.construct_papers_table_from_api(**config)\n\u001b[32m    661\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m table == \u001b[33m\"\u001b[39m\u001b[33marxiv_authors\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m662\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43marxiv_authors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstruct_authors_table_from_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m table == \u001b[33m\"\u001b[39m\u001b[33marxiv_categories\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    664\u001b[39m     \u001b[38;5;28mself\u001b[39m.arxiv_categories.construct_category_table_from_api(**config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/uiuc/research-arcade/research_arcade/csv_database/csv_arxiv_authors.py:164\u001b[39m, in \u001b[36mCSVArxivAuthors.construct_authors_table_from_api\u001b[39m\u001b[34m(self, arxiv_ids, dest_dir)\u001b[39m\n\u001b[32m    162\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbase_arxiv_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_arxiv_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m164\u001b[39m     paper_sch = \u001b[43msch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_paper\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mARXIV:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mbase_arxiv_id\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m     authors = paper_sch.authors\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m author \u001b[38;5;129;01min\u001b[39;00m authors:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/site-packages/semanticscholar/SemanticScholar.py:130\u001b[39m, in \u001b[36mSemanticScholar.get_paper\u001b[39m\u001b[34m(self, paper_id, fields)\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m    108\u001b[39m \u001b[33;03mPaper lookup\u001b[39;00m\n\u001b[32m    109\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    126\u001b[39m \u001b[33;03m:raises: ObjectNotFoundException: if Paper ID not found.\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[33;03m'''\u001b[39;00m\n\u001b[32m    129\u001b[39m loop = asyncio.get_event_loop()\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m paper = \u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_AsyncSemanticScholar\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_paper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpaper_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpaper_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfields\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfields\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m paper\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/site-packages/nest_asyncio.py:92\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     90\u001b[39m     f._log_destroy_pending = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stopping:\n\u001b[32m     94\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/site-packages/nest_asyncio.py:115\u001b[39m, in \u001b[36m_patch_loop.<locals>._run_once\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    108\u001b[39m     heappop(scheduled)\n\u001b[32m    110\u001b[39m timeout = (\n\u001b[32m    111\u001b[39m     \u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._stopping\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[32m    113\u001b[39m         scheduled[\u001b[32m0\u001b[39m]._when - \u001b[38;5;28mself\u001b[39m.time(), \u001b[32m0\u001b[39m), \u001b[32m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[38;5;28mself\u001b[39m._process_events(event_list)\n\u001b[32m    118\u001b[39m end_time = \u001b[38;5;28mself\u001b[39m.time() + \u001b[38;5;28mself\u001b[39m._clock_resolution\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/selectors.py:566\u001b[39m, in \u001b[36mKqueueSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    564\u001b[39m ready = []\n\u001b[32m    565\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m     kev_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_ev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    568\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.semanticscholar.org/graph/v1/paper/ARXIV:1903.03894?fields=abstract%2Cauthors%2Cauthors.affiliations%2Cauthors.authorId%2Cauthors.citationCount%2Cauthors.externalIds%2Cauthors.hIndex%2Cauthors.homepage%2Cauthors.name%2Cauthors.paperCount%2Cauthors.url%2CcitationCount%2CcitationStyles%2Ccitations%2Ccitations.abstract%2Ccitations.authors%2Ccitations.citationCount%2Ccitations.citationStyles%2Ccitations.corpusId%2Ccitations.externalIds%2Ccitations.fieldsOfStudy%2Ccitations.influentialCitationCount%2Ccitations.isOpenAccess%2Ccitations.journal%2Ccitations.openAccessPdf%2Ccitations.paperId%2Ccitations.publicationDate%2Ccitations.publicationTypes%2Ccitations.publicationVenue%2Ccitations.referenceCount%2Ccitations.s2FieldsOfStudy%2Ccitations.title%2Ccitations.url%2Ccitations.venue%2Ccitations.year%2CcorpusId%2Cembedding%2CexternalIds%2CfieldsOfStudy%2CinfluentialCitationCount%2CisOpenAccess%2Cjournal%2CopenAccessPdf%2CpaperId%2CpublicationDate%2CpublicationTypes%2CpublicationVenue%2CreferenceCount%2Creferences%2Creferences.abstract%2Creferences.authors%2Creferences.citationCount%2Creferences.citationStyles%2Creferences.corpusId%2Creferences.externalIds%2Creferences.fieldsOfStudy%2Creferences.influentialCitationCount%2Creferences.isOpenAccess%2Creferences.journal%2Creferences.openAccessPdf%2Creferences.paperId%2Creferences.publicationDate%2Creferences.publicationTypes%2Creferences.publicationVenue%2Creferences.referenceCount%2Creferences.s2FieldsOfStudy%2Creferences.title%2Creferences.url%2Creferences.venue%2Creferences.year%2Cs2FieldsOfStudy%2Ctitle%2Ctldr%2Curl%2Cvenue%2Cyear \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "config = {\"arxiv_ids\": [\"1903.03894v4\", \"1806.08804v4\"], \"dest_dir\": \"./download\"}\n",
    "research_arcade.construct_table_from_api(\"arxiv_authors\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bc87bb",
   "metadata": {},
   "source": [
    "#### Construct Table from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdfb12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: CSV file /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/csv_data/arxiv_authors.csv does not exist.\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"/home/jingjunx/openreview_benchmark/Code/research-arcade/examples/csv_data/arxiv_authors.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"arxiv_authors\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b970d0",
   "metadata": {},
   "source": [
    "#### Construct Table from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c340e625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: JSON file /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/json_data/arxiv_authors.json does not exist.\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"/home/jingjunx/openreview_benchmark/Code/research-arcade/examples/json_data/arxiv_authors.json\"}\n",
    "research_arcade.construct_table_from_json(\"arxiv_authors\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68f6ebb",
   "metadata": {},
   "source": [
    "#### Insert Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3985ae0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted author: Ashish Vaswani\n",
      "Inserted author: Noam Shazeer\n",
      "Inserted author: Niki Parmar\n",
      "Inserted author: Jakob Uszkoreit\n",
      "Inserted author: Llion Jones\n"
     ]
    }
   ],
   "source": [
    "# Insert authors from the Transformer paper\n",
    "authors = [\n",
    "    {\n",
    "        'semantic_scholar_id': 'ss_ashish_vaswani',\n",
    "        'name': 'Ashish Vaswani',\n",
    "        'homepage': 'https://scholar.google.com/citations?user=oR9sCGYAAAAJ'\n",
    "    },\n",
    "    {\n",
    "        'semantic_scholar_id': 'ss_noam_shazeer',\n",
    "        'name': 'Noam Shazeer',\n",
    "        'homepage': 'https://scholar.google.com/citations?user=oR9sCGYAAAAJ'\n",
    "    },\n",
    "    {\n",
    "        'semantic_scholar_id': 'ss_niki_parmar',\n",
    "        'name': 'Niki Parmar',\n",
    "        'homepage': 'https://scholar.google.com/citations?user=oR9sCGYAAAAJ'\n",
    "    },\n",
    "    {\n",
    "        'semantic_scholar_id': 'ss_jakob_uszkoreit',\n",
    "        'name': 'Jakob Uszkoreit',\n",
    "        'homepage': 'https://scholar.google.com/citations?user=oR9sCGYAAAAJ'\n",
    "    },\n",
    "    {\n",
    "        'semantic_scholar_id': 'ss_llion_jones',\n",
    "        'name': 'Llion Jones',\n",
    "        'homepage': 'https://scholar.google.com/citations?user=oR9sCGYAAAAJ'\n",
    "    }\n",
    "]\n",
    "\n",
    "for author in authors:\n",
    "    research_arcade.insert_node(\"arxiv_authors\", node_features=author)\n",
    "    print(f\"Inserted author: {author['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb67d02",
   "metadata": {},
   "source": [
    "#### Get All Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3dc3170a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total authors in database: 16\n",
      "\n",
      "All authors:\n",
      "    id semantic_scholar_id                 name  \\\n",
      "0    1            83539859             Rex Ying   \n",
      "1    2            40974349      Dylan Bourgeois   \n",
      "2    3           145829303          Jiaxuan You   \n",
      "3    4             2095762            M. Zitnik   \n",
      "4    5             1702139          J. Leskovec   \n",
      "5    6            83539859             Rex Ying   \n",
      "6    7           145829303          Jiaxuan You   \n",
      "7    8           143622465   Christopher Morris   \n",
      "8    9           145201124            Xiang Ren   \n",
      "9   10            49437682  William L. Hamilton   \n",
      "10  11             1702139          J. Leskovec   \n",
      "11  12   ss_ashish_vaswani       Ashish Vaswani   \n",
      "12  13     ss_noam_shazeer         Noam Shazeer   \n",
      "13  14      ss_niki_parmar          Niki Parmar   \n",
      "14  15  ss_jakob_uszkoreit      Jakob Uszkoreit   \n",
      "15  16      ss_llion_jones          Llion Jones   \n",
      "\n",
      "                                             homepage  \n",
      "0     https://www.semanticscholar.org/author/83539859  \n",
      "1     https://www.semanticscholar.org/author/40974349  \n",
      "2    https://www.semanticscholar.org/author/145829303  \n",
      "3      https://www.semanticscholar.org/author/2095762  \n",
      "4      https://www.semanticscholar.org/author/1702139  \n",
      "5     https://www.semanticscholar.org/author/83539859  \n",
      "6    https://www.semanticscholar.org/author/145829303  \n",
      "7    https://www.semanticscholar.org/author/143622465  \n",
      "8    https://www.semanticscholar.org/author/145201124  \n",
      "9     https://www.semanticscholar.org/author/49437682  \n",
      "10     https://www.semanticscholar.org/author/1702139  \n",
      "11                          https://ashishvaswani.com  \n",
      "12  https://scholar.google.com/citations?user=oR9s...  \n",
      "13  https://scholar.google.com/citations?user=oR9s...  \n",
      "14  https://scholar.google.com/citations?user=oR9s...  \n",
      "15  https://scholar.google.com/citations?user=oR9s...  \n"
     ]
    }
   ],
   "source": [
    "authors_df = research_arcade.get_all_node_features(\"arxiv_authors\")\n",
    "print(f\"Total authors in database: {len(authors_df)}\")\n",
    "print(\"\\nAll authors:\")\n",
    "print(authors_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9ab85d",
   "metadata": {},
   "source": [
    "#### Get Specific Author by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7069ebcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author details:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "author_id = {\"semantic_scholar_id\": \"2375099373\"}\n",
    "author_features = research_arcade.get_node_features_by_id(\"arxiv_authors\", author_id)\n",
    "print(\"Author details:\")\n",
    "print(author_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd33e25",
   "metadata": {},
   "source": [
    "#### Update an Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6b73cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Author updated successfully!\n"
     ]
    }
   ],
   "source": [
    "updated_author = {\n",
    "    'semantic_scholar_id': 'ss_ashish_vaswani',\n",
    "    'homepage': 'https://ashishvaswani.com'\n",
    "}\n",
    "\n",
    "research_arcade.update_node(\"arxiv_authors\", node_features=updated_author)\n",
    "print(\"Author updated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0a0d3d",
   "metadata": {},
   "source": [
    "### arxiv_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bd5398",
   "metadata": {},
   "source": [
    "#### Table Schema\n",
    "- `id` (SERIAL PK)\n",
    "- `name` (VARCHAR, unique)\n",
    "- `description` (TEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec7af3a",
   "metadata": {},
   "source": [
    "#### Insert From API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78ab747c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '1903.03894v4', 'title': 'GNNExplainer: Generating Explanations for Graph Neural Networks', 'abstract': \"Graph Neural Networks (GNNs) are a powerful tool for machine learning on graphs.GNNs combine node feature information with the graph structure by recursively passing neural messages along edges of the input graph. However, incorporating both graph structure and feature information leads to complex models, and explaining predictions made by GNNs remains unsolved. Here we propose GNNExplainer, the first general, model-agnostic approach for providing interpretable explanations for predictions of any GNN-based model on any graph-based machine learning task. Given an instance, GNNExplainer identifies a compact subgraph structure and a small subset of node features that have a crucial role in GNN's prediction. Further, GNNExplainer can generate consistent and concise explanations for an entire class of instances. We formulate GNNExplainer as an optimization task that maximizes the mutual information between a GNN's prediction and distribution of possible subgraph structures. Experiments on synthetic and real-world graphs show that our approach can identify important graph structures as well as node features, and outperforms baselines by 17.1% on average. GNNExplainer provides a variety of benefits, from the ability to visualize semantically relevant structures to interpretability, to giving insights into errors of faulty GNNs.\", 'authors': ['Rex Ying', 'Dylan Bourgeois', 'Jiaxuan You', 'Marinka Zitnik', 'Jure Leskovec'], 'published': '2019-03-10 00:56:26+00:00', 'categories': ['cs.LG', 'stat.ML'], 'url': 'http://arxiv.org/abs/1903.03894v4'}\n",
      "{'id': '1806.08804v4', 'title': 'Hierarchical Graph Representation Learning with Differentiable Pooling', 'abstract': 'Recently, graph neural networks (GNNs) have revolutionized the field of graph representation learning through effectively learned node embeddings, and achieved state-of-the-art results in tasks such as node classification and link prediction. However, current GNN methods are inherently flat and do not learn hierarchical representations of graphs---a limitation that is especially problematic for the task of graph classification, where the goal is to predict the label associated with an entire graph. Here we propose DiffPool, a differentiable graph pooling module that can generate hierarchical representations of graphs and can be combined with various graph neural network architectures in an end-to-end fashion. DiffPool learns a differentiable soft cluster assignment for nodes at each layer of a deep GNN, mapping nodes to a set of clusters, which then form the coarsened input for the next GNN layer. Our experimental results show that combining existing GNN methods with DiffPool yields an average improvement of 5-10% accuracy on graph classification benchmarks, compared to all existing pooling approaches, achieving a new state-of-the-art on four out of five benchmark data sets.', 'authors': ['Rex Ying', 'Jiaxuan You', 'Christopher Morris', 'Xiang Ren', 'William L. Hamilton', 'Jure Leskovec'], 'published': '2018-06-22 18:04:46+00:00', 'categories': ['cs.LG', 'cs.NE', 'cs.SI', 'stat.ML'], 'url': 'http://arxiv.org/abs/1806.08804v4'}\n"
     ]
    }
   ],
   "source": [
    "config = {\"arxiv_ids\": [\"1903.03894v4\", \"1806.08804v4\"], \"dest_dir\": \"./download\"}\n",
    "research_arcade.construct_table_from_api(\"arxiv_categories\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b158826",
   "metadata": {},
   "source": [
    "#### Construct Table from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d835faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: CSV file /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/csv_data/arxiv_categories.csv does not exist.\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"/home/jingjunx/openreview_benchmark/Code/research-arcade/examples/csv_data/arxiv_categories.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"arxiv_categories\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b0cc00",
   "metadata": {},
   "source": [
    "#### Construct Table from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f20d2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: JSON file /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/json_data/arxiv_categories.json does not exist.\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"/home/jingjunx/openreview_benchmark/Code/research-arcade/examples/json_data/arxiv_categories.json\"}\n",
    "research_arcade.construct_table_from_json(\"arxiv_categories\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a12f6ec",
   "metadata": {},
   "source": [
    "#### Insert Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d37aee70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted category: cs.CL\n",
      "Inserted category: cs.LG\n",
      "Inserted category: cs.AI\n",
      "Inserted category: cs.CV\n",
      "Inserted category: stat.ML\n"
     ]
    }
   ],
   "source": [
    "categories = [\n",
    "    {\n",
    "        'name': 'cs.CL',\n",
    "        'description': 'Computation and Language (Natural Language Processing)'\n",
    "    },\n",
    "    {\n",
    "        'name': 'cs.LG',\n",
    "        'description': 'Machine Learning'\n",
    "    },\n",
    "    {\n",
    "        'name': 'cs.AI',\n",
    "        'description': 'Artificial Intelligence'\n",
    "    },\n",
    "    {\n",
    "        'name': 'cs.CV',\n",
    "        'description': 'Computer Vision and Pattern Recognition'\n",
    "    },\n",
    "    {\n",
    "        'name': 'stat.ML',\n",
    "        'description': 'Machine Learning (Statistics)'\n",
    "    }\n",
    "]\n",
    "\n",
    "for category in categories:\n",
    "    research_arcade.insert_node(\"arxiv_categories\", node_features=category)\n",
    "    print(f\"Inserted category: {category['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bf3437",
   "metadata": {},
   "source": [
    "#### Get All Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68ad1ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total categories: 7\n",
      "\n",
      "All categories:\n",
      "   id     name                                        description\n",
      "0   1    cs.LG                                                NaN\n",
      "1   2  stat.ML                                                NaN\n",
      "2   3    cs.NE                                                NaN\n",
      "3   4    cs.SI                                                NaN\n",
      "4   5    cs.CL  Computation and Language (Natural Language Pro...\n",
      "5   6    cs.AI                            Artificial Intelligence\n",
      "6   7    cs.CV            Computer Vision and Pattern Recognition\n"
     ]
    }
   ],
   "source": [
    "categories_df = research_arcade.get_all_node_features(\"arxiv_categories\")\n",
    "print(f\"Total categories: {len(categories_df)}\")\n",
    "print(\"\\nAll categories:\")\n",
    "print(categories_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79da529e",
   "metadata": {},
   "source": [
    "### arxiv_figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9542d3",
   "metadata": {},
   "source": [
    "#### Table Schema\n",
    "\n",
    "- `id` (SERIAL PK)\n",
    "- `paper_arxiv_id` (VARCHAR FK → papers.arxiv_id)\n",
    "- `path` (VARCHAR)\n",
    "- `caption` (TEXT)\n",
    "- `label` (TEXT)\n",
    "- `name` (TEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2b784b",
   "metadata": {},
   "source": [
    "#### Construct Table from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f453a3cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3093e20",
   "metadata": {},
   "source": [
    "#### Construct Table from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895a731b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07daea82",
   "metadata": {},
   "source": [
    "#### Insert From API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9dfb5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"arxiv_ids\": [\"1903.03894v4\", \"1806.08804v4\"], \"dest_dir\": \"./download\"}\n",
    "research_arcade.construct_table_from_api(\"arxiv_figures\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a42e5a4",
   "metadata": {},
   "source": [
    "#### Insert Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0805ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted Figure 1\n",
      "Inserted Figure 2\n",
      "Inserted Figure 3\n"
     ]
    }
   ],
   "source": [
    "# Insert figures for the Transformer paper\n",
    "figures = [\n",
    "    {\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'path': '/figures/transformer_architecture.png',\n",
    "        'caption': 'The Transformer model architecture. The left side shows the encoder stack and the right side shows the decoder stack.',\n",
    "        'label': 'fig:architecture',\n",
    "        'name': 'Figure 1'\n",
    "    },\n",
    "    {\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'path': '/figures/scaled_dot_product_attention.png',\n",
    "        'caption': 'Scaled Dot-Product Attention and Multi-Head Attention mechanisms.',\n",
    "        'label': 'fig:attention',\n",
    "        'name': 'Figure 2'\n",
    "    },\n",
    "    {\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'path': '/figures/positional_encoding.png',\n",
    "        'caption': 'Positional encoding visualization showing sine and cosine functions of different frequencies.',\n",
    "        'label': 'fig:positional',\n",
    "        'name': 'Figure 3'\n",
    "    }\n",
    "]\n",
    "\n",
    "for figure in figures:\n",
    "    research_arcade.insert_node(\"arxiv_figures\", node_features=figure)\n",
    "    print(f\"Inserted {figure['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed171cf",
   "metadata": {},
   "source": [
    "#### Get All Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "682af0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total figures: 68\n",
      "\n",
      "All figures:\n",
      "   name                                            caption  \\\n",
      "0   NaN                             Updated figure caption   \n",
      "1   NaN  \\caption{\\textbf{A.} \\gnn computation graph $G...   \n",
      "2   NaN  \\caption{For $v$'s explanation $G_S$ (in green...   \n",
      "3   NaN  \\caption{For $v$'s explanation $G_S$ (in green...   \n",
      "4   NaN  \\caption{Evaluation of single-instance explana...   \n",
      "..  ...                                                ...   \n",
      "63  NaN                                         \\caption{}   \n",
      "64  NaN                                         \\caption{}   \n",
      "65  NaN                                         \\caption{}   \n",
      "66  NaN                                         \\caption{}   \n",
      "67  NaN                                         \\caption{}   \n",
      "\n",
      "                                   label  \n",
      "0            \\label{fig:explainer-intro}  \n",
      "1   \\label{fig:definition-node-features}  \n",
      "2    \\label{fig:including-node-features}  \n",
      "3    \\label{fig:including-node-features}  \n",
      "4              \\label{fig:subgraph_node}  \n",
      "..                                   ...  \n",
      "63                                   NaN  \n",
      "64                                   NaN  \n",
      "65                                   NaN  \n",
      "66                                   NaN  \n",
      "67                                   NaN  \n",
      "\n",
      "[68 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "figures_df = research_arcade.get_all_node_features(\"arxiv_figures\")\n",
    "print(f\"Total figures: {len(figures_df)}\")\n",
    "print(\"\\nAll figures:\")\n",
    "print(figures_df[['name', 'caption', 'label']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b7fe75",
   "metadata": {},
   "source": [
    "#### delete specific node by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b39b8315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure_id = {\"id\": 1}\n",
    "research_arcade.delete_node_by_id(\"arxiv_figures\", figure_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fcc00b",
   "metadata": {},
   "source": [
    "#### update specific node by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14611ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_figure = {\n",
    "    'id': 2,\n",
    "    'paper_arxiv_id': 1453.1644,\n",
    "    'path': 'path',\n",
    "    'caption': 'Updated figure caption'\n",
    "}\n",
    "research_arcade.update_node(\"arxiv_figures\", node_features=updated_figure)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b97dd0",
   "metadata": {},
   "source": [
    "#### get specific node by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db5e2934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 2, 'paper_arxiv_id': '1453.1644', 'path': 'path', 'caption': 'Updated figure caption', 'label': '\\\\label{fig:explainer-intro}', 'name': nan}\n"
     ]
    }
   ],
   "source": [
    "figure_id = {\"id\": 2}\n",
    "figure = research_arcade.get_node_features_by_id(\"arxiv_figures\", figure_id)\n",
    "print(figure.to_dict(orient=\"records\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84273e0",
   "metadata": {},
   "source": [
    "### arxiv_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a8e3d7",
   "metadata": {},
   "source": [
    "#### Table Schema\n",
    "\n",
    "- `id` (SERIAL PK)\n",
    "- `paper_arxiv_id` (VARCHAR FK → papers.arxiv_id)\n",
    "- `path` (VARCHAR)\n",
    "- `caption` (TEXT)\n",
    "- `label` (TEXT)\n",
    "- `table_text` (TEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf1bca9",
   "metadata": {},
   "source": [
    "#### Insert From API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf406a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"arxiv_ids\": [\"1903.03894v4\", \"1806.08804v4\"], \"dest_dir\": \"./download\"}\n",
    "research_arcade.construct_table_from_api(\"arxiv_tables\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780bbb49",
   "metadata": {},
   "source": [
    "#### Construct Table from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09f7de0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: CSV file ./examples/csv_data/csv_arxiv_tables_example.csv does not exist.\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"./examples/csv_data/csv_arxiv_tables_example.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"arxiv_tables\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfce9ad",
   "metadata": {},
   "source": [
    "#### Construct Table from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7dc5f03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: JSON file ./examples/json_data/json_arxiv_tables_example.json does not exist.\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"./examples/json_data/json_arxiv_tables_example.json\"}\n",
    "research_arcade.construct_table_from_json(\"arxiv_tables\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a804eeb0",
   "metadata": {},
   "source": [
    "#### Insert Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "958e7434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted table: {'paper_arxiv_id': '1706.03762v7', 'caption': 'Performance comparison', 'label': 'label', 'table_text': 'Table content here'}\n"
     ]
    }
   ],
   "source": [
    "tables = [\n",
    "    {\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'caption': 'Performance comparison',\n",
    "        'label': 'label',\n",
    "        'table_text': 'Table content here'\n",
    "    }\n",
    "]\n",
    "\n",
    "for table in tables:\n",
    "    research_arcade.insert_node(\"arxiv_tables\", node_features=table)\n",
    "    print(f\"Inserted table: {table}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc98fca",
   "metadata": {},
   "source": [
    "#### Get All Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "beb34231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total categories: 7\n",
      "\n",
      "All categories:\n",
      "   id     name                                        description\n",
      "0   1    cs.LG                                                NaN\n",
      "1   2  stat.ML                                                NaN\n",
      "2   3    cs.NE                                                NaN\n",
      "3   4    cs.SI                                                NaN\n",
      "4   5    cs.CL  Computation and Language (Natural Language Pro...\n",
      "5   6    cs.AI                            Artificial Intelligence\n",
      "6   7    cs.CV            Computer Vision and Pattern Recognition\n"
     ]
    }
   ],
   "source": [
    "categories_df = research_arcade.get_all_node_features(\"arxiv_categories\")\n",
    "print(f\"Total categories: {len(categories_df)}\")\n",
    "print(\"\\nAll categories:\")\n",
    "print(categories_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2135bc84",
   "metadata": {},
   "source": [
    "#### delete specific node by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ce03073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_id = {\"id\": 1}\n",
    "research_arcade.delete_node_by_id(\"arxiv_tables\", table_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9ff34e",
   "metadata": {},
   "source": [
    "#### update specific node by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a9ef7919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_table = {\n",
    "    'id': 2,\n",
    "    'paper_arxiv_id': '1706.03762v7',\n",
    "    'caption': 'Performance comparison',\n",
    "    'label': 'label',\n",
    "    'table_text': 'Table content here'\n",
    "}\n",
    "research_arcade.update_node(\"arxiv_tables\", node_features=updated_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb224b11",
   "metadata": {},
   "source": [
    "#### get all nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3d7abc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tables: 12\n"
     ]
    }
   ],
   "source": [
    "tables_df = research_arcade.get_all_node_features(\"arxiv_tables\")\n",
    "print(f\"Total tables: {len(tables_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6429d07d",
   "metadata": {},
   "source": [
    "#### get specific node by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7cb4765f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 2, 'paper_arxiv_id': '1706.03762v7', 'path': nan, 'caption': 'Performance comparison', 'label': 'label', 'table_text': 'Table content here'}\n"
     ]
    }
   ],
   "source": [
    "table_id = {\"id\": 2}\n",
    "table = research_arcade.get_node_features_by_id(\"arxiv_tables\", table_id)\n",
    "print(table.to_dict(orient=\"records\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919685c7",
   "metadata": {},
   "source": [
    "### arxiv_sections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41fa44d",
   "metadata": {},
   "source": [
    "#### Table Schema\n",
    "\n",
    "- `id` (SERIAL PK)\n",
    "- `content` (TEXT)\n",
    "- `title` (TEXT)\n",
    "- `appendix` (BOOLEAN)\n",
    "- `paper_arxiv_id` (VARCHAR FK → papers.arxiv_id)\n",
    "- `section_in_paper_id` (INT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96352bbd",
   "metadata": {},
   "source": [
    "#### Insert From API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "162d6124",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"arxiv_ids\": [\"1903.03894v4\", \"1806.08804v4\"], \"dest_dir\": \"./download\"}\n",
    "research_arcade.construct_table_from_api(\"arxiv_sections\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab90b15",
   "metadata": {},
   "source": [
    "#### Construct Table from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4c29fcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: CSV file ./examples/csv_data/csv_arxiv_sections_example.csv does not exist.\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"./examples/csv_data/csv_arxiv_sections_example.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"arxiv_sections\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09736cf9",
   "metadata": {},
   "source": [
    "#### Construct Table from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a6a6dce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: JSON file ./examples/json_data/json_arxiv_sections_example.json does not exist.\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"./examples/json_data/json_arxiv_sections_example.json\"}\n",
    "research_arcade.construct_table_from_json(\"arxiv_sections\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954233ee",
   "metadata": {},
   "source": [
    "#### Insert Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ce3825c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted section: Introduction\n",
      "Inserted section: Background\n",
      "Inserted section: Model Architecture\n",
      "Inserted section: Training\n",
      "Inserted section: Results\n",
      "Inserted section: Conclusion\n"
     ]
    }
   ],
   "source": [
    "# Insert sections for the Transformer paper\n",
    "sections = [\n",
    "    {\n",
    "        'content': 'The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder...',\n",
    "        'title': 'Introduction',\n",
    "        'appendix': False,\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'section_in_paper_id': 1\n",
    "    },\n",
    "    {\n",
    "        'content': 'Most competitive neural sequence transduction models have an encoder-decoder structure. Here, the encoder maps an input sequence of symbol representations...',\n",
    "        'title': 'Background',\n",
    "        'appendix': False,\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'section_in_paper_id': 2\n",
    "    },\n",
    "    {\n",
    "        'content': 'Most neural sequence transduction models have an encoder-decoder structure. The Transformer follows this overall architecture using stacked self-attention and point-wise, fully connected layers...',\n",
    "        'title': 'Model Architecture',\n",
    "        'appendix': False,\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'section_in_paper_id': 3\n",
    "    },\n",
    "    {\n",
    "        'content': 'In this section we describe the training regime for our models...',\n",
    "        'title': 'Training',\n",
    "        'appendix': False,\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'section_in_paper_id': 4\n",
    "    },\n",
    "    {\n",
    "        'content': 'On the WMT 2014 English-to-German translation task, the big transformer model outperforms the best previously reported models...',\n",
    "        'title': 'Results',\n",
    "        'appendix': False,\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'section_in_paper_id': 5\n",
    "    },\n",
    "    {\n",
    "        'content': 'In this work, we presented the Transformer, the first sequence transduction model based entirely on attention, replacing the recurrent layers...',\n",
    "        'title': 'Conclusion',\n",
    "        'appendix': False,\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'section_in_paper_id': 6\n",
    "    }\n",
    "]\n",
    "\n",
    "for section in sections:\n",
    "    research_arcade.insert_node(\"arxiv_sections\", node_features=section)\n",
    "    print(f\"Inserted section: {section['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b803be10",
   "metadata": {},
   "source": [
    "#### delete specific node by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "80bfc218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_id = {\"id\": 1}\n",
    "research_arcade.delete_node_by_id(\"arxiv_sections\", section_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cac1d4",
   "metadata": {},
   "source": [
    "#### update specific node by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3175d60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_section = {\n",
    "    'id': 1,\n",
    "    'title': 'Updated Section Title',\n",
    "    'content': 'Updated content'\n",
    "}\n",
    "research_arcade.update_node(\"arxiv_sections\", node_features=updated_section)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c615c3",
   "metadata": {},
   "source": [
    "#### get specific node by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "470b7110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 2, 'content': \"\\n\\\\label{sec:related}\\n\\n\\n\\nAlthough the problem of explaining GNNs is not well-studied, the related problems of interpretability and neural debugging received substantial attention in machine learning. At a high level, we can group those interpretability methods for non-graph neural networks into two main families.  \\n\\nMethods in the first family formulate simple proxy models of full neural networks. This can be done in a model-agnostic way, usually by learning a locally faithful approximation around the prediction, for example through linear models~\\\\citep{ribeiro_why_2016} or sets of rules, representing sufficient conditions on the prediction~\\\\citep{augasta_reverse_2012,lakkaraju_interpretable_2017,calders_deepred_2016}. Methods in the second family identify important aspects of the computation, for example, through feature gradients~\\\\citep{Erhan2009VisualizingHF,fleet_visualizing_2014}, backpropagation of neurons' contributions to the input features~\\\\citep{chen2018learning,shrikumar_learning_2017,sundararajan_axiomatic_nodate}, and counterfactual reasoning~\\\\citep{Kang2019explaine}. \\nHowever, the saliency maps~\\\\citep{fleet_visualizing_2014} produced by these methods have been shown to be misleading in some instances~\\\\citep{2018sanity} and prone to issues like gradient saturation~\\\\citep{shrikumar_learning_2017,sundararajan_axiomatic_nodate}. These issues are exacerbated on discrete inputs such as graph adjacency matrices since the gradient values can be very large but only on very small intervals. Because of that, such approaches are not suitable for explaining predictions made by neural networks on graphs.\\n\\nInstead of creating new, inherently interpretable models, post-hoc interpretability methods~\\\\citep{adadi_peeking_2018,fisher_all_2018,guidotti_survey_2018,hooker_discovering_2004,koh_understanding_2017,DBLP:journals/corr/abs-1811-09720} consider models as black boxes and then probe them for relevant information. \\nHowever, no work has been done to leverage relational structures like graphs. The lack of methods for explaining predictions on graph-structured data is problematic, as in many cases, predictions on graphs are induced by a complex combination of nodes and paths of edges between them. For example, in some tasks, an edge is important only when another alternative path exists in the graph to form a cycle, and those two features, only when considered together, can accurately predict node labels ~\\\\citep{mutag,duvenaud_convolutional_2015}. Their joint contribution thus cannot be modeled as a simple linear combinations of individual contributions. \\n\\nFinally, recent \\\\gnn models augment interpretability via attention mechanisms~\\\\citep{neil2018interpretable, velickovic2018graph,PhysRevLett.120.145301}. However, although the learned edge attention values can indicate important graph structure, the values are the same for predictions across all nodes. Thus, this contradicts with many applications where an edge is essential for predicting the label of one node but not the label of another node. Furthermore, these approaches are either limited to specific \\\\gnn architectures or cannot explain predictions by jointly considering both graph structure and node feature information.\\n\\n\\n\\\\hide{\\nMethods in the first family formulate a simpler proxy model for the full neural network. This can be done in a model-agnostic way, usually by learning a locally faithful approximation around the prediction, for example with a linear model~\\\\cite{ribeiro_why_2016} or a set of rules, representing sufficient conditions on the prediction~\\\\cite{augasta_reverse_2012,calders_deepred_2016,lakkaraju_interpretable_2017}. \\nGlobal distillations of the main model have also been proposed, for instance by reducing deep neural networks to decision trees~\\\\cite{calders_deepred_2016, schmitz_ann-dt:_1999}. However, such approaches often produce intractably large surrogate models, which in practice are uninterpretable.\\n\\nA second family of models instead aims to highlight relevant aspects of the computation within the provided model. The main approach here is to inspect feature gradients~\\\\cite{Erhan2009VisualizingHF} but many other related ideas have also been proposed~\\\\cite{sundararajan_axiomatic_nodate, shrikumar_learning_2017}. When overlayed to the input data, these methods produce a saliency map~\\\\cite{fleet_visualizing_2014} which reveals important features or raw pixels. However, saliency maps have been shown to be misleading in some instances~\\\\cite{2018sanity} and prone to issues such as gradient saturation~\\\\cite{sundararajan_axiomatic_nodate, shrikumar_learning_2017}. These issues are exacerbated on discrete inputs such as graph adjacency matrices, since the gradient values can be very large but on a very small interval. This means such approaches are unsuitable for explaining relational structure of a \\\\gnn, which is our goal here.\\n%editing the adjacency matrix will not cause large changes in the interpretation despite significantly impacting the network itself.\\n\\nLast, algorithms that find patterns of the input data~\\\\cite{koh_understanding_2017, DBLP:journals/corr/abs-1811-09720} to identify influential samples are an example of post-hoc interpretability methods. Instead of creating new, inherently interpretable models, thse approaches consider the model as a black box~\\\\cite{guidotti_survey_2018, adadi_peeking_2018} and then probe it for relevant information. Most techniques isolate individual input samples, with some methods allowing for important interactions to be highlighted~\\\\cite{fisher_all_2018, hooker_discovering_2004}. However, no work has been done to leverage stronger relational structures like graphs. In contrast, in many cases prediction on graphs can be induced by a complex composition of nodes and their paths. For example, in some tasks an edge could be important only when another alternative path exists to form a cycle, which determines the class of the node. Therefore their joint contribution cannot be modeled well using linear combinations of individual contributions. %While it is important to discover the entire subgraph structure, this process is highly non-linear.\\n}\\nMethods in the first family formulate a simpler proxy model for the full neural network. This can be done in a model-agnostic way, usually by learning a locally faithful approximation around the prediction, for example with a linear model~\\\\cite{ribeiro_why_2016} or a set of rules, representing sufficient conditions on the prediction~\\\\cite{augasta_reverse_2012,calders_deepred_2016,lakkaraju_interpretable_2017}. \\nGlobal distillations of the main model have also been proposed, for instance by reducing deep neural networks to decision trees~\\\\cite{calders_deepred_2016, schmitz_ann-dt:_1999}. However, such approaches often produce intractably large surrogate models, which in practice are uninterpretable.\\n\\nA second family of models instead aims to highlight relevant aspects of the computation within the provided model. The main approach here is to inspect feature gradients~\\\\cite{Erhan2009VisualizingHF} but many other related ideas have also been proposed~\\\\cite{sundararajan_axiomatic_nodate, shrikumar_learning_2017}. When overlayed to the input data, these methods produce a saliency map~\\\\cite{fleet_visualizing_2014} which reveals important features or raw pixels. However, saliency maps have been shown to be misleading in some instances~\\\\cite{2018sanity} and prone to issues such as gradient saturation~\\\\cite{sundararajan_axiomatic_nodate, shrikumar_learning_2017}. These issues are exacerbated on discrete inputs such as graph adjacency matrices, since the gradient values can be very large but on a very small interval. This means such approaches are unsuitable for explaining relational structure of a \\\\gnn, which is our goal here.\\n\\n\\nLast, algorithms that find patterns of the input data~\\\\cite{koh_understanding_2017, DBLP:journals/corr/abs-1811-09720} to identify influential samples are an example of post-hoc interpretability methods. Instead of creating new, inherently interpretable models, thse approaches consider the model as a black box~\\\\cite{guidotti_survey_2018, adadi_peeking_2018} and then probe it for relevant information. Most techniques isolate individual input samples, with some methods allowing for important interactions to be highlighted~\\\\cite{fisher_all_2018, hooker_discovering_2004}. However, no work has been done to leverage stronger relational structures like graphs. In contrast, in many cases prediction on graphs can be induced by a complex composition of nodes and their paths. For example, in some tasks an edge could be important only when another alternative path exists to form a cycle, which determines the class of the node. Therefore their joint contribution cannot be modeled well using linear combinations of individual contributions. \\n\\n\\\\hide{\\nRecent instances of \\\\gnn models have been proposed to augment the interpretability properties of \\\\gnns~\\\\cite{PhysRevLett.120.145301, neil2018interpretable, velickovic2018graph}. However, in contrast to our work here, \\\\rex{these approaches are limited to their own \\\\gnn architecture, and cannot make explanations using both features and subgraph structure jointly.}\\n%these approaches design a novel \\\\gnn architectures explicitly for the purpose of interpretability. \\n\\\\rex{Notably, although the edge attention values in graph attention networks can serve as indication of structure importance, it is the same for predictions on all nodes. Thus it contradicts with many application scenario where an edge is important for predictions on one node, but not the other.\\n(or maybe move to experiments)}\\n\\\\rex{remove?} Our goal here is different, as we are already given a trained model in the \\\\gnn-family and aim to explain its predictions.\\n}\\nRecent instances of \\\\gnn models have been proposed to augment the interpretability properties of \\\\gnns~\\\\cite{PhysRevLett.120.145301, neil2018interpretable, velickovic2018graph}. However, in contrast to our work here, \\\\rex{these approaches are limited to their own \\\\gnn architecture, and cannot make explanations using both features and subgraph structure jointly.}these approaches are limited to their own \\\\gnn architecture, and cannot make explanations using both features and subgraph structure jointly.\\n\\\\rex{Notably, although the edge attention values in graph attention networks can serve as indication of structure importance, it is the same for predictions on all nodes. Thus it contradicts with many application scenario where an edge is important for predictions on one node, but not the other.\\n(or maybe move to experiments)}Notably, although the edge attention values in graph attention networks can serve as indication of structure importance, it is the same for predictions on all nodes. Thus it contradicts with many application scenario where an edge is important for predictions on one node, but not the other.\\n(or maybe move to experiments)\\n\\\\rex{remove?}remove? Our goal here is different, as we are already given a trained model in the \\\\gnn-family and aim to explain its predictions.\\n\\n\\n\\\\hide{\\n% Maybe merge with Background\\n\\\\xhdr{Graph Neural Networks} Graph Neural Networks (\\\\gnn)~\\\\cite{scarselli} obtain node embeddings by recursively propagating information from its neighbours. This framework was later unified into a general Neural Message-Passing scheme~\\\\cite{gilmer2017neural}, and more recently into the relational inductive bias model~\\\\cite{battaglia}. For a more detailed review of recent developments we please refer the reader to~\\\\cite{zhang_deep_2018, zhou_graph_2018, battaglia,hamilton2017representation}.\\n%\\nUnder this model, \\\\gnns have achieved state-of-the-art performance across a variety of tasks, such as node classification~\\\\cite{kipf2016semi, graphsage}, link prediction~\\\\cite{zhang2018link, schlichtkrull2018modeling}, graph clustering~\\\\cite{defferrard2016convolutional, ying2018hierarchical} or graph classification~\\\\cite{ying2018hierarchical, dai2016discriminative, duvenaud_convolutional_2015}. These tasks occur in domains where the graph structure is ubiquitous, such as social networks~\\\\cite{backstrom2011supervised}, content graphs~\\\\cite{pinsage}, biology~\\\\cite{agrawal2018large}, and chemoinformatics~\\\\cite{duvenaud_convolutional_2015,jin2017predicting,zitnik2018decagon}.\\n%\\nRecent instances of \\\\gnn models have been proposed to augment the interpretability properties of \\\\gnns~\\\\cite{PhysRevLett.120.145301, neil2018interpretable, velickovic2018graph}. However, in contrast to our work here, \\\\rex{these approaches are limited to their own \\\\gnn architecture, and cannot make explanations using both features and subgraph structure jointly.}\\n%these approaches design a novel \\\\gnn architectures explicitly for the purpose of interpretability. \\n\\\\rex{Notably, although the edge attention values in graph attention networks can serve as indication of structure importance, it is the same for predictions on all nodes. Thus it contradicts with many application scenario where an edge is important for predictions on one node, but not the other.\\n(or maybe move to experiments)}\\n\\\\rex{remove?} Our goal here is different, as we are already given a trained model in the \\\\gnn-family and aim to explain its predictions.\\n%, an approach that is at odds with our goal of post-hoc interpretation for any generic \\\\gnn~ model.\\n\\n%\\\\xhdr{Relation to adverserial attacks}\\n}\\n\\\\xhdr{Graph Neural Networks}Graph Neural Networks Graph Neural Networks (\\\\gnn)~\\\\cite{scarselli} obtain node embeddings by recursively propagating information from its neighbours. This framework was later unified into a general Neural Message-Passing scheme~\\\\cite{gilmer2017neural}, and more recently into the relational inductive bias model~\\\\cite{battaglia}. For a more detailed review of recent developments we please refer the reader to~\\\\cite{zhang_deep_2018, zhou_graph_2018, battaglia,hamilton2017representation}.\\nUnder this model, \\\\gnns have achieved state-of-the-art performance across a variety of tasks, such as node classification~\\\\cite{kipf2016semi, graphsage}, link prediction~\\\\cite{zhang2018link, schlichtkrull2018modeling}, graph clustering~\\\\cite{defferrard2016convolutional, ying2018hierarchical} or graph classification~\\\\cite{ying2018hierarchical, dai2016discriminative, duvenaud_convolutional_2015}. These tasks occur in domains where the graph structure is ubiquitous, such as social networks~\\\\cite{backstrom2011supervised}, content graphs~\\\\cite{pinsage}, biology~\\\\cite{agrawal2018large}, and chemoinformatics~\\\\cite{duvenaud_convolutional_2015,jin2017predicting,zitnik2018decagon}.\\nRecent instances of \\\\gnn models have been proposed to augment the interpretability properties of \\\\gnns~\\\\cite{PhysRevLett.120.145301, neil2018interpretable, velickovic2018graph}. However, in contrast to our work here, \\\\rex{these approaches are limited to their own \\\\gnn architecture, and cannot make explanations using both features and subgraph structure jointly.}these approaches are limited to their own \\\\gnn architecture, and cannot make explanations using both features and subgraph structure jointly.\\n\\\\rex{Notably, although the edge attention values in graph attention networks can serve as indication of structure importance, it is the same for predictions on all nodes. Thus it contradicts with many application scenario where an edge is important for predictions on one node, but not the other.\\n(or maybe move to experiments)}Notably, although the edge attention values in graph attention networks can serve as indication of structure importance, it is the same for predictions on all nodes. Thus it contradicts with many application scenario where an edge is important for predictions on one node, but not the other.\\n(or maybe move to experiments)\\n\\\\rex{remove?}remove? Our goal here is different, as we are already given a trained model in the \\\\gnn-family and aim to explain its predictions.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\", 'title': 'Related work', 'appendix': False, 'paper_arxiv_id': '1903.03894v4', 'section_in_paper_id': 2.0}\n"
     ]
    }
   ],
   "source": [
    "section_id = {\"id\": 2}\n",
    "section = research_arcade.get_node_features_by_id(\"arxiv_sections\", section_id)\n",
    "print(section.to_dict(orient=\"records\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68788ac2",
   "metadata": {},
   "source": [
    "#### Get All Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e0eee27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sections:     id                                            content  \\\n",
      "0    2  \\n\\label{sec:related}\\n\\n\\n\\nAlthough the prob...   \n",
      "1    3  \\n\\label{sec:explainer}\\n\\n\\n\\begin{figure*}[t...   \n",
      "2    4  \\n\\label{sec:exp}\\n\\n\\n\\n\\n\\n\\hide{\\nResults i...   \n",
      "3    5  \\n\\label{sec:conclusion}\\n\\nWe present \\longna...   \n",
      "4    6  \\n\\nThe problem of multi-instance explanations...   \n",
      "5    7  \\n\\nIn the context of multi-instance explanati...   \n",
      "6    8  \\n\\n\\xhdr{Training details}Training details\\nW...   \n",
      "7    9  \\n\\label{sec:intro}\\nIn recent years there has...   \n",
      "8   10  \\n\\nOur work builds upon a rich line of recent...   \n",
      "9   11  \\n\\label{sec:proposed}\\n\\nThe key idea of \\nam...   \n",
      "10  12  \\n\\label{sec:ex}\\n\\nWe evaluate the benefits o...   \n",
      "11  13  \\n\\nWe introduced a differentiable pooling met...   \n",
      "12  14  \\nThis research has been supported in part by ...   \n",
      "13  15  The dominant sequence transduction models are ...   \n",
      "14  16  Most competitive neural sequence transduction ...   \n",
      "15  17  Most neural sequence transduction models have ...   \n",
      "16  18  In this section we describe the training regim...   \n",
      "17  19  On the WMT 2014 English-to-German translation ...   \n",
      "18  20  In this work, we presented the Transformer, th...   \n",
      "19  21  \\n\\n\\n\\hide{\\n\\begin{figure}[h]\\n    \\centerin...   \n",
      "20  22  \\n\\label{sec:related}\\n\\n\\n\\nAlthough the prob...   \n",
      "21  23  \\n\\label{sec:explainer}\\n\\n\\n\\begin{figure*}[t...   \n",
      "22  24  \\n\\label{sec:exp}\\n\\n\\n\\n\\n\\n\\hide{\\nResults i...   \n",
      "23  25  \\n\\label{sec:conclusion}\\n\\nWe present \\longna...   \n",
      "24  26  \\n\\nThe problem of multi-instance explanations...   \n",
      "25  27  \\n\\nIn the context of multi-instance explanati...   \n",
      "26  28  \\n\\n\\xhdr{Training details}Training details\\nW...   \n",
      "27  29  \\n\\label{sec:intro}\\nIn recent years there has...   \n",
      "28  30  \\n\\nOur work builds upon a rich line of recent...   \n",
      "29  31  \\n\\label{sec:proposed}\\n\\nThe key idea of \\nam...   \n",
      "30  32  \\n\\label{sec:ex}\\n\\nWe evaluate the benefits o...   \n",
      "31  33  \\n\\nWe introduced a differentiable pooling met...   \n",
      "32  34  \\nThis research has been supported in part by ...   \n",
      "33  35  The dominant sequence transduction models are ...   \n",
      "34  36  Most competitive neural sequence transduction ...   \n",
      "35  37  Most neural sequence transduction models have ...   \n",
      "36  38  In this section we describe the training regim...   \n",
      "37  39  On the WMT 2014 English-to-German translation ...   \n",
      "38  40  In this work, we presented the Transformer, th...   \n",
      "\n",
      "                                                title  appendix  \\\n",
      "0                                        Related work     False   \n",
      "1   Formulating explanations for graph neural netw...     False   \n",
      "2                                         Experiments     False   \n",
      "3                                          Conclusion     False   \n",
      "4                         Multi-instance explanations     False   \n",
      "5   Experiments on multi-instance explanations and...     False   \n",
      "6                      Further implementation details     False   \n",
      "7                                        Introduction     False   \n",
      "8                                        Related Work     False   \n",
      "9                                     Proposed Method     False   \n",
      "10                                        Experiments     False   \n",
      "11                                         Conclusion     False   \n",
      "12                                    Acknowledgement     False   \n",
      "13                                       Introduction     False   \n",
      "14                                         Background     False   \n",
      "15                                 Model Architecture     False   \n",
      "16                                           Training     False   \n",
      "17                                            Results     False   \n",
      "18                                         Conclusion     False   \n",
      "19                                       Introduction     False   \n",
      "20                                       Related work     False   \n",
      "21  Formulating explanations for graph neural netw...     False   \n",
      "22                                        Experiments     False   \n",
      "23                                         Conclusion     False   \n",
      "24                        Multi-instance explanations     False   \n",
      "25  Experiments on multi-instance explanations and...     False   \n",
      "26                     Further implementation details     False   \n",
      "27                                       Introduction     False   \n",
      "28                                       Related Work     False   \n",
      "29                                    Proposed Method     False   \n",
      "30                                        Experiments     False   \n",
      "31                                         Conclusion     False   \n",
      "32                                    Acknowledgement     False   \n",
      "33                                       Introduction     False   \n",
      "34                                         Background     False   \n",
      "35                                 Model Architecture     False   \n",
      "36                                           Training     False   \n",
      "37                                            Results     False   \n",
      "38                                         Conclusion     False   \n",
      "\n",
      "   paper_arxiv_id  section_in_paper_id  \n",
      "0    1903.03894v4                  2.0  \n",
      "1    1903.03894v4                  3.0  \n",
      "2    1903.03894v4                  4.0  \n",
      "3    1903.03894v4                  5.0  \n",
      "4    1903.03894v4                  6.0  \n",
      "5    1903.03894v4                  7.0  \n",
      "6    1903.03894v4                  8.0  \n",
      "7    1806.08804v4                  1.0  \n",
      "8    1806.08804v4                  2.0  \n",
      "9    1806.08804v4                  3.0  \n",
      "10   1806.08804v4                  4.0  \n",
      "11   1806.08804v4                  5.0  \n",
      "12   1806.08804v4                  6.0  \n",
      "13   1706.03762v7                  1.0  \n",
      "14   1706.03762v7                  2.0  \n",
      "15   1706.03762v7                  3.0  \n",
      "16   1706.03762v7                  4.0  \n",
      "17   1706.03762v7                  5.0  \n",
      "18   1706.03762v7                  6.0  \n",
      "19   1903.03894v4                  1.0  \n",
      "20   1903.03894v4                  2.0  \n",
      "21   1903.03894v4                  3.0  \n",
      "22   1903.03894v4                  4.0  \n",
      "23   1903.03894v4                  5.0  \n",
      "24   1903.03894v4                  6.0  \n",
      "25   1903.03894v4                  7.0  \n",
      "26   1903.03894v4                  8.0  \n",
      "27   1806.08804v4                  1.0  \n",
      "28   1806.08804v4                  2.0  \n",
      "29   1806.08804v4                  3.0  \n",
      "30   1806.08804v4                  4.0  \n",
      "31   1806.08804v4                  5.0  \n",
      "32   1806.08804v4                  6.0  \n",
      "33   1706.03762v7                  1.0  \n",
      "34   1706.03762v7                  2.0  \n",
      "35   1706.03762v7                  3.0  \n",
      "36   1706.03762v7                  4.0  \n",
      "37   1706.03762v7                  5.0  \n",
      "38   1706.03762v7                  6.0  \n",
      "\n",
      "All sections:\n",
      "                                                title  section_in_paper_id  \\\n",
      "0                                        Related work                  2.0   \n",
      "1   Formulating explanations for graph neural netw...                  3.0   \n",
      "2                                         Experiments                  4.0   \n",
      "3                                          Conclusion                  5.0   \n",
      "4                         Multi-instance explanations                  6.0   \n",
      "5   Experiments on multi-instance explanations and...                  7.0   \n",
      "6                      Further implementation details                  8.0   \n",
      "7                                        Introduction                  1.0   \n",
      "8                                        Related Work                  2.0   \n",
      "9                                     Proposed Method                  3.0   \n",
      "10                                        Experiments                  4.0   \n",
      "11                                         Conclusion                  5.0   \n",
      "12                                    Acknowledgement                  6.0   \n",
      "13                                       Introduction                  1.0   \n",
      "14                                         Background                  2.0   \n",
      "15                                 Model Architecture                  3.0   \n",
      "16                                           Training                  4.0   \n",
      "17                                            Results                  5.0   \n",
      "18                                         Conclusion                  6.0   \n",
      "19                                       Introduction                  1.0   \n",
      "20                                       Related work                  2.0   \n",
      "21  Formulating explanations for graph neural netw...                  3.0   \n",
      "22                                        Experiments                  4.0   \n",
      "23                                         Conclusion                  5.0   \n",
      "24                        Multi-instance explanations                  6.0   \n",
      "25  Experiments on multi-instance explanations and...                  7.0   \n",
      "26                     Further implementation details                  8.0   \n",
      "27                                       Introduction                  1.0   \n",
      "28                                       Related Work                  2.0   \n",
      "29                                    Proposed Method                  3.0   \n",
      "30                                        Experiments                  4.0   \n",
      "31                                         Conclusion                  5.0   \n",
      "32                                    Acknowledgement                  6.0   \n",
      "33                                       Introduction                  1.0   \n",
      "34                                         Background                  2.0   \n",
      "35                                 Model Architecture                  3.0   \n",
      "36                                           Training                  4.0   \n",
      "37                                            Results                  5.0   \n",
      "38                                         Conclusion                  6.0   \n",
      "\n",
      "    appendix  \n",
      "0      False  \n",
      "1      False  \n",
      "2      False  \n",
      "3      False  \n",
      "4      False  \n",
      "5      False  \n",
      "6      False  \n",
      "7      False  \n",
      "8      False  \n",
      "9      False  \n",
      "10     False  \n",
      "11     False  \n",
      "12     False  \n",
      "13     False  \n",
      "14     False  \n",
      "15     False  \n",
      "16     False  \n",
      "17     False  \n",
      "18     False  \n",
      "19     False  \n",
      "20     False  \n",
      "21     False  \n",
      "22     False  \n",
      "23     False  \n",
      "24     False  \n",
      "25     False  \n",
      "26     False  \n",
      "27     False  \n",
      "28     False  \n",
      "29     False  \n",
      "30     False  \n",
      "31     False  \n",
      "32     False  \n",
      "33     False  \n",
      "34     False  \n",
      "35     False  \n",
      "36     False  \n",
      "37     False  \n",
      "38     False  \n"
     ]
    }
   ],
   "source": [
    "sections_df = research_arcade.get_all_node_features(\"arxiv_sections\")\n",
    "print(f\"Total sections: {sections_df}\")\n",
    "print(\"\\nAll sections:\")\n",
    "print(sections_df[['title', 'section_in_paper_id', 'appendix']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658f018e",
   "metadata": {},
   "source": [
    "### arxiv_paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4109d7d9",
   "metadata": {},
   "source": [
    "#### Table Schema\n",
    "\n",
    "- `id` (SERIAL PK)\n",
    "- `paragraph_id` (INT)\n",
    "- `content` (TEXT)\n",
    "- `paper_arxiv_id` (VARCHAR FK → papers.arxiv_id)\n",
    "- `paper_section` (TEXT)\n",
    "- `section_id` (INT)\n",
    "- `paragraph_in_paper_id` (INT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1f700e",
   "metadata": {},
   "source": [
    "#### Insert From API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "059ce209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 523.01it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 92.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1903.03894v4\n",
      "Key to References: {'fig:explainer-motivation': 'figures_3', 'fig:explainer-intro': 'figures_4', 'fig:definition-node-features': 'figures_5', 'fig:including-node-features': 'figures_7', 'fig:subgraph_node': 'figures_8', 'fig:subgraph_graph': 'figures_9', 'fig:prototype': 'figures_12', 'fig:my_label': 'figures_11', 'fig:synth_datasets': 'table_13', 'tab:results_pr': 'table_15'}\n",
      "No paper found for  cho2011friendship\n",
      "No paper found for  you2018graph\n",
      "No paper found for  zitnik2018decagon\n",
      "No paper found for  zhang_deep_2018\n",
      "No paper found for  zhou_graph_2018\n",
      "No paper found for  graphsage\n",
      "No paper found for  kipf2016semi\n",
      "No paper found for  ying2018hierarchical\n",
      "No paper found for  zhang2018link\n",
      "No paper found for  doshi-velez_towards_2017\n",
      "No paper found for  lakkaraju_interpretable_2017\n",
      "No paper found for  ribeiro_why_2016\n",
      "No paper found for  schmitz_ann-dt:_1999\n",
      "No paper found for  chen2018learning\n",
      "No paper found for  Erhan2009VisualizingHF\n",
      "No paper found for  lundberg_unified_2017\n",
      "No paper found for  sundararajan_axiomatic_nodate\n",
      "No paper found for  koh_understanding_2017\n",
      "No paper found for  DBLP:journals/corr/abs-1811-09720\n",
      "No paper found for  ribeiro_why_2016\n",
      "No paper found for  augasta_reverse_2012\n",
      "No paper found for  lakkaraju_interpretable_2017\n",
      "No paper found for  calders_deepred_2016\n",
      "No paper found for  Erhan2009VisualizingHF\n",
      "No paper found for  fleet_visualizing_2014\n",
      "No paper found for  chen2018learning\n",
      "No paper found for  shrikumar_learning_2017\n",
      "No paper found for  sundararajan_axiomatic_nodate\n",
      "No paper found for  Kang2019explaine\n",
      "No paper found for  fleet_visualizing_2014\n",
      "No paper found for  2018sanity\n",
      "No paper found for  shrikumar_learning_2017\n",
      "No paper found for  sundararajan_axiomatic_nodate\n",
      "No paper found for  adadi_peeking_2018\n",
      "No paper found for  fisher_all_2018\n",
      "No paper found for  guidotti_survey_2018\n",
      "No paper found for  hooker_discovering_2004\n",
      "No paper found for  koh_understanding_2017\n",
      "No paper found for  DBLP:journals/corr/abs-1811-09720\n",
      "No paper found for  mutag\n",
      "No paper found for  duvenaud_convolutional_2015\n",
      "No paper found for  neil2018interpretable\n",
      "No paper found for  velickovic2018graph\n",
      "No paper found for  PhysRevLett.120.145301\n",
      "No paper found for  ribeiro_why_2016\n",
      "No paper found for  augasta_reverse_2012\n",
      "No paper found for  calders_deepred_2016\n",
      "No paper found for  lakkaraju_interpretable_2017\n",
      "No paper found for  calders_deepred_2016\n",
      "No paper found for  schmitz_ann-dt:_1999\n",
      "No paper found for  Erhan2009VisualizingHF\n",
      "No paper found for  sundararajan_axiomatic_nodate\n",
      "No paper found for  shrikumar_learning_2017\n",
      "No paper found for  fleet_visualizing_2014\n",
      "No paper found for  2018sanity\n",
      "No paper found for  sundararajan_axiomatic_nodate\n",
      "No paper found for  shrikumar_learning_2017\n",
      "No paper found for  koh_understanding_2017\n",
      "No paper found for  DBLP:journals/corr/abs-1811-09720\n",
      "No paper found for  guidotti_survey_2018\n",
      "No paper found for  adadi_peeking_2018\n",
      "No paper found for  fisher_all_2018\n",
      "No paper found for  hooker_discovering_2004\n",
      "No paper found for  ribeiro_why_2016\n",
      "No paper found for  augasta_reverse_2012\n",
      "No paper found for  calders_deepred_2016\n",
      "No paper found for  lakkaraju_interpretable_2017\n",
      "No paper found for  calders_deepred_2016\n",
      "No paper found for  schmitz_ann-dt:_1999\n",
      "No paper found for  Erhan2009VisualizingHF\n",
      "No paper found for  sundararajan_axiomatic_nodate\n",
      "No paper found for  shrikumar_learning_2017\n",
      "No paper found for  fleet_visualizing_2014\n",
      "No paper found for  2018sanity\n",
      "No paper found for  sundararajan_axiomatic_nodate\n",
      "No paper found for  shrikumar_learning_2017\n",
      "No paper found for  koh_understanding_2017\n",
      "No paper found for  DBLP:journals/corr/abs-1811-09720\n",
      "No paper found for  guidotti_survey_2018\n",
      "No paper found for  adadi_peeking_2018\n",
      "No paper found for  fisher_all_2018\n",
      "No paper found for  hooker_discovering_2004\n",
      "No paper found for  PhysRevLett.120.145301\n",
      "No paper found for  neil2018interpretable\n",
      "No paper found for  velickovic2018graph\n",
      "No paper found for  PhysRevLett.120.145301\n",
      "No paper found for  neil2018interpretable\n",
      "No paper found for  velickovic2018graph\n",
      "No paper found for  scarselli\n",
      "No paper found for  gilmer2017neural\n",
      "No paper found for  battaglia\n",
      "No paper found for  zhang_deep_2018\n",
      "No paper found for  zhou_graph_2018\n",
      "No paper found for  battaglia\n",
      "No paper found for  hamilton2017representation\n",
      "No paper found for  kipf2016semi\n",
      "No paper found for  graphsage\n",
      "No paper found for  zhang2018link\n",
      "No paper found for  schlichtkrull2018modeling\n",
      "No paper found for  defferrard2016convolutional\n",
      "No paper found for  ying2018hierarchical\n",
      "No paper found for  ying2018hierarchical\n",
      "No paper found for  dai2016discriminative\n",
      "No paper found for  duvenaud_convolutional_2015\n",
      "No paper found for  backstrom2011supervised\n",
      "No paper found for  pinsage\n",
      "No paper found for  agrawal2018large\n",
      "No paper found for  duvenaud_convolutional_2015\n",
      "No paper found for  jin2017predicting\n",
      "No paper found for  zitnik2018decagon\n",
      "No paper found for  PhysRevLett.120.145301\n",
      "No paper found for  neil2018interpretable\n",
      "No paper found for  velickovic2018graph\n",
      "No paper found for  scarselli\n",
      "No paper found for  gilmer2017neural\n",
      "No paper found for  battaglia\n",
      "No paper found for  zhang_deep_2018\n",
      "No paper found for  zhou_graph_2018\n",
      "No paper found for  battaglia\n",
      "No paper found for  hamilton2017representation\n",
      "No paper found for  kipf2016semi\n",
      "No paper found for  graphsage\n",
      "No paper found for  zhang2018link\n",
      "No paper found for  schlichtkrull2018modeling\n",
      "No paper found for  defferrard2016convolutional\n",
      "No paper found for  ying2018hierarchical\n",
      "No paper found for  ying2018hierarchical\n",
      "No paper found for  dai2016discriminative\n",
      "No paper found for  duvenaud_convolutional_2015\n",
      "No paper found for  backstrom2011supervised\n",
      "No paper found for  pinsage\n",
      "No paper found for  agrawal2018large\n",
      "No paper found for  duvenaud_convolutional_2015\n",
      "No paper found for  jin2017predicting\n",
      "No paper found for  zitnik2018decagon\n",
      "No paper found for  PhysRevLett.120.145301\n",
      "No paper found for  neil2018interpretable\n",
      "No paper found for  velickovic2018graph\n",
      "No paper found for  battaglia\n",
      "No paper found for  zhang_deep_2018\n",
      "No paper found for  zhou_graph_2018\n",
      "No paper found for  graphsage\n",
      "No paper found for  xu2018powerful\n",
      "No paper found for  kipf2016semi\n",
      "No paper found for  xujumping\n",
      "No paper found for  velickovic2018graph\n",
      "No paper found for  chen2018supervised\n",
      "No paper found for  kipf2016semi\n",
      "No paper found for  xujumping\n",
      "No paper found for  velickovic2018graph\n",
      "No paper found for  chen2018supervised\n",
      "No paper found for  mutag\n",
      "No paper found for  yanardag2015deep\n",
      "fig:synth_datasets\n",
      "fig:synth_datasets\n",
      "No paper found for  velickovic2018graph\n",
      "No paper found for  velickovic2018graph\n",
      "No paper found for  velickovic2018graph\n",
      "No paper found for  velickovic2018graph\n",
      "fig:synth_datasets\n",
      "fig:synth_datasets\n",
      "fig:synth_datasets\n",
      "fig:synth_datasets\n",
      "No paper found for  mutag\n",
      "No paper found for  kumar2018community\n",
      "No paper found for  kumar2018community\n",
      "No paper found for  mutag\n",
      "No paper found for  mutag\n",
      "No paper found for  ying2018hierarchical\n",
      "1806.08804v4\n",
      "Key to References: {'fig:assignment_vis': 'figures_157', 'tab:results': 'table_158', 'tab:results2': 'table_159'}\n",
      "No paper found for  hamilton2017inductive\n",
      "No paper found for  kipf2017semi\n",
      "No paper found for  Vel+2018\n",
      "No paper found for  dai2016discriminative\n",
      "No paper found for  Duv+2015\n",
      "No paper found for  Gil+2017\n",
      "No paper found for  Gil+2017\n",
      "No paper found for  hamilton2017inductive\n",
      "No paper found for  hamilton2017inductive\n",
      "No paper found for  Sch+2017\n",
      "No paper found for  dai2016discriminative\n",
      "No paper found for  Duv+2015\n",
      "No paper found for  Gil+2017\n",
      "No paper found for  Li+2016\n",
      "No paper found for  krizhevsky2012imagenet\n",
      "No paper found for  Bru+2014\n",
      "No paper found for  Def+2015\n",
      "No paper found for  Duv+2015\n",
      "No paper found for  hamilton2017inductive\n",
      "No paper found for  kipf2017semi\n",
      "No paper found for  Lei+2017\n",
      "No paper found for  niepert2016learning\n",
      "No paper found for  Vel+2018\n",
      "No paper found for  Li+2016\n",
      "No paper found for  bianchini2001\n",
      "No paper found for  Sca+2009\n",
      "No paper found for  dai2016discriminative\n",
      "No paper found for  Gil+2017\n",
      "No paper found for  Ham+2017a\n",
      "No paper found for  bronstein2017geometric\n",
      "No paper found for  hamilton2017inductive\n",
      "No paper found for  kipf2017semi\n",
      "No paper found for  kipf2018\n",
      "No paper found for  dai2016discriminative\n",
      "No paper found for  Duv+2015\n",
      "No paper found for  zhang2018end\n",
      "No paper found for  Mer+2005\n",
      "No paper found for  Lus+2013\n",
      "No paper found for  Fou+2017\n",
      "No paper found for  Jin+2018\n",
      "No paper found for  Sch+2017\n",
      "No paper found for  Duv+2015\n",
      "No paper found for  Li+2016\n",
      "No paper found for  Gil+2017\n",
      "No paper found for  niepert2016learning\n",
      "No paper found for  zhang2018end\n",
      "No paper found for  Def+2015\n",
      "No paper found for  simonovsky2017dynamic\n",
      "No paper found for  Fey+2018\n",
      "No paper found for  niepert2016learning\n",
      "No paper found for  niepert2016learning\n",
      "No paper found for  Borgwardt2005\n",
      "No paper found for  She+2009\n",
      "No paper found for  She+2011\n",
      "No paper found for  Yan+2015a\n",
      "No paper found for  kriege2016valid\n",
      "No paper found for  niepert2016learning\n",
      "No paper found for  She+2011\n",
      "No paper found for  Gil+2017\n",
      "No paper found for  Duv+2015\n",
      "No paper found for  Li+2016\n",
      "No paper found for  Bru+2014\n",
      "No paper found for  Def+2015\n",
      "No paper found for  kipf2017semi\n",
      "No paper found for  dai2016discriminative\n",
      "No paper found for  Lei+2017\n",
      "No paper found for  Jin+2018\n",
      "No paper found for  simonovsky2017dynamic\n",
      "No paper found for  Vel+2018\n",
      "No paper found for  hamilton2017inductive\n",
      "No paper found for  zhang2018end\n",
      "No paper found for  Fou+2017\n",
      "No paper found for  Sch+2017\n",
      "No paper found for  Mer+2005\n",
      "No paper found for  Sca+2009\n",
      "No paper found for  Ham+2017a\n",
      "No paper found for  Borgwardt2005\n",
      "No paper found for  She+2009\n",
      "No paper found for  She+2011\n",
      "No paper found for  Yan+2015a\n",
      "No paper found for  kriege2016valid\n",
      "No paper found for  niepert2016learning\n",
      "No paper found for  She+2011\n",
      "No paper found for  Gil+2017\n",
      "No paper found for  Duv+2015\n",
      "No paper found for  Li+2016\n",
      "No paper found for  Bru+2014\n",
      "No paper found for  Def+2015\n",
      "No paper found for  kipf2017semi\n",
      "No paper found for  dai2016discriminative\n",
      "No paper found for  Lei+2017\n",
      "No paper found for  Jin+2018\n",
      "No paper found for  simonovsky2017dynamic\n",
      "No paper found for  Vel+2018\n",
      "No paper found for  hamilton2017inductive\n",
      "No paper found for  zhang2018end\n",
      "No paper found for  Fou+2017\n",
      "No paper found for  Sch+2017\n",
      "No paper found for  Mer+2005\n",
      "No paper found for  Sca+2009\n",
      "No paper found for  Ham+2017a\n",
      "No paper found for  simonovsky2017dynamic\n",
      "No paper found for  Gil+2017\n",
      "No paper found for  hamilton2017inductive\n",
      "No paper found for  kipf2017semi\n",
      "No paper found for  liao2018graph\n",
      "No paper found for  liao2018graph\n",
      "No paper found for  zhang2018end\n",
      "No paper found for  Gil+2017\n",
      "No paper found for  zhang2018end\n",
      "No paper found for  Gil+2017\n",
      "No paper found for  zhang2018end\n",
      "No paper found for  Gil+2017\n",
      "No paper found for  KKMMN2016\n",
      "No paper found for  Borgwardt2005a\n",
      "No paper found for  Fer+2013\n",
      "No paper found for  Dob+2003\n",
      "No paper found for  Yan+2015a\n",
      "No paper found for  Yan+2015a\n",
      "No paper found for  kipf2017semi\n",
      "No paper found for  hamilton2017inductive\n",
      "No paper found for  ioffe2015batch\n",
      "No paper found for  dai2016discriminative\n",
      "No paper found for  dhillon2007weighted\n",
      "No paper found for  Def+2015\n",
      "No paper found for  dhillon2007weighted\n",
      "No paper found for  Def+2015\n",
      "No paper found for  dhillon2007weighted\n",
      "No paper found for  hamilton2017inductive\n",
      "No paper found for  kipf2017semi\n",
      "No paper found for  dai2016discriminative\n",
      "No paper found for  simonovsky2017dynamic\n",
      "No paper found for  niepert2016learning\n",
      "No paper found for  vinyals2015order\n",
      "No paper found for  Gil+2017\n",
      "No paper found for  zhang2018end\n",
      "No paper found for  hamilton2017inductive\n",
      "No paper found for  kipf2017semi\n",
      "No paper found for  dai2016discriminative\n",
      "No paper found for  simonovsky2017dynamic\n",
      "No paper found for  niepert2016learning\n",
      "No paper found for  vinyals2015order\n",
      "No paper found for  Gil+2017\n",
      "No paper found for  zhang2018end\n",
      "No paper found for  hamilton2017inductive\n",
      "No paper found for  kipf2017semi\n",
      "No paper found for  dai2016discriminative\n",
      "No paper found for  simonovsky2017dynamic\n",
      "No paper found for  niepert2016learning\n",
      "No paper found for  vinyals2015order\n",
      "No paper found for  Gil+2017\n",
      "No paper found for  zhang2018end\n",
      "No paper found for  She+2009\n",
      "No paper found for  Borgwardt2005\n",
      "No paper found for  She+2011\n",
      "No paper found for  kriege2016valid\n",
      "No paper found for  Cha+11\n",
      "No paper found for  dhillon2007weighted\n",
      "tab:results\n",
      "No paper found for  dai2016discriminative\n",
      "tab:results2\n",
      "No paper found for  liao2018graph\n",
      "No paper found for  hamilton2017inductive\n",
      "No paper found for  verma2018graph\n",
      "Paper count:  2\n",
      "Total nodes:  254\n",
      "Total edges:  474\n",
      "Paper nodes:  2\n",
      "Figure nodes:  0\n",
      "Table nodes:  2\n",
      "Text nodes:  250\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/chongshan0lin/Documents/Research/uiuc/research-arcade/research_arcade/csv_database/csv_arxiv_paragraphs.py:66: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "config = {\"arxiv_ids\": [\"1903.03894v4\", \"1806.08804v4\"], \"dest_dir\": \"./download\"}\n",
    "research_arcade.construct_table_from_api(\"arxiv_paragraphs\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42032133",
   "metadata": {},
   "source": [
    "#### Construct Table from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae51e995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: CSV file ./examples/csv_data/csv_arxiv_paragraphs_example.csv does not exist.\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"./examples/csv_data/csv_arxiv_paragraphs_example.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"arxiv_paragraphs\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bbc021",
   "metadata": {},
   "source": [
    "#### Construct Table from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7dcfc9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: JSON file ./examples/json_data/json_arxiv_paragraphs_example.json does not exist.\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"./examples/json_data/json_arxiv_paragraphs_example.json\"}\n",
    "research_arcade.construct_table_from_json(\"arxiv_paragraphs\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa3595b",
   "metadata": {},
   "source": [
    "#### Insert Paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1a9ef878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted paragraph 1 from Introduction\n",
      "Inserted paragraph 2 from Introduction\n",
      "Inserted paragraph 3 from Introduction\n",
      "Inserted paragraph 4 from Introduction\n",
      "Inserted paragraph 5 from Introduction\n"
     ]
    }
   ],
   "source": [
    "# Insert paragraphs from the Introduction section\n",
    "paragraphs = [\n",
    "    {\n",
    "        'paragraph_id': 1,\n",
    "        'content': 'Recurrent neural networks, long short-term memory and gated recurrent neural networks in particular, have been firmly established as state of the art approaches in sequence modeling and transduction problems such as language modeling and machine translation.',\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'paper_section': 'Introduction',\n",
    "        'section_id': 1,\n",
    "        'paragraph_in_paper_id': 1\n",
    "    },\n",
    "    {\n",
    "        'paragraph_id': 2,\n",
    "        'content': 'Numerous efforts have since continued to push the boundaries of recurrent language models and encoder-decoder architectures. Recurrent models typically factor computation along the symbol positions of the input and output sequences.',\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'paper_section': 'Introduction',\n",
    "        'section_id': 1,\n",
    "        'paragraph_in_paper_id': 2\n",
    "    },\n",
    "    {\n",
    "        'paragraph_id': 3,\n",
    "        'content': 'Aligning the positions to steps in computation time, they generate a sequence of hidden states h_t, as a function of the previous hidden state h_{t-1} and the input for position t. This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples.',\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'paper_section': 'Introduction',\n",
    "        'section_id': 1,\n",
    "        'paragraph_in_paper_id': 3\n",
    "    },\n",
    "    {\n",
    "        'paragraph_id': 4,\n",
    "        'content': 'Attention mechanisms have become an integral part of compelling sequence modeling and transduction models in various tasks, allowing modeling of dependencies without regard to their distance in the input or output sequences.',\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'paper_section': 'Introduction',\n",
    "        'section_id': 1,\n",
    "        'paragraph_in_paper_id': 4\n",
    "    },\n",
    "    {\n",
    "        'paragraph_id': 5,\n",
    "        'content': 'In this work we propose the Transformer, a model architecture eschewing recurrence and instead relying entirely on an attention mechanism to draw global dependencies between input and output. The Transformer allows for significantly more parallelization and can reach a new state of the art in translation quality after being trained for as little as twelve hours on eight P100 GPUs.',\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'paper_section': 'Introduction',\n",
    "        'section_id': 1,\n",
    "        'paragraph_in_paper_id': 5\n",
    "    }\n",
    "]\n",
    "\n",
    "for paragraph in paragraphs:\n",
    "    research_arcade.insert_node(\"arxiv_paragraphs\", node_features=paragraph)\n",
    "    print(f\"Inserted paragraph {paragraph['paragraph_id']} from {paragraph['paper_section']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafedfa1",
   "metadata": {},
   "source": [
    "#### delete specific node by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2b429c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_id = {\"id\": 1}\n",
    "research_arcade.delete_node_by_id(\"arxiv_paragraphs\", paragraph_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f466537b",
   "metadata": {},
   "source": [
    "#### update specific node by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7d457607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_paragraph = {\n",
    "    'id': 2,\n",
    "    'content': 'Updated paragraph content'\n",
    "}\n",
    "research_arcade.update_node(\"arxiv_paragraphs\", node_features=updated_paragraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f761426f",
   "metadata": {},
   "source": [
    "#### get specific node by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e7d5db5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 2, 'paragraph_id': 1, 'content': 'Updated paragraph content', 'paper_arxiv_id': '1903.03894v4', 'paper_section': 'Introduction', 'section_id': nan, 'paragraph_in_paper_id': nan}\n"
     ]
    }
   ],
   "source": [
    "paragraph_id = {\"id\": 2}\n",
    "paragraph = research_arcade.get_node_features_by_id(\"arxiv_paragraphs\", paragraph_id)\n",
    "print(paragraph.to_dict(orient=\"records\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc46e5b0",
   "metadata": {},
   "source": [
    "#### Get All Paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "67b78650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total paragraphs: 255\n",
      "\n",
      "First 3 paragraphs:\n",
      "   paragraph_id paper_section  \\\n",
      "0             1  Introduction   \n",
      "1             2  Introduction   \n",
      "2             3  Introduction   \n",
      "\n",
      "                                             content  \n",
      "0                          Updated paragraph content  \n",
      "1  Despite their strengths, {\\gnn}\\gnns lack tran...  \n",
      "2  While currently there are no methods for expla...  \n"
     ]
    }
   ],
   "source": [
    "paragraphs_df = research_arcade.get_all_node_features(\"arxiv_paragraphs\")\n",
    "print(f\"Total paragraphs: {len(paragraphs_df)}\")\n",
    "print(\"\\nFirst 3 paragraphs:\")\n",
    "print(paragraphs_df[['paragraph_id', 'paper_section', 'content']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964a0e97",
   "metadata": {},
   "source": [
    "## EdgeTableOperations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8379c368",
   "metadata": {},
   "source": [
    "### openreview_arxiv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2f7df1",
   "metadata": {},
   "source": [
    "#### construct table from api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "08ecf25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling openreview arxiv data for venue: ICLR.cc/2017/conference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/490 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object, got 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m config = {\u001b[33m\"\u001b[39m\u001b[33mvenue\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mICLR.cc/2017/conference\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mresearch_arcade\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstruct_table_from_api\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mopenreview_arxiv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/uiuc/research-arcade/research_arcade/research_arcade.py:654\u001b[39m, in \u001b[36mResearchArcade.construct_table_from_api\u001b[39m\u001b[34m(self, table, config)\u001b[39m\n\u001b[32m    652\u001b[39m     \u001b[38;5;28mself\u001b[39m.openreview_revisions_reviews.construct_revisions_reviews_table(**config)\n\u001b[32m    653\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m table == \u001b[33m\"\u001b[39m\u001b[33mopenreview_arxiv\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m654\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopenreview_arxiv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstruct_openreview_arxiv_table_from_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m table == \u001b[33m\"\u001b[39m\u001b[33mopenreview_paragraphs\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    656\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[33m\"\u001b[39m\u001b[33mpdf_dir\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/uiuc/research-arcade/research_arcade/csv_database/csv_openreview_arxiv.py:180\u001b[39m, in \u001b[36mCSVOpenReviewArxiv.construct_openreview_arxiv_table_from_api\u001b[39m\u001b[34m(self, venue)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconstruct_openreview_arxiv_table_from_api\u001b[39m(\u001b[38;5;28mself\u001b[39m, venue: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m:\n\u001b[32m    178\u001b[39m     \u001b[38;5;66;03m# 从API爬取数据\u001b[39;00m\n\u001b[32m    179\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCrawling openreview arxiv data for venue: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvenue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     openreview_arxiv_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopenreview_crawler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcrawl_openreview_arxiv_data_from_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvenue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m     \u001b[38;5;66;03m# 插入数据\u001b[39;00m\n\u001b[32m    183\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(openreview_arxiv_data) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/uiuc/research-arcade/research_arcade/openreview_utils/openreview_crawler.py:1009\u001b[39m, in \u001b[36mOpenReviewCrawler.crawl_openreview_arxiv_data_from_api\u001b[39m\u001b[34m(self, venue)\u001b[39m\n\u001b[32m   1007\u001b[39m \u001b[38;5;66;03m# get arxiv id if exists\u001b[39;00m\n\u001b[32m   1008\u001b[39m arxiv_id = \u001b[38;5;28mself\u001b[39m._search_title_with_name(title)\n\u001b[32m-> \u001b[39m\u001b[32m1009\u001b[39m processed_arxiv_id = \u001b[43mre\u001b[49m\u001b[43m.\u001b[49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m^https?://arxiv\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43m.org/abs/\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marxiv_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m   1011\u001b[39m time.sleep(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/re/__init__.py:186\u001b[39m, in \u001b[36msub\u001b[39m\u001b[34m(pattern, repl, string, count, flags)\u001b[39m\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msub\u001b[39m(pattern, repl, string, count=\u001b[32m0\u001b[39m, flags=\u001b[32m0\u001b[39m):\n\u001b[32m    180\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the string obtained by replacing the leftmost\u001b[39;00m\n\u001b[32m    181\u001b[39m \u001b[33;03m    non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[32m    182\u001b[39m \u001b[33;03m    replacement repl.  repl can be either a string or a callable;\u001b[39;00m\n\u001b[32m    183\u001b[39m \u001b[33;03m    if a string, backslash escapes in it are processed.  If it is\u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[33;03m    a callable, it's passed the Match object and must return\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[33;03m    a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: expected string or bytes-like object, got 'NoneType'"
     ]
    }
   ],
   "source": [
    "config = {\"venue\": \"ICLR.cc/2017/conference\"}\n",
    "research_arcade.construct_table_from_api(\"openreview_arxiv\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe15ea5",
   "metadata": {},
   "source": [
    "#### construct table from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367c244e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading openreview arxiv data from /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/csv_data/openreview_arxiv.csv...\n",
      "Inserting data into CSV file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 367.36it/s]\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"/home/jingjunx/openreview_benchmark/Code/research-arcade/examples/csv_data/openreview_arxiv.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"openreview_arxiv\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea96acb4",
   "metadata": {},
   "source": [
    "#### construct table from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06be91df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading openreview arxiv data from /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/json_data/openreview_arxiv.json...\n",
      "Inserting data into CSV file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 381.26it/s]\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"/home/jingjunx/openreview_benchmark/Code/research-arcade/examples/json_data/openreview_arxiv.json\"}\n",
    "research_arcade.construct_table_from_json(\"openreview_arxiv\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e7e482",
   "metadata": {},
   "source": [
    "#### insert edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b97354",
   "metadata": {},
   "outputs": [],
   "source": [
    "openreview_arxiv = {'venue': 'ICLR.cc/2025/Conference', \n",
    "                    'paper_openreview_id': 'zkNCWtw2fd', \n",
    "                    'arxiv_id': '2408.10536v1',\n",
    "                    'title': 'Synergistic Approach for Simultaneous Optimization of Monolingual, Cross-lingual, and Multilingual Information Retrieval'\n",
    "}\n",
    "research_arcade.insert_edge(\"openreview_arxiv\", openreview_arxiv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f99bb5",
   "metadata": {},
   "source": [
    "#### delete specific edge by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cf9d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 1 records from 'openreview_arxiv' with paper_openreview_id = zkNCWtw2fd.\n",
      "{'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': 'zkNCWtw2fd', 'arxiv_id': '2408.10536v1', 'title': 'Synergistic Approach for Simultaneous Optimization of Monolingual, Cross-lingual, and Multilingual Information Retrieval'}\n"
     ]
    }
   ],
   "source": [
    "openreview_id = {\"paper_openreview_id\": \"zkNCWtw2fd\"}\n",
    "openreview_arxiv_df = research_arcade.delete_edge_by_id(\"openreview_arxiv\", openreview_id)\n",
    "print(openreview_arxiv_df.to_dict(orient=\"records\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0c2ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 1 records from 'arxiv_id' with arxiv_id = http://arxiv.org/abs/2408.10536v1.\n",
      "{'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': 'zkNCWtw2fd', 'arxiv_id': 'http://arxiv.org/abs/2408.10536v1', 'title': 'Synergistic Approach for Simultaneous Optimization of Monolingual, Cross-lingual, and Multilingual Information Retrieval'}\n"
     ]
    }
   ],
   "source": [
    "arxiv_id = {\"arxiv_id\": \"http://arxiv.org/abs/2408.10536v1\"}\n",
    "openreview_arxiv_df = research_arcade.delete_edge_by_id(\"openreview_arxiv\", arxiv_id)\n",
    "print(openreview_arxiv_df.to_dict(orient=\"records\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395894f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 1 records from 'openreview_arxiv' with paper_openreview_id = zkNCWtw2fd and arxiv_id = http://arxiv.org/abs/2408.10536v1.\n",
      "{'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': 'zkNCWtw2fd', 'arxiv_id': 'http://arxiv.org/abs/2408.10536v1', 'title': 'Synergistic Approach for Simultaneous Optimization of Monolingual, Cross-lingual, and Multilingual Information Retrieval'}\n"
     ]
    }
   ],
   "source": [
    "openreview_arxiv_id = {\"paper_openreview_id\": \"zkNCWtw2fd\", \"arxiv_id\": \"http://arxiv.org/abs/2408.10536v1\"}\n",
    "openreview_arxiv_df = research_arcade.delete_edge_by_id(\"openreview_arxiv\", openreview_arxiv_id)\n",
    "print(openreview_arxiv_df.to_dict(orient=\"records\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e5bcf5",
   "metadata": {},
   "source": [
    "#### get all edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb73c5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "openreview_arxiv_df = research_arcade.get_all_edge_features(\"openreview_arxiv\")\n",
    "print(len(openreview_arxiv_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b11f904",
   "metadata": {},
   "source": [
    "#### get neighborhood by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34403462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': 'DnBjhWLVU1', 'arxiv_id': '2507.04683v1', 'title': 'Recovering Plasticity of Neural Networks via Soft Weight Rescaling'}\n",
      "{'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': 'DnBjhWLVU1', 'arxiv_id': '2507.04683v1', 'title': 'Recovering Plasticity of Neural Networks via Soft Weight Rescaling'}\n"
     ]
    }
   ],
   "source": [
    "openreview_id = {\"paper_openreview_id\": \"DnBjhWLVU1\"}\n",
    "openreview_arxiv_df = research_arcade.get_neighborhood(\"openreview_arxiv\", openreview_id)\n",
    "print(openreview_arxiv_df.to_dict(orient=\"records\")[0])\n",
    "\n",
    "arxiv_id = {\"arxiv_id\": \"2507.04683v1\"}\n",
    "openreview_arxiv_df = research_arcade.get_neighborhood(\"openreview_arxiv\", arxiv_id)\n",
    "print(openreview_arxiv_df.to_dict(orient=\"records\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f34a27b",
   "metadata": {},
   "source": [
    "### openreview_papers_authors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71e3f7d",
   "metadata": {},
   "source": [
    "#### construct table from api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab86711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"venue\": \"ICLR.cc/2025/Conference\"}\n",
    "research_arcade.construct_table_from_api(\"openreview_papers_authors\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865ade2e",
   "metadata": {},
   "source": [
    "#### construct table from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ae94fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading papers-authors data from /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/csv_data/openreview_papers_authors.csv...\n",
      "Inserting papers-authors data from /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/csv_data/openreview_papers_authors.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 645/645 [00:01<00:00, 439.35it/s]\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"/home/jingjunx/openreview_benchmark/Code/research-arcade/examples/csv_data/openreview_papers_authors.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"openreview_papers_authors\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbe48af",
   "metadata": {},
   "source": [
    "#### construct table from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46539003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading papers-authors data from /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/json_data/openreview_papers_authors.json...\n",
      "Inserting papers-authors data from /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/json_data/openreview_papers_authors.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 271.20it/s]\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"/home/jingjunx/openreview_benchmark/Code/research-arcade/examples/json_data/openreview_papers_authors.json\"}\n",
    "research_arcade.construct_table_from_json(\"openreview_papers_authors\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88640acc",
   "metadata": {},
   "source": [
    "#### insert edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8718f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_authors = [{'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'author_openreview_id': '~Elias_Stengel-Eskin1'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'author_openreview_id': '~Zaid_Khan1'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'author_openreview_id': '~Jaemin_Cho1'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'author_openreview_id': '~Mohit_Bansal2'}]\n",
    "for item in paper_authors:\n",
    "    research_arcade.insert_edge(\"openreview_papers_authors\", item)\n",
    "\n",
    "author_papers = [{'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': 'Xbl6t6zxZs', 'author_openreview_id': '~Elias_Stengel-Eskin1'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': 'fDcn3S8oAt', 'author_openreview_id': '~Elias_Stengel-Eskin1'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': 'j9wBgcxa7N', 'author_openreview_id': '~Elias_Stengel-Eskin1'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': 'zd0iX5xBhA', 'author_openreview_id': '~Elias_Stengel-Eskin1'}, \n",
    "                 {'venue': 'ICLR.cc/2024/Conference', 'paper_openreview_id': 'L4nOxziGf9', 'author_openreview_id': '~Elias_Stengel-Eskin1'}, \n",
    "                 {'venue': 'ICLR.cc/2024/Conference', 'paper_openreview_id': 'qL9gogRepu', 'author_openreview_id': '~Elias_Stengel-Eskin1'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'author_openreview_id': '~Elias_Stengel-Eskin1'}]\n",
    "for item in author_papers:\n",
    "    research_arcade.insert_edge(\"openreview_papers_authors\", item)\n",
    "\n",
    "paper_author = [{'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'author_openreview_id': '~Elias_Stengel-Eskin1'}]\n",
    "for item in paper_author:\n",
    "    research_arcade.insert_edge(\"openreview_papers_authors\", item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79943d00",
   "metadata": {},
   "source": [
    "#### delete specific edge by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c108f1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The connection for paper 00SnKBGTsz is deleted successfully.\n",
      "[{'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'author_openreview_id': '~Elias_Stengel-Eskin1'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'author_openreview_id': '~Jaemin_Cho1'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'author_openreview_id': '~Mohit_Bansal2'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'author_openreview_id': '~Zaid_Khan1'}]\n"
     ]
    }
   ],
   "source": [
    "paper_id = {\"paper_openreview_id\": \"00SnKBGTsz\"}\n",
    "openreview_papers_authors = research_arcade.delete_edge_by_id(\"openreview_papers_authors\", paper_id)\n",
    "print(openreview_papers_authors.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf60e3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The connection for author ~Elias_Stengel-Eskin1 is deleted successfully.\n",
      "[{'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': 'Xbl6t6zxZs', 'author_openreview_id': '~Elias_Stengel-Eskin1'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': 'fDcn3S8oAt', 'author_openreview_id': '~Elias_Stengel-Eskin1'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': 'j9wBgcxa7N', 'author_openreview_id': '~Elias_Stengel-Eskin1'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': 'zd0iX5xBhA', 'author_openreview_id': '~Elias_Stengel-Eskin1'}, {'venue': 'ICLR.cc/2024/Conference', 'paper_openreview_id': 'L4nOxziGf9', 'author_openreview_id': '~Elias_Stengel-Eskin1'}, {'venue': 'ICLR.cc/2024/Conference', 'paper_openreview_id': 'qL9gogRepu', 'author_openreview_id': '~Elias_Stengel-Eskin1'}]\n"
     ]
    }
   ],
   "source": [
    "author_id = {'author_openreview_id': '~Elias_Stengel-Eskin1'}\n",
    "openreview_papers_authors = research_arcade.delete_edge_by_id(\"openreview_papers_authors\", author_id)\n",
    "print(openreview_papers_authors.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916d4348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The connection between paper 00SnKBGTsz and author ~Elias_Stengel-Eskin1 is deleted successfully.\n",
      "[{'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'author_openreview_id': '~Elias_Stengel-Eskin1'}]\n"
     ]
    }
   ],
   "source": [
    "paper_author = {\"paper_openreview_id\": \"00SnKBGTsz\", 'author_openreview_id': '~Elias_Stengel-Eskin1'}\n",
    "openreview_papers_authors = research_arcade.delete_edge_by_id(\"openreview_papers_authors\", paper_author)\n",
    "print(openreview_papers_authors.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5bc5cb",
   "metadata": {},
   "source": [
    "#### get all edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f5d385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "651\n"
     ]
    }
   ],
   "source": [
    "openreview_papers_authors = research_arcade.get_all_edge_features(\"openreview_papers_authors\")\n",
    "print(len(openreview_papers_authors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00be98f7",
   "metadata": {},
   "source": [
    "#### get neighborhood by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33d7f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'author_openreview_id': '~Zaid_Khan1'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'author_openreview_id': '~Jaemin_Cho1'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'author_openreview_id': '~Mohit_Bansal2'}]\n",
      "[{'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': 'Xbl6t6zxZs', 'author_openreview_id': '~Elias_Stengel-Eskin1'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': 'fDcn3S8oAt', 'author_openreview_id': '~Elias_Stengel-Eskin1'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': 'j9wBgcxa7N', 'author_openreview_id': '~Elias_Stengel-Eskin1'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': 'zd0iX5xBhA', 'author_openreview_id': '~Elias_Stengel-Eskin1'}, {'venue': 'ICLR.cc/2024/Conference', 'paper_openreview_id': 'L4nOxziGf9', 'author_openreview_id': '~Elias_Stengel-Eskin1'}, {'venue': 'ICLR.cc/2024/Conference', 'paper_openreview_id': 'qL9gogRepu', 'author_openreview_id': '~Elias_Stengel-Eskin1'}]\n"
     ]
    }
   ],
   "source": [
    "paper_id = {\"paper_openreview_id\": \"00SnKBGTsz\"}\n",
    "openreview_papers_authors = research_arcade.get_neighborhood(\"openreview_papers_authors\", paper_id)\n",
    "print(openreview_papers_authors.to_dict(orient=\"records\"))\n",
    "\n",
    "author_id = {'author_openreview_id': '~Elias_Stengel-Eskin1'}\n",
    "openreview_papers_authors = research_arcade.get_neighborhood(\"openreview_papers_authors\", author_id)\n",
    "print(openreview_papers_authors.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9e7ee6",
   "metadata": {},
   "source": [
    "### openreview_papers_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b435f458",
   "metadata": {},
   "source": [
    "#### construct table from api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851e73c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"venue\": \"ICLR.cc/2017/conference\"}\n",
    "research_arcade.construct_table_from_api(\"openreview_papers_reviews\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1434141",
   "metadata": {},
   "source": [
    "#### construct table from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbfab7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading paper-review connection data from /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/csv_data/openreview_papers_reviews.csv...\n",
      "Inserting data into CSV file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 183/183 [00:00<00:00, 538.84it/s]\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"/home/jingjunx/openreview_benchmark/Code/research-arcade/examples/csv_data/openreview_papers_reviews.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"openreview_papers_reviews\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2723eb",
   "metadata": {},
   "source": [
    "#### construct table from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a961ef19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading paper-review connection data from /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/json_data/openreview_papers_reviews.json...\n",
      "Inserting data into CSV file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 309.29it/s]\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"/home/jingjunx/openreview_benchmark/Code/research-arcade/examples/json_data/openreview_papers_reviews.json\"}\n",
    "research_arcade.construct_table_from_json(\"openreview_papers_reviews\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c41c54c",
   "metadata": {},
   "source": [
    "#### insert edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f64c647",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:00<00:00, 281.10it/s]\n"
     ]
    }
   ],
   "source": [
    "paper_review = {'venue': 'ICLR.cc/2025/Conference', \n",
    "                'paper_openreview_id': '00SnKBGTsz', \n",
    "                'review_openreview_id': '13mj0Rtn5W', \n",
    "                'title': 'Response by Authors', \n",
    "                'time': '2024-11-27 17:27:45'}\n",
    "research_arcade.insert_edge(\"openreview_papers_reviews\", paper_review)\n",
    "\n",
    "paper_reviews = [{'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': '7XT4kLWV2f', 'title': 'Official Review by Reviewer_wuGW', 'time': '2024-11-01 14:52:22'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'i3QgWgrJff', 'title': 'Official Review by Reviewer_rVo8', 'time': '2024-11-04 02:37:10'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'GMsjHLXdOx', 'title': 'Official Review by Reviewer_c5nB', 'time': '2024-11-04 09:59:14'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'r8ZflFk3T7', 'title': 'Official Review by Reviewer_VQ9Y', 'time': '2024-11-06 00:15:47'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': '4CnQpVCYkF', 'title': 'Response by Authors', 'time': '2024-11-20 22:48:42'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'h1qvpjhRP3', 'title': 'Response by Authors', 'time': '2024-11-20 22:51:07'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'pOR42YNLtU', 'title': 'Response by Authors', 'time': '2024-11-20 22:55:04'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'Aq2tBtB0lt', 'title': 'Response by Authors', 'time': '2024-11-20 22:57:18'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'm1iUqPHpwk', 'title': 'Response by Authors', 'time': '2024-11-20 22:58:29'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': '66buacQmRe', 'title': 'Response by Authors', 'time': '2024-11-20 23:02:21'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'Bgr7Ol90m7', 'title': 'Response by Authors', 'time': '2024-11-22 23:11:06'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'H2h2K6a8x5', 'title': 'Response by Reviewer', 'time': '2024-11-23 10:04:58'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'la5jPwJU4g', 'title': 'Response by Authors', 'time': '2024-11-24 19:17:22'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'DjVKsUoFN2', 'title': 'Response by Reviewer', 'time': '2024-11-25 04:00:18'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'C3MhCuKhTf', 'title': 'Response by Authors', 'time': '2024-11-25 19:44:38'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'ZqwAYtcmhv', 'title': 'Response by Authors', 'time': '2024-11-25 19:45:43'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': '9OQJoesINr', 'title': 'Response by Reviewer', 'time': '2024-11-25 20:07:51'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'wqTNtVDwef', 'title': 'Response by Authors', 'time': '2024-11-26 03:32:30'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'NEsxOTkkIV', 'title': 'Response by Reviewer', 'time': '2024-11-26 20:00:00'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': '13mj0Rtn5W', 'title': 'Response by Authors', 'time': '2024-11-27 17:27:45'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'hWat8aFBRw', 'title': 'Response by Reviewer', 'time': '2024-11-27 11:34:03'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'wnsiUkDh00', 'title': 'Response by Authors', 'time': '2024-11-27 17:28:35'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'zpboemkkjR', 'title': 'Meta Review of Submission11063 by Area_Chair_eoLd', 'time': '2024-12-20 15:14:25'}, \n",
    "                 {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'kokKFEn2fw', 'title': 'Paper Decision', 'time': '2025-01-22 05:35:00'}\n",
    "]\n",
    "for item in tqdm(paper_reviews):\n",
    "    research_arcade.insert_edge(\"openreview_papers_reviews\", item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14af202",
   "metadata": {},
   "source": [
    "#### delete specific edge by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2da07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The connection between paper 00SnKBGTsz and review 13mj0Rtn5W is deleted successfully.\n",
      "[{'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': '13mj0Rtn5W', 'title': 'Response by Authors', 'time': '2024-11-27 17:27:45'}]\n"
     ]
    }
   ],
   "source": [
    "paper_review_id = {\"paper_openreview_id\": \"00SnKBGTsz\", \"review_openreview_id\": \"13mj0Rtn5W\"}\n",
    "openreview_papers_reviews = research_arcade.delete_edge_by_id(\"openreview_papers_reviews\", paper_review_id)\n",
    "print(openreview_papers_reviews.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddb4882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The connection between review 13mj0Rtn5W is deleted successfully.\n",
      "[{'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': '13mj0Rtn5W', 'title': 'Response by Authors', 'time': '2024-11-27 17:27:45'}]\n"
     ]
    }
   ],
   "source": [
    "review_id = {\"review_openreview_id\": \"13mj0Rtn5W\"}\n",
    "openreview_papers_reviews = research_arcade.delete_edge_by_id(\"openreview_papers_reviews\", review_id)\n",
    "print(openreview_papers_reviews.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ee90b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The connection between paper 00SnKBGTsz is deleted successfully.\n",
      "[{'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': '7XT4kLWV2f', 'title': 'Official Review by Reviewer_wuGW', 'time': '2024-11-01 14:52:22'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'i3QgWgrJff', 'title': 'Official Review by Reviewer_rVo8', 'time': '2024-11-04 02:37:10'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'GMsjHLXdOx', 'title': 'Official Review by Reviewer_c5nB', 'time': '2024-11-04 09:59:14'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'r8ZflFk3T7', 'title': 'Official Review by Reviewer_VQ9Y', 'time': '2024-11-06 00:15:47'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': '4CnQpVCYkF', 'title': 'Response by Authors', 'time': '2024-11-20 22:48:42'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'h1qvpjhRP3', 'title': 'Response by Authors', 'time': '2024-11-20 22:51:07'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'pOR42YNLtU', 'title': 'Response by Authors', 'time': '2024-11-20 22:55:04'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'Aq2tBtB0lt', 'title': 'Response by Authors', 'time': '2024-11-20 22:57:18'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'm1iUqPHpwk', 'title': 'Response by Authors', 'time': '2024-11-20 22:58:29'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': '66buacQmRe', 'title': 'Response by Authors', 'time': '2024-11-20 23:02:21'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'Bgr7Ol90m7', 'title': 'Response by Authors', 'time': '2024-11-22 23:11:06'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'H2h2K6a8x5', 'title': 'Response by Reviewer', 'time': '2024-11-23 10:04:58'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'la5jPwJU4g', 'title': 'Response by Authors', 'time': '2024-11-24 19:17:22'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'DjVKsUoFN2', 'title': 'Response by Reviewer', 'time': '2024-11-25 04:00:18'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'C3MhCuKhTf', 'title': 'Response by Authors', 'time': '2024-11-25 19:44:38'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'ZqwAYtcmhv', 'title': 'Response by Authors', 'time': '2024-11-25 19:45:43'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': '9OQJoesINr', 'title': 'Response by Reviewer', 'time': '2024-11-25 20:07:51'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'wqTNtVDwef', 'title': 'Response by Authors', 'time': '2024-11-26 03:32:30'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'NEsxOTkkIV', 'title': 'Response by Reviewer', 'time': '2024-11-26 20:00:00'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'hWat8aFBRw', 'title': 'Response by Reviewer', 'time': '2024-11-27 11:34:03'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'wnsiUkDh00', 'title': 'Response by Authors', 'time': '2024-11-27 17:28:35'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'zpboemkkjR', 'title': 'Meta Review of Submission11063 by Area_Chair_eoLd', 'time': '2024-12-20 15:14:25'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'kokKFEn2fw', 'title': 'Paper Decision', 'time': '2025-01-22 05:35:00'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': '13mj0Rtn5W', 'title': 'Response by Authors', 'time': '2024-11-27 17:27:45'}]\n"
     ]
    }
   ],
   "source": [
    "paper_id = {\"paper_openreview_id\": \"00SnKBGTsz\"}\n",
    "openreview_papers_reviews = research_arcade.delete_edge_by_id(\"openreview_papers_reviews\", paper_id)\n",
    "print(openreview_papers_reviews.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf61f51",
   "metadata": {},
   "source": [
    "#### get all edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26608e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183\n"
     ]
    }
   ],
   "source": [
    "openreview_papers_reviews = research_arcade.get_all_edge_features(\"openreview_papers_reviews\")\n",
    "print(len(openreview_papers_reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1f9e8f",
   "metadata": {},
   "source": [
    "#### get neighborhood by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422386ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': '13mj0Rtn5W', 'title': 'Response by Authors', 'time': '2024-11-27 17:27:45'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': '7XT4kLWV2f', 'title': 'Official Review by Reviewer_wuGW', 'time': '2024-11-01 14:52:22'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'i3QgWgrJff', 'title': 'Official Review by Reviewer_rVo8', 'time': '2024-11-04 02:37:10'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'GMsjHLXdOx', 'title': 'Official Review by Reviewer_c5nB', 'time': '2024-11-04 09:59:14'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'r8ZflFk3T7', 'title': 'Official Review by Reviewer_VQ9Y', 'time': '2024-11-06 00:15:47'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': '4CnQpVCYkF', 'title': 'Response by Authors', 'time': '2024-11-20 22:48:42'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'h1qvpjhRP3', 'title': 'Response by Authors', 'time': '2024-11-20 22:51:07'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'pOR42YNLtU', 'title': 'Response by Authors', 'time': '2024-11-20 22:55:04'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'Aq2tBtB0lt', 'title': 'Response by Authors', 'time': '2024-11-20 22:57:18'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'm1iUqPHpwk', 'title': 'Response by Authors', 'time': '2024-11-20 22:58:29'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': '66buacQmRe', 'title': 'Response by Authors', 'time': '2024-11-20 23:02:21'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'Bgr7Ol90m7', 'title': 'Response by Authors', 'time': '2024-11-22 23:11:06'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'H2h2K6a8x5', 'title': 'Response by Reviewer', 'time': '2024-11-23 10:04:58'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'la5jPwJU4g', 'title': 'Response by Authors', 'time': '2024-11-24 19:17:22'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'DjVKsUoFN2', 'title': 'Response by Reviewer', 'time': '2024-11-25 04:00:18'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'C3MhCuKhTf', 'title': 'Response by Authors', 'time': '2024-11-25 19:44:38'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'ZqwAYtcmhv', 'title': 'Response by Authors', 'time': '2024-11-25 19:45:43'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': '9OQJoesINr', 'title': 'Response by Reviewer', 'time': '2024-11-25 20:07:51'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'wqTNtVDwef', 'title': 'Response by Authors', 'time': '2024-11-26 03:32:30'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'NEsxOTkkIV', 'title': 'Response by Reviewer', 'time': '2024-11-26 20:00:00'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'hWat8aFBRw', 'title': 'Response by Reviewer', 'time': '2024-11-27 11:34:03'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'wnsiUkDh00', 'title': 'Response by Authors', 'time': '2024-11-27 17:28:35'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'zpboemkkjR', 'title': 'Meta Review of Submission11063 by Area_Chair_eoLd', 'time': '2024-12-20 15:14:25'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': 'kokKFEn2fw', 'title': 'Paper Decision', 'time': '2025-01-22 05:35:00'}]\n",
      "[{'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'review_openreview_id': '13mj0Rtn5W', 'title': 'Response by Authors', 'time': '2024-11-27 17:27:45'}]\n"
     ]
    }
   ],
   "source": [
    "paper_id = {\"paper_openreview_id\": \"00SnKBGTsz\"}\n",
    "openreview_papers_reviews = research_arcade.get_neighborhood(\"openreview_papers_reviews\", paper_id)\n",
    "print(openreview_papers_reviews.to_dict(orient=\"records\"))\n",
    "\n",
    "review_id = {\"review_openreview_id\": \"13mj0Rtn5W\"}\n",
    "openreview_papers_reviews = research_arcade.get_neighborhood(\"openreview_papers_reviews\", review_id)\n",
    "print(openreview_papers_reviews.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ec16c5",
   "metadata": {},
   "source": [
    "### openreview_papers_revisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632dcfb2",
   "metadata": {},
   "source": [
    "#### construct table from api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce26116b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting V2 Notes:  51%|█████▏    | 5994/11672 [00:14<00:01, 3320.94it/s]"
     ]
    }
   ],
   "source": [
    "config = {\"venue\": \"ICLR.cc/2025/Conference\"}\n",
    "research_arcade.construct_table_from_api(\"openreview_papers_revisions\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41c1538",
   "metadata": {},
   "source": [
    "#### construct table from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255bbffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading paper-revision data from /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/csv_data/openreview_papers_revisions.csv...\n",
      "Inserting paper-revision data from /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/csv_data/openreview_papers_revisions.csv into CSV file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 359.89it/s]\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"/home/jingjunx/openreview_benchmark/Code/research-arcade/examples/csv_data/openreview_papers_revisions.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"openreview_papers_revisions\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd05f0b",
   "metadata": {},
   "source": [
    "#### construct table from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81738d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading revisions data from /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/json_data/openreview_papers_revisions.json...\n",
      "Inserting paper-revision data from /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/json_data/openreview_papers_revisions.json into CSV file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 343.89it/s]\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"/home/jingjunx/openreview_benchmark/Code/research-arcade/examples/json_data/openreview_papers_revisions.json\"}\n",
    "research_arcade.construct_table_from_json(\"openreview_papers_revisions\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3002e378",
   "metadata": {},
   "source": [
    "#### insert edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3437636",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 208.16it/s]\n"
     ]
    }
   ],
   "source": [
    "paper_revision = {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'revision_openreview_id': 'dzL3IRBnE4', 'title': 'Camera_Ready_Revision', 'time': '2025-03-01 03:36:55'}\n",
    "research_arcade.insert_edge(\"openreview_papers_revisions\", paper_revision)\n",
    "\n",
    "paper_revisions = [{'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'revision_openreview_id': 'oT4N28siLO', 'title': 'Camera_Ready_Revision', 'time': '2025-03-02 01:35:16'}, \n",
    "                   {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'revision_openreview_id': 'dzL3IRBnE4', 'title': 'Camera_Ready_Revision', 'time': '2025-03-01 03:36:55'}]\n",
    "for item in tqdm(paper_revisions):\n",
    "    research_arcade.insert_edge(\"openreview_papers_revisions\", item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8502e808",
   "metadata": {},
   "source": [
    "#### delete specific node by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e92545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The connection between paper 00SnKBGTsz and revision dzL3IRBnE4 is deleted successfully.\n",
      "[{'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'revision_openreview_id': 'dzL3IRBnE4', 'title': 'Camera_Ready_Revision', 'time': '2025-03-01 03:36:55'}]\n"
     ]
    }
   ],
   "source": [
    "paper_revision_id = {\"paper_openreview_id\": \"00SnKBGTsz\", \"revision_openreview_id\": \"dzL3IRBnE4\"}\n",
    "paper_revision = research_arcade.delete_edge_by_id(\"openreview_papers_revisions\", paper_revision_id)\n",
    "print(paper_revision.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc419f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The connection for revision dzL3IRBnE4 is deleted successfully.\n",
      "[{'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'revision_openreview_id': 'dzL3IRBnE4', 'title': 'Camera_Ready_Revision', 'time': '2025-03-01 03:36:55'}]\n"
     ]
    }
   ],
   "source": [
    "revision_id = {\"revision_openreview_id\": \"dzL3IRBnE4\"}\n",
    "paper_revision = research_arcade.delete_edge_by_id(\"openreview_papers_revisions\", revision_id)\n",
    "print(paper_revision.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4eea26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The connection for paper 00SnKBGTsz is deleted successfully.\n",
      "[{'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'revision_openreview_id': 'oT4N28siLO', 'title': 'Camera_Ready_Revision', 'time': '2025-03-02 01:35:16'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'revision_openreview_id': 'dzL3IRBnE4', 'title': 'Camera_Ready_Revision', 'time': '2025-03-01 03:36:55'}]\n"
     ]
    }
   ],
   "source": [
    "paper_id = {\"paper_openreview_id\": \"00SnKBGTsz\"}\n",
    "paper_revision = research_arcade.delete_edge_by_id(\"openreview_papers_revisions\", paper_id)\n",
    "print(paper_revision.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c86c11",
   "metadata": {},
   "source": [
    "#### get all edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d449a5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "openreview_papers_revisions = research_arcade.get_all_edge_features(\"openreview_papers_revisions\")\n",
    "print(len(openreview_papers_revisions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd884f01",
   "metadata": {},
   "source": [
    "#### get neighborhood by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e0d12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'revision_openreview_id': 'dzL3IRBnE4', 'title': 'Camera_Ready_Revision', 'time': '2025-03-01 03:36:55'}, {'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'revision_openreview_id': 'oT4N28siLO', 'title': 'Camera_Ready_Revision', 'time': '2025-03-02 01:35:16'}]\n",
      "[{'venue': 'ICLR.cc/2025/Conference', 'paper_openreview_id': '00SnKBGTsz', 'revision_openreview_id': 'dzL3IRBnE4', 'title': 'Camera_Ready_Revision', 'time': '2025-03-01 03:36:55'}]\n"
     ]
    }
   ],
   "source": [
    "paper_id = {\"paper_openreview_id\": \"00SnKBGTsz\"}\n",
    "paper_revision = research_arcade.get_neighborhood(\"openreview_papers_revisions\", paper_id)\n",
    "print(paper_revision.to_dict(orient=\"records\"))\n",
    "\n",
    "revision_id = {\"revision_openreview_id\": \"dzL3IRBnE4\"}\n",
    "paper_revision = research_arcade.get_neighborhood(\"openreview_papers_revisions\", revision_id)\n",
    "print(paper_revision.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d9fe27",
   "metadata": {},
   "source": [
    "### openreview_revisions_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6cece4",
   "metadata": {},
   "source": [
    "#### construct table based on existing tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4e2763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207\n",
      "12\n",
      "Constructing revisions-reviews connections for 3 papers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 41.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revisions-reviews table construction completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "papers_reviews_df = research_arcade.get_all_edge_features(\"openreview_papers_reviews\")\n",
    "print(len(papers_reviews_df))\n",
    "papers_revisions_df = research_arcade.get_all_edge_features(\"openreview_papers_revisions\")\n",
    "print(len(papers_revisions_df))\n",
    "config = {\"papers_reviews_df\": papers_reviews_df, \"papers_revisions_df\": papers_revisions_df}\n",
    "research_arcade.construct_table_from_api(\"openreview_revisions_reviews\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d947b5",
   "metadata": {},
   "source": [
    "#### construct table from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c473509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading revisions-reviews data from /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/csv_data/openreview_revisions_reviews.csv...\n",
      "Inserting revisions-reviews data from /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/csv_data/openreview_revisions_reviews.csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:00<00:00, 553.12it/s]\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"/home/jingjunx/openreview_benchmark/Code/research-arcade/examples/csv_data/openreview_revisions_reviews.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"openreview_revisions_reviews\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0439cad",
   "metadata": {},
   "source": [
    "#### construct table from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7848f5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading revisions-reviews data from /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/json_data/openreview_revisions_reviews.json...\n",
      "Inserting revisions-reviews data from /home/jingjunx/openreview_benchmark/Code/research-arcade/examples/json_data/openreview_revisions_reviews.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 375.56it/s]\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"/home/jingjunx/openreview_benchmark/Code/research-arcade/examples/json_data/openreview_revisions_reviews.json\"}\n",
    "research_arcade.construct_table_from_json(\"openreview_revisions_reviews\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c636263c",
   "metadata": {},
   "source": [
    "#### insert edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55eb677",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [00:00<00:00, 477.83it/s]\n"
     ]
    }
   ],
   "source": [
    "revision_review = {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'wumckDPIQ3'}\n",
    "research_arcade.insert_edge(\"openreview_revisions_reviews\", revision_review)\n",
    "\n",
    "revision_reviews = [{'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'wumckDPIQ3'}, \n",
    "                    {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': '138cOdBpgA'}, \n",
    "                    {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'yKh1fQYnUZ'}, \n",
    "                    {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'Pvt0OjNSp2'}, \n",
    "                    {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'MUhlEYyBD9'}, \n",
    "                    {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': '2mqiS3J8wC'}, \n",
    "                    {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'Er8QTorcyr'}, \n",
    "                    {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'AvtD9uxRtX'}, \n",
    "                    {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': '2tgxTGynNm'}, \n",
    "                    {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': '5MKJE3sFsd'}, \n",
    "                    {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'wViZ0H4ErF'}, \n",
    "                    {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': '0c1It75dTb'}, \n",
    "                    {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'PFwia9lcjP'}, \n",
    "                    {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'ygCqaGNPee'}]\n",
    "for item in tqdm(revision_reviews):\n",
    "    research_arcade.insert_edge(\"openreview_revisions_reviews\", item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8572b6a",
   "metadata": {},
   "source": [
    "#### delete edge by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bd3753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The connection between revision cX02yuzwWI and review wumckDPIQ3 is deleted successfully.\n",
      "[{'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'wumckDPIQ3'}]\n"
     ]
    }
   ],
   "source": [
    "revision_review_id = {'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'wumckDPIQ3'}\n",
    "revision_review = research_arcade.delete_edge_by_id(\"openreview_revisions_reviews\", revision_review_id)\n",
    "print(revision_review.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d066b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The connection for review wumckDPIQ3 is deleted successfully.\n",
      "[{'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'wumckDPIQ3'}]\n"
     ]
    }
   ],
   "source": [
    "review_id = {'review_openreview_id': 'wumckDPIQ3'}\n",
    "revision_review = research_arcade.delete_edge_by_id(\"openreview_revisions_reviews\", review_id)\n",
    "print(revision_review.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8527e2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The connection for revision cX02yuzwWI is deleted successfully.\n",
      "[{'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'wumckDPIQ3'}, {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': '138cOdBpgA'}, {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'yKh1fQYnUZ'}, {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'Pvt0OjNSp2'}, {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'MUhlEYyBD9'}, {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': '2mqiS3J8wC'}, {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'Er8QTorcyr'}, {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'AvtD9uxRtX'}, {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': '2tgxTGynNm'}, {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': '5MKJE3sFsd'}, {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'wViZ0H4ErF'}, {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': '0c1It75dTb'}, {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'PFwia9lcjP'}, {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'ygCqaGNPee'}]\n"
     ]
    }
   ],
   "source": [
    "paper_id = {'revision_openreview_id': 'cX02yuzwWI'}\n",
    "revision_review = research_arcade.delete_edge_by_id(\"openreview_revisions_reviews\", paper_id)\n",
    "print(revision_review.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5ace45",
   "metadata": {},
   "source": [
    "#### get all edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df983a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    }
   ],
   "source": [
    "openreview_revisions_reviews = research_arcade.get_all_edge_features(\"openreview_revisions_reviews\")\n",
    "print(len(openreview_revisions_reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da9e537",
   "metadata": {},
   "source": [
    "#### get neighborhood by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fbce88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': '138cOdBpgA'}, {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'yKh1fQYnUZ'}, {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'Pvt0OjNSp2'}, {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'MUhlEYyBD9'}, {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': '2mqiS3J8wC'}, {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'Er8QTorcyr'}, {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'AvtD9uxRtX'}, {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': '2tgxTGynNm'}, {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': '5MKJE3sFsd'}, {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'wViZ0H4ErF'}, {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': '0c1It75dTb'}, {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'PFwia9lcjP'}, {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'ygCqaGNPee'}, {'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'wumckDPIQ3'}]\n",
      "[{'venue': 'ICLR.cc/2025/Conference', 'revision_openreview_id': 'cX02yuzwWI', 'review_openreview_id': 'wumckDPIQ3'}]\n"
     ]
    }
   ],
   "source": [
    "revision_id = {'revision_openreview_id': 'cX02yuzwWI'}\n",
    "revision_review = research_arcade.get_neighborhood(\"openreview_revisions_reviews\", revision_id)\n",
    "print(revision_review.to_dict(orient=\"records\"))\n",
    "\n",
    "review_id = {'review_openreview_id': 'wumckDPIQ3'}\n",
    "revision_review = research_arcade.get_neighborhood(\"openreview_revisions_reviews\", review_id)\n",
    "print(revision_review.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a8c986",
   "metadata": {},
   "source": [
    "### arxiv_citations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743759a9",
   "metadata": {},
   "source": [
    "#### Insert Citation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bd670a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citation created!\n"
     ]
    }
   ],
   "source": [
    "citation = {\n",
    "    'citing_arxiv_id': '1810.04805v2',\n",
    "    'cited_arxiv_id': '1706.03762v7',\n",
    "    'bib_title': 'attention is all you need',\n",
    "    'bib_key': 'something',\n",
    "    'citing_sections': 'citing_sections',\n",
    "}\n",
    "research_arcade.insert_edge(\"arxiv_citation\", edge_features=citation)\n",
    "research_arcade.insert_edge(\"arxiv_citation\", edge_features=citation)\n",
    "research_arcade.insert_edge(\"arxiv_citation\", edge_features=citation)\n",
    "print(\"Citation created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eb7be6",
   "metadata": {},
   "source": [
    "#### Construct Table from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a832338c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: CSV file ./examples/csv_data/csv_arxiv_paper_citation_example.csv does not exist.\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"./examples/csv_data/csv_arxiv_paper_citation_example.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"arxiv_paper_citation\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f90fe8",
   "metadata": {},
   "source": [
    "#### Construct Table from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5f9c499d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: JSON file ./examples/json_data/json_arxiv_paper_citation_example.json does not exist.\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"./examples/json_data/json_arxiv_paper_citation_example.json\"}\n",
    "research_arcade.construct_table_from_json(\"arxiv_paper_citation\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fce64f",
   "metadata": {},
   "source": [
    "#### get all edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "804ca66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "all_citations = research_arcade.get_all_edge_features(\"arxiv_citation\")\n",
    "print(len(all_citations))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20271218",
   "metadata": {},
   "source": [
    "#### get papers cited by a paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "37759e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 1, 'citing_arxiv_id': '1810.04805v2', 'cited_arxiv_id': '1706.03762v7', 'bib_title': 'attention is all you need', 'bib_key': 'something', 'citing_sections': '\"citing_sections\"', 'citing_paragraphs': '[]'}]\n"
     ]
    }
   ],
   "source": [
    "citing_id = {\"citing_paper_id\": \"1810.04805v2\"}\n",
    "cited_papers = research_arcade.get_neighborhood(\"arxiv_citation\", citing_id)\n",
    "print(cited_papers.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cb613e",
   "metadata": {},
   "source": [
    "#### get papers that cite a paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "916724d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 1, 'citing_arxiv_id': '1810.04805v2', 'cited_arxiv_id': '1706.03762v7', 'bib_title': 'attention is all you need', 'bib_key': 'something', 'citing_sections': '\"citing_sections\"', 'citing_paragraphs': '[]'}]\n"
     ]
    }
   ],
   "source": [
    "cited_id = {\"cited_paper_id\": \"1706.03762v7\"}\n",
    "citing_papers = research_arcade.get_neighborhood(\"arxiv_citation\", cited_id)\n",
    "print(citing_papers.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738be620",
   "metadata": {},
   "source": [
    "#### Get All Citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1e71eff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total citations: 1\n",
      "   id citing_arxiv_id cited_arxiv_id                  bib_title    bib_key  \\\n",
      "0   1    1810.04805v2   1706.03762v7  attention is all you need  something   \n",
      "\n",
      "     citing_sections citing_paragraphs  \n",
      "0  \"citing_sections\"                []  \n"
     ]
    }
   ],
   "source": [
    "all_citations = research_arcade.get_all_edge_features(\"arxiv_citation\")\n",
    "print(f\"Total citations: {len(all_citations)}\")\n",
    "print(all_citations.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf6cf3e",
   "metadata": {},
   "source": [
    "#### Get Cited Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a421a7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers cited:\n",
      "   id citing_arxiv_id cited_arxiv_id                  bib_title    bib_key  \\\n",
      "0   1    1810.04805v2   1706.03762v7  attention is all you need  something   \n",
      "\n",
      "     citing_sections citing_paragraphs  \n",
      "0  \"citing_sections\"                []  \n"
     ]
    }
   ],
   "source": [
    "citing_paper = {'citing_paper_id': '1810.04805v2'}\n",
    "cited_papers = research_arcade.get_neighborhood(\"arxiv_citation\", primary_key=citing_paper)\n",
    "print(\"Papers cited:\")\n",
    "print(cited_papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0161a49",
   "metadata": {},
   "source": [
    "#### Get Citing Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "51bf24b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers that cite:\n",
      "   id citing_arxiv_id cited_arxiv_id                  bib_title    bib_key  \\\n",
      "0   1    1810.04805v2   1706.03762v7  attention is all you need  something   \n",
      "\n",
      "     citing_sections citing_paragraphs  \n",
      "0  \"citing_sections\"                []  \n"
     ]
    }
   ],
   "source": [
    "cited_paper = {'cited_paper_id': '1706.03762v7'}\n",
    "citing_papers = research_arcade.get_neighborhood(\"arxiv_citation\", primary_key=cited_paper)\n",
    "print(\"Papers that cite:\")\n",
    "print(citing_papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591a68a8",
   "metadata": {},
   "source": [
    "#### Delete Citation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f575868a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted citation: 1810.04805v2 -> 1706.03762v7\n",
      "Citation deleted!\n"
     ]
    }
   ],
   "source": [
    "citation_id = {\n",
    "    'citing_paper_id': '1810.04805v2',\n",
    "    'cited_paper_id': '1706.03762v7'\n",
    "}\n",
    "research_arcade.delete_edge_by_id(\"arxiv_citation\", primary_key=citation_id)\n",
    "print(\"Citation deleted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea198b1",
   "metadata": {},
   "source": [
    "#### delete by citing_paper_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6aeaaa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "citing_id = {\"citing_paper_id\": \"1810.04805v2\"}\n",
    "result = research_arcade.delete_edge_by_id(\"arxiv_citation\", citing_id)\n",
    "# print(result.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356370fc",
   "metadata": {},
   "source": [
    "#### delete by cited_paper_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c123698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cited_id = {\"cited_paper_id\": \"1706.03762v7\"}\n",
    "result = research_arcade.delete_edge_by_id(\"arxiv_citation\", cited_id)\n",
    "# print(result.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8dbc03",
   "metadata": {},
   "source": [
    "### arxiv_papers_authors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0214eb69",
   "metadata": {},
   "source": [
    "#### Insert Paper-Author Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d003813b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linked author ss_ashish_vaswani (position 1)\n",
      "Linked author ss_noam_shazeer (position 2)\n",
      "Linked author ss_niki_parmar (position 3)\n"
     ]
    }
   ],
   "source": [
    "paper_authors = [\n",
    "    {'paper_arxiv_id': '1706.03762v7', 'author_id': 'ss_ashish_vaswani', 'author_sequence': 1, 'author_name': 'Ashish Vaswani'},\n",
    "    {'paper_arxiv_id': '1706.03762v7', 'author_id': 'ss_noam_shazeer', 'author_sequence': 2, 'author_name': 'Noam Shazeer'},\n",
    "    {'paper_arxiv_id': '1706.03762v7', 'author_id': 'ss_niki_parmar', 'author_sequence': 3, 'author_name': 'Niki Parmar'}\n",
    "]\n",
    "for relation in paper_authors:\n",
    "    research_arcade.insert_edge(\"arxiv_paper_author\", edge_features=relation)\n",
    "    print(f\"Linked author {relation['author_id']} (position {relation['author_sequence']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dde4a6",
   "metadata": {},
   "source": [
    "#### Construct Table from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4f8f35f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported 10 paper-author relationships from ./csv_data/arxiv_paper_authors.csv\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"./csv_data/arxiv_paper_authors.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"arxiv_paper_author\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76982f47",
   "metadata": {},
   "source": [
    "#### Construct Table from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3650d387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new paper-author relationships to import\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"./json_data/arxiv_paper_authors.json\"}\n",
    "research_arcade.construct_table_from_json(\"arxiv_paper_author\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe99fc42",
   "metadata": {},
   "source": [
    "#### Get All Paper-Author Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a7e4aa15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total relationships: 23\n",
      "  paper_arxiv_id   author_id  author_sequence author_name\n",
      "0     2502.13728  2166504589                1         NaN\n",
      "1     2503.09712  2042303571                1         NaN\n",
      "2     2506.12689  2367197357                4         NaN\n",
      "3     2504.11669    50997909                1         NaN\n",
      "4     2504.11367  2258720735                1         NaN\n",
      "5     2502.07436  2345008510                3         NaN\n",
      "6       2504.108     1795170                2         NaN\n",
      "7      2502.1353  2258638253                6         NaN\n",
      "8     2504.10800     1795170                2         NaN\n",
      "9     2502.13530  2258638253                6         NaN\n"
     ]
    }
   ],
   "source": [
    "all_relations = research_arcade.get_all_edge_features(\"arxiv_paper_author\")\n",
    "print(f\"Total relationships: {len(all_relations)}\")\n",
    "print(all_relations.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f53661",
   "metadata": {},
   "source": [
    "#### Get Authors for a Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ad73601f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authors:\n",
      "  paper_arxiv_id          author_id  author_sequence     author_name\n",
      "0   1706.03762v7  ss_ashish_vaswani                1  Ashish Vaswani\n",
      "1   1706.03762v7    ss_noam_shazeer                2    Noam Shazeer\n",
      "2   1706.03762v7     ss_niki_parmar                3     Niki Parmar\n"
     ]
    }
   ],
   "source": [
    "paper_id = {'paper_arxiv_id': '1706.03762v7'}\n",
    "authors = research_arcade.get_neighborhood(\"arxiv_paper_author\", primary_key=paper_id)\n",
    "print(\"Authors:\")\n",
    "print(authors.sort_values('author_sequence'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5fb2f7",
   "metadata": {},
   "source": [
    "#### Get Papers by Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0b75672f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers by author:\n",
      "  paper_arxiv_id          author_id  author_sequence     author_name\n",
      "0   1706.03762v7  ss_ashish_vaswani                1  Ashish Vaswani\n"
     ]
    }
   ],
   "source": [
    "author_id = {'author_id': 'ss_ashish_vaswani'}\n",
    "papers = research_arcade.get_neighborhood(\"arxiv_paper_author\", primary_key=author_id)\n",
    "print(\"Papers by author:\")\n",
    "print(papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0121bb34",
   "metadata": {},
   "source": [
    "#### Delete Paper-Author Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "467f5d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relationship deleted!\n"
     ]
    }
   ],
   "source": [
    "relation_id = {'paper_arxiv_id': '1706.03762v7', 'author_id': 'ss_ashish_vaswani'}\n",
    "research_arcade.delete_edge_by_id(\"arxiv_paper_author\", primary_key=relation_id)\n",
    "print(\"Relationship deleted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ed1ff0",
   "metadata": {},
   "source": [
    "#### delete by paper_arxiv_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c5cca237",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_id = {\"paper_arxiv_id\": \"2505.21249\"}\n",
    "result = research_arcade.delete_edge_by_id(\"arxiv_paper_author\", paper_id)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151de990",
   "metadata": {},
   "source": [
    "#### delete by author_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "726222fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_id = {\"author_id\": 3129798}\n",
    "result = research_arcade.delete_edge_by_id(\"arxiv_paper_author\", author_id)\n",
    "# print(result.to_dict(orient=\"records\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f0d463",
   "metadata": {},
   "source": [
    "### arxiv_papers_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44d5dc6",
   "metadata": {},
   "source": [
    "#### Insert Paper-Category Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1ef9cd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linked 1\n",
      "Linked 1\n",
      "Linked 2\n"
     ]
    }
   ],
   "source": [
    "paper_categories = [\n",
    "    {'paper_arxiv_id': '1706.03762v7', 'category_id': '1'},\n",
    "    {'paper_arxiv_id': '1706.03762v7', 'category_id': '1'},\n",
    "    {'paper_arxiv_id': '1706.03762v7', 'category_id': '2'}\n",
    "]\n",
    "for relation in paper_categories:\n",
    "    research_arcade.insert_edge(\"arxiv_paper_category\", edge_features=relation)\n",
    "    print(f\"Linked {relation['category_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be703298",
   "metadata": {},
   "source": [
    "#### Construct Table from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a65eec91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new paper-category relationships to import\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"./csv_data/arxiv_paper_category.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"arxiv_paper_category\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace82ed4",
   "metadata": {},
   "source": [
    "#### Construct Table from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7d2fd8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported 10 paper-category relationships from ./json_data/arxiv_paper_category.json\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"./json_data/arxiv_paper_category.json\"}\n",
    "research_arcade.construct_table_from_json(\"arxiv_paper_category\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c91b45",
   "metadata": {},
   "source": [
    "#### Get All Paper-Category Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "14b718ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total relationships: 33\n",
      "  paper_arxiv_id  category_id\n",
      "0     2402.07925           85\n",
      "1     2505.14516          390\n",
      "2     2501.18192           29\n",
      "3     2504.07777           91\n",
      "4   1912.03049v4          263\n"
     ]
    }
   ],
   "source": [
    "all_relations = research_arcade.get_all_edge_features(\"arxiv_paper_category\")\n",
    "print(f\"Total relationships: {len(all_relations)}\")\n",
    "print(all_relations.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcd00cf",
   "metadata": {},
   "source": [
    "#### Get Categories for Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c31e6276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories:\n",
      "  paper_arxiv_id  category_id\n",
      "0   1706.03762v7            1\n",
      "1   1706.03762v7            1\n",
      "2   1706.03762v7            2\n"
     ]
    }
   ],
   "source": [
    "paper_id = {'paper_arxiv_id': '1706.03762v7'}\n",
    "categories = research_arcade.get_neighborhood(\"arxiv_paper_category\", primary_key=paper_id)\n",
    "print(\"Categories:\")\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bfc5c3",
   "metadata": {},
   "source": [
    "#### Get Papers in Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "85d96d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Papers in category:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "category_id = {'category_id': 'cs.LG'}\n",
    "papers = research_arcade.get_neighborhood(\"arxiv_paper_category\", primary_key=category_id)\n",
    "print(\"Papers in category:\")\n",
    "print(papers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef01d67",
   "metadata": {},
   "source": [
    "#### Delete Paper-Category Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e1c16ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relationship deleted!\n"
     ]
    }
   ],
   "source": [
    "relation_id = {'paper_arxiv_id': '1706.03762v7', 'category_id': 'cs.AI'}\n",
    "research_arcade.delete_edge_by_id(\"arxiv_paper_category\", primary_key=relation_id)\n",
    "print(\"Relationship deleted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e19cc7c",
   "metadata": {},
   "source": [
    "#### delete by paper_arxiv_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d17fbc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_id = {\"paper_arxiv_id\": \"1706.03762v7\"}\n",
    "result = research_arcade.delete_edge_by_id(\"arxiv_paper_category\", paper_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b554daee",
   "metadata": {},
   "source": [
    "#### delete by category_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "89f7afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_id = {\"category_id\": 1}\n",
    "result = research_arcade.delete_edge_by_id(\"arxiv_paper_category\", category_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9018dc95",
   "metadata": {},
   "source": [
    "### arxiv_papers_figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f482e8bd",
   "metadata": {},
   "source": [
    "#### Insert Paper-Figure Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f23b8d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linked figure 1)\n",
      "Linked figure 2)\n"
     ]
    }
   ],
   "source": [
    "paper_figures = [\n",
    "    {'paper_arxiv_id': '1706.03762v7', 'figure_id': 1},\n",
    "    {'paper_arxiv_id': '1706.03762v7', 'figure_id': 2}\n",
    "]\n",
    "for relation in paper_figures:\n",
    "    research_arcade.insert_edge(\"arxiv_paper_figure\", edge_features=relation)\n",
    "    print(f\"Linked figure {relation['figure_id']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868906f2",
   "metadata": {},
   "source": [
    "#### Construct Table from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a7fd24bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported 2 paper-figure relationships from ./csv_data/arxiv_paper_figures.csv\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"./csv_data/arxiv_paper_figures.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"arxiv_paper_figure\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e58c580",
   "metadata": {},
   "source": [
    "#### Construct Table from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0033ac7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported 10 paper-figure relationships from ./json_data/arxiv_paper_figures.json\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"./json_data/arxiv_paper_figures.json\"}\n",
    "research_arcade.construct_table_from_json(\"arxiv_paper_figure\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e7e940",
   "metadata": {},
   "source": [
    "#### construct table from api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "016e7991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv_id\n",
      "1806.08804v4\n",
      "label\n",
      "\\label{fig:illustration}\n",
      "arxiv_id\n",
      "1806.08804v4\n",
      "label\n",
      "\\label{fig:assignment_vis}\n",
      "arxiv_id\n",
      "1806.08804v4\n",
      "label\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv_id\n",
      "1806.08804v4\n",
      "label\n",
      "None\n",
      "arxiv_id\n",
      "1806.08804v4\n",
      "label\n",
      "None\n",
      "arxiv_id\n",
      "1806.08804v4\n",
      "label\n",
      "None\n",
      "arxiv_id\n",
      "1806.08804v4\n",
      "label\n",
      "None\n",
      "arxiv_id\n",
      "1806.08804v4\n",
      "label\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chongshan0lin/Documents/Research/uiuc/research-arcade/research_arcade/csv_database/csv_arxiv_paper_figures.py:75: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n",
      "/Users/chongshan0lin/Documents/Research/uiuc/research-arcade/research_arcade/csv_database/csv_arxiv_paper_figures.py:75: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n",
      "/Users/chongshan0lin/Documents/Research/uiuc/research-arcade/research_arcade/csv_database/csv_arxiv_paper_figures.py:75: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n",
      "/Users/chongshan0lin/Documents/Research/uiuc/research-arcade/research_arcade/csv_database/csv_arxiv_paper_figures.py:75: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n",
      "/Users/chongshan0lin/Documents/Research/uiuc/research-arcade/research_arcade/csv_database/csv_arxiv_paper_figures.py:75: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n",
      "/Users/chongshan0lin/Documents/Research/uiuc/research-arcade/research_arcade/csv_database/csv_arxiv_paper_figures.py:75: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([df, new_row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "config = {\"arxiv_ids\": [\"1806.08804v4\"], \"dest_dir\": \"./download\"}\n",
    "research_arcade.construct_table_from_api(\"arxiv_paper_figures\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a7e7d4",
   "metadata": {},
   "source": [
    "#### Get Figures for Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2764b5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figures:\n",
      "  paper_arxiv_id  figure_id\n",
      "0   1806.08804v4       15.0\n",
      "1   1806.08804v4       16.0\n",
      "2   1806.08804v4        NaN\n",
      "3   1806.08804v4        NaN\n",
      "4   1806.08804v4        NaN\n",
      "5   1806.08804v4        NaN\n",
      "6   1806.08804v4        NaN\n",
      "7   1806.08804v4        NaN\n"
     ]
    }
   ],
   "source": [
    "paper_id = {'paper_arxiv_id': '1806.08804v4'}\n",
    "figures = research_arcade.get_neighborhood(\"arxiv_paper_figure\", primary_key=paper_id)\n",
    "print(\"Figures:\")\n",
    "print(figures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590f0b86",
   "metadata": {},
   "source": [
    "#### delete by paper_arxiv_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "db1dfc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_id = {\"paper_arxiv_id\": \"2507.13024\"}\n",
    "result = research_arcade.delete_edge_by_id(\"arxiv_paper_figure\", paper_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44708d9c",
   "metadata": {},
   "source": [
    "#### delete by figure_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ccd68983",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_id = {\"figure_id\": 1}\n",
    "result = research_arcade.delete_edge_by_id(\"arxiv_paper_figure\", figure_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d323fc6",
   "metadata": {},
   "source": [
    "#### delete by both ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4c1d6000",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_figure_id = {\n",
    "    \"paper_arxiv_id\": \"2410.23123v2\",\n",
    "    \"figure_id\": 476323\n",
    "}\n",
    "result = research_arcade.delete_edge_by_id(\"arxiv_paper_figure\", paper_figure_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbae75c",
   "metadata": {},
   "source": [
    "#### get all edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e669f356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "all_edges = research_arcade.get_all_edge_features(\"arxiv_paper_figure\")\n",
    "print(len(all_edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0850ee21",
   "metadata": {},
   "source": [
    "### arxiv_papers_tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30b66b0",
   "metadata": {},
   "source": [
    "#### Insert Paper-Table Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4bfd6281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linked table 1\n",
      "Linked table 2\n"
     ]
    }
   ],
   "source": [
    "paper_tables = [\n",
    "    {'paper_arxiv_id': '1706.03762v7', 'table_id': 1},\n",
    "    {'paper_arxiv_id': '1706.03762v7', 'table_id': 2}\n",
    "]\n",
    "for relation in paper_tables:\n",
    "    research_arcade.insert_edge(\"arxiv_paper_table\", edge_features=relation)\n",
    "    print(f\"Linked table {relation['table_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e929a0",
   "metadata": {},
   "source": [
    "#### Construct Table from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bcc0645f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new paper-table relationships to import\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"./csv_data/arxiv_paper_tables.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"arxiv_paper_table\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964f33d6",
   "metadata": {},
   "source": [
    "#### Construct Table from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9f492aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported 10 paper-table relationships from ./json_data/arxiv_paper_tables.json\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"./json_data/arxiv_paper_tables.json\"}\n",
    "research_arcade.construct_table_from_json(\"arxiv_paper_table\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94170afb",
   "metadata": {},
   "source": [
    "#### construct table from api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1739f22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table arxiv_paper_table does not support construction from API\n"
     ]
    }
   ],
   "source": [
    "config = {\"arxiv_ids\": [\"1706.03762v7\"], \"dest_dir\": \"./download\"}\n",
    "research_arcade.construct_table_from_api(\"arxiv_paper_table\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba774a7",
   "metadata": {},
   "source": [
    "#### Get Tables for Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7e77b1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables:\n"
     ]
    }
   ],
   "source": [
    "paper_id = {'paper_arxiv_id': '1706.03762v7'}\n",
    "tables = research_arcade.get_neighborhood(\"arxiv_paper_table\", primary_key=paper_id)\n",
    "print(\"Tables:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73a3e42",
   "metadata": {},
   "source": [
    "#### delete by paper_arxiv_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a3f10d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_id = {\"paper_arxiv_id\": \"1706.03762v7\"}\n",
    "result = research_arcade.delete_edge_by_id(\"arxiv_paper_table\", paper_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30ba6f5",
   "metadata": {},
   "source": [
    "#### delete by table_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "aa9acf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_id = {\"table_id\": 1}\n",
    "result = research_arcade.delete_edge_by_id(\"arxiv_paper_table\", table_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81e493a",
   "metadata": {},
   "source": [
    "#### delete by both ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "65330fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_table_id = {\n",
    "    \"paper_arxiv_id\": \"1706.03762v7\",\n",
    "    \"table_id\": 1\n",
    "}\n",
    "result = research_arcade.delete_edge_by_id(\"arxiv_paper_table\", paper_table_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1227ad75",
   "metadata": {},
   "source": [
    "#### get all edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1020d632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "all_edges = research_arcade.get_all_edge_features(\"arxiv_paper_table\")\n",
    "print(len(all_edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00083dab",
   "metadata": {},
   "source": [
    "### arxiv_paragraphs_references"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ebbe80",
   "metadata": {},
   "source": [
    "#### Insert Paragraph-Reference Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "34e89f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_references = [\n",
    "    {'paragraph_id': 1, 'paper_section': 'established approaches', 'paper_arxiv_id': '1706.03762v7', 'reference_label': \"{something}\", 'reference_type': 'figure'}\n",
    "]\n",
    "\n",
    "for relation in paragraph_references:\n",
    "    research_arcade.insert_edge(\"arxiv_paragraph_reference\", edge_features=relation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd2c9d8",
   "metadata": {},
   "source": [
    "#### Construct Table from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c9ff38b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: CSV file ./examples/csv_data/csv_arxiv_paragraph_reference_example.csv does not exist.\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"./examples/csv_data/csv_arxiv_paragraph_reference_example.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"arxiv_paragraph_reference\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f487b672",
   "metadata": {},
   "source": [
    "#### Construct Table from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "349a7aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: JSON file ./examples/json_data/json_arxiv_paragraph_reference_example.json does not exist.\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"./examples/json_data/json_arxiv_paragraph_reference_example.json\"}\n",
    "research_arcade.construct_table_from_json(\"arxiv_paragraph_reference\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb857b77",
   "metadata": {},
   "source": [
    "#### construct table from api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4daf3349",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"arxiv_ids\": [\"1806.08804v4\", \"1903.03894v4\"], \"dest_dir\": \"./download\"}\n",
    "research_arcade.construct_table_from_api(\"arxiv_paragraph_references\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf09c6b3",
   "metadata": {},
   "source": [
    "#### delete by paragraph_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "aaed50b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_id = {\"paragraph_id\": 1}\n",
    "result = research_arcade.delete_edge_by_id(\"arxiv_paragraph_reference\", paragraph_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a82f9a",
   "metadata": {},
   "source": [
    "#### Get References in Paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cba14d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "References:\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "paragraph_id = {'paragraph_id': 1}\n",
    "references = research_arcade.get_neighborhood(\"arxiv_paragraph_reference\", primary_key=paragraph_id)\n",
    "print(\"References:\")\n",
    "print(references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff2276e",
   "metadata": {},
   "source": [
    "#### get all edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "29f278ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_edges = research_arcade.get_all_edge_features(\"arxiv_paragraph_reference\")\n",
    "print(len(all_edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99639687",
   "metadata": {},
   "source": [
    "### arxiv_paragraphs_citations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671651c8",
   "metadata": {},
   "source": [
    "#### Insert paragraph citation relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bb601f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph 1 cites 1706.03762v7\n",
      "Paragraph 4 cites 1706.03762v7\n"
     ]
    }
   ],
   "source": [
    "# Link specific paragraphs to cited papers\n",
    "paragraph_citations = [\n",
    "    {\n",
    "        'paragraph_id': 1,\n",
    "        'paper_section': 'Introduction',\n",
    "        'citing_arxiv_id': '1810.04805v2',\n",
    "        'cited_arxiv_id': '1706.03762v7',\n",
    "        'bib_key': 'vaswani2017attention'\n",
    "    },\n",
    "    {\n",
    "        'paragraph_id': 4,\n",
    "        'paper_section': 'Related Work',\n",
    "        'citing_arxiv_id': '1810.04805v2',\n",
    "        'cited_arxiv_id': '1706.03762v7',\n",
    "        'bib_key': 'vaswani2017attention'\n",
    "    }\n",
    "]\n",
    "\n",
    "for relation in paragraph_citations:\n",
    "    research_arcade.insert_edge(\"arxiv_paragraph_citation\", edge_features=relation)\n",
    "    print(f\"Paragraph {relation['paragraph_id']} cites {relation['cited_arxiv_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801c8b9f",
   "metadata": {},
   "source": [
    "#### construct table from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "67c0ece6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: CSV file /examples/csv_data/arxiv_paragraph_figures.csv does not exist.\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"/examples/csv_data/arxiv_paragraph_figures.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"arxiv_paragraph_figure\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4014bb5",
   "metadata": {},
   "source": [
    "#### construct table from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "04b1bf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: JSON file /examples/csv_data/arxiv_paragraph_figures.json does not exist.\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"/examples/csv_data/arxiv_paragraph_figures.json\"}\n",
    "research_arcade.construct_table_from_json(\"arxiv_paragraph_figure\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36e0416",
   "metadata": {},
   "source": [
    "#### construct table from api\n",
    "Notice: API construction requires paragraphs data preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1480f061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table arxiv_paragraph_citation does not support construction from API\n"
     ]
    }
   ],
   "source": [
    "config = {\"arxiv_ids\": [\"1810.04805v2\"], \"dest_dir\": \"./download\"}\n",
    "research_arcade.construct_table_from_api(\"arxiv_paragraph_citation\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d50958",
   "metadata": {},
   "source": [
    "#### insert edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6b9f485b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(3)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph_citation = {\n",
    "    'paragraph_id': 0,\n",
    "    'paper_section': 'Introduction',\n",
    "    'citing_arxiv_id': '1810.04805v2',\n",
    "    'bib_key': 'vaswani2017attention',\n",
    "    'cited_arxiv_id': '1706.03762v7',  # optional\n",
    "    'paragraph_global_id': 1  # optional\n",
    "}\n",
    "research_arcade.insert_edge(\"arxiv_paragraph_citation\", paragraph_citation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769d549b",
   "metadata": {},
   "source": [
    "#### delete by paragraph_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "64ed1bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 1 paragraph citations\n"
     ]
    }
   ],
   "source": [
    "paragraph_citation = {\n",
    "    'paragraph_id': 1\n",
    "}\n",
    "count = research_arcade.delete_edge_by_id('arxiv_paragraph_citation', paragraph_citation)\n",
    "print(f\"Deleted {count} paragraph citations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50824fef",
   "metadata": {},
   "source": [
    "#### get all edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f8ada2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total paragraph citations: 2\n"
     ]
    }
   ],
   "source": [
    "all_citations = research_arcade.get_all_edge_features('arxiv_paragraph_citation')\n",
    "if all_citations is not None:\n",
    "    print(f\"Total paragraph citations: {len(all_citations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb56f50",
   "metadata": {},
   "source": [
    "#### get neighborhood by reference_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5d083404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For arxiv_paragraph_citation, provide 'paragraph_id', 'paragraph_global_id', 'citing_arxiv_id', or 'cited_arxiv_id'.\n"
     ]
    }
   ],
   "source": [
    "paragraph_citation = {\n",
    "    'reference_id': 1\n",
    "}\n",
    "result = research_arcade.get_neighborhood('arxiv_paragraph_citation', paragraph_citation)\n",
    "if result is not None:\n",
    "    print(result.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64b44c2",
   "metadata": {},
   "source": [
    "### arxiv_paragraph_figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feae7073",
   "metadata": {},
   "source": [
    "#### construct table from api\n",
    "Notice:  paragraph_references, paragraphs, figures, sections tables need to be updated first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b85c9e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arxiv_id\n",
      "1706.03762v7\n",
      "Empty DataFrame\n",
      "Columns: [id, paragraph_id, paper_section, paper_arxiv_id, reference_label, reference_type]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "config = {\"arxiv_ids\": [\"1706.03762v7\"], \"dest_dir\": \"./download\"}\n",
    "research_arcade.construct_table_from_api(\"arxiv_paragraph_figures\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4b5943",
   "metadata": {},
   "source": [
    "#### construct table from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "705a420e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: CSV file /path/to/arxiv_paragraph_figures.csv does not exist.\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"/path/to/arxiv_paragraph_figures.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"arxiv_paragraph_figure\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1da8ce",
   "metadata": {},
   "source": [
    "#### construct table from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6724e5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: JSON file /path/to/arxiv_paragraph_figures.json does not exist.\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"/path/to/arxiv_paragraph_figures.json\"}\n",
    "research_arcade.construct_table_from_json(\"arxiv_paragraph_figure\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432cb68f",
   "metadata": {},
   "source": [
    "#### insert edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "205059fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted paragraph-figure relationship with id: 1\n"
     ]
    }
   ],
   "source": [
    "paragraph_figure = {\n",
    "    'paragraph_id': 1,      # 全局段落 ID\n",
    "    'figure_id': 1,         # 图片 ID\n",
    "    'paper_arxiv_id': '1706.03762v7',\n",
    "    'paper_section_id': 1   # 章节 ID\n",
    "}\n",
    "new_id = research_arcade.insert_edge(\"arxiv_paragraph_figure\", edge_features=paragraph_figure)\n",
    "print(f\"Inserted paragraph-figure relationship with id: {new_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2dd378",
   "metadata": {},
   "source": [
    "#### delete by paragraph_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c7a8f073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 1 relationships\n"
     ]
    }
   ],
   "source": [
    "paragraph_id = {\"paragraph_id\": 1}\n",
    "result = research_arcade.delete_edge_by_id(\"arxiv_paragraph_figure\", paragraph_id)\n",
    "print(f\"Deleted {result} relationships\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93a6de1",
   "metadata": {},
   "source": [
    "#### delete by figure_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6eff43d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: False\n"
     ]
    }
   ],
   "source": [
    "figure_id = {\"figure_id\": 1}\n",
    "result = research_arcade.delete_edge_by_id(\"arxiv_paragraph_figure\", figure_id)\n",
    "print(f\"Deleted: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9308b7c",
   "metadata": {},
   "source": [
    "#### delete by both paragraph_id and figure_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "272f1590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 0 relationships\n"
     ]
    }
   ],
   "source": [
    "paragraph_figure_id = {\n",
    "    \"paragraph_id\": 1,\n",
    "    \"figure_id\": 1\n",
    "}\n",
    "result = research_arcade.delete_edge_by_id(\"arxiv_paragraph_figure\", paragraph_figure_id)\n",
    "print(f\"Deleted {result} relationships\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a58cb47",
   "metadata": {},
   "source": [
    "#### get all edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fc68dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_edges = research_arcade.get_all_edge_features(\"arxiv_paragraph_figure\")\n",
    "if all_edges is not None:\n",
    "    print(f\"Total paragraph-figure relationships: {len(all_edges)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313498e6",
   "metadata": {},
   "source": [
    "#### get figures for a paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a4a2c6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_id = {\"paragraph_id\": 1}\n",
    "figures = research_arcade.get_neighborhood(\"arxiv_paragraph_figure\", paragraph_id)\n",
    "if figures is not None:\n",
    "    print(\"Figures referenced by paragraph:\")\n",
    "    print(figures.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32a9282",
   "metadata": {},
   "source": [
    "#### get paragraphs for a figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2ec80bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_id = {\"figure_id\": 1}\n",
    "paragraphs = research_arcade.get_neighborhood(\"arxiv_paragraph_figure\", figure_id)\n",
    "if paragraphs is not None:\n",
    "    print(\"Paragraphs that reference this figure:\")\n",
    "    print(paragraphs.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d722704",
   "metadata": {},
   "source": [
    "### arxiv_paragraph_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc4fe47",
   "metadata": {},
   "source": [
    "#### construct table from api\n",
    "Notice:  paragraph_references, paragraphs, figures, sections tables need to be updated first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1bc1055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"arxiv_ids\": [\"1706.03762v7\"], \"dest_dir\": \"./download\"}\n",
    "research_arcade.construct_table_from_api(\"arxiv_paragraph_tables\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4236b0c5",
   "metadata": {},
   "source": [
    "#### construct table from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "63320c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: CSV file /path/to/arxiv_paragraph_tables.csv does not exist.\n"
     ]
    }
   ],
   "source": [
    "config = {\"csv_file\": \"/path/to/arxiv_paragraph_tables.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"arxiv_paragraph_table\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87f9414",
   "metadata": {},
   "source": [
    "#### construct table from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "189673ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: JSON file /path/to/arxiv_paragraph_tables.json does not exist.\n"
     ]
    }
   ],
   "source": [
    "config = {\"json_file\": \"/path/to/arxiv_paragraph_tables.json\"}\n",
    "research_arcade.construct_table_from_json(\"arxiv_paragraph_table\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7908883",
   "metadata": {},
   "source": [
    "#### insert edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1197cd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted paragraph-table relationship with id: 1\n"
     ]
    }
   ],
   "source": [
    "paragraph_table = {\n",
    "    'paragraph_id': 1,     \n",
    "    'table_id': 1,         \n",
    "    'paper_arxiv_id': '1706.03762v7',\n",
    "    'paper_section_id': 1   \n",
    "}\n",
    "new_id = research_arcade.insert_edge(\"arxiv_paragraph_table\", edge_features=paragraph_table)\n",
    "print(f\"Inserted paragraph-table relationship with id: {new_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1a804c",
   "metadata": {},
   "source": [
    "#### delete by paragraph_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b82d2136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 1 relationships\n"
     ]
    }
   ],
   "source": [
    "paragraph_id = {\"paragraph_id\": 1}\n",
    "result = research_arcade.delete_edge_by_id(\"arxiv_paragraph_table\", paragraph_id)\n",
    "print(f\"Deleted {result} relationships\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819057e6",
   "metadata": {},
   "source": [
    "#### delete by table_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7ffc22e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: False\n"
     ]
    }
   ],
   "source": [
    "table_id = {\"table_id\": 1}\n",
    "result = research_arcade.delete_edge_by_id(\"arxiv_paragraph_table\", table_id)\n",
    "print(f\"Deleted: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b14bf7",
   "metadata": {},
   "source": [
    "#### delete by both paragraph_id and table_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e75497f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 0 relationships\n"
     ]
    }
   ],
   "source": [
    "paragraph_table_id = {\n",
    "    \"paragraph_id\": 1,\n",
    "    \"table_id\": 1\n",
    "}\n",
    "result = research_arcade.delete_edge_by_id(\"arxiv_paragraph_table\", paragraph_table_id)\n",
    "print(f\"Deleted {result} relationships\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a30347b",
   "metadata": {},
   "source": [
    "#### get all edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "6ad2d0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_edges = research_arcade.get_all_edge_features(\"arxiv_paragraph_table\")\n",
    "if all_edges is not None:\n",
    "    print(f\"Total paragraph-table relationships: {len(all_edges)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f941b136",
   "metadata": {},
   "source": [
    "#### get tables for a paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "85824b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_id = {\"paragraph_id\": 1}\n",
    "tables = research_arcade.get_neighborhood(\"arxiv_paragraph_table\", paragraph_id)\n",
    "if tables is not None:\n",
    "    print(\"Tables referenced by paragraph:\")\n",
    "    print(tables.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b18aaa6",
   "metadata": {},
   "source": [
    "#### get paragraphs for a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9f0fd0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_id = {\"table_id\": 1}\n",
    "paragraphs = research_arcade.get_neighborhood(\"arxiv_paragraph_table\", table_id)\n",
    "if paragraphs is not None:\n",
    "    print(\"Paragraphs that reference this table:\")\n",
    "    print(paragraphs.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74a66f5",
   "metadata": {},
   "source": [
    "## BatchProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abd96b3",
   "metadata": {},
   "source": [
    "### batch_openreview_conference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7169e57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling openreview arxiv data for venue: {'venue': 'ICLR.cc/2025/Conference'}...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new openreview arxiv data to insert.\n",
      "Crawling author data from OpenReview API...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new author data to insert.\n",
      "Crawling paper data from OpenReview API...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new paper data to insert.\n",
      "Crawling review data from OpenReview API...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new review data to insert.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "CSVOpenReviewParagraphs.construct_paragraphs_table_from_api() missing 3 required positional arguments: 'pdf_dir', 'filter_list', and 'log_file'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[143]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m config = {\u001b[33m\"\u001b[39m\u001b[33mvenue\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mICLR.cc/2025/Conference\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mresearch_arcade\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstruct_tables_from_venue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/uiuc/research-arcade/research_arcade/research_arcade.py:841\u001b[39m, in \u001b[36mResearchArcade.construct_tables_from_venue\u001b[39m\u001b[34m(self, config)\u001b[39m\n\u001b[32m    839\u001b[39m \u001b[38;5;28mself\u001b[39m.openreview_papers.construct_papers_table_from_api(config)\n\u001b[32m    840\u001b[39m \u001b[38;5;28mself\u001b[39m.openreview_reviews.construct_reviews_table_from_api(config)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopenreview_paragraphs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstruct_paragraphs_table_from_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[38;5;28mself\u001b[39m.openreview_revisions.construct_revisions_table_from_api(config)\n\u001b[32m    843\u001b[39m \u001b[38;5;28mself\u001b[39m.openreview_papers_authors.construct_papers_authors_table_from_api(config)\n",
      "\u001b[31mTypeError\u001b[39m: CSVOpenReviewParagraphs.construct_paragraphs_table_from_api() missing 3 required positional arguments: 'pdf_dir', 'filter_list', and 'log_file'"
     ]
    }
   ],
   "source": [
    "config = {\"venue\": \"ICLR.cc/2025/Conference\"}\n",
    "research_arcade.construct_tables_from_venue(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b469c0",
   "metadata": {},
   "source": [
    "### batch_arxiv_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d1a6c486",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[145]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      2\u001b[39m arxiv_ids = [\u001b[33m'\u001b[39m\u001b[33m1802.08773\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m1806.02473\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m2412.17767\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m2507.10539\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m2511.22036\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      5\u001b[39m config = {\n\u001b[32m      6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33marxiv_ids\u001b[39m\u001b[33m'\u001b[39m: arxiv_ids,\n\u001b[32m      7\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mdest_dir\u001b[39m\u001b[33m'\u001b[39m: os.getenv(\u001b[33m'\u001b[39m\u001b[33mPAPER_FOLDER_PATH\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      8\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mresearch_arcade\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstruct_tables_from_arxiv_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/uiuc/research-arcade/research_arcade/research_arcade.py:818\u001b[39m, in \u001b[36mResearchArcade.construct_tables_from_arxiv_ids\u001b[39m\u001b[34m(self, config)\u001b[39m\n\u001b[32m    815\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconstruct_tables_from_arxiv_ids\u001b[39m(\u001b[38;5;28mself\u001b[39m, config: \u001b[38;5;28mdict\u001b[39m) -> Optional[pd.DataFrame]:\n\u001b[32m    816\u001b[39m \n\u001b[32m    817\u001b[39m     \u001b[38;5;66;03m# Use sequential construction\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m818\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43marxiv_papers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconstruct_papers_table_from_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    819\u001b[39m     \u001b[38;5;28mself\u001b[39m.arxiv_sections.construct_sections_table_from_api(**config)\n\u001b[32m    820\u001b[39m     \u001b[38;5;28mself\u001b[39m.arxiv_authors.construct_authors_table_from_api(**config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/uiuc/research-arcade/research_arcade/csv_database/csv_arxiv_papers.py:230\u001b[39m, in \u001b[36mCSVArxivPapers.construct_papers_table_from_api\u001b[39m\u001b[34m(self, arxiv_ids, dest_dir)\u001b[39m\n\u001b[32m    228\u001b[39m md = MultiDownload()\n\u001b[32m    229\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m     \u001b[43mmd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_arxiv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43marxiv_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_type\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mid\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlatex\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdest_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    231\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mpaper with id \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marxiv_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m downloaded\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/uiuc/research-arcade/research_arcade/utils/error_handler.py:37\u001b[39m, in \u001b[36mapi_calling_error_exponential_backoff.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m attempts < modified_retries:\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     39\u001b[39m         wait_time = modified_base_wait_time * (\u001b[32m2\u001b[39m**attempts)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Research/uiuc/research-arcade/research_arcade/arxiv_utils/multi_input/multi_download.py:69\u001b[39m, in \u001b[36mMultiDownload.download_arxiv\u001b[39m\u001b[34m(self, input, input_type, output_type, dest_dir)\u001b[39m\n\u001b[32m     65\u001b[39m     pdf_path = paper.download_pdf(filename = filename_pdf, dirpath = dest_dir)\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_type == \u001b[33m\"\u001b[39m\u001b[33mlatex\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     latex_path = \u001b[43mpaper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdownload_source\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename_latex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirpath\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m     \u001b[38;5;66;03m# Extract the real (with or without the version number) arxiv id\u001b[39;00m\n\u001b[32m     71\u001b[39m     \u001b[38;5;28mprint\u001b[39m(latex_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/site-packages/arxiv/__init__.py:240\u001b[39m, in \u001b[36mResult.download_source\u001b[39m\u001b[34m(self, dirpath, filename, download_domain)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;66;03m# Bodge: construct the source URL from the PDF URL.\u001b[39;00m\n\u001b[32m    239\u001b[39m src_url = pdf_url.replace(\u001b[33m\"\u001b[39m\u001b[33m/pdf/\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m/src/\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m written_path, _ = \u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m written_path\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/urllib/request.py:240\u001b[39m, in \u001b[36murlretrieve\u001b[39m\u001b[34m(url, filename, reporthook, data)\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    224\u001b[39m \u001b[33;03mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[32m    225\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    236\u001b[39m \u001b[33;03mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[32m    237\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    238\u001b[39m url_type, path = _splittype(url)\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m contextlib.closing(\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[32m    241\u001b[39m     headers = fp.info()\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[32m    244\u001b[39m     \u001b[38;5;66;03m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/urllib/request.py:215\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    214\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/urllib/request.py:515\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    512\u001b[39m     req = meth(req)\n\u001b[32m    514\u001b[39m sys.audit(\u001b[33m'\u001b[39m\u001b[33murllib.Request\u001b[39m\u001b[33m'\u001b[39m, req.full_url, req.data, req.headers, req.get_method())\n\u001b[32m--> \u001b[39m\u001b[32m515\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[32m    518\u001b[39m meth_name = protocol+\u001b[33m\"\u001b[39m\u001b[33m_response\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/urllib/request.py:532\u001b[39m, in \u001b[36mOpenerDirector._open\u001b[39m\u001b[34m(self, req, data)\u001b[39m\n\u001b[32m    529\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    531\u001b[39m protocol = req.type\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[43m                          \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m_open\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[32m    535\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/urllib/request.py:492\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    491\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m492\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    494\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/urllib/request.py:1392\u001b[39m, in \u001b[36mHTTPSHandler.https_open\u001b[39m\u001b[34m(self, req)\u001b[39m\n\u001b[32m   1391\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[32m-> \u001b[39m\u001b[32m1392\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1393\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/urllib/request.py:1344\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1342\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1343\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1344\u001b[39m         \u001b[43mh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1345\u001b[39m \u001b[43m                  \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTransfer-encoding\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1346\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[32m   1347\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/http/client.py:1338\u001b[39m, in \u001b[36mHTTPConnection.request\u001b[39m\u001b[34m(self, method, url, body, headers, encode_chunked)\u001b[39m\n\u001b[32m   1335\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\u001b[38;5;28mself\u001b[39m, method, url, body=\u001b[38;5;28;01mNone\u001b[39;00m, headers={}, *,\n\u001b[32m   1336\u001b[39m             encode_chunked=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   1337\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1338\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/http/client.py:1384\u001b[39m, in \u001b[36mHTTPConnection._send_request\u001b[39m\u001b[34m(self, method, url, body, headers, encode_chunked)\u001b[39m\n\u001b[32m   1380\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(body, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m   1381\u001b[39m     \u001b[38;5;66;03m# RFC 2616 Section 3.7.1 says that text default has a\u001b[39;00m\n\u001b[32m   1382\u001b[39m     \u001b[38;5;66;03m# default charset of iso-8859-1.\u001b[39;00m\n\u001b[32m   1383\u001b[39m     body = _encode(body, \u001b[33m'\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1384\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/http/client.py:1333\u001b[39m, in \u001b[36mHTTPConnection.endheaders\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1332\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[32m-> \u001b[39m\u001b[32m1333\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/http/client.py:1093\u001b[39m, in \u001b[36mHTTPConnection._send_output\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1091\u001b[39m msg = \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mself\u001b[39m._buffer)\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer[:]\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1096\u001b[39m \n\u001b[32m   1097\u001b[39m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n\u001b[32m   1098\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(message_body, \u001b[33m'\u001b[39m\u001b[33mread\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m   1099\u001b[39m         \u001b[38;5;66;03m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[32m   1100\u001b[39m         \u001b[38;5;66;03m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[32m   1101\u001b[39m         \u001b[38;5;66;03m# files to be taken into account.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/http/client.py:1037\u001b[39m, in \u001b[36mHTTPConnection.send\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.sock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1036\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_open:\n\u001b[32m-> \u001b[39m\u001b[32m1037\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1038\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1039\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m NotConnected()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/http/client.py:1472\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1469\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1470\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mConnect to a host on a given (SSL) port.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1472\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1474\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tunnel_host:\n\u001b[32m   1475\u001b[39m         server_hostname = \u001b[38;5;28mself\u001b[39m._tunnel_host\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/http/client.py:1013\u001b[39m, in \u001b[36mHTTPConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1010\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m   1012\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tunnel_host:\n\u001b[32m-> \u001b[39m\u001b[32m1013\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tunnel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/http/client.py:971\u001b[39m, in \u001b[36mHTTPConnection._tunnel\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    969\u001b[39m response = \u001b[38;5;28mself\u001b[39m.response_class(\u001b[38;5;28mself\u001b[39m.sock, method=\u001b[38;5;28mself\u001b[39m._method)\n\u001b[32m    970\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m971\u001b[39m     (version, code, message) = \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    973\u001b[39m     \u001b[38;5;28mself\u001b[39m._raw_proxy_headers = _read_headers(response.fp)\n\u001b[32m    975\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.debuglevel > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research-arcade/lib/python3.12/socket.py:720\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    722\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Example papers\n",
    "arxiv_ids = ['1802.08773', '1806.02473', '2412.17767', '2507.10539', '2511.22036']\n",
    "\n",
    "\n",
    "config = {\n",
    "    'arxiv_ids': arxiv_ids,\n",
    "    'dest_dir': os.getenv('PAPER_FOLDER_PATH')\n",
    "}\n",
    "\n",
    "research_arcade.construct_tables_from_arxiv_ids(config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca3399a",
   "metadata": {},
   "source": [
    "## ContinuousCrawling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4c8efc",
   "metadata": {},
   "source": [
    "### arxiv_continuous_crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c7e1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "research_arcade.continuous_crawling(interval_days=2, delay_days=2, paper_category='All', dest_dir=\"./download\", arxiv_id_dest=\"./data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
