{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# ResearchArcade Complete Tutorial\n",
    "\n",
    "This tutorial demonstrates how to work with the ResearchArcade database, covering all node types and edge relationships.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup](#setup)\n",
    "2. [OpenReview Data](#openreview)\n",
    "3. [ArXiv Papers](#arxiv-papers)\n",
    "4. [ArXiv Authors](#arxiv-authors)\n",
    "5. [ArXiv Categories](#arxiv-categories)\n",
    "6. [ArXiv Figures](#arxiv-figures)\n",
    "7. [ArXiv Tables](#arxiv-tables)\n",
    "8. [ArXiv Sections](#arxiv-sections)\n",
    "9. [ArXiv Paragraphs](#arxiv-paragraphs)\n",
    "10. [Relationships/Edges](#relationships)\n",
    "11. [Advanced Queries](#advanced-queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-section",
   "metadata": {},
   "source": [
    "## 1. Setup <a name=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from research_arcade.research_arcade import ResearchArcade\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "project_root = Path(__file__).resolve().parent.parent\n",
    "sys.path.insert(0, str(project_root))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db-backend",
   "metadata": {},
   "source": [
    "### Choose Database Backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "csv-backend",
   "metadata": {},
   "source": [
    "#### CSV Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "csv-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_type = \"csv\"\n",
    "config = {\n",
    "    \"csv_dir\": \"/data/jingjunx/my_research_arcade_data/\"\n",
    "}\n",
    "\n",
    "research_arcade = ResearchArcade(db_type=db_type, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sql-backend",
   "metadata": {},
   "source": [
    "#### SQL Based (PostgreSQL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sql-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_type = \"sql\"\n",
    "config = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"dbname\": \"iclr_openreview_database\",\n",
    "    \"user\": \"jingjunx\",\n",
    "    \"password\": \"\",\n",
    "    \"port\": \"5432\"\n",
    "}\n",
    "\n",
    "research_arcade = ResearchArcade(db_type=db_type, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "openreview-section",
   "metadata": {},
   "source": [
    "## 2. OpenReview Data <a name=\"openreview\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "openreview-authors-header",
   "metadata": {},
   "source": [
    "### openreview_authors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "openreview-construct-api",
   "metadata": {},
   "source": [
    "#### construct table from api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "openreview-api",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"venue\": \"ICLR.cc/2025/Conference\"}\n",
    "research_arcade.construct_table_from_api(\"openreview_authors\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "openreview-construct-csv",
   "metadata": {},
   "source": [
    "#### construct table from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "openreview-csv",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"csv_file\": \"/home/jingjunx/openreview_benchmark/Code/paper-crawler/examples/csv_data/csv_openreview_author_example.csv\"}\n",
    "research_arcade.construct_table_from_csv(\"openreview_authors\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "openreview-construct-json",
   "metadata": {},
   "source": [
    "#### construct table from json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "openreview-json",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"json_file\": \"/home/jingjunx/openreview_benchmark/Code/paper-crawler/examples/json_data/json_openreview_author_example.json\"}\n",
    "research_arcade.construct_table_from_json(\"openreview_authors\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "openreview-insert",
   "metadata": {},
   "source": [
    "#### insert node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "openreview-insert-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_author = {'venue': 'ICLR.cc/2025/Conference', \n",
    "              'author_openreview_id': '~ishmam_zabir1', \n",
    "              'author_full_name': 'ishmam zabir', \n",
    "              'email': '****@microsoft.com', \n",
    "              'affiliation': 'Microsoft', \n",
    "              'homepage': 'https://scholar.google.com/citations?user=X7bjzrUAAAAJ&hl=en&oi=ao', \n",
    "              'dblp': ''}\n",
    "research_arcade.insert_node(\"openreview_authors\", node_features=new_author)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-papers-section",
   "metadata": {},
   "source": [
    "## 3. ArXiv Papers <a name=\"arxiv-papers\"></a>\n",
    "\n",
    "### Table Schema\n",
    "- `id` (SERIAL PK)\n",
    "- `arxiv_id` (VARCHAR, unique) - e.g., 1802.08773v3\n",
    "- `base_arxiv_id` (VARCHAR) - e.g., 1802.08773\n",
    "- `version` (INT) - e.g., 3\n",
    "- `title` (TEXT)\n",
    "- `abstract` (TEXT)\n",
    "- `submit_date` (DATE)\n",
    "- `metadata` (JSONB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-papers-insert",
   "metadata": {},
   "source": [
    "### Insert a Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insert-paper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Insert the famous \"Attention is All You Need\" paper\n",
    "new_paper = {\n",
    "    'arxiv_id': '1706.03762v7',\n",
    "    'base_arxiv_id': '1706.03762',\n",
    "    'version': 7,\n",
    "    'title': 'Attention Is All You Need',\n",
    "    'abstract': 'The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.',\n",
    "    'submit_date': '2017-06-12',\n",
    "    'metadata': {'venue': 'NeurIPS 2017', 'pdf_url': 'https://arxiv.org/pdf/1706.03762.pdf'}\n",
    "}\n",
    "\n",
    "research_arcade.insert_node(\"arxiv_papers\", node_features=new_paper)\n",
    "print(\"Paper inserted successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insert-paper-bert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Insert BERT paper\n",
    "bert_paper = {\n",
    "    'arxiv_id': '1810.04805v2',\n",
    "    'base_arxiv_id': '1810.04805',\n",
    "    'version': 2,\n",
    "    'title': 'BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding',\n",
    "    'abstract': 'We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications.',\n",
    "    'submit_date': '2018-10-11',\n",
    "    'metadata': {'venue': 'NAACL 2019', 'citations': 50000}\n",
    "}\n",
    "\n",
    "research_arcade.insert_node(\"arxiv_papers\", node_features=bert_paper)\n",
    "print(\"BERT paper inserted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-papers-get-all",
   "metadata": {},
   "source": [
    "### Get All Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "get-all-papers",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_papers_df = research_arcade.get_all_node_features(\"arxiv_papers\")\n",
    "print(f\"Total papers in database: {len(arxiv_papers_df)}\")\n",
    "print(\"\\nFirst 5 papers:\")\n",
    "print(arxiv_papers_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-papers-get-by-id",
   "metadata": {},
   "source": [
    "### Get Specific Paper by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "get-paper-by-id",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_id = {\"arxiv_id\": \"1706.03762v7\"}\n",
    "paper_features = research_arcade.get_node_features_by_id(\"arxiv_papers\", paper_id)\n",
    "print(\"Paper details:\")\n",
    "print(paper_features.to_dict(orient=\"records\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-papers-update",
   "metadata": {},
   "source": [
    "### Update a Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "update-paper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update metadata for a paper\n",
    "updated_paper = {\n",
    "    'arxiv_id': '1706.03762v7',\n",
    "    'metadata': {\n",
    "        'venue': 'NeurIPS 2017',\n",
    "        'pdf_url': 'https://arxiv.org/pdf/1706.03762.pdf',\n",
    "        'citations': 75000,\n",
    "        'influential': True\n",
    "    }\n",
    "}\n",
    "\n",
    "research_arcade.update_node(\"arxiv_papers\", node_features=updated_paper)\n",
    "print(\"Paper updated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-papers-delete",
   "metadata": {},
   "source": [
    "### Delete a Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delete-paper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a paper by ID\n",
    "paper_id = {\"arxiv_id\": \"1706.03762v7\"}\n",
    "deleted_paper = research_arcade.delete_node_by_id(\"arxiv_papers\", paper_id)\n",
    "print(\"Deleted paper:\")\n",
    "print(deleted_paper.to_dict(orient=\"records\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-authors-section",
   "metadata": {},
   "source": [
    "## 4. ArXiv Authors <a name=\"arxiv-authors\"></a>\n",
    "\n",
    "### Table Schema\n",
    "- `id` (SERIAL PK)\n",
    "- `semantic_scholar_id` (VARCHAR, unique)\n",
    "- `name` (VARCHAR)\n",
    "- `homepage` (VARCHAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-authors-insert",
   "metadata": {},
   "source": [
    "### Insert Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insert-authors",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert authors from the Transformer paper\n",
    "authors = [\n",
    "    {\n",
    "        'semantic_scholar_id': 'ss_ashish_vaswani',\n",
    "        'name': 'Ashish Vaswani',\n",
    "        'homepage': 'https://scholar.google.com/citations?user=oR9sCGYAAAAJ'\n",
    "    },\n",
    "    {\n",
    "        'semantic_scholar_id': 'ss_noam_shazeer',\n",
    "        'name': 'Noam Shazeer',\n",
    "        'homepage': 'https://scholar.google.com/citations?user=oR9sCGYAAAAJ'\n",
    "    },\n",
    "    {\n",
    "        'semantic_scholar_id': 'ss_niki_parmar',\n",
    "        'name': 'Niki Parmar',\n",
    "        'homepage': 'https://scholar.google.com/citations?user=oR9sCGYAAAAJ'\n",
    "    },\n",
    "    {\n",
    "        'semantic_scholar_id': 'ss_jakob_uszkoreit',\n",
    "        'name': 'Jakob Uszkoreit',\n",
    "        'homepage': 'https://scholar.google.com/citations?user=oR9sCGYAAAAJ'\n",
    "    },\n",
    "    {\n",
    "        'semantic_scholar_id': 'ss_llion_jones',\n",
    "        'name': 'Llion Jones',\n",
    "        'homepage': 'https://scholar.google.com/citations?user=oR9sCGYAAAAJ'\n",
    "    }\n",
    "]\n",
    "\n",
    "for author in authors:\n",
    "    research_arcade.insert_node(\"arxiv_authors\", node_features=author)\n",
    "    print(f\"Inserted author: {author['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-authors-get-all",
   "metadata": {},
   "source": [
    "### Get All Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "get-all-authors",
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_df = research_arcade.get_all_node_features(\"arxiv_authors\")\n",
    "print(f\"Total authors in database: {len(authors_df)}\")\n",
    "print(\"\\nAll authors:\")\n",
    "print(authors_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-authors-get-by-id",
   "metadata": {},
   "source": [
    "### Get Specific Author by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "get-author-by-id",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_id = {\"semantic_scholar_id\": \"ss_ashish_vaswani\"}\n",
    "author_features = research_arcade.get_node_features_by_id(\"arxiv_authors\", author_id)\n",
    "print(\"Author details:\")\n",
    "print(author_features.to_dict(orient=\"records\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-authors-update",
   "metadata": {},
   "source": [
    "### Update an Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "update-author",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_author = {\n",
    "    'semantic_scholar_id': 'ss_ashish_vaswani',\n",
    "    'homepage': 'https://ashishvaswani.com'\n",
    "}\n",
    "\n",
    "research_arcade.update_node(\"arxiv_authors\", node_features=updated_author)\n",
    "print(\"Author updated successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-categories-section",
   "metadata": {},
   "source": [
    "## 5. ArXiv Categories <a name=\"arxiv-categories\"></a>\n",
    "\n",
    "### Table Schema\n",
    "- `id` (SERIAL PK)\n",
    "- `name` (VARCHAR, unique)\n",
    "- `description` (TEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-categories-insert",
   "metadata": {},
   "source": [
    "### Insert Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insert-categories",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [\n",
    "    {\n",
    "        'name': 'cs.CL',\n",
    "        'description': 'Computation and Language (Natural Language Processing)'\n",
    "    },\n",
    "    {\n",
    "        'name': 'cs.LG',\n",
    "        'description': 'Machine Learning'\n",
    "    },\n",
    "    {\n",
    "        'name': 'cs.AI',\n",
    "        'description': 'Artificial Intelligence'\n",
    "    },\n",
    "    {\n",
    "        'name': 'cs.CV',\n",
    "        'description': 'Computer Vision and Pattern Recognition'\n",
    "    },\n",
    "    {\n",
    "        'name': 'stat.ML',\n",
    "        'description': 'Machine Learning (Statistics)'\n",
    "    }\n",
    "]\n",
    "\n",
    "for category in categories:\n",
    "    research_arcade.insert_node(\"arxiv_categories\", node_features=category)\n",
    "    print(f\"Inserted category: {category['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-categories-get-all",
   "metadata": {},
   "source": [
    "### Get All Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "get-all-categories",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_df = research_arcade.get_all_node_features(\"arxiv_categories\")\n",
    "print(f\"Total categories: {len(categories_df)}\")\n",
    "print(\"\\nAll categories:\")\n",
    "print(categories_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-figures-section",
   "metadata": {},
   "source": [
    "## 6. ArXiv Figures <a name=\"arxiv-figures\"></a>\n",
    "\n",
    "### Table Schema\n",
    "- `id` (SERIAL PK)\n",
    "- `paper_arxiv_id` (VARCHAR FK → papers.arxiv_id)\n",
    "- `path` (VARCHAR)\n",
    "- `caption` (TEXT)\n",
    "- `label` (TEXT)\n",
    "- `name` (TEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-figures-insert",
   "metadata": {},
   "source": [
    "### Insert Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insert-figures",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert figures for the Transformer paper\n",
    "figures = [\n",
    "    {\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'path': '/figures/transformer_architecture.png',\n",
    "        'caption': 'The Transformer model architecture. The left side shows the encoder stack and the right side shows the decoder stack.',\n",
    "        'label': 'fig:architecture',\n",
    "        'name': 'Figure 1'\n",
    "    },\n",
    "    {\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'path': '/figures/scaled_dot_product_attention.png',\n",
    "        'caption': 'Scaled Dot-Product Attention and Multi-Head Attention mechanisms.',\n",
    "        'label': 'fig:attention',\n",
    "        'name': 'Figure 2'\n",
    "    },\n",
    "    {\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'path': '/figures/positional_encoding.png',\n",
    "        'caption': 'Positional encoding visualization showing sine and cosine functions of different frequencies.',\n",
    "        'label': 'fig:positional',\n",
    "        'name': 'Figure 3'\n",
    "    }\n",
    "]\n",
    "\n",
    "for figure in figures:\n",
    "    research_arcade.insert_node(\"arxiv_figures\", node_features=figure)\n",
    "    print(f\"Inserted {figure['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-figures-get-all",
   "metadata": {},
   "source": [
    "### Get All Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "get-all-figures",
   "metadata": {},
   "outputs": [],
   "source": [
    "figures_df = research_arcade.get_all_node_features(\"arxiv_figures\")\n",
    "print(f\"Total figures: {len(figures_df)}\")\n",
    "print(\"\\nAll figures:\")\n",
    "print(figures_df[['name', 'caption', 'label']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-tables-section",
   "metadata": {},
   "source": [
    "## 7. ArXiv Tables <a name=\"arxiv-tables\"></a>\n",
    "\n",
    "### Table Schema\n",
    "- `id` (SERIAL PK)\n",
    "- `paper_arxiv_id` (VARCHAR FK → papers.arxiv_id)\n",
    "- `path` (VARCHAR)\n",
    "- `caption` (TEXT)\n",
    "- `label` (TEXT)\n",
    "- `table_text` (TEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-tables-insert",
   "metadata": {},
   "source": [
    "### Insert Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insert-tables",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert tables for the Transformer paper\n",
    "tables = [\n",
    "    {\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'path': '/tables/model_variations.tex',\n",
    "        'caption': 'Variations on the Transformer architecture with different hyperparameters.',\n",
    "        'label': 'tab:variations',\n",
    "        'table_text': 'Model | N | d_model | d_ff | h | d_k | d_v | P_drop | train time\\nbase | 6 | 512 | 2048 | 8 | 64 | 64 | 0.1 | 12 hrs'\n",
    "    },\n",
    "    {\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'path': '/tables/wmt_results.tex',\n",
    "        'caption': 'Performance of the Transformer on WMT 2014 English-German and English-French translation tasks.',\n",
    "        'label': 'tab:wmt',\n",
    "        'table_text': 'Model | EN-DE BLEU | EN-FR BLEU\\nTransformer (base) | 27.3 | 38.1\\nTransformer (big) | 28.4 | 41.8'\n",
    "    },\n",
    "    {\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'path': '/tables/parsing_results.tex',\n",
    "        'caption': 'English constituency parsing results on WSJ test set.',\n",
    "        'label': 'tab:parsing',\n",
    "        'table_text': 'Model | WSJ 23 F1\\nTransformer | 91.3'\n",
    "    }\n",
    "]\n",
    "\n",
    "for table in tables:\n",
    "    research_arcade.insert_node(\"arxiv_tables\", node_features=table)\n",
    "    print(f\"Inserted table: {table['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-tables-get-all",
   "metadata": {},
   "source": [
    "### Get All Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "get-all-tables",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_df = research_arcade.get_all_node_features(\"arxiv_tables\")\n",
    "print(f\"Total tables: {len(tables_df)}\")\n",
    "print(\"\\nAll tables:\")\n",
    "print(tables_df[['label', 'caption']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-sections-section",
   "metadata": {},
   "source": [
    "## 8. ArXiv Sections <a name=\"arxiv-sections\"></a>\n",
    "\n",
    "### Table Schema\n",
    "- `id` (SERIAL PK)\n",
    "- `content` (TEXT)\n",
    "- `title` (TEXT)\n",
    "- `appendix` (BOOLEAN)\n",
    "- `paper_arxiv_id` (VARCHAR FK → papers.arxiv_id)\n",
    "- `section_in_paper_id` (INT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-sections-insert",
   "metadata": {},
   "source": [
    "### Insert Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insert-sections",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert sections for the Transformer paper\n",
    "sections = [\n",
    "    {\n",
    "        'content': 'The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder...',\n",
    "        'title': 'Introduction',\n",
    "        'appendix': False,\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'section_in_paper_id': 1\n",
    "    },\n",
    "    {\n",
    "        'content': 'Most competitive neural sequence transduction models have an encoder-decoder structure. Here, the encoder maps an input sequence of symbol representations...',\n",
    "        'title': 'Background',\n",
    "        'appendix': False,\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'section_in_paper_id': 2\n",
    "    },\n",
    "    {\n",
    "        'content': 'Most neural sequence transduction models have an encoder-decoder structure. The Transformer follows this overall architecture using stacked self-attention and point-wise, fully connected layers...',\n",
    "        'title': 'Model Architecture',\n",
    "        'appendix': False,\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'section_in_paper_id': 3\n",
    "    },\n",
    "    {\n",
    "        'content': 'In this section we describe the training regime for our models...',\n",
    "        'title': 'Training',\n",
    "        'appendix': False,\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'section_in_paper_id': 4\n",
    "    },\n",
    "    {\n",
    "        'content': 'On the WMT 2014 English-to-German translation task, the big transformer model outperforms the best previously reported models...',\n",
    "        'title': 'Results',\n",
    "        'appendix': False,\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'section_in_paper_id': 5\n",
    "    },\n",
    "    {\n",
    "        'content': 'In this work, we presented the Transformer, the first sequence transduction model based entirely on attention, replacing the recurrent layers...',\n",
    "        'title': 'Conclusion',\n",
    "        'appendix': False,\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'section_in_paper_id': 6\n",
    "    }\n",
    "]\n",
    "\n",
    "for section in sections:\n",
    "    research_arcade.insert_node(\"arxiv_sections\", node_features=section)\n",
    "    print(f\"Inserted section: {section['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-sections-get-all",
   "metadata": {},
   "source": [
    "### Get All Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "get-all-sections",
   "metadata": {},
   "outputs": [],
   "source": [
    "sections_df = research_arcade.get_all_node_features(\"arxiv_sections\")\n",
    "print(f\"Total sections: {len(sections_df)}\")\n",
    "print(\"\\nAll sections:\")\n",
    "print(sections_df[['title', 'section_in_paper_id', 'appendix']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-paragraphs-section",
   "metadata": {},
   "source": [
    "## 9. ArXiv Paragraphs <a name=\"arxiv-paragraphs\"></a>\n",
    "\n",
    "### Table Schema\n",
    "- `id` (SERIAL PK)\n",
    "- `paragraph_id` (INT)\n",
    "- `content` (TEXT)\n",
    "- `paper_arxiv_id` (VARCHAR FK → papers.arxiv_id)\n",
    "- `paper_section` (TEXT)\n",
    "- `section_id` (INT)\n",
    "- `paragraph_in_paper_id` (INT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-paragraphs-insert",
   "metadata": {},
   "source": [
    "### Insert Paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insert-paragraphs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert paragraphs from the Introduction section\n",
    "paragraphs = [\n",
    "    {\n",
    "        'paragraph_id': 1,\n",
    "        'content': 'Recurrent neural networks, long short-term memory and gated recurrent neural networks in particular, have been firmly established as state of the art approaches in sequence modeling and transduction problems such as language modeling and machine translation.',\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'paper_section': 'Introduction',\n",
    "        'section_id': 1,\n",
    "        'paragraph_in_paper_id': 1\n",
    "    },\n",
    "    {\n",
    "        'paragraph_id': 2,\n",
    "        'content': 'Numerous efforts have since continued to push the boundaries of recurrent language models and encoder-decoder architectures. Recurrent models typically factor computation along the symbol positions of the input and output sequences.',\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'paper_section': 'Introduction',\n",
    "        'section_id': 1,\n",
    "        'paragraph_in_paper_id': 2\n",
    "    },\n",
    "    {\n",
    "        'paragraph_id': 3,\n",
    "        'content': 'Aligning the positions to steps in computation time, they generate a sequence of hidden states h_t, as a function of the previous hidden state h_{t-1} and the input for position t. This inherently sequential nature precludes parallelization within training examples, which becomes critical at longer sequence lengths, as memory constraints limit batching across examples.',\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'paper_section': 'Introduction',\n",
    "        'section_id': 1,\n",
    "        'paragraph_in_paper_id': 3\n",
    "    },\n",
    "    {\n",
    "        'paragraph_id': 4,\n",
    "        'content': 'Attention mechanisms have become an integral part of compelling sequence modeling and transduction models in various tasks, allowing modeling of dependencies without regard to their distance in the input or output sequences.',\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'paper_section': 'Introduction',\n",
    "        'section_id': 1,\n",
    "        'paragraph_in_paper_id': 4\n",
    "    },\n",
    "    {\n",
    "        'paragraph_id': 5,\n",
    "        'content': 'In this work we propose the Transformer, a model architecture eschewing recurrence and instead relying entirely on an attention mechanism to draw global dependencies between input and output. The Transformer allows for significantly more parallelization and can reach a new state of the art in translation quality after being trained for as little as twelve hours on eight P100 GPUs.',\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'paper_section': 'Introduction',\n",
    "        'section_id': 1,\n",
    "        'paragraph_in_paper_id': 5\n",
    "    }\n",
    "]\n",
    "\n",
    "for paragraph in paragraphs:\n",
    "    research_arcade.insert_node(\"arxiv_paragraphs\", node_features=paragraph)\n",
    "    print(f\"Inserted paragraph {paragraph['paragraph_id']} from {paragraph['paper_section']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arxiv-paragraphs-get-all",
   "metadata": {},
   "source": [
    "### Get All Paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "get-all-paragraphs",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraphs_df = research_arcade.get_all_node_features(\"arxiv_paragraphs\")\n",
    "print(f\"Total paragraphs: {len(paragraphs_df)}\")\n",
    "print(\"\\nFirst 3 paragraphs:\")\n",
    "print(paragraphs_df[['paragraph_id', 'paper_section', 'content']].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relationships-section",
   "metadata": {},
   "source": [
    "## 10. Relationships/Edges <a name=\"relationships\"></a>\n",
    "\n",
    "This section demonstrates how to create relationships between different entities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paper-authors-edge",
   "metadata": {},
   "source": [
    "### Paper-Author Relationships (arxiv_paper_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insert-paper-authors",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create authorship relationships for the Transformer paper\n",
    "paper_authors = [\n",
    "    {\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'author_id': 'ss_ashish_vaswani',\n",
    "        'author_sequence': 1\n",
    "    },\n",
    "    {\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'author_id': 'ss_noam_shazeer',\n",
    "        'author_sequence': 2\n",
    "    },\n",
    "    {\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'author_id': 'ss_niki_parmar',\n",
    "        'author_sequence': 3\n",
    "    },\n",
    "    {\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'author_id': 'ss_jakob_uszkoreit',\n",
    "        'author_sequence': 4\n",
    "    },\n",
    "    {\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'author_id': 'ss_llion_jones',\n",
    "        'author_sequence': 5\n",
    "    }\n",
    "]\n",
    "\n",
    "for relation in paper_authors:\n",
    "    research_arcade.insert_edge(\"arxiv_paper_authors\", edge_features=relation)\n",
    "    print(f\"Linked author {relation['author_id']} to paper (position {relation['author_sequence']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paper-categories-edge",
   "metadata": {},
   "source": [
    "### Paper-Category Relationships (arxiv_paper_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insert-paper-categories",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link papers to categories\n",
    "paper_categories = [\n",
    "    {\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'category_id': 1  # cs.CL\n",
    "    },\n",
    "    {\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'category_id': 2  # cs.LG\n",
    "    },\n",
    "    {\n",
    "        'paper_arxiv_id': '1810.04805v2',\n",
    "        'category_id': 1  # cs.CL\n",
    "    },\n",
    "    {\n",
    "        'paper_arxiv_id': '1810.04805v2',\n",
    "        'category_id': 3  # cs.AI\n",
    "    }\n",
    "]\n",
    "\n",
    "for relation in paper_categories:\n",
    "    research_arcade.insert_edge(\"arxiv_paper_category\", edge_features=relation)\n",
    "    print(f\"Linked paper {relation['paper_arxiv_id']} to category {relation['category_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "citations-edge",
   "metadata": {},
   "source": [
    "### Citation Relationships (arxiv_citations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insert-citations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create citation relationships (BERT cites Transformer)\n",
    "citations = [\n",
    "    {\n",
    "        'citing_arxiv_id': '1810.04805v2',  # BERT\n",
    "        'cited_arxiv_id': '1706.03762v7',   # Transformer\n",
    "        'citing_sections': ['Introduction', 'Related Work', 'Model Architecture']\n",
    "    }\n",
    "]\n",
    "\n",
    "for citation in citations:\n",
    "    research_arcade.insert_edge(\"arxiv_citations\", edge_features=citation)\n",
    "    print(f\"Created citation: {citation['citing_arxiv_id']} → {citation['cited_arxiv_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paper-figures-edge",
   "metadata": {},
   "source": [
    "### Paper-Figure Relationships (arxiv_paper_figures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insert-paper-figures",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link figures to papers\n",
    "paper_figures = [\n",
    "    {\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'figure_id': 1\n",
    "    },\n",
    "    {\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'figure_id': 2\n",
    "    },\n",
    "    {\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'figure_id': 3\n",
    "    }\n",
    "]\n",
    "\n",
    "for relation in paper_figures:\n",
    "    research_arcade.insert_edge(\"arxiv_paper_figures\", edge_features=relation)\n",
    "    print(f\"Linked figure {relation['figure_id']} to paper {relation['paper_arxiv_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paper-tables-edge",
   "metadata": {},
   "source": [
    "### Paper-Table Relationships (arxiv_paper_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insert-paper-tables",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link tables to papers\n",
    "paper_tables = [\n",
    "    {\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'table_id': 1\n",
    "    },\n",
    "    {\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'table_id': 2\n",
    "    },\n",
    "    {\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'table_id': 3\n",
    "    }\n",
    "]\n",
    "\n",
    "for relation in paper_tables:\n",
    "    research_arcade.insert_edge(\"arxiv_paper_tables\", edge_features=relation)\n",
    "    print(f\"Linked table {relation['table_id']} to paper {relation['paper_arxiv_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paragraph-citations-edge",
   "metadata": {},
   "source": [
    "### Paragraph Citation Relationships (arxiv_paragraph_citations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insert-paragraph-citations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link specific paragraphs to cited papers\n",
    "paragraph_citations = [\n",
    "    {\n",
    "        'paragraph_id': 1,\n",
    "        'paper_section': 'Introduction',\n",
    "        'citing_arxiv_id': '1810.04805v2',\n",
    "        'cited_arxiv_id': '1706.03762v7',\n",
    "        'bib_key': 'vaswani2017attention'\n",
    "    },\n",
    "    {\n",
    "        'paragraph_id': 4,\n",
    "        'paper_section': 'Related Work',\n",
    "        'citing_arxiv_id': '1810.04805v2',\n",
    "        'cited_arxiv_id': '1706.03762v7',\n",
    "        'bib_key': 'vaswani2017attention'\n",
    "    }\n",
    "]\n",
    "\n",
    "for relation in paragraph_citations:\n",
    "    research_arcade.insert_edge(\"arxiv_paragraph_citations\", edge_features=relation)\n",
    "    print(f\"Paragraph {relation['paragraph_id']} cites {relation['cited_arxiv_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paragraph-references-edge",
   "metadata": {},
   "source": [
    "### Paragraph References (arxiv_paragraph_references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insert-paragraph-references",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link paragraphs to internal references (figures, tables, equations)\n",
    "paragraph_references = [\n",
    "    {\n",
    "        'paragraph_id': 10,\n",
    "        'paper_section': 'Model Architecture',\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'reference_label': 'fig:architecture',\n",
    "        'reference_type': 'figure'\n",
    "    },\n",
    "    {\n",
    "        'paragraph_id': 12,\n",
    "        'paper_section': 'Model Architecture',\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'reference_label': 'fig:attention',\n",
    "        'reference_type': 'figure'\n",
    "    },\n",
    "    {\n",
    "        'paragraph_id': 20,\n",
    "        'paper_section': 'Results',\n",
    "        'paper_arxiv_id': '1706.03762v7',\n",
    "        'reference_label': 'tab:wmt',\n",
    "        'reference_type': 'table'\n",
    "    }\n",
    "]\n",
    "\n",
    "for relation in paragraph_references:\n",
    "    research_arcade.insert_edge(\"arxiv_paragraph_references\", edge_features=relation)\n",
    "    print(f\"Paragraph {relation['paragraph_id']} references {relation['reference_type']}: {relation['reference_label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paragraph-tables-edge",
   "metadata": {},
   "source": [
    "### Paragraph-Table Relationships (arxiv_paragraph_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insert-paragraph-tables",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link paragraphs that discuss specific tables\n",
    "paragraph_tables = [\n",
    "    {\n",
    "        'paragraph_id': 18,\n",
    "        'table_id': 1\n",
    "    },\n",
    "    {\n",
    "        'paragraph_id': 20,\n",
    "        'table_id': 2\n",
    "    },\n",
    "    {\n",
    "        'paragraph_id': 25,\n",
    "        'table_id': 3\n",
    "    }\n",
    "]\n",
    "\n",
    "for relation in paragraph_tables:\n",
    "    research_arcade.insert_edge(\"paragraph_tables\", edge_features=relation)\n",
    "    print(f\"Linked paragraph {relation['paragraph_id']} to table {relation['table_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paragraph-figures-edge",
   "metadata": {},
   "source": [
    "### Paragraph-Figure Relationships (arxiv_paragraph_figures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insert-paragraph-figures",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link paragraphs that discuss specific figures\n",
    "paragraph_figures = [\n",
    "    {\n",
    "        'paragraph_id': 10,\n",
    "        'figure_id': 1\n",
    "    },\n",
    "    {\n",
    "        'paragraph_id': 12,\n",
    "        'figure_id': 2\n",
    "    },\n",
    "    {\n",
    "        'paragraph_id': 15,\n",
    "        'figure_id': 3\n",
    "    }\n",
    "]\n",
    "\n",
    "for relation in paragraph_figures:\n",
    "    research_arcade.insert_edge(\"paragraph_figures\", edge_features=relation)\n",
    "    print(f\"Linked paragraph {relation['paragraph_id']} to figure {relation['figure_id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-queries-section",
   "metadata": {},
   "source": [
    "## 11. Advanced Queries <a name=\"advanced-queries\"></a>\n",
    "\n",
    "Examples of more complex operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "batch-insert",
   "metadata": {},
   "source": [
    "### Batch Insert Multiple Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "batch-insert-papers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch insert multiple papers at once\n",
    "papers_batch = [\n",
    "    {\n",
    "        'arxiv_id': '1409.0473v7',\n",
    "        'base_arxiv_id': '1409.0473',\n",
    "        'version': 7,\n",
    "        'title': 'Neural Machine Translation by Jointly Learning to Align and Translate',\n",
    "        'abstract': 'Neural machine translation is a recently proposed approach to machine translation...',\n",
    "        'submit_date': '2014-09-01',\n",
    "        'metadata': {'venue': 'ICLR 2015'}\n",
    "    },\n",
    "    {\n",
    "        'arxiv_id': '1512.03385v1',\n",
    "        'base_arxiv_id': '1512.03385',\n",
    "        'version': 1,\n",
    "        'title': 'Deep Residual Learning for Image Recognition',\n",
    "        'abstract': 'Deeper neural networks are more difficult to train...',\n",
    "        'submit_date': '2015-12-10',\n",
    "        'metadata': {'venue': 'CVPR 2016'}\n",
    "    }\n",
    "]\n",
    "\n",
    "for paper in papers_batch:\n",
    "    research_arcade.insert_node(\"arxiv_papers\", node_features=paper)\n",
    "    \n",
    "print(f\"Batch inserted {len(papers_batch)} papers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "query-paper-authors",
   "metadata": {},
   "source": [
    "### Query Papers by a Specific Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "query-by-author",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all papers by a specific author\n",
    "author_id = \"ss_ashish_vaswani\"\n",
    "author_papers = research_arcade.query_edges(\n",
    "    \"arxiv_paper_authors\",\n",
    "    filters={\"author_id\": author_id}\n",
    ")\n",
    "\n",
    "print(f\"Papers by {author_id}:\")\n",
    "for _, paper in author_papers.iterrows():\n",
    "    paper_details = research_arcade.get_node_features_by_id(\n",
    "        \"arxiv_papers\",\n",
    "        {\"arxiv_id\": paper['paper_arxiv_id']}\n",
    "    )\n",
    "    print(f\"  - {paper_details['title'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "query-citations",
   "metadata": {},
   "source": [
    "### Find All Papers Citing a Specific Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "query-citations-to",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all papers that cite the Transformer paper\n",
    "cited_paper = \"1706.03762v7\"\n",
    "citations = research_arcade.query_edges(\n",
    "    \"arxiv_citations\",\n",
    "    filters={\"cited_arxiv_id\": cited_paper}\n",
    ")\n",
    "\n",
    "print(f\"Papers citing {cited_paper}:\")\n",
    "for _, citation in citations.iterrows():\n",
    "    citing_paper = research_arcade.get_node_features_by_id(\n",
    "        \"arxiv_papers\",\n",
    "        {\"arxiv_id\": citation['citing_arxiv_id']}\n",
    "    )\n",
    "    print(f\"  - {citing_paper['title'].iloc[0]}\")\n",
    "    print(f\"    Cited in sections: {citation['citing_sections']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "query-paper-content",
   "metadata": {},
   "source": [
    "### Get Complete Paper Structure (Sections + Paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "query-paper-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the complete structure of a paper\n",
    "paper_id = \"1706.03762v7\"\n",
    "\n",
    "# Get paper\n",
    "paper = research_arcade.get_node_features_by_id(\"arxiv_papers\", {\"arxiv_id\": paper_id})\n",
    "print(f\"Paper: {paper['title'].iloc[0]}\\n\")\n",
    "\n",
    "# Get sections\n",
    "sections = research_arcade.query_nodes(\n",
    "    \"arxiv_sections\",\n",
    "    filters={\"paper_arxiv_id\": paper_id}\n",
    ")\n",
    "sections = sections.sort_values('section_in_paper_id')\n",
    "\n",
    "print(\"Paper Structure:\")\n",
    "for _, section in sections.iterrows():\n",
    "    print(f\"\\n{section['section_in_paper_id']}. {section['title']}\")\n",
    "    \n",
    "    # Get paragraphs for this section\n",
    "    paragraphs = research_arcade.query_nodes(\n",
    "        \"arxiv_paragraphs\",\n",
    "        filters={\n",
    "            \"paper_arxiv_id\": paper_id,\n",
    "            \"section_id\": section['section_in_paper_id']\n",
    "        }\n",
    "    )\n",
    "    paragraphs = paragraphs.sort_values('paragraph_id')\n",
    "    \n",
    "    for _, para in paragraphs.iterrows():\n",
    "        print(f\"  Para {para['paragraph_id']}: {para['content'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "query-figures-tables",
   "metadata": {},
   "source": [
    "### Get All Figures and Tables for a Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "query-paper-figures-tables",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all figures and tables for a specific paper\n",
    "paper_id = \"1706.03762v7\"\n",
    "\n",
    "# Get figures\n",
    "figures = research_arcade.query_nodes(\n",
    "    \"arxiv_figures\",\n",
    "    filters={\"paper_arxiv_id\": paper_id}\n",
    ")\n",
    "\n",
    "print(\"Figures:\")\n",
    "for _, fig in figures.iterrows():\n",
    "    print(f\"  {fig['name']}: {fig['caption']}\")\n",
    "\n",
    "# Get tables\n",
    "tables = research_arcade.query_nodes(\n",
    "    \"arxiv_tables\",\n",
    "    filters={\"paper_arxiv_id\": paper_id}\n",
    ")\n",
    "\n",
    "print(\"\\nTables:\")\n",
    "for _, tab in tables.iterrows():\n",
    "    print(f\"  {tab['label']}: {tab['caption']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "query-category-papers",
   "metadata": {},
   "source": [
    "### Find All Papers in a Specific Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "query-by-category",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all papers in the cs.CL category\n",
    "category_id = 1  # cs.CL\n",
    "\n",
    "paper_categories = research_arcade.query_edges(\n",
    "    \"arxiv_paper_category\",\n",
    "    filters={\"category_id\": category_id}\n",
    ")\n",
    "\n",
    "print(\"Papers in cs.CL category:\")\n",
    "for _, pc in paper_categories.iterrows():\n",
    "    paper = research_arcade.get_node_features_by_id(\n",
    "        \"arxiv_papers\",\n",
    "        {\"arxiv_id\": pc['paper_arxiv_id']}\n",
    "    )\n",
    "    print(f\"  - {paper['title'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "query-collaboration",
   "metadata": {},
   "source": [
    "### Find Author Collaborations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "query-collaborations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all co-authors of a specific author\n",
    "author_id = \"ss_ashish_vaswani\"\n",
    "\n",
    "# Get papers by this author\n",
    "author_papers = research_arcade.query_edges(\n",
    "    \"arxiv_paper_authors\",\n",
    "    filters={\"author_id\": author_id}\n",
    ")\n",
    "\n",
    "# Get all co-authors\n",
    "coauthors = set()\n",
    "for _, paper_relation in author_papers.iterrows():\n",
    "    paper_id = paper_relation['paper_arxiv_id']\n",
    "    all_authors = research_arcade.query_edges(\n",
    "        \"arxiv_paper_authors\",\n",
    "        filters={\"paper_arxiv_id\": paper_id}\n",
    "    )\n",
    "    for _, author_relation in all_authors.iterrows():\n",
    "        if author_relation['author_id'] != author_id:\n",
    "            coauthors.add(author_relation['author_id'])\n",
    "\n",
    "print(f\"Co-authors of {author_id}:\")\n",
    "for coauthor_id in coauthors:\n",
    "    author = research_arcade.get_node_features_by_id(\n",
    "        \"arxiv_authors\",\n",
    "        {\"semantic_scholar_id\": coauthor_id}\n",
    "    )\n",
    "    print(f\"  - {author['name'].iloc[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistics",
   "metadata": {},
   "source": [
    "### Database Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "database-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get statistics about the database\n",
    "stats = {\n",
    "    'papers': len(research_arcade.get_all_node_features(\"arxiv_papers\")),\n",
    "    'authors': len(research_arcade.get_all_node_features(\"arxiv_authors\")),\n",
    "    'categories': len(research_arcade.get_all_node_features(\"arxiv_categories\")),\n",
    "    'figures': len(research_arcade.get_all_node_features(\"arxiv_figures\")),\n",
    "    'tables': len(research_arcade.get_all_node_features(\"arxiv_tables\")),\n",
    "    'sections': len(research_arcade.get_all_node_features(\"arxiv_sections\")),\n",
    "    'paragraphs': len(research_arcade.get_all_node_features(\"arxiv_paragraphs\")),\n",
    "}\n",
    "\n",
    "print(\"Database Statistics:\")\n",
    "print(\"=\" * 40)\n",
    "for entity, count in stats.items():\n",
    "    print(f\"{entity.capitalize():15s}: {count:5d}\")\n",
    "print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup-section",
   "metadata": {},
   "source": [
    "## Cleanup and Best Practices\n",
    "\n",
    "### Validation Before Insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "validation-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always validate data before insertion\n",
    "def validate_paper(paper_data):\n",
    "    required_fields = ['arxiv_id', 'base_arxiv_id', 'version', 'title', 'abstract']\n",
    "    for field in required_fields:\n",
    "        if field not in paper_data or not paper_data[field]:\n",
    "            raise ValueError(f\"Missing required field: {field}\")\n",
    "    return True\n",
    "\n",
    "# Example usage\n",
    "try:\n",
    "    new_paper = {\n",
    "        'arxiv_id': '2023.12345v1',\n",
    "        'base_arxiv_id': '2023.12345',\n",
    "        'version': 1,\n",
    "        'title': 'New Research Paper',\n",
    "        'abstract': 'This is an abstract...'\n",
    "    }\n",
    "    \n",
    "    if validate_paper(new_paper):\n",
    "        research_arcade.insert_node(\"arxiv_papers\", node_features=new_paper)\n",
    "        print(\"Paper inserted successfully!\")\nexcept ValueError as e:\n",
    "    print(f\"Validation error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This tutorial has covered:\n",
    "\n",
    "1. Setting up the ResearchArcade database connection\n",
    "2. Working with OpenReview data\n",
    "3. CRUD operations for all ArXiv entity types:\n",
    "   - Papers\n",
    "   - Authors\n",
    "   - Categories\n",
    "   - Figures\n",
    "   - Tables\n",
    "   - Sections\n",
    "   - Paragraphs\n",
    "4. Creating relationships between entities:\n",
    "   - Authorship\n",
    "   - Citations\n",
    "   - Paper-Category links\n",
    "   - Paper-Figure/Table links\n",
    "   - Paragraph-level references\n",
    "5. Advanced querying patterns\n",
    "6. Best practices for data validation\n",
    "\n",
    "For more information, refer to the ResearchArcade documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
