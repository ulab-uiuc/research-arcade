@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@article{baek2024researchagent,
  title={Researchagent: Iterative research idea generation over scientific literature with large language models},
  author={Baek, Jinheon and Jauhar, Sujay Kumar and Cucerzan, Silviu and Hwang, Sung Ju},
  journal={arXiv preprint arXiv:2404.07738},
  year={2024}
}

@article{chen2025learning,
  title={Learning to reason with search for llms via reinforcement learning},
  author={Chen, Mingyang and Li, Tianpeng and Sun, Haoze and Zhou, Yijie and Zhu, Chenzheng and Wang, Haofen and Pan, Jeff Z and Zhang, Wen and Chen, Huajun and Yang, Fan and others},
  journal={arXiv preprint arXiv:2503.19470},
  year={2025}
}

@article{jin2025search,
  title={Search-r1: Training llms to reason and leverage search engines with reinforcement learning},
  author={Jin, Bowen and Zeng, Hansi and Yue, Zhenrui and Yoon, Jinsung and Arik, Sercan and Wang, Dong and Zamani, Hamed and Han, Jiawei},
  journal={arXiv preprint arXiv:2503.09516},
  year={2025}
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2021}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}

@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
title = {A Fast Learning Algorithm for Deep Belief Nets},
year = {2006}
}

@inproceedings{
hu2024learning,
title={Learning Multi-Agent Communication from Graph Modeling Perspective},
author={Shengchao Hu and Li Shen and Ya Zhang and Dacheng Tao},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024}
}

@inproceedings{Chen2023LabelfreeNC,
  title={Label-free Node Classification on Graphs with Large Language Models (LLMs)},
  author={Chen, Zhikai and Mao, Haitao and Wen, Hongzhi and Han, Haoyu and Jin, Wei and Zhang, Haiyang and Liu, Hui and Tang, Jiliang},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}


@inproceedings{Zhao2022LearningOL,
  title={Learning on Large-scale Text-attributed Graphs via Variational Inference},
  author={Zhao, Jianan and Qu, Meng and Li, Chaozhuo and Yan, Hao and Liu, Qian and Li, Rui and Xie, Xing and Tang, Jian},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2023}
}

@article{xu2023language,
  title={Language agents with reinforcement learning for strategic play in the werewolf game},
  author={Xu, Zelai and Yu, Chao and Fang, Fei and Wang, Yu and Wu, Yi},
  journal={arXiv preprint arXiv:2310.18940},
  year={2023}
}

@article{hu2024nova,
  title={Nova: An Iterative Planning and Search Approach to Enhance Novelty and Diversity of LLM Generated Ideas},
  author={Hu, Xiang and Fu, Hongyu and Wang, Jinge and Wang, Yifeng and Li, Zhikun and Xu, Renjun and Lu, Yu and Jin, Yaochu and Pan, Lili and Lan, Zhenzhong},
  journal={arXiv preprint arXiv:2410.14255},
  year={2024}
}

@article{Yang2012DefiningAE,
  title={Defining and evaluating network communities based on ground-truth},
  author={Jaewon Yang and Jure Leskovec},
  journal={Knowledge and Information Systems},
  year={2012},
}

@article{West2016ARS,
  title={A Recommendation System Based on Hierarchical Clustering of an Article-Level Citation Network},
  author={Jevin D. West and Ian Wesley-Smith and Carl T. Bergstrom},
  journal={IEEE Transactions on Big Data},
  year={2016},
}

@book{egghe1990introduction,
  title={Introduction to informetrics. Quantitative methods in library, documentation and information science},
  author={Egghe, Leo and Rousseau, Ronald},
  year={1990},
  publisher={Elsevier Science Publishers}
}

@inproceedings{Tang2008ArnetMinerEA,
  title={ArnetMiner: extraction and mining of academic social networks},
  author={Jie Tang and Jing Zhang and Limin Yao and Juan-Zi Li and Li Zhang and Zhong Su},
  booktitle={Knowledge Discovery and Data Mining},
  year={2008},
}

@article{newman2001structure,
  title={The structure of scientific collaboration networks},
  author={Newman, Mark EJ},
  journal={Proceedings of the national academy of sciences},
  year={2001},
  publisher={National Acad Sciences}
}

@article{hua2023war,
  title={War and peace (waragent): Large language model-based multi-agent simulation of world wars},
  author={Hua, Wenyue and Fan, Lizhou and Li, Lingyao and Mei, Kai and Ji, Jianchao and Ge, Yingqiang and Hemphill, Libby and Zhang, Yongfeng},
  journal={arXiv preprint arXiv:2311.17227},
  year={2023}
}

@article{AI4Science2023TheIO,
  title={The impact of large language models on scientific discovery: a preliminary study using gpt-4},
  author={AI4Science, Microsoft Research and Quantum, Microsoft Azure},
  journal={arXiv preprint arXiv:2311.07361},
  year={2023}
}

@article{Gao2023S3SS,
  title={S$^{3}$: Social-network Simulation System with Large Language Model-Empowered Agents},
  author={Gao, Chen and Lan, Xiaochong and Lu, Zhihong and Mao, Jinzhu and Piao, Jinghua and Wang, Huandong and Jin, Depeng and Li, Yong},
  journal={arXiv preprint arXiv:2307.14984},
  year={2023}
}

@article{jumper2021highly,
  title={Highly accurate protein structure prediction with AlphaFold},
  author={Jumper, John and Evans, Richard and Pritzel, Alexander and Green, Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool, Kathryn and Bates, Russ and {\v{Z}}{\'\i}dek, Augustin and Potapenko, Anna and others},
  journal={nature},
  year={2021},
  publisher={Nature Publishing Group}
}

@article{huang2024empirical,
  title={An empirical study of llm-as-a-judge for llm evaluation: Fine-tuned judge models are task-specific classifiers},
  author={Huang, Hui and Qu, Yingqi and Liu, Jing and Yang, Muyun and Zhao, Tiejun},
  journal={arXiv preprint arXiv:2403.02839},
  year={2024}
}

@inproceedings{
lee2024reasoning,
title={Reasoning Abilities of Large Language Models through the Lens of Abstraction and Reasoning},
author={Seungpil Lee and Woochang Sim and Donghyeon Shin and Sejin Kim and Sundong Kim},
booktitle={The First Workshop on System-2 Reasoning at Scale, NeurIPS'24},
year={2024},
}

@article{wei2023larger,
  title={Larger language models do in-context learning differently},
  author={Wei, Jerry and Wei, Jason and Tay, Yi and Tran, Dustin and Webson, Albert and Lu, Yifeng and Chen, Xinyun and Liu, Hanxiao and Huang, Da and Zhou, Denny and others},
  journal={arXiv preprint arXiv:2303.03846},
  year={2023}
}

@inproceedings{
wang2024autosurvey,
title={AutoSurvey: Large Language Models Can Automatically Write Surveys},
author={Yidong Wang and Qi Guo and Wenjin Yao and Hongbo Zhang and Xin Zhang and Zhen Wu and Meishan Zhang and Xinyu Dai and Min zhang and Qingsong Wen and Wei Ye and Shikun Zhang and Yue Zhang},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
}

@inproceedings{huang2024mlagentbench,
  title={MLAgentBench: Evaluating Language Agents on Machine Learning Experimentation},
  author={Huang, Qian and Vora, Jian and Liang, Percy and Leskovec, Jure},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}

@article{girotra2023ideas,
  title={Ideas are dimes a dozen: Large language models for idea generation in innovation},
  author={Girotra, Karan and Meincke, Lennart and Terwiesch, Christian and Ulrich, Karl T},
  journal={Available at SSRN 4526071},
  year={2023}
}

@inproceedings{qian2023communicative,
    title = "{C}hat{D}ev: Communicative Agents for Software Development",
    author = "Qian, Chen  and
      Liu, Wei  and
      Liu, Hongzhang  and
      Chen, Nuo  and
      Dang, Yufan  and
      Li, Jiahao  and
      Yang, Cheng  and
      Chen, Weize  and
      Su, Yusheng  and
      Cong, Xin  and
      Xu, Juyuan  and
      Li, Dahai  and
      Liu, Zhiyuan  and
      Sun, Maosong",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2024.acl-long.810",
    abstract = "Software development is a complex task that necessitates cooperation among multiple members with diverse skills. Numerous studies used deep learning to improve specific phases in a waterfall model, such as design, coding, and testing. However, the deep learning model in each phase requires unique designs, leading to technical inconsistencies across various phases, which results in a fragmented and ineffective development process. In this paper, we introduce ChatDev, a chat-powered software development framework in which specialized agents driven by large language models (LLMs) are guided in what to communicate (via chat chain) and how to communicate (via communicative dehallucination). These agents actively contribute to the design, coding, and testing phases through unified language-based communication, with solutions derived from their multi-turn dialogues. We found their utilization of natural language is advantageous for system design, and communicating in programming language proves helpful in debugging. This paradigm demonstrates how linguistic communication facilitates multi-agent collaboration, establishing language as a unifying bridge for autonomous task-solving among LLM agents. The code and data are available at https://github.com/OpenBMB/ChatDev.",
}

@article{guyot2006agent,
  title={Agent-based participatory simulations: Merging multi-agent systems and role-playing games},
  author={Guyot, Paul and Honiden, Shinichi},
  journal={Journal of artificial societies and social simulation},
  year={2006}
}


@article{jablonka202314,
  title={14 examples of how LLMs can transform materials science and chemistry: a reflection on a large language model hackathon},
  author={Jablonka, Kevin Maik and Ai, Qianxiang and Al-Feghali, Alexander and Badhwar, Shruti and Bocarsly, Joshua D and Bran, Andres M and Bringuier, Stefan and Brinson, L Catherine and Choudhary, Kamal and Circi, Defne and others},
  journal={Digital Discovery},
  year={2023},
  publisher={Royal Society of Chemistry}
}

@article{blanco2023role,
  title={The role of AI in drug discovery: challenges, opportunities, and strategies},
  author={Blanco-Gonzalez, Alexandre and Cabezon, Alfonso and Seco-Gonzalez, Alejandro and Conde-Torres, Daniel and Antelo-Riveiro, Paula and Pineiro, Angel and Garcia-Fandino, Rebeca},
  journal={Pharmaceuticals},
  year={2023},
  publisher={MDPI}
}

@article{lin2023evolutionary,
  title={Evolutionary-scale prediction of atomic-level protein structure with a language model},
  author={Lin, Zeming and Akin, Halil and Rao, Roshan and Hie, Brian and Zhu, Zhongkai and Lu, Wenting and Smetanin, Nikita and Verkuil, Robert and Kabeli, Ori and Shmueli, Yaniv and others},
  journal={Science},
  year={2023},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{martinkus2022agent,
title={Agent-based Graph Neural Networks},
author={Karolis Martinkus and P{\'a}l Andr{\'a}s Papp and Benedikt Schesch and Roger Wattenhofer},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
}

@article{ai4science2023impact,
  title={The impact of large language models on scientific discovery: a preliminary study using gpt-4},
  author={AI4Science, Microsoft Research and Quantum, Microsoft Azure},
  journal={arXiv preprint arXiv:2311.07361},
  year={2023}
}

@inproceedings{
zhuge2024language,
title={{GPTS}warm: Language Agents as Optimizable Graphs},
author={Mingchen Zhuge and Wenyi Wang and Louis Kirsch and Francesco Faccio and Dmitrii Khizbullin and J{\"u}rgen Schmidhuber},
booktitle={Forty-first International Conference on Machine Learning},
year={2024},
}

@inproceedings{jin2024agentreview,
    title = "{A}gent{R}eview: Exploring Peer Review Dynamics with {LLM} Agents",
    author = "Jin, Yiqiao  and
      Zhao, Qinlin  and
      Wang, Yiyang  and
      Chen, Hao  and
      Zhu, Kaijie  and
      Xiao, Yijia  and
      Wang, Jindong",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2024.emnlp-main.70",
    abstract = "Peer review is fundamental to the integrity and advancement of scientific publication. Traditional methods of peer review analyses often rely on exploration and statistics of existing peer review data, which do not adequately address the multivariate nature of the process, account for the latent variables, and are further constrained by privacy concerns due to the sensitive nature of the data. We introduce AgentReview, the first large language model (LLM) based peer review simulation framework, which effectively disentangles the impacts of multiple latent factors and addresses the privacy issue. Our study reveals significant insights, including a notable 37.1{\%} variation in paper decisions due to reviewers{'} biases, supported by sociological theories such as the social influence theory, altruism fatigue, and authority bias. We believe that this study could offer valuable insights to improve the design of peer review mechanisms.",
}

@inproceedings{gong2023mindagent,
    title = "{M}ind{A}gent: Emergent Gaming Interaction",
    author = "Gong, Ran  and
      Huang, Qiuyuan  and
      Ma, Xiaojian  and
      Noda, Yusuke  and
      Durante, Zane  and
      Zheng, Zilong  and
      Terzopoulos, Demetri  and
      Fei-Fei, Li  and
      Gao, Jianfeng  and
      Vo, Hoi",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2024",
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2024.findings-naacl.200",
    abstract = "Large Foundation Models (LFMs) can perform complex scheduling in a multi-agent system and can coordinate agents to complete sophisticated tasks that require extensive collaboration.However, despite the introduction of numerous gaming frameworks, the community lacks adequate benchmarks that support the implementation of a general multi-agent infrastructure encompassing collaboration between LFMs and human-NPCs. We propose a novel infrastructure{---}Mindagent{---}for evaluating planning and coordination capabilities in the context of gaming interaction. In particular, our infrastructure leverages an existing gaming framework to (i) act as the coordinator for a multi-agent system, (ii) collaborate with human players via instructions, and (iii) enable in-context learning based on few-shot prompting with feedback.Furthermore, we introduce {``}Cuisineworld{''}, a new gaming scenario and its related benchmark that supervises multiple agents playing the game simultaneously and measures multi-agent collaboration efficiency. We have conducted comprehensive evaluations with a new auto-metric Collaboration Score: CoS for assessing the collaboration efficiency. Finally, Mindagent can be deployed in real-world gaming scenarios in a customized VR version of Cuisineworld and adapted in the {``}Minecraft{''} domain. Our work involving LFMs within our new infrastructure for general-purpose scheduling and coordination can elucidate how such skills may be obtained by learning from large language corpora.",
}

@inproceedings{
yan2023comprehensive,
title={A Comprehensive Study on Text-attributed Graphs: Benchmarking and Rethinking},
author={Hao Yan and Chaozhuo Li and Ruosong Long and Chao Yan and Jianan Zhao and Wenwen Zhuang and Jun Yin and Peiyan Zhang and Weihao Han and Hao Sun and Weiwei Deng and Qi Zhang and Lichao Sun and Xing Xie and Senzhang Wang},
booktitle={Thirty-seventh Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
year={2023},
}
%%%%%%%%%%%%%%%%%%%%%


@article{he2023explanations,
  title={Explanations as features: Llm-based features for text-attributed graphs},
  author={He, Xiaoxin and Bresson, Xavier and Laurent, Thomas and Hooi, Bryan and others},
  journal={arXiv preprint arXiv:2305.19523},
  year={2023}
}

@article{yang2021graphformers,
  title={Graphformers: Gnn-nested transformers for representation learning on textual graph},
  author={Yang, Junhan and Liu, Zheng and Xiao, Shitao and Li, Chaozhuo and Lian, Defu and Agrawal, Sanjay and Singh, Amit and Sun, Guangzhong and Xie, Xing},
  journal={Advances in Neural Information Processing Systems},
  year={2021}
}

@article{hu2020open,
  title={Open graph benchmark: Datasets for machine learning on graphs},
  author={Hu, Weihua and Fey, Matthias and Zitnik, Marinka and Dong, Yuxiao and Ren, Hongyu and Liu, Bowen and Catasta, Michele and Leskovec, Jure},
  journal={Advances in neural information processing systems},
  year={2020}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
year={2016},
publisher={MIT Press}
}

@misc{wu2024stark,
      title={STaRK: Benchmarking LLM Retrieval on Textual and Relational Knowledge Bases}, 
      author={Shirley Wu and Shiyu Zhao and Michihiro Yasunaga and Kexin Huang and Kaidi Cao and Qian Huang and Vassilis N. Ioannidis and Karthik Subbian and James Zou and Jure Leskovec},
      year={2024},
      eprint={2404.13207},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}

@inproceedings{
zhu2024dyval,
title={DyVal: Dynamic Evaluation of Large Language Models for Reasoning Tasks},
author={Kaijie Zhu and Jiaao Chen and Jindong Wang and Neil Zhenqiang Gong and Diyi Yang and Xing Xie},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
}

@misc{zhu2024dyval2,
      title={DyVal 2: Dynamic Evaluation of Large Language Models by Meta Probing Agents}, 
      author={Kaijie Zhu and Jindong Wang and Qinlin Zhao and Ruochen Xu and Xing Xie},
      year={2024},
      eprint={2402.14865},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@article{liu2023reviewergpt,
  title={Reviewergpt? an exploratory study on using large language models for paper reviewing},
  author={Liu, Ryan and Shah, Nihar B},
  journal={arXiv preprint arXiv:2306.00622},
  year={2023}
}

@article{thelwall2024can,
  title={Can ChatGPT evaluate research quality?},
  author={Thelwall, Mike},
  journal={arXiv preprint arXiv:2402.05519},
  year={2024}
}

@inproceedings{zhou-etal-2024-llm-reliable,
    title = "Is {LLM} a Reliable Reviewer? A Comprehensive Evaluation of {LLM} on Automatic Paper Reviewing Tasks",
    author = "Zhou, Ruiyang  and
      Chen, Lu  and
      Yu, Kai",
    editor = "Calzolari, Nicoletta  and
      Kan, Min-Yen  and
      Hoste, Veronique  and
      Lenci, Alessandro  and
      Sakti, Sakriani  and
      Xue, Nianwen",
    booktitle = "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
    year = "2024",
    address = "Torino, Italia",
    publisher = "ELRA and ICCL",
    abstract = "The use of large language models (LLM), especially ChatGPT, to help with research has come into practice. Researchers use it for timely advice and hope to obtain in-depth feedback. However, can LLM be a qualified and reliable reviewer? Although there already exist several review-related datasets, few works have carefully and thoroughly inspected model{'}s capability as a reviewer, especially the correctness of generated reviews. In this paper, we first evaluate GPT-3.5 and GPT-4 (the current top-performing LLM) on 2 types of tasks under different settings: the score prediction task and the review generation task. In addition, we propose a dataset containing 197 review-revision multiple-choice questions (RR-MCQ) with detailed labels from the review-rebuttal forum in ICLR-2023. By asking questions from technical details to the overall presentation and quality, our RR-MCQ data provides a more complete model ability assessment. The results show that LLM is generally helpful, but great caution is needed as it always makes mistakes. Although it can give passable decisions ({\textgreater} 60{\%} accuracy) on single options, completely correct answers are still rare (about 20{\%}); models are still weak on long paper processing, zero-shot scoring, and giving critical feedback like human reviewers.",
}


@article{gao2024empowering,
  title={Empowering biomedical discovery with ai agents},
  author={Gao, Shanghua and Fang, Ada and Huang, Yepeng and Giunchiglia, Valentina and Noori, Ayush and Schwarz, Jonathan Richard and Ektefaie, Yasha and Kondic, Jovana and Zitnik, Marinka},
  journal={arXiv preprint arXiv:2404.02831},
  year={2024}
}

@article{kuznetsov2024can,
  title={What Can Natural Language Processing Do for Peer Review?},
  author={Kuznetsov, Ilia and Afzal, Osama Mohammed and Dercksen, Koen and Dycke, Nils and Goldberg, Alexander and Hope, Tom and Hovy, Dirk and Kummerfeld, Jonathan K and Lauscher, Anne and Leyton-Brown, Kevin and others},
  journal={arXiv preprint arXiv:2405.06563},
  year={2024}
}


@misc{buriak2023can,
  title={Can ChatGPT and Other AI Bots Serve as Peer Reviewers?},
  author={Buriak, Jillian M and Hersam, Mark C and Kamat, Prashant V},
  journal={ACS Energy Letters},
  year={2023},
  publisher={ACS Publications}
}


@inproceedings{divekar2019embodied,
  title={Embodied Conversational AI Agents in a Multi-modal Multi-agent Competitive Dialogue.},
  author={Divekar, Rahul R and Mou, Xiangyang and Chen, Lisha and De Bayser, Maira Gatti and Guerra, Melina Alberio and Su, Hui},
  booktitle={IJCAI},
  year={2019}
}

@inproceedings{sun2024reviewflow,
  title={ReviewFlow: Intelligent Scaffolding to Support Academic Peer Reviewing},
  author={Sun, Lu and Chan, Aaron and Chang, Yun Seo and Dow, Steven P},
  booktitle={Proceedings of the 29th International Conference on Intelligent User Interfaces},
  year={2024}
}


@article{liang2023can,
  title={Can large language models provide useful feedback on research papers? A large-scale empirical analysis},
  author={Liang, Weixin and Zhang, Yuhui and Cao, Hancheng and Wang, Binglu and Ding, Daisy and Yang, Xinyu and Vodrahalli, Kailas and He, Siyu and Smith, Daniel and Yin, Yian and others},
  journal={arXiv preprint arXiv:2310.01783},
  year={2023}
}


@article{liang2024monitoring,
  title={Monitoring ai-modified content at scale: A case study on the impact of chatgpt on ai conference peer reviews},
  author={Liang, Weixin and Izzo, Zachary and Zhang, Yaohui and Lepp, Haley and Cao, Hancheng and Zhao, Xuandong and Chen, Lingjiao and Ye, Haotian and Liu, Sheng and Huang, Zhi and others},
  journal={arXiv preprint arXiv:2403.07183},
  year={2024}
}



@inproceedings{zhou2024llm,
  title={Is LLM a Reliable Reviewer? A Comprehensive Evaluation of LLM on Automatic Paper Reviewing Tasks},
  author={Zhou, Ruiyang and Chen, Lu and Yu, Kai},
  booktitle={Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)},
  year={2024}
}




@article{brameier2023artificial,
  title={Artificial Intelligence in Orthopaedic Surgery: Can a Large Language Model “Write” a Believable Orthopaedic Journal Article?},
  author={Brameier, Devon T and Alnasser, Ahmad A and Carnino, Jonathan M and Bhashyam, Abhiram R and von Keudell, Arvind G and Weaver, Michael J},
  journal={JBJS},
  year={2023},
  publisher={LWW}
}



@misc{kiela2021dynabench,
      title={Dynabench: Rethinking Benchmarking in NLP}, 
      author={Douwe Kiela and Max Bartolo and Yixin Nie and Divyansh Kaushik and Atticus Geiger and Zhengxuan Wu and Bertie Vidgen and Grusha Prasad and Amanpreet Singh and Pratik Ringshia and Zhiyi Ma and Tristan Thrush and Sebastian Riedel and Zeerak Waseem and Pontus Stenetorp and Robin Jia and Mohit Bansal and Christopher Potts and Adina Williams},
      year={2021},
      eprint={2104.14337},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{ma2021dynaboard,
      title={Dynaboard: An Evaluation-As-A-Service Platform for Holistic Next-Generation Benchmarking}, 
      author={Zhiyi Ma and Kawin Ethayarajh and Tristan Thrush and Somya Jain and Ledell Wu and Robin Jia and Christopher Potts and Adina Williams and Douwe Kiela},
      year={2021},
      eprint={2106.06052},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{HumanEval,
      title={Evaluating Large Language Models Trained on Code}, 
      author={Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde de Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William Hebgen Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie Tang and Igor Babuschkin and Suchir Balaji and Shantanu Jain and William Saunders and Christopher Hesse and Andrew N. Carr and Jan Leike and Josh Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba},
      year={2021},
      eprint={2107.03374},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{
MMLU,
title={Measuring Massive Multitask Language Understanding},
author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
booktitle={International Conference on Learning Representations},
year={2021},
}

@misc{GSM8K,
      title={Training Verifiers to Solve Math Word Problems}, 
      author={Karl Cobbe and Vineet Kosaraju and Mohammad Bavarian and Mark Chen and Heewoo Jun and Lukasz Kaiser and Matthias Plappert and Jerry Tworek and Jacob Hilton and Reiichiro Nakano and Christopher Hesse and John Schulman},
      year={2021},
      eprint={2110.14168},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{hellaswag,
    title = "{H}ella{S}wag: Can a Machine Really Finish Your Sentence?",
    author = "Zellers, Rowan  and
      Holtzman, Ari  and
      Bisk, Yonatan  and
      Farhadi, Ali  and
      Choi, Yejin",
    editor = "Korhonen, Anna  and
      Traum, David  and
      M{\`a}rquez, Llu{\'\i}s",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/P19-1472",
    abstract = "Recent work by Zellers et al. (2018) introduced a new task of commonsense natural language inference: given an event description such as {``}A woman sits at a piano,{''} a machine must select the most likely followup: {``}She sets her fingers on the keys.{''} With the introduction of BERT, near human-level performance was reached. Does this mean that machines can perform human level commonsense inference? In this paper, we show that commonsense inference still proves difficult for even state-of-the-art models, by presenting HellaSwag, a new challenge dataset. Though its questions are trivial for humans ({\textgreater}95{\%} accuracy), state-of-the-art models struggle ({\textless}48{\%}). We achieve this via Adversarial Filtering (AF), a data collection paradigm wherein a series of discriminators iteratively select an adversarial set of machine-generated wrong answers. AF proves to be surprisingly robust. The key insight is to scale up the length and complexity of the dataset examples towards a critical {`}Goldilocks{'} zone wherein generated text is ridiculous to humans, yet often misclassified by state-of-the-art models. Our construction of HellaSwag, and its resulting difficulty, sheds light on the inner workings of deep pretrained models. More broadly, it suggests a new path forward for NLP research, in which benchmarks co-evolve with the evolving state-of-the-art in an adversarial way, so as to present ever-harder challenges.",
}

@article{MATH,
  title={Measuring Mathematical Problem Solving With the MATH Dataset},
  author={Dan Hendrycks and Collin Burns and Saurav Kadavath and Akul Arora and Steven Basart and Eric Tang and Dawn Song and Jacob Steinhardt},
  journal={NeurIPS},
  year={2021}
}


@inproceedings{BBH,
    title = "Challenging {BIG}-Bench Tasks and Whether Chain-of-Thought Can Solve Them",
    author = {Suzgun, Mirac  and
      Scales, Nathan  and
      Sch{\"a}rli, Nathanael  and
      Gehrmann, Sebastian  and
      Tay, Yi  and
      Chung, Hyung Won  and
      Chowdhery, Aakanksha  and
      Le, Quoc  and
      Chi, Ed  and
      Zhou, Denny  and
      Wei, Jason},
    editor = "Rogers, Anna  and
      Boyd-Graber, Jordan  and
      Okazaki, Naoaki",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2023.findings-acl.824",
    abstract = "BIG-Bench (Srivastava et al., 2022) is a diverse evaluation suite that focuses on tasks believed to be beyond the capabilities of current language models. Language models have already made good progress on this benchmark, with the best model in the BIG-Bench paper outperforming average reported human-rater results on 65{\%} of the BIG-Bench tasks via few-shot prompting. But on what tasks do language models fall short of average human-rater performance, and are those tasks actually unsolvable by current language models? In this work, we focus on a suite of 23 challenging BIG-Bench tasks which we call BIG-Bench Hard (BBH). These are the tasks for which prior language model evaluations did not outperform the average human-rater. We find that applying chain-of-thought (CoT) prompting to BBH tasks enables PaLM to surpass the average human-rater performance on 10 of the 23 tasks, and Codex (code-davinci-002) to surpass the average human-rater performance on 17 of the 23 tasks. Since many tasks in BBH require multi-step reasoning, few-shot prompting without CoT, as done in the BIG-Bench evaluations (Srivastava et al., 2022), substantially underestimates the best performance and capabilities of language models, which is better captured via CoT prompting. As further analysis, we explore the interaction between CoT and model scale on BBH, finding that CoT enables emergent task performance on several BBH tasks with otherwise flat scaling curves.",
}

@misc{HHH,
      title={A General Language Assistant as a Laboratory for Alignment}, 
      author={Amanda Askell and Yuntao Bai and Anna Chen and Dawn Drain and Deep Ganguli and Tom Henighan and Andy Jones and Nicholas Joseph and Ben Mann and Nova DasSarma and Nelson Elhage and Zac Hatfield-Dodds and Danny Hernandez and Jackson Kernion and Kamal Ndousse and Catherine Olsson and Dario Amodei and Tom Brown and Jack Clark and Sam McCandlish and Chris Olah and Jared Kaplan},
      year={2021},
      eprint={2112.00861},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{TruthfulQA,
    title = "{T}ruthful{QA}: Measuring How Models Mimic Human Falsehoods",
    author = "Lin, Stephanie  and
      Hilton, Jacob  and
      Evans, Owain",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2022.acl-long.229",
    abstract = "We propose a benchmark to measure whether a language model is truthful in generating answers to questions. The benchmark comprises 817 questions that span 38 categories, including health, law, finance and politics. We crafted questions that some humans would answer falsely due to a false belief or misconception. To perform well, models must avoid generating false answers learned from imitating human texts. We tested GPT-3, GPT-Neo/J, GPT-2 and a T5-based model. The best model was truthful on 58{\%} of questions, while human performance was 94{\%}. Models generated many false answers that mimic popular misconceptions and have the potential to deceive humans. The largest models were generally the least truthful. This contrasts with other NLP tasks, where performance improves with model size. However, this result is expected if false answers are learned from the training distribution. We suggest that scaling up models alone is less promising for improving truthfulness than fine-tuning using training objectives other than imitation of text from the web.",
}

@inproceedings{TriviaQA,
    title = "{T}rivia{QA}: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension",
    author = "Joshi, Mandar  and
      Choi, Eunsol  and
      Weld, Daniel  and
      Zettlemoyer, Luke",
    editor = "Barzilay, Regina  and
      Kan, Min-Yen",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/P17-1147",
    abstract = "We present TriviaQA, a challenging reading comprehension dataset containing over 650K question-answer-evidence triples. TriviaQA includes 95K question-answer pairs authored by trivia enthusiasts and independently gathered evidence documents, six per question on average, that provide high quality distant supervision for answering the questions. We show that, in comparison to other recently introduced large-scale datasets, TriviaQA (1) has relatively complex, compositional questions, (2) has considerable syntactic and lexical variability between questions and corresponding answer-evidence sentences, and (3) requires more cross sentence reasoning to find answers. We also present two baseline algorithms: a feature-based classifier and a state-of-the-art neural network, that performs well on SQuAD reading comprehension. Neither approach comes close to human performance (23{\%} and 40{\%} vs. 80{\%}), suggesting that TriviaQA is a challenging testbed that is worth significant future study.",
}

@article{NQ,
    title = "Natural Questions: A Benchmark for Question Answering Research",
    author = "Kwiatkowski, Tom  and
      Palomaki, Jennimaria  and
      Redfield, Olivia  and
      Collins, Michael  and
      Parikh, Ankur  and
      Alberti, Chris  and
      Epstein, Danielle  and
      Polosukhin, Illia  and
      Devlin, Jacob  and
      Lee, Kenton  and
      Toutanova, Kristina  and
      Jones, Llion  and
      Kelcey, Matthew  and
      Chang, Ming-Wei  and
      Dai, Andrew M.  and
      Uszkoreit, Jakob  and
      Le, Quoc  and
      Petrov, Slav",
    editor = "Lee, Lillian  and
      Johnson, Mark  and
      Roark, Brian  and
      Nenkova, Ani",
    journal = "Transactions of the Association for Computational Linguistics",
    year = "2019",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    doi = "10.1162/tacl_a_00276",
    abstract = "We present the Natural Questions corpus, a question answering data set. Questions consist of real anonymized, aggregated queries issued to the Google search engine. An annotator is presented with a question along with a Wikipedia page from the top 5 search results, and annotates a long answer (typically a paragraph) and a short answer (one or more entities) if present on the page, or marks null if no long/short answer is present. The public release consists of 307,373 training examples with single annotations; 7,830 examples with 5-way annotations for development data; and a further 7,842 examples with 5-way annotated sequestered as test data. We present experiments validating quality of the data. We also describe analysis of 25-way annotations on 302 examples, giving insights into human variability on the annotation task. We introduce robust metrics for the purposes of evaluating question answering systems; demonstrate high human upper bounds on these metrics; and establish baseline results using competitive methods drawn from related literature.",
}

@misc{ARC,
      title={Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge}, 
      author={Peter Clark and Isaac Cowhey and Oren Etzioni and Tushar Khot and Ashish Sabharwal and Carissa Schoenick and Oyvind Tafjord},
      year={2018},
      eprint={1803.05457},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@inproceedings{talmor-etal-2019-commonsenseqa,
    title = "{C}ommonsense{QA}: A Question Answering Challenge Targeting Commonsense Knowledge",
    author = "Talmor, Alon  and
      Herzig, Jonathan  and
      Lourie, Nicholas  and
      Berant, Jonathan",
    editor = "Burstein, Jill  and
      Doran, Christy  and
      Solorio, Thamar",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/N19-1421",
    abstract = "When answering a question, people often draw upon their rich world knowledge in addition to the particular context. Recent work has focused primarily on answering questions given some relevant document or context, and required very little general background. To investigate question answering with prior knowledge, we present CommonsenseQA: a challenging new dataset for commonsense question answering. To capture common sense beyond associations, we extract from ConceptNet (Speer et al., 2017) multiple target concepts that have the same semantic relation to a single source concept. Crowd-workers are asked to author multiple-choice questions that mention the source concept and discriminate in turn between each of the target concepts. This encourages workers to create questions with complex semantics that often require prior knowledge. We create 12,247 questions through this procedure and demonstrate the difficulty of our task with a large number of strong baselines. Our best baseline is based on BERT-large (Devlin et al., 2018) and obtains 56{\%} accuracy, well below human performance, which is 89{\%}.",
}

@article{geva2021strategyqa,
  title = {{Did Aristotle Use a Laptop? A Question Answering Benchmark with Implicit Reasoning Strategies}},
  author = {Geva, Mor and Khashabi, Daniel and Segal, Elad and Khot, Tushar and Roth, Dan and Berant, Jonathan},
  journal = {Transactions of the Association for Computational Linguistics (TACL)},
  year = {2021},
}

@inproceedings{
liang2024mapping,
title={Mapping the Increasing Use of {LLM}s in Scientific Papers},
author={Weixin Liang and Yaohui Zhang and Zhengxuan Wu and Haley Lepp and Wenlong Ji and Xuandong Zhao and Hancheng Cao and Sheng Liu and Siyu He and Zhi Huang and Diyi Yang and Christopher Potts and Christopher D Manning and James Y. Zou},
booktitle={First Conference on Language Modeling},
year={2024},
}

@article{latona2024ai,
  title={The AI Review Lottery: Widespread AI-Assisted Peer Reviews Boost Paper Scores and Acceptance Rates},
  author={Latona, Giuseppe Russo and Ribeiro, Manoel Horta and Davidson, Tim R and Veselovsky, Veniamin and West, Robert},
  journal={arXiv preprint arXiv:2405.02150},
  year={2024}
}

@inproceedings{
geng2024chatgpt,
title={Is Chat{GPT} Transforming Academics' Writing Style?},
author={Mingmeng GENG and Roberto Trotta},
booktitle={ICML 2024 Next Generation of AI Safety Workshop},
year={2024},
}

@article{wu2024not,
  title={Not just disclosure of generative artificial intelligence like ChatGPT in scientific writing: peer-review process also needs},
  author={Wu, Haiyang and Li, Wanqing and Chen, Xiaofeng and Li, Cheng},
  journal={International Journal of Surgery},
  year={2024},
  publisher={LWW}
}

@article{mitra2024sociotechnical,
  title={Sociotechnical Implications of Generative Artificial Intelligence for Information Access},
  author={Mitra, Bhaskar and Cramer, Henriette and Gurevich, Olya},
  journal={arXiv preprint arXiv:2405.11612},
  year={2024}
}

@article{wu2024applications,
  title={Applications of generative AI in peer review process: friend or foe?},
  author={Wu, Haiyang and Sun, Zaijie and Guo, Qiang and Li, Cheng},
  journal={International Journal of Surgery},
  year={2024},
  publisher={LWW}
}



@article{choi2024accelerating,
  title={Accelerating materials language processing with large language models},
  author={Choi, Jaewoong and Lee, Byungju},
  journal={Communications Materials},
  year={2024},
  publisher={Nature Publishing Group UK London}
}

@inproceedings{tan2024large,
    title = "Large Language Models for Data Annotation and Synthesis: A Survey",
    author = "Tan, Zhen  and
      Li, Dawei  and
      Wang, Song  and
      Beigi, Alimohammad  and
      Jiang, Bohan  and
      Bhattacharjee, Amrita  and
      Karami, Mansooreh  and
      Li, Jundong  and
      Cheng, Lu  and
      Liu, Huan",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing",
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2024.emnlp-main.54",
    abstract = "Data annotation and synthesis generally refers to the labeling or generating of raw data with relevant information, which could be used for improving the efficacy of machine learning models. The process, however, is labor-intensive and costly. The emergence of advanced Large Language Models (LLMs), exemplified by GPT-4, presents an unprecedented opportunity to automate the complicated process of data annotation and synthesis. While existing surveys have extensively covered LLM architecture, training, and general applications, we uniquely focus on their specific utility for data annotation. This survey contributes to three core aspects: LLM-Based Annotation Generation, LLM-Generated Annotations Assessment, and LLM-Generated Annotations Utilization. Furthermore, this survey includes an in-depth taxonomy of data types that LLMs can annotate, a comprehensive review of learning strategies for models utilizing LLM-generated annotations, and a detailed discussion of the primary challenges and limitations associated with using LLMs for data annotation and synthesis. Serving as a key guide, this survey aims to assist researchers and practitioners in exploring the potential of the latest LLMs for data annotation, thereby fostering future advancements in this critical field.",
}

@inproceedings{
hong2023metagpt,
title={Meta{GPT}: Meta Programming for A Multi-Agent Collaborative Framework},
author={Sirui Hong and Mingchen Zhuge and Jonathan Chen and Xiawu Zheng and Yuheng Cheng and Jinlin Wang and Ceyao Zhang and Zili Wang and Steven Ka Shing Yau and Zijuan Lin and Liyang Zhou and Chenyu Ran and Lingfeng Xiao and Chenglin Wu and J{\"u}rgen Schmidhuber},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024}
}

@inproceedings{zhou2023sotopia,
  title={{SOTOPIA}: Interactive Evaluation for Social Intelligence in Language Agents},
  author={Zhou, Xuhui and Zhu, Hao and Mathur, Leena and Zhang, Ruohong and Yu, Haofei and Qi, Zhengyang and Morency, Louis-Philippe and Bisk, Yonatan and Fried, Daniel and Neubig, Graham and others},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}

@Article{su11102789,
AUTHOR = {Maer-Matei, Monica Mihaela and Mocanu, Cristina and Zamfir, Ana-Maria and Georgescu, Tiberiu Marian},
TITLE = {Skill Needs for Early Career Researchers—A Text Mining Approach},
JOURNAL = {Sustainability},
YEAR = {2019},
ISSN = {2071-1050},
ABSTRACT = {Research and development activities are one of the main drivers for progress, economic growth and wellbeing in many societies. This article proposes a text mining approach applied to a large amount of data extracted from job vacancies advertisements, aiming to shed light on the main skills and demands that characterize first stage research positions in Europe. Results show that data handling and processing skills are essential for early career researchers, irrespective of their research field. Also, as many analyzed first stage research positions are connected to universities, they include teaching activities to a great extent. Management of time, risks, projects, and resources plays an important part in the job requirements included in the analyzed advertisements. Such information is relevant not only for early career researchers who perform job selection taking into account the match of possessed skills with the required ones, but also for educational institutions that are responsible for skills development of the future R&D professionals.},
DOI = {10.3390/su11102789}
}

@article{acharya2023science,
  title={The science behind soft skills: do’s and don’ts for early career researchers and beyond. A review paper from the EU-CardioRNA COST Action CA17129},
  author={Acharya, Shubhra and Preda, Mihai Bogdan and Papatheodorou, Ioanna and Palioura, Dimitra and Giardoglou, Panagiota and Tsata, Vasiliki and Erceg, Sanja and Barbalata, Teodora and Ben-Aicha, Soumaya and Martino, Fabiana and others},
  journal={Open Research Europe},
  year={2023},
  publisher={European Commission, Directorate General for Research and Innovation}
}

@inproceedings{
tao2024magis,
title={{MAGIS}: {LLM}-Based Multi-Agent Framework for GitHub Issue Resolution},
author={Wei Tao and Yucheng Zhou and Yanlin Wang and Wenqiang Zhang and Hongyu Zhang and Yu Cheng},
booktitle={The Thirty-eighth Annual Conference on Neural Information Processing Systems},
year={2024},
}

@misc{lee2024unified,
      title={A Unified Debugging Approach via LLM-Based Multi-Agent Synergy}, 
      author={Cheryl Lee and Chunqiu Steven Xia and Jen-tse Huang and Zhouruixin Zhu and Lingming Zhang and Michael R. Lyu},
      year={2024},
      eprint={2404.17153},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@misc{bouzenia2024repairagent,
      title={RepairAgent: An Autonomous, LLM-Based Agent for Program Repair}, 
      author={Islem Bouzenia and Premkumar Devanbu and Michael Pradel},
      year={2024},
      eprint={2403.17134},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@inproceedings{park2023generative,
  title={Generative agents: Interactive simulacra of human behavior},
  author={Park, Joon Sung and O'Brien, Joseph and Cai, Carrie Jun and Morris, Meredith Ringel and Liang, Percy and Bernstein, Michael S},
  booktitle={Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
  year={2023}
}

@article{guo2024embodied,
  title={Embodied LLM Agents Learn to Cooperate in Organized Teams},
  author={Guo, Xudong and Huang, Kaixuan and Liu, Jiale and Fan, Wenhui and V{\'e}lez, Natalia and Wu, Qingyun and Wang, Huazheng and Griffiths, Thomas L and Wang, Mengdi},
  journal={arXiv preprint arXiv:2403.12482},
  year={2024}
}

@article{li2023metaagents,
  title={MetaAgents: Simulating interactions of human behaviors for llm-based task-oriented coordination via collaborative generative agents},
  author={Li, Yuan and Zhang, Yixuan and Sun, Lichao},
  journal={arXiv preprint arXiv:2310.06500},
  year={2023}
}

@misc{park2024enhancing,
      title={Enhancing Anomaly Detection in Financial Markets with an LLM-based Multi-Agent Framework}, 
      author={Taejin Park},
      year={2024},
      eprint={2403.19735},
      archivePrefix={arXiv},
      primaryClass={q-fin.RM}
}

@inproceedings{
zhang2024building,
title={Building Cooperative Embodied Agents Modularly with Large Language Models},
author={Hongxin Zhang and Weihua Du and Jiaming Shan and Qinhong Zhou and Yilun Du and Joshua B. Tenenbaum and Tianmin Shu and Chuang Gan},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
}

@misc{zhang2024combo,
      title={COMBO: Compositional World Models for Embodied Multi-Agent Cooperation}, 
      author={Hongxin Zhang and Zeyuan Wang and Qiushi Lyu and Zheyuan Zhang and Sunli Chen and Tianmin Shu and Yilun Du and Chuang Gan},
      year={2024},
      eprint={2404.10775},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{zheng2023judging,
author = {Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric P. and Zhang, Hao and Gonzalez, Joseph E. and Stoica, Ion},
title = {Judging LLM-as-a-judge with MT-bench and Chatbot Arena},
year = {2024},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Evaluating large language model (LLM) based chat assistants is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore using strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and limitations of LLM-as-a-judge, including position, verbosity, and self-enhancement biases, as well as limited reasoning ability, and propose solutions to mitigate some of them. We then verify the agreement between LLM judges and human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80\% agreement, the same level of agreement between humans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain. Additionally, we show our benchmark and traditional benchmarks complement each other by evaluating several variants of LLaMA and Vicuna. The MT-bench questions, 3K expert votes, and 30K conversations with human preferences are publicly available at https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge.},
booktitle = {Proceedings of the 37th International Conference on Neural Information Processing Systems},
articleno = {2020},
numpages = {29},
location = {New Orleans, LA, USA},
series = {NIPS '23}
}

@inproceedings{fu2023gptscore,
    title = "{GPTS}core: Evaluate as You Desire",
    author = "Fu, Jinlan  and
      Ng, See-Kiong  and
      Jiang, Zhengbao  and
      Liu, Pengfei",
    editor = "Duh, Kevin  and
      Gomez, Helena  and
      Bethard, Steven",
    booktitle = "Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)",
    year = "2024",
    address = "Mexico City, Mexico",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2024.naacl-long.365",
    abstract = "Generative Artificial Intelligence (AI) has enabled the development of sophisticated models that are capable of producing high-caliber text, images, and other outputs through the utilization of large pre-trained models.Nevertheless, assessing the quality of the generation is an even more arduous task than the generation itself, and this issue has not been given adequate consideration recently.This paper proposes a novel evaluation framework, GPTScore, which utilizes the emergent abilities (e.g., in-context learning, zero-shot instruction) of generative pre-trained models to score generated texts. There are 19 pre-trained models explored in this paper, ranging in size from 80M (e.g., Flan-T5-small) to 175B (e.g., GPT3).Experimental results on four text generation tasks, 22 evaluation aspects, and corresponding 37 datasets demonstrate that this approach can effectively allow us to achieve what one desires to evaluate for texts simply by natural language instructions.This nature helps us overcome several long-standing challenges in text evaluation{--}how to achieve customized, multi-faceted evaluation without model training. We make our code publicly available.",
}

@article{m2022exploring,
  title={Exploring the role of artificial intelligence in enhancing academic performance: A case study of ChatGPT},
  author={M Alshater, Muneer},
  journal={Available at SSRN 4312358},
  year={2022}
}

@article{sternberg2001relationship,
  title={The relationship between academic and practical intelligence: A case study in Kenya},
  author={Sternberg, Robert J and Nokes, Catherine and Geissler, P Wenzel and Prince, Ruth and Okatcha, Frederick and Bundy, Donald A and Grigorenko, Elena L},
  journal={Intelligence},
  year={2001},
  publisher={Elsevier}
}
@inproceedings{currie2023academic,
  title={Academic integrity and artificial intelligence: is ChatGPT hype, hero or heresy?},
  author={Currie, Geoffrey M},
  booktitle={Seminars in Nuclear Medicine},
  year={2023},
  organization={Elsevier}
}

@book{fink2019conducting,
  title={Conducting research literature reviews: From the internet to paper},
  author={Fink, Arlene},
  year={2019},
  publisher={Sage publications}
}

@article{pickering2014benefits,
  title={The benefits of publishing systematic quantitative literature reviews for PhD candidates and other early-career researchers},
  author={Pickering, Catherine and Byrne, Jason},
  journal={Higher Education Research \& Development},
  year={2014},
  publisher={Taylor \& Francis}
}

@article{rahman2023chatgpt,
  title={ChatGPT and academic research: A review and recommendations based on practical examples},
  author={Rahman, Md Mizanur and Terano, Harold Jan and Rahman, Md Nafizur and Salamzadeh, Aidin and Rahaman, Md Saidur},
  journal={Rahman, M., Terano, HJR, Rahman, N., Salamzadeh, A., Rahaman, S.(2023). ChatGPT and Academic Research: A Review and Recommendations Based on Practical Examples. Journal of Education, Management and Development Studies},
  year={2023}
}


@article{zhai2021review,
  title={A Review of Artificial Intelligence (AI) in Education from 2010 to 2020},
  author={Zhai, Xuesong and Chu, Xiaoyan and Chai, Ching Sing and Jong, Morris Siu Yung and Istenic, Andreja and Spector, Michael and Liu, Jia-Bao and Yuan, Jing and Li, Yan},
  journal={Complexity},
  year={2021},
  publisher={Hindawi Limited}
}

@book{woolf1991ai,
  title={AI in Education},
  author={Woolf, Beverly},
  year={1991},
  publisher={University of Massachusetts at Amherst, Department of Computer and~…}
}

@article{zhang2021ai,
  title={AI technologies for education: Recent research \& future directions},
  author={Zhang, Ke and Aslan, Ayse Begum},
  journal={Computers and Education: Artificial Intelligence},
  year={2021},
  publisher={Elsevier}
}

@misc{ollama8b,
  author = {Meta AI},
  title = {LLaMA 3: 8B},
  howpublished = {\url{https://ollama.com/library/llama3:8b}},
  year = {2023}
}

@misc{ollama70b,
  author = {Meta AI},
  title = {LLaMA 3: 70B},
  howpublished = {\url{https://ollama.com/library/llama3:70b}},
  year = {2023}
}

@article{spearman1961proof,
  title={The proof and measurement of association between two things.},
  author={Spearman, Charles},
  year={1961},
  publisher={Appleton-Century-Crofts}
}


@misc{mistralMixtral,
  author = {Mistral AI},
  title = {Mixtral of Experts},
  howpublished = {\url{https://mistral.ai/news/mixtral-of-experts/}},
  year = {2023}
}

@misc{ollamaQwen,
  author = {Meta AI},
  title = {Qwen: 32B},
  howpublished = {\url{https://ollama.com/library/qwen:32b}},
  year = {2023}
}

@misc{openaiGPT4o,
  author = {OpenAI},
  title = {GPT-4O and More Tools to ChatGPT Free},
  howpublished = {\url{https://openai.com/index/gpt-4o-and-more-tools-to-chatgpt-free/}},
  year = {2024}
}

@inproceedings{balloni2015challenges,
  title={Challenges and reflections on information, knowledge, and wisdom societies and sociotechnical systems},
  author={Balloni, Antonio Jos{\'e} and Targowski, Andrew S},
  booktitle={Enterprise Systems. Strategic, Organizational, and Technological Dimensions: International Workshops, Pre-ICIS 2010, St. Louis, MO, USA, December 12, 2010, Pre-ICIS 2011, Shanghai, China, December 4, 2011, and Pre-ICIS 2012, Orlando, FL, USA, December 16, 2012, Revised Selected Papers},
  year={2015},
  organization={Springer}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}


@inproceedings{wu2024shall,
    title = "Shall We Team Up: Exploring Spontaneous Cooperation of Competing {LLM} Agents",
    author = "Wu, Zengqing  and
      Peng, Run  and
      Zheng, Shuyuan  and
      Liu, Qianying  and
      Han, Xu  and
      Kwon, Brian I.  and
      Onizuka, Makoto  and
      Tang, Shaojie  and
      Xiao, Chuan",
    editor = "Al-Onaizan, Yaser  and
      Bansal, Mohit  and
      Chen, Yun-Nung",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2024",
    year = "2024",
    address = "Miami, Florida, USA",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2024.findings-emnlp.297",
    abstract = "Large Language Models (LLMs) have increasingly been utilized in social simulations, where they are often guided by carefully crafted instructions to stably exhibit human-like behaviors during simulations. Nevertheless, we doubt the necessity of shaping agents{'} behaviors for accurate social simulations. Instead, this paper emphasizes the importance of spontaneous phenomena, wherein agents deeply engage in contexts and make adaptive decisions without explicit directions. We explored spontaneous cooperation across three competitive scenarios and successfully simulated the gradual emergence of cooperation, findings that align closely with human behavioral data. This approach not only aids the computational social science community in bridging the gap between simulations and real-world dynamics but also offers the AI community a novel method to assess LLMs{'} capability of deliberate reasoning.Our source code is available at https://github.com/wuzengqing001225/SABM{\_}ShallWeTeamUp",
}

@inproceedings{
abdelnabi2023llm,
title={{LLM}-Deliberation: Evaluating {LLM}s with Interactive Multi-Agent Negotiation Game},
author={Sahar Abdelnabi and Amr Gomaa and Sarath Sivaprasad and Lea Sch{\"o}nherr and Mario Fritz},
booktitle={ICLR 2024 Workshop on Large Language Model (LLM) Agents},
year={2024},
}


@article{wu2021too,
  title={Too many cooks: Bayesian inference for coordinating multi-agent collaboration},
  author={Wu, Sarah A and Wang, Rose E and Evans, James A and Tenenbaum, Joshua B and Parkes, David C and Kleiman-Weiner, Max},
  journal={Topics in Cognitive Science},
  year={2021},
  publisher={Wiley Online Library}
}


@article{wang2023scientific,
  title={Scientific discovery in the age of artificial intelligence},
  author={Wang, Hanchen and Fu, Tianfan and Du, Yuanqi and Gao, Wenhao and Huang, Kexin and Liu, Ziming and Chandak, Payal and Liu, Shengchao and Van Katwyk, Peter and Deac, Andreea and others},
  journal={Nature},
  year={2023},
  publisher={Nature Publishing Group UK London}
}



@inproceedings{he2024if,
  title={If in a Crowdsourced Data Annotation Pipeline, a GPT-4},
  author={He, Zeyu and Huang, Chieh-Yang and Ding, Chien-Kuang Cornelia and Rohatgi, Shaurya and Huang, Ting-Hao Kenneth},
  booktitle={Proceedings of the CHI Conference on Human Factors in Computing Systems},
  year={2024}
}


@misc{synthediaMistral,
  author = {Synthedia},
  title = {Mistral Has a New 176B Parameter},
  howpublished = {\url{https://synthedia.substack.com/p/mistral-has-a-new-176b-parameter}},
  year = {2024}
}

@article{kendall1938new,
  title={A new measure of rank correlation},
  author={Kendall, Maurice G},
  journal={Biometrika},
  year={1938},
  publisher={JSTOR}
}


@article{ji2023survey,
  title={Survey of hallucination in natural language generation},
  author={Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
  journal={ACM Computing Surveys},
  year={2023},
  publisher={ACM New York, NY}
}

@article{
zhong2024chatgpt, 
title={Can LLM Replace Stack Overflow? A Study on Robustness and Reliability of Large Language Model Code Generation}, 
DOI={10.1609/aaai.v38i19.30185}, 
abstractNote={Recently, large language models (LLMs) have shown an extraordinary ability to understand natural language and generate programming code. It has been a common practice for software engineers to consult LLMs when encountering coding questions. Although efforts have been made to avoid syntax errors and align the code with the intended semantics, the reliability, and robustness of the code generation from LLMs have not yet been thoroughly studied. The executable code is not equivalent to reliable and robust code, especially in the context of real-world software development. For example, the misuse of APIs in the generated code could lead to severe problems, such as resource leaks, program crashes, etc. Existing code evaluation benchmarks and datasets focus on crafting small tasks such as programming questions in coding interviews, which, however, deviates from the problem that developers would ask LLM for real-world coding help. To fill the missing piece, in this work, we propose a dataset RobustAPI for evaluating the reliability and robustness of code generated by LLMs. We collect 1208 coding questions from Stack Overflow on 18 representative Java APIs. We summarize the common misuse patterns of these APIs and evaluate them on current popular LLMs. The evaluation results show that even for GPT-4, 62% of the generated code contains API misuses, which would cause unexpected consequences if the code is introduced into real-world software.}, 
journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
author={Zhong, Li and Wang, Zilong}, 
year={2024} 
}

@inproceedings{abdelnabi2022open,
  title={Open-domain, content-based, multi-modal fact-checking of out-of-context images via online resources},
  author={Abdelnabi, Sahar and Hasan, Rakibul and Fritz, Mario},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  year={2022}
}

@article{d2024marg,
  title={Marg: Multi-agent review generation for scientific papers},
  author={D'Arcy, Mike and Hope, Tom and Birnbaum, Larry and Downey, Doug},
  journal={arXiv preprint arXiv:2401.04259},
  year={2024}
}


@article{lu2024ai,
  title={The ai scientist: Towards fully automated open-ended scientific discovery},
  author={Lu, Chris and Lu, Cong and Lange, Robert Tjarko and Foerster, Jakob and Clune, Jeff and Ha, David},
  journal={arXiv preprint arXiv:2408.06292},
  year={2024}
}

@article{si2024can,
  title={Can LLMs generate novel research ideas? a large-scale human study with 100+ nlp researchers},
  author={Si, Chenglei and Yang, Diyi and Hashimoto, Tatsunori},
  journal={arXiv preprint arXiv:2409.04109},
  year={2024}
}

@article{hosseini2022ethical,
  title={An ethical exploration of increased average number of authors per publication},
  author={Hosseini, Mohammad and Lewis, Jonathan and Zwart, Hub and Gordijn, Bert},
  journal={Science and engineering ethics},
  year={2022},
  publisher={Springer}
}

@inproceedings{lhoest2021datasets,
    title = "Datasets: A Community Library for Natural Language Processing",
    author = "Lhoest, Quentin  and
      Villanova del Moral, Albert  and
      Jernite, Yacine  and
      Thakur, Abhishek  and
      von Platen, Patrick  and
      Patil, Suraj  and
      Chaumond, Julien  and
      Drame, Mariama  and
      Plu, Julien  and
      Tunstall, Lewis  and
      Davison, Joe  and
      {\v{S}}a{\v{s}}ko, Mario  and
      Chhablani, Gunjan  and
      Malik, Bhavitvya  and
      Brandeis, Simon  and
      Le Scao, Teven  and
      Sanh, Victor  and
      Xu, Canwen  and
      Patry, Nicolas  and
      McMillan-Major, Angelina  and
      Schmid, Philipp  and
      Gugger, Sylvain  and
      Delangue, Cl{\'e}ment  and
      Matussi{\`e}re, Th{\'e}o  and
      Debut, Lysandre  and
      Bekman, Stas  and
      Cistac, Pierric  and
      Goehringer, Thibault  and
      Mustar, Victor  and
      Lagunas, Fran{\c{c}}ois  and
      Rush, Alexander  and
      Wolf, Thomas",
    editor = "Adel, Heike  and
      Shi, Shuming",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    doi = "10.18653/v1/2021.emnlp-demo.21",
    abstract = "The scale, variety, and quantity of publicly-available NLP datasets has grown rapidly as researchers propose new tasks, larger models, and novel benchmarks. Datasets is a community library for contemporary NLP designed to support this ecosystem. Datasets aims to standardize end-user interfaces, versioning, and documentation, while providing a lightweight front-end that behaves similarly for small datasets as for internet-scale corpora. The design of the library incorporates a distributed, community-driven approach to adding datasets and documenting usage. After a year of development, the library now includes more than 650 unique datasets, has more than 250 contributors, and has helped support a variety of novel cross-dataset research projects and shared tasks. The library is available at \url{https://github.com/huggingface/datasets}.",
}

@article{kuperman2024causes,
  title={On the causes and ramifications of multi-authorship in science},
  author={Kuperman, Vadim Y and Sokol, Gerald H},
  journal={Scientometrics},
  year={2024},
  publisher={Springer}
}

@article{kumari2023collaborative,
  title={Collaborative authorship patterns in computer science publications},
  author={Kumari, Priti and Kumar, Rajeev},
  journal={Annals of Library and Information Studies},
  year={2023}
}

@inproceedings{Huang2023MLAgentBenchEL,
  title={MLAgentBench: Evaluating Language Agents on Machine Learning Experimentation},
  author={Qian Huang and Jian Vora and Percy Liang and Jure Leskovec},
  year={2023},
}


@article{leskovec2007graph,
	title = {Graph evolution: {Densification} and shrinking diameters},
	issn = {1556-4681},
	shorttitle = {Graph evolution},
	doi = {10.1145/1217299.1217301},
	abstract = {How do real graphs evolve over time? What are normal growth patterns in social, technological, and information networks? Many studies have discovered patterns in static graphs, identifying properties in a single snapshot of a large network or in a very small number of snapshots; these include heavy tails for in- and out-degree distributions, communities, small-world phenomena, and others. However, given the lack of information about network evolution over long periods, it has been hard to convert these findings into statements about trends over time.Here we study a wide range of real graphs, and we observe some surprising phenomena. First, most of these graphs densify over time with the number of edges growing superlinearly in the number of nodes. Second, the average distance between nodes often shrinks over time in contrast to the conventional wisdom that such distance parameters should increase slowly as a function of the number of nodes (like O(log n) or O(log(log n)).Existing graph generation models do not exhibit these types of behavior even at a qualitative level. We provide a new graph generator, based on a forest fire spreading process that has a simple, intuitive justification, requires very few parameters (like the flammability of nodes), and produces graphs exhibiting the full range of properties observed both in prior work and in the present study.We also notice that the forest fire model exhibits a sharp transition between sparse graphs and graphs that are densifying. Graphs with decreasing distance between the nodes are generated around this transition point.Last, we analyze the connection between the temporal evolution of the degree distribution and densification of a graph. We find that the two are fundamentally related. We also observe that real networks exhibit this type of relation between densification and the degree distribution.},
	urldate = {2024-10-02},
	journal = {ACM Trans. Knowl. Discov. Data},
	author = {Leskovec, Jure and Kleinberg, Jon and Faloutsos, Christos},
	year = {2007},
}


@article{kleinberg1999authoritative,
	title = {Authoritative sources in a hyperlinked environment},
	issn = {0004-5411},
	doi = {10.1145/324133.324140},
	abstract = {The network structure of a hyperlinked environment can be a rich source of information about the content of the environment, provided we have effective means for understanding it. We develop a set of algorithmic tools for extracting information from the link structures of such environments, and report on experiments that demonstrate their effectiveness in a variety of context on the World Wide Web. The central issue we address within our framework is the distillation of broad search topics, through the discovery of “authorative” information sources on such topics. We propose and test an algorithmic formulation of the notion of authority, based on the relationship between a set of relevant authoritative pages and the set of “hub pages” that join them together in  the link structure. Our formulation has connections to the eigenvectors of certain matrices associated with the link graph; these connections in turn motivate additional heuristrics for link-based analysis.},
	urldate = {2024-10-02},
	journal = {J. ACM},
	author = {Kleinberg, Jon M.},
	year = {1999},
}

@article{domingo2023stochastic,
  title={Stochastic optimal control matching},
  author={Domingo-Enrich, Carles and Han, Jiequn and Amos, Brandon and Bruna, Joan and Chen, Ricky TQ},
  journal={arXiv preprint arXiv:2312.02027},
  year={2023}
}

@article{holm2020longitudinal,
  title={Longitudinal citation prediction using temporal graph neural networks},
  author={Holm, Andreas Nugaard and Plank, Barbara and Wright, Dustin and Augenstein, Isabelle},
  journal={arXiv preprint arXiv:2012.05742},
  year={2020}
}

@article{cao2024worst,
  title={On the Worst Prompt Performance of Large Language Models},
  author={Cao, Bowen and Cai, Deng and Zhang, Zhisong and Zou, Yuexian and Lam, Wai},
  journal={arXiv preprint arXiv:2406.10248},
  year={2024}
}

@article{yu20244real,
  title={4Real: Towards Photorealistic 4D Scene Generation via Video Diffusion Models},
  author={Yu, Heng and Wang, Chaoyang and Zhuang, Peiye and Menapace, Willi and Siarohin, Aliaksandr and Cao, Junli and Jeni, Laszlo A and Tulyakov, Sergey and Lee, Hsin-Ying},
  journal={arXiv preprint arXiv:2406.07472},
  year={2024}
}

@inproceedings{tasseskill,
  title={Skill Machines: Temporal Logic Skill Composition in Reinforcement Learning},
  author={Tasse, Geraud Nangue and Jarvis, Devon and James, Steven and Rosman, Benjamin},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024},
}

@article{han2024multistable,
  title={Multistable Shape from Shading Emerges from Patch Diffusion},
  author={Han, Xinran Nicole and Zickler, Todd and Nishino, Ko},
  journal={arXiv preprint arXiv:2405.14530},
  year={2024}
}

@article{tu2024mixed,
  title={Mixed Dynamics In Linear Networks: Unifying the Lazy and Active Regimes},
  author={Tu, Zhenfeng and Aranguri, Santiago and Jacot, Arthur},
  journal={arXiv preprint arXiv:2405.17580},
  year={2024}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{goodfellow2014generative,
  title={Generative adversarial nets},
  author={Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={Advances in neural information processing systems},
  year={2014}
}

@article{kingma2013auto,
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@inproceedings{
zhou2024sotopia,
title={{SOTOPIA}: Interactive Evaluation for Social Intelligence in Language Agents},
author={Xuhui Zhou and Hao Zhu and Leena Mathur and Ruohong Zhang and Haofei Yu and Zhengyang Qi and Louis-Philippe Morency and Yonatan Bisk and Daniel Fried and Graham Neubig and Maarten Sap},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024}
}

@inproceedings{yang2024large,
	address = {Bangkok, Thailand and virtual meeting},
	title = {Large {Language} {Models} for {Automated} {Open}-domain {Scientific} {Hypotheses} {Discovery}},
	doi = {10.18653/v1/2024.findings-acl.804},
	abstract = {Hypothetical induction is recognized as the main reasoning type when scientists make observations about the world and try to propose hypotheses to explain those observations. Past research on hypothetical induction is under a constrained setting: (1) the observation annotations in the dataset are carefully manually handpicked sentences (resulting in a close-domain setting); and (2) the ground truth hypotheses are mostly commonsense knowledge, making the task less challenging. In this work, we tackle these problems by proposing the first dataset for social science academic hypotheses discovery, with the final goal to create systems that automatically generate valid, novel, and helpful scientific hypotheses, given only a pile of raw web corpus. Unlike previous settings, the new dataset requires (1) using open-domain data (raw web corpus) as observations; and (2) proposing hypotheses even new to humanity. A multi-module framework is developed for the task, including three different feedback mechanisms to boost performance, which exhibits superior performance in terms of both GPT-4 based and expert-based evaluation. To the best of our knowledge, this is the first work showing that LLMs are able to generate novel (“not existing in literature”) and valid (“reflecting reality”) scientific hypotheses1.},
	language = {en},
	urldate = {2024-10-02},
	booktitle = {Findings of the {Association} for {Computational} {Linguistics} {ACL} 2024},
	publisher = {Association for Computational Linguistics},
	author = {Yang, Zonglin and Du, Xinya and Li, Junxian and Zheng, Jie and Poria, Soujanya and Cambria, Erik},
	year = {2024},
}

@inproceedings{you2020design,
 author = {You, Jiaxuan and Ying, Zhitao and Leskovec, Jure},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 publisher = {Curran Associates, Inc.},
 title = {Design Space for Graph Neural Networks},
 year = {2020}
}


@inproceedings{
kipf2016semi-supervised,
title={Semi-Supervised Classification with Graph Convolutional Networks},
author={Thomas N. Kipf and Max Welling},
booktitle={International Conference on Learning Representations},
year={2017},
}

@inproceedings{hamilton2018inductive,
author = {Hamilton, William L. and Ying, Rex and Leskovec, Jure},
title = {Inductive representation learning on large graphs},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Low-dimensional embeddings of nodes in large graphs have proved extremely useful in a variety of prediction tasks, from content recommendation to identifying protein functions. However, most existing approaches require that all nodes in the graph are present during training of the embeddings; these previous approaches are inherently transductive and do not naturally generalize to unseen nodes. Here we present GraphSAGE, a general inductive framework that leverages node feature information (e.g., text attributes) to efficiently generate node embeddings for previously unseen data. Instead of training individual embeddings for each node, we learn a function that generates embeddings by sampling and aggregating features from a node's local neighborhood. Our algorithm outperforms strong baselines on three inductive node-classification benchmarks: we classify the category of unseen nodes in evolving information graphs based on citation and Reddit post data, and we show that our algorithm generalizes to completely unseen graphs using a multi-graph dataset of protein-protein interactions.},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
location = {Long Beach, California, USA},
series = {NIPS'17}
}

@inproceedings{
velickovic2018graph,
title={Graph Attention Networks},
author={Petar Veličković and Guillem Cucurull and Arantxa Casanova and Adriana Romero and Pietro Liò and Yoshua Bengio},
booktitle={International Conference on Learning Representations},
year={2018},
}

@inproceedings{strubell2019energy,
    title = "Energy and Policy Considerations for Deep Learning in {NLP}",
    author = "Strubell, Emma  and
      Ganesh, Ananya  and
      McCallum, Andrew",
    editor = "Korhonen, Anna  and
      Traum, David  and
      M{\`a}rquez, Llu{\'\i}s",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics",
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    abstract = "Recent progress in hardware and methodology for training neural networks has ushered in a new generation of large networks trained on abundant data. These models have obtained notable gains in accuracy across many NLP tasks. However, these accuracy improvements depend on the availability of exceptionally large computational resources that necessitate similarly substantial energy consumption. As a result these models are costly to train and develop, both financially, due to the cost of hardware and electricity or cloud compute time, and environmentally, due to the carbon footprint required to fuel modern tensor processing hardware. In this paper we bring this issue to the attention of NLP researchers by quantifying the approximate financial and environmental costs of training a variety of recently successful neural network models for NLP. Based on these findings, we propose actionable recommendations to reduce costs and improve equity in NLP research and practice.",
}

@inproceedings{jin2020bert,
  title={Is bert really robust? a strong baseline for natural language attack on text classification and entailment},
  author={Jin, Di and Jin, Zhijing and Zhou, Joey Tianyi and Szolovits, Peter},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  year={2020}
}

@inproceedings{qi2020stanza,
  title={Stanza: A Python Natural Language Processing Toolkit for Many Human Languages},
  author={Qi, Peng and Zhang, Yuhao and Zhang, Yuhui and Bolton, Jason and Manning, Christopher D},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations},
  year={2020}
}

@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}



@misc{widom2006,
  author       = {Jennifer Widom},
  title        = {Tips for Writing Technical Papers},
  year         = {2006},
  url          = {https://cs.stanford.edu/people/widom/paper-writing.html#intro},
  note         = {Accessed: 2024-10-01}
}

@article{elali2023ai,
  title={AI-generated research paper fabrication and plagiarism in the scientific community},
  author={Elali, Faisal R and Rachid, Leena N},
  journal={Patterns},
  year={2023},
  publisher={Elsevier}
}


@article{huang2023surveyhallucinationlargelanguage,
  title={A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions},
  author={Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong, Weihong and Feng, Zhangyin and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and others},
  journal={ACM Transactions on Information Systems},
  year={2023},
  publisher={ACM New York, NY}
}

@article{lewis2020retrieval,
  title={Retrieval-augmented generation for knowledge-intensive nlp tasks},
  author={Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and others},
  journal={Advances in Neural Information Processing Systems},
  year={2020}
}

@misc{tips,
  author       = {Jennifer Widom},
  title        = {Tips for Writing Technical Papers
},
  howpublished = {\url{https://cs.stanford.edu/people/widom/paper-writing.html}},
  year         = {2006},
  note         = {Accessed: Oct 2024}
}