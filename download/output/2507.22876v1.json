{"title": "Automatically discovering heuristics in a complex SAT solver with large language models", "author": "Yiwen Sun", "abstract": null, "citations": {"npc": {"bib_key": "npc", "bib_title": "The complexity of theorem-proving procedures", "bib_author ": "Cook, Stephen A", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Introduction", "subsection": null, "subsubsection": null, "prev_context": "As the first proven NP-complete problem\\cite{npc}", "next_context": ", SAT holds immense theoretical significance, and serves as a cornerstone of the computational complexity theory."}], "importance_score": 1.0}, "satsurvey17": {"bib_key": "satsurvey17", "bib_title": "A survey of {SAT} solver", "bib_author ": "Gong, Weiwei", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Introduction", "subsection": null, "subsubsection": null, "prev_context": "Moreover, SAT arises from a wide range of applications, such as software verification, artificial intelligence, automated reasoning, cryptography, and scheduling~\\cite{satsurvey17}", "next_context": "."}], "importance_score": 1.0}, "satsurvey19": {"bib_key": "satsurvey19", "bib_title": "A comprehensive study and analysis on {SAT-solvers}: advances, usages and achievements", "bib_author ": "Alouneh, Sahel", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Introduction", "subsection": null, "subsubsection": null, "prev_context": "Modern SAT solvers, driven by cutting-edge algorithms and heuristics, serve as a backbone for mission-critical industrial applications, enabling breakthroughs in semiconductor manufacturing, cybersecurity, and mission-critical software development~\\cite{satsurvey19}", "next_context": "."}], "importance_score": 1.0}, "edasurvey": {"bib_key": "edasurvey", "bib_title": "A survey of circuit foundation model: Foundation {AI} models for {VLSI} circuit design and {EDA}", "bib_author ": "Fang, Wenji", "arxiv_id": null, "short_id": "2504.03711", "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Introduction", "subsection": null, "subsubsection": null, "prev_context": "For example, the Electronic Design Automation (EDA) task requires SAT solvers to handle various complex problem instances~\\cite{edasurvey}", "next_context": "."}], "importance_score": 1.0}, "satautomation": {"bib_key": "satautomation", "bib_title": "Automated configuration and selection of SAT solvers", "bib_author ": "Hoos, Holger H", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Introduction", "subsection": null, "subsubsection": null, "prev_context": "To address this requirement, hyperparameter optimization approaches, which also refer to as algorithm configuration, have been developed for automated SAT solver improvement\\cite{satautomation, satparameter, satparameter2}", "next_context": "such that they can automatically choose well-performing settings for the given problem instance."}], "importance_score": 0.3333333333333333}, "satparameter": {"bib_key": "satparameter", "bib_title": "Parameter Setting in SAT Solver using Machine Learning Techniques.", "bib_author ": "Beskyd, Filip", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Introduction", "subsection": null, "subsubsection": null, "prev_context": "To address this requirement, hyperparameter optimization approaches, which also refer to as algorithm configuration, have been developed for automated SAT solver improvement\\cite{satautomation, satparameter, satparameter2}", "next_context": "such that they can automatically choose well-performing settings for the given problem instance."}], "importance_score": 0.3333333333333333}, "satparameter2": {"bib_key": "satparameter2", "bib_title": "Improving {SAT} Solver Performance Through {MLP}-Predicted Genetic Algorithm Parameters", "bib_author ": "Saouli, Sabrine", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Introduction", "subsection": null, "subsubsection": null, "prev_context": "To address this requirement, hyperparameter optimization approaches, which also refer to as algorithm configuration, have been developed for automated SAT solver improvement\\cite{satautomation, satparameter, satparameter2}", "next_context": "such that they can automatically choose well-performing settings for the given problem instance."}], "importance_score": 0.3333333333333333}, "gpt4": {"bib_key": "gpt4", "bib_title": "{GPT-4} technical report", "bib_author ": "Achiam, Josh", "arxiv_id": null, "short_id": "2303.08774", "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Introduction", "subsection": null, "subsubsection": null, "prev_context": "Large Language Models (LLMs), the recent fascinating advance in generative artificial intelligence (AI)~\\cite{gpt4, deepseekv3, deepseekr1, qwen, qwen3, llama, gemini}", "next_context": ", provide new opportunities to surpass the limitations of manually designed frameworks~\\cite{algorithmdesign}."}], "importance_score": 0.14285714285714285}, "deepseekv3": {"bib_key": "deepseekv3", "bib_title": "{Deepseek-V3} technical report", "bib_author ": "Liu, Aixin", "arxiv_id": null, "short_id": "2412.19437", "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Introduction", "subsection": null, "subsubsection": null, "prev_context": "Large Language Models (LLMs), the recent fascinating advance in generative artificial intelligence (AI)~\\cite{gpt4, deepseekv3, deepseekr1, qwen, qwen3, llama, gemini}", "next_context": ", provide new opportunities to surpass the limitations of manually designed frameworks~\\cite{algorithmdesign}."}], "importance_score": 0.14285714285714285}, "deepseekr1": {"bib_key": "deepseekr1", "bib_title": "{Deepseek-R1}: Incentivizing reasoning capability in {LLMs} via reinforcement learning", "bib_author ": "Guo, Daya", "arxiv_id": null, "short_id": "2501.12948", "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Introduction", "subsection": null, "subsubsection": null, "prev_context": "Large Language Models (LLMs), the recent fascinating advance in generative artificial intelligence (AI)~\\cite{gpt4, deepseekv3, deepseekr1, qwen, qwen3, llama, gemini}", "next_context": ", provide new opportunities to surpass the limitations of manually designed frameworks~\\cite{algorithmdesign}."}], "importance_score": 0.14285714285714285}, "qwen": {"bib_key": "qwen", "bib_title": "Qwen technical report", "bib_author ": "Bai, Jinze", "arxiv_id": null, "short_id": "2309.16609", "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Introduction", "subsection": null, "subsubsection": null, "prev_context": "Large Language Models (LLMs), the recent fascinating advance in generative artificial intelligence (AI)~\\cite{gpt4, deepseekv3, deepseekr1, qwen, qwen3, llama, gemini}", "next_context": ", provide new opportunities to surpass the limitations of manually designed frameworks~\\cite{algorithmdesign}."}], "importance_score": 0.14285714285714285}, "qwen3": {"bib_key": "qwen3", "bib_title": "Qwen3 technical report", "bib_author ": "Yang, An", "arxiv_id": null, "short_id": "2505.09388", "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Introduction", "subsection": null, "subsubsection": null, "prev_context": "Large Language Models (LLMs), the recent fascinating advance in generative artificial intelligence (AI)~\\cite{gpt4, deepseekv3, deepseekr1, qwen, qwen3, llama, gemini}", "next_context": ", provide new opportunities to surpass the limitations of manually designed frameworks~\\cite{algorithmdesign}."}], "importance_score": 0.14285714285714285}, "llama": {"bib_key": "llama", "bib_title": "Llama: Open and efficient foundation language models", "bib_author ": "Touvron, Hugo", "arxiv_id": null, "short_id": "2302.13971", "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Introduction", "subsection": null, "subsubsection": null, "prev_context": "Large Language Models (LLMs), the recent fascinating advance in generative artificial intelligence (AI)~\\cite{gpt4, deepseekv3, deepseekr1, qwen, qwen3, llama, gemini}", "next_context": ", provide new opportunities to surpass the limitations of manually designed frameworks~\\cite{algorithmdesign}."}], "importance_score": 0.14285714285714285}, "gemini": {"bib_key": "gemini", "bib_title": "Gemini: a family of highly capable multimodal models", "bib_author ": "Team, Gemini", "arxiv_id": null, "short_id": "2312.11805", "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Introduction", "subsection": null, "subsubsection": null, "prev_context": "Large Language Models (LLMs), the recent fascinating advance in generative artificial intelligence (AI)~\\cite{gpt4, deepseekv3, deepseekr1, qwen, qwen3, llama, gemini}", "next_context": ", provide new opportunities to surpass the limitations of manually designed frameworks~\\cite{algorithmdesign}."}], "importance_score": 0.14285714285714285}, "algorithmdesign": {"bib_key": "algorithmdesign", "bib_title": "A systematic survey on large language models for algorithm design", "bib_author ": "Liu, Fei", "arxiv_id": null, "short_id": "2410.14716", "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Introduction", "subsection": null, "subsubsection": null, "prev_context": "Large Language Models (LLMs), the recent fascinating advance in generative artificial intelligence (AI)~\\cite{gpt4, deepseekv3, deepseekr1, qwen, qwen3, llama, gemini}, provide new opportunities to surpass the limitations of manually designed frameworks~\\cite{algorithmdesign}", "next_context": "."}], "importance_score": 1.0}, "FunSearch": {"bib_key": "FunSearch", "bib_title": "Mathematical discoveries from program search with large language models", "bib_author ": "Romera-Paredes, Bernardino", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Introduction", "subsection": null, "subsubsection": null, "prev_context": "After DeepMind's pioneering work on complex mathematical and bin-packing problems~\\cite{FunSearch}", "next_context": ", LLMs have demonstrated promising applications in automated algorithm design\\cite{eoh, reevo, autosat, droc, hsevo, extracting, alphaevolve}."}], "importance_score": 1.0}, "eoh": {"bib_key": "eoh", "bib_title": "Evolution of Heuristics: Towards Efficient Automatic Algorithm Design Using Large Language Model", "bib_author ": "Liu, Fei", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Introduction", "subsection": null, "subsubsection": null, "prev_context": "After DeepMind's pioneering work on complex mathematical and bin-packing problems~\\cite{FunSearch}, LLMs have demonstrated promising applications in automated algorithm design\\cite{eoh, reevo, autosat, droc, hsevo, extracting, alphaevolve}", "next_context": "."}], "importance_score": 0.14285714285714285}, "reevo": {"bib_key": "reevo", "bib_title": "ReEvo: Large Language Models as Hyper-Heuristics with Reflective Evolution", "bib_author ": "Ye, Haoran", "arxiv_id": null, "short_id": "2402.01145", "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Introduction", "subsection": null, "subsubsection": null, "prev_context": "After DeepMind's pioneering work on complex mathematical and bin-packing problems~\\cite{FunSearch}, LLMs have demonstrated promising applications in automated algorithm design\\cite{eoh, reevo, autosat, droc, hsevo, extracting, alphaevolve}", "next_context": "."}], "importance_score": 0.14285714285714285}, "autosat": {"bib_key": "autosat", "bib_title": "{AutoSAT}: Automatically optimize {SAT} solvers via large language models", "bib_author ": "Sun, Yiwen", "arxiv_id": null, "short_id": "2402.10705", "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Introduction", "subsection": null, "subsubsection": null, "prev_context": "After DeepMind's pioneering work on complex mathematical and bin-packing problems~\\cite{FunSearch}, LLMs have demonstrated promising applications in automated algorithm design\\cite{eoh, reevo, autosat, droc, hsevo, extracting, alphaevolve}", "next_context": "."}, {"section": "Introduction", "subsection": null, "subsubsection": null, "prev_context": "These complex solvers often employ carefully customized data structures to improve computational efficiency, but meanwhile bring significant adaptation barriers for automated optimization~\\cite{autosat}", "next_context": "."}, {"section": "Method", "subsection": "Presearch Strategy", "subsubsection": null, "prev_context": "Previous work~\\cite{autosat}", "next_context": "usually utilizes strategy such as evolutionary algorithms (EA) and greedy hill climbers to optimize different functions, and faces scalability issues when optimizing multiple functions with numerous candidates."}, {"section": "Method", "subsection": "Presearch Strategy", "subsubsection": null, "prev_context": "Under the assumption used in AutoSAT\\cite{autosat}", "next_context": "on the heuristic function optimization, the(1+\\lambda)EA variants require a budget ofO(n^2+n\\lambda)~\\cite{jansen2005choice}."}], "importance_score": 3.142857142857143}, "droc": {"bib_key": "droc", "bib_title": "{DRoC}: Elevating Large Language Models for Complex Vehicle Routing via Decomposed Retrieval of Constraints", "bib_author ": "Jiang, Xia", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Introduction", "subsection": null, "subsubsection": null, "prev_context": "After DeepMind's pioneering work on complex mathematical and bin-packing problems~\\cite{FunSearch}, LLMs have demonstrated promising applications in automated algorithm design\\cite{eoh, reevo, autosat, droc, hsevo, extracting, alphaevolve}", "next_context": "."}], "importance_score": 0.14285714285714285}, "hsevo": {"bib_key": "hsevo", "bib_title": "Hsevo: Elevating automatic heuristic design with diversity-driven harmony search and genetic algorithm using {LLMs}", "bib_author ": "Dat, Pham Vu Tuan", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Introduction", "subsection": null, "subsubsection": null, "prev_context": "After DeepMind's pioneering work on complex mathematical and bin-packing problems~\\cite{FunSearch}, LLMs have demonstrated promising applications in automated algorithm design\\cite{eoh, reevo, autosat, droc, hsevo, extracting, alphaevolve}", "next_context": "."}], "importance_score": 0.14285714285714285}, "extracting": {"bib_key": "extracting", "bib_title": "Extracting problem structure with LLMs for optimized SAT local search", "bib_author ": "Schidler, Andr{\\'e}", "arxiv_id": null, "short_id": "2501.14630", "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Introduction", "subsection": null, "subsubsection": null, "prev_context": "After DeepMind's pioneering work on complex mathematical and bin-packing problems~\\cite{FunSearch}, LLMs have demonstrated promising applications in automated algorithm design\\cite{eoh, reevo, autosat, droc, hsevo, extracting, alphaevolve}", "next_context": "."}], "importance_score": 0.14285714285714285}, "alphaevolve": {"bib_key": "alphaevolve", "bib_title": "{AlphaEvolve}: A coding agent for scientific and algorithmic discovery", "bib_author ": "Novikov, Alex", "arxiv_id": null, "short_id": "2506.13131", "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Introduction", "subsection": null, "subsubsection": null, "prev_context": "After DeepMind's pioneering work on complex mathematical and bin-packing problems~\\cite{FunSearch}, LLMs have demonstrated promising applications in automated algorithm design\\cite{eoh, reevo, autosat, droc, hsevo, extracting, alphaevolve}", "next_context": "."}], "importance_score": 0.14285714285714285}, "longcontext": {"bib_key": "longcontext", "bib_title": "Long-context llms struggle with long in-context learning", "bib_author ": "Li, Tianle", "arxiv_id": null, "short_id": "2404.02060", "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Introduction", "subsection": null, "subsubsection": null, "prev_context": "In addition, while the conventional token length limit for large language models (LLMs) is around200ktokens~\\cite{longcontext, longcontext2}", "next_context": ", the SOTA SAT solvers, such as Kissat~\\cite{kissat}and Cadical~\\cite{cadical},  have been refined over decades and thus have more than250ktokens."}], "importance_score": 0.5}, "longcontext2": {"bib_key": "longcontext2", "bib_title": "A comprehensive survey on long context language modeling", "bib_author ": "Liu, Jiaheng", "arxiv_id": null, "short_id": "2503.17407", "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Introduction", "subsection": null, "subsubsection": null, "prev_context": "In addition, while the conventional token length limit for large language models (LLMs) is around200ktokens~\\cite{longcontext, longcontext2}", "next_context": ", the SOTA SAT solvers, such as Kissat~\\cite{kissat}and Cadical~\\cite{cadical},  have been refined over decades and thus have more than250ktokens."}], "importance_score": 0.5}, "kissat": {"bib_key": "kissat", "bib_title": "Cadical, kissat, paracooba, plingeling and treengeling entering the sat competition 2020", "bib_author ": "Fleury, ABKFM", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Introduction", "subsection": null, "subsubsection": null, "prev_context": "In addition, while the conventional token length limit for large language models (LLMs) is around200ktokens~\\cite{longcontext, longcontext2}, the SOTA SAT solvers, such as Kissat~\\cite{kissat}", "next_context": "and Cadical~\\cite{cadical},  have been refined over decades and thus have more than250ktokens."}, {"section": "Results", "subsection": "Discovery of promising heuristics", "subsubsection": null, "prev_context": "BaselinesApart from the classic CDCL-based SAT solver MiniSat~\\cite{minisat}, we also compare with SOTA SAT solvers Kissat~\\cite{kissat}", "next_context": "and Cadical~\\cite{cadical}, whose performance are fully optimized through hybrid heuristics and complex data structures."}], "importance_score": 2.0}, "cadical": {"bib_key": "cadical", "bib_title": "CaDiCaL at the SAT Race 2019", "bib_author ": "Armin Biere", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Introduction", "subsection": null, "subsubsection": null, "prev_context": "In addition, while the conventional token length limit for large language models (LLMs) is around200ktokens~\\cite{longcontext, longcontext2}, the SOTA SAT solvers, such as Kissat~\\cite{kissat}and Cadical~\\cite{cadical}", "next_context": ",  have been refined over decades and thus have more than250ktokens."}, {"section": "Results", "subsection": "Discovery of promising heuristics", "subsubsection": null, "prev_context": "BaselinesApart from the classic CDCL-based SAT solver MiniSat~\\cite{minisat}, we also compare with SOTA SAT solvers Kissat~\\cite{kissat}and Cadical~\\cite{cadical}", "next_context": ", whose performance are fully optimized through hybrid heuristics and complex data structures."}], "importance_score": 2.0}, "sat2023": {"bib_key": "sat2023", "bib_title": "Proceedings of SAT Competition 2023: Solver, Benchmark and Proof Checker Descriptions", "bib_author ": "", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Results", "subsection": "Discovery of promising heuristics", "subsubsection": null, "prev_context": "DatasetsWe selected11datasets to test the capabilities of AutoModSAT, consisting of7datasets from the SAT Competition 2023 and 2024~\\cite{sat2023, sat2024}", "next_context": ",3datasets generated by Picat~\\cite{picat}, and another dataset from real industrial EDA scenarios."}], "importance_score": 0.5}, "sat2024": {"bib_key": "sat2024", "bib_title": "Proceedings of SAT Competition 2024: Solver, Benchmark and Proof Checker Descriptions", "bib_author ": "", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Results", "subsection": "Discovery of promising heuristics", "subsubsection": null, "prev_context": "DatasetsWe selected11datasets to test the capabilities of AutoModSAT, consisting of7datasets from the SAT Competition 2023 and 2024~\\cite{sat2023, sat2024}", "next_context": ",3datasets generated by Picat~\\cite{picat}, and another dataset from real industrial EDA scenarios."}], "importance_score": 0.5}, "picat": {"bib_key": "picat", "bib_title": "Constraint solving and planning with Picat", "bib_author ": "Zhou, Neng-Fa", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Results", "subsection": "Discovery of promising heuristics", "subsubsection": null, "prev_context": "DatasetsWe selected11datasets to test the capabilities of AutoModSAT, consisting of7datasets from the SAT Competition 2023 and 2024~\\cite{sat2023, sat2024},3datasets generated by Picat~\\cite{picat}", "next_context": ", and another dataset from real industrial EDA scenarios."}, {"section": "Results", "subsection": "Discovery of promising heuristics", "subsubsection": null, "prev_context": "Another3datasets are manually generated by the Picat tool, including KnightTour, MineSweeper, and Zamkeller, which can formulate constrained satisfied problems into Conjunctive Normal Form (CNF) formulas~\\cite{picat}", "next_context": "."}, {"section": "Experimental details", "subsection": "Dataset description", "subsubsection": null, "prev_context": "For the generated instances using Picat~\\cite{picat}", "next_context": ", we adopt  the settings in Chapters 2 and 3 of the book by NengFa Zhou~\\cite{picat}and conduct grid sampling within a parameter space."}, {"section": "Experimental details", "subsection": "Dataset description", "subsubsection": null, "prev_context": "For the generated instances using Picat~\\cite{picat}, we adopt  the settings in Chapters 2 and 3 of the book by NengFa Zhou~\\cite{picat}", "next_context": "and conduct grid sampling within a parameter space."}], "importance_score": 4.0}, "minisat": {"bib_key": "minisat", "bib_title": "Minisat v1.13-a sat solver with conflict-clause minimization", "bib_author ": "Sorensson, Niklas", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Results", "subsection": "Discovery of promising heuristics", "subsubsection": null, "prev_context": "BaselinesApart from the classic CDCL-based SAT solver MiniSat~\\cite{minisat}", "next_context": ", we also compare with SOTA SAT solvers Kissat~\\cite{kissat}and Cadical~\\cite{cadical}, whose performance are fully optimized through hybrid heuristics and complex data structures."}], "importance_score": 1.0}, "smac3": {"bib_key": "smac3", "bib_title": "{SMAC3}: A versatile {Bayesian} optimization package for hyperparameter optimization", "bib_author ": "Lindauer, Marius", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Results", "subsection": "Discovery of promising heuristics", "subsubsection": null, "prev_context": "More precisely,  we employed SMAC3 (Sequential Model-based Algorithm Configuration)~\\cite{smac3}", "next_context": "to optimize the parameters of the aforementioned SAT solvers."}], "importance_score": 1.0}, "watch": {"bib_key": "watch", "bib_title": "Formalization and implementation of modern SAT solvers", "bib_author ": "Mari{\\'c}, Filip", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Method", "subsection": "Principles for Developing Complex SAT Solvers", "subsubsection": null, "prev_context": "For instance, complex SAT solvers frequently employ customized low-level data structures such as watch lists for unit propagation and clause databases with lazy deletion schemes~\\cite{watch}", "next_context": ", which are optimized for memory locality and cache efficiency."}], "importance_score": 1.0}, "promptengineering": {"bib_key": "promptengineering", "bib_title": "Prompt engineering in large language models", "bib_author ": "Marvin, Ggaliwango", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Method", "subsection": "Automatic Prompt Optimization", "subsubsection": null, "prev_context": "Prompt engineering remains a significant challenge in LLMs applications~\\cite{promptengineering}", "next_context": "."}], "importance_score": 1.0}, "ape": {"bib_key": "ape", "bib_title": "Large language models are zero-shot reasoners", "bib_author ": "Kojima, Takeshi", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Method", "subsection": "Automatic Prompt Optimization", "subsubsection": null, "prev_context": "~\\cite{ape, zhou2022large, pryzant2023automatic}", "next_context": ", our task faces two critical constraints: prohibitive execution time (5000seconds timeout per instance), and the absence of definitive labels due to the performance variance across different datasets."}], "importance_score": 0.3333333333333333}, "zhou2022large": {"bib_key": "zhou2022large", "bib_title": "Large language models are human-level prompt engineers", "bib_author ": "Zhou, Yongchao", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Method", "subsection": "Automatic Prompt Optimization", "subsubsection": null, "prev_context": "~\\cite{ape, zhou2022large, pryzant2023automatic}", "next_context": ", our task faces two critical constraints: prohibitive execution time (5000seconds timeout per instance), and the absence of definitive labels due to the performance variance across different datasets."}], "importance_score": 0.3333333333333333}, "pryzant2023automatic": {"bib_key": "pryzant2023automatic", "bib_title": "Automatic Prompt Optimization with \u201cGradient Descent\u201d and Beam Search", "bib_author ": "Pryzant, Reid", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Method", "subsection": "Automatic Prompt Optimization", "subsubsection": null, "prev_context": "~\\cite{ape, zhou2022large, pryzant2023automatic}", "next_context": ", our task faces two critical constraints: prohibitive execution time (5000seconds timeout per instance), and the absence of definitive labels due to the performance variance across different datasets."}], "importance_score": 0.3333333333333333}, "codet5+": {"bib_key": "codet5+", "bib_title": "{CodeT5+}: Open Code Large Language Models for Code Understanding and Generation", "bib_author ": "Wang, Yue", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Method", "subsection": "Automatic Prompt Optimization", "subsubsection": null, "prev_context": "~\\cite{codet5+}", "next_context": "to generate embeddings for the synthesized code, which is preprocessed according to the Google C++ style guide~\\cite{googlestyle}(e.g., removing comments and ensuring uniform indentation)."}], "importance_score": 1.0}, "googlestyle": {"bib_key": "googlestyle", "bib_title": "{{Google C++} Style Guide}", "bib_author ": "{Google}", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Method", "subsection": "Automatic Prompt Optimization", "subsubsection": null, "prev_context": "~\\cite{codet5+}to generate embeddings for the synthesized code, which is preprocessed according to the Google C++ style guide~\\cite{googlestyle}", "next_context": "(e.g., removing comments and ensuring uniform indentation)."}], "importance_score": 1.0}, "kmeans++": {"bib_key": "kmeans++", "bib_title": "k-means++ the advantages of careful seeding", "bib_author ": "Arthur, David", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Method", "subsection": "Automatic Prompt Optimization", "subsubsection": null, "prev_context": "Specifically, we apply the K-Means++~\\cite{kmeans++}", "next_context": "to partition the embeddings intoKclusters."}], "importance_score": 1.0}, "doerr2018towards": {"bib_key": "doerr2018towards", "bib_title": "Towards a theory-guided benchmarking suite for discrete black-box optimization heuristics: profiling (1+ $\\lambda$) EA variants on OneMax and LeadingOnes", "bib_author ": "Doerr, Carola", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Method", "subsection": "Presearch Strategy", "subsubsection": null, "prev_context": "For instance, in optimizing heuristic functions as a pseudo-Boolean optimization problem (e.g., LLMs provide merely two candidates for each function) with sequential dependency, EAs require approximately0.54n^2(nis the number of functions need to be optimized) trials of generating new heuristics functions as illustrated in recent empirical studies\\cite{doerr2018towards, ye2020benchmarking}", "next_context": "."}], "importance_score": 0.5}, "ye2020benchmarking": {"bib_key": "ye2020benchmarking", "bib_title": "Benchmarking a genetic algorithm with configurable crossover probability", "bib_author ": "Ye, Furong", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Method", "subsection": "Presearch Strategy", "subsubsection": null, "prev_context": "For instance, in optimizing heuristic functions as a pseudo-Boolean optimization problem (e.g., LLMs provide merely two candidates for each function) with sequential dependency, EAs require approximately0.54n^2(nis the number of functions need to be optimized) trials of generating new heuristics functions as illustrated in recent empirical studies\\cite{doerr2018towards, ye2020benchmarking}", "next_context": "."}], "importance_score": 0.5}, "doerr2018static": {"bib_key": "doerr2018static", "bib_title": "Static and self-adjusting mutation strengths for multi-valued decision variables", "bib_author ": "Doerr, Benjamin", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Method", "subsection": "Presearch Strategy", "subsubsection": null, "prev_context": "These facts indicate that significant optimization time is required for achieving the optimal results~\\cite{doerr2018static, doerr2019theory}", "next_context": "."}], "importance_score": 0.5}, "doerr2019theory": {"bib_key": "doerr2019theory", "bib_title": "Theory of evolutionary computation: Recent developments in discrete optimization", "bib_author ": "Doerr, Benjamin", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Method", "subsection": "Presearch Strategy", "subsubsection": null, "prev_context": "These facts indicate that significant optimization time is required for achieving the optimal results~\\cite{doerr2018static, doerr2019theory}", "next_context": "."}], "importance_score": 0.5}, "jansen2005choice": {"bib_key": "jansen2005choice", "bib_title": "On the choice of the offspring population size in evolutionary algorithms", "bib_author ": "Jansen, Thomas", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Method", "subsection": "Presearch Strategy", "subsubsection": null, "prev_context": "Under the assumption used in AutoSAT\\cite{autosat}on the heuristic function optimization, the(1+\\lambda)EA variants require a budget ofO(n^2+n\\lambda)~\\cite{jansen2005choice}", "next_context": "."}], "importance_score": 1.0}, "cdcl": {"bib_key": "cdcl", "bib_title": "GRASP: A search algorithm for propositional satisfiability", "bib_author ": "Marques-Silva, Joao P", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Preliminaries", "subsection": "CDCL solver", "subsubsection": null, "prev_context": "Conflict-Driven Clause Learning (CDCL)~\\cite{cdcl}", "next_context": "is the most common approach and plays a dominant role in modern high-performance SAT solvers."}, {"section": "ModSAT: A Modularized SAT solver", "subsection": "Overview of ModSAT", "subsubsection": null, "prev_context": "~\\cite{cdcl}", "next_context": "in Algorithm~\\ref{alg:CDCL},"}], "importance_score": 2.0}, "vsids": {"bib_key": "vsids", "bib_title": "Conflict-driven clause learning sat solvers", "bib_author ": "Biere, Armin", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Preliminaries", "subsection": "CDCL solver", "subsubsection": null, "prev_context": "For example, Variable State Independent Decaying Sum (VSIDS)~\\cite{vsids}", "next_context": "is a family of branching heuristics that seek to assign a value to the most promising variable  in the Make Decision phase."}], "importance_score": 1.0}, "lrb": {"bib_key": "lrb", "bib_title": "Learning rate based branching heuristic for {SAT} solvers", "bib_author ": "Liang, Jia Hui", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Preliminaries", "subsection": "CDCL solver", "subsubsection": null, "prev_context": "Another important branching heuristic is Learning-Rate Branching (LRB)~\\cite{lrb}", "next_context": ", which frames branching as an optimization problem that picks a variable to maximize a metric called learning rate."}], "importance_score": 1.0}, "ramos2011between": {"bib_key": "ramos2011between", "bib_title": "Between restarts and backjumps", "bib_author ": "Ramos, Antonio", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Preliminaries", "subsection": "CDCL solver", "subsubsection": null, "prev_context": "Fast restart~\\cite{ramos2011between}", "next_context": "is a widely used method, and Luby restarts~\\cite{luby}is also heavily used because they represent a prior optimal strategy."}], "importance_score": 1.0}, "luby": {"bib_key": "luby", "bib_title": "Optimal speedup of Las Vegas algorithms", "bib_author ": "Luby, Michael", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Preliminaries", "subsection": "CDCL solver", "subsubsection": null, "prev_context": "Fast restart~\\cite{ramos2011between}is a widely used method, and Luby restarts~\\cite{luby}", "next_context": "is also heavily used because they represent a prior optimal strategy."}], "importance_score": 1.0}, "glucose": {"bib_key": "glucose", "bib_title": "Glucose 2.1: Aggressive, but reactive, clause database management, dynamic restarts", "bib_author ": "Audemard, Gilles", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Preliminaries", "subsection": "CDCL solver", "subsubsection": null, "prev_context": "However, most implementations are now switched to Glucose-style restarts~\\cite{glucose}", "next_context": ", which are widely used in the SAT Competition."}], "importance_score": 1.0}, "biere2015evaluating": {"bib_key": "biere2015evaluating", "bib_title": "Evaluating CDCL restart schemes", "bib_author ": "Biere, Armin", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Preliminaries", "subsection": "CDCL solver", "subsubsection": null, "prev_context": "For more details, see the extensive overview given by Armin Biere~\\cite{biere2015evaluating}", "next_context": "."}], "importance_score": 1.0}, "precosat": {"bib_key": "precosat", "bib_title": "Lingeling, plingeling, picosat and precosat at sat race 2010", "bib_author ": "Biere, Armin", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Preliminaries", "subsection": "CDCL solver", "subsubsection": null, "prev_context": "PrecoSAT and PicoSAT~\\cite{precosat}", "next_context": "utilize a Jeroslow-Wang score~\\cite{jeroslow1990solving}to adjust the saved phases either on all or only on irreundant clauses in regular intervals following a luby sequence."}], "importance_score": 1.0}, "jeroslow1990solving": {"bib_key": "jeroslow1990solving", "bib_title": "Solving propositional satisfiability problems", "bib_author ": "Jeroslow, Robert G", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Preliminaries", "subsection": "CDCL solver", "subsubsection": null, "prev_context": "PrecoSAT and PicoSAT~\\cite{precosat}utilize a Jeroslow-Wang score~\\cite{jeroslow1990solving}", "next_context": "to adjust the saved phases either on all or only on irreundant clauses in regular intervals following a luby sequence."}], "importance_score": 1.0}, "Strangenight": {"bib_key": "Strangenight", "bib_title": "Strangenight", "bib_author ": "Soos, Mate", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Preliminaries", "subsection": "CDCL solver", "subsubsection": null, "prev_context": "StrangeNight~\\cite{Strangenight}", "next_context": "employs a strategy of flipping values with a certain probability that depends on the depth of the assignment."}], "importance_score": 1.0}, "balint2015overview": {"bib_key": "balint2015overview", "bib_title": "Overview and analysis of the SAT Challenge 2012 solver competition", "bib_author ": "Balint, Adrian", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Preliminaries", "subsection": "CDCL solver", "subsubsection": null, "prev_context": "These rephasing heuristics have been used and compared in the SAT solver Riss~\\cite{balint2015overview}", "next_context": "."}], "importance_score": 1.0}, "openai_docs": {"bib_key": "openai_docs", "bib_title": "{{OpenAI API Documentation}}", "bib_author ": "{OpenAI}", "arxiv_id": null, "short_id": null, "title": null, "author": null, "published": null, "similar_score": null, "context": [{"section": "Automatic Prompt Optimization", "subsection": null, "subsubsection": null, "prev_context": "The basic prompt template follows the instructions in OpenAI framework docs~\\cite{openai_docs}", "next_context": ", which obeys the following format:\\itemDefine the\\textbf{Role}of an agent as a solver expert who needs to assess and improve the heuristics function in the SAT solver."}], "importance_score": 1.0}}, "refs": [], "table": [{"original": "\\begin{table*}[t]\n\\belowrulesep=0pt\n\\aboverulesep=0pt\n\\begin{center}\n\\caption{\\textbf{Dataset information}.  Datasets used in this paper  are taken  from the SAT Competition 2023, 2024 (SC 2023, SC 2024 for short), Picat (a language tool for problem generation), and the industrial EDA scenario. The size of each dataset and statistics on the number of variables and clauses are provided, which clearly show the diversity of the problem instances. More details are provided in Supplementary.}\n\\vskip 0.04in\n\\resizebox{0.8\\textwidth}{!}{\n\\begin{tabular}{lcc|cc|cc}\n\\toprule\ndataset            & size & source & variables mean & variables std & clauses mean & clauses std \\\\\n\\midrule\ncryptography-ascon           & 20 & SC 2023 & 146,636 & 15,010 & 342,940 & 37,315 \\\\\nregister-allocation       & 20  & SC 2023 & 381 & 193 & 5,813 & 5,622 \\\\\nsocial-golfer          & 20 & SC 2023 & 15,540 & 12,157 & 131,517 & 79,751\\\\\nhashtable-safety              & 20  & SC 2023 & 11,712,548 & 4,874,397 & 53,644,509 & 22,032,387 \\\\\nargumentation 2023             & 20  & SC 2023 & 962 & 190 & 27,960 & 23,034 \\\\ \nargumentation 2024           & 21  & SC 2024 & 909 & 187 & 35,110 & 29,989  \\\\\nhamiltonian              & 40  & SC 2024 & 511 & 60 & 4,062 & 533 \\\\\n\\midrule\nMineSweeper              & 88  & Picat & 618,801 & 531,657 & 9,065,224 & 7,909,645  \\\\\nKnightTour           & 56  & Picat & 223,697 & 313,704 & 10,692,883 & 17,482,123  \\\\\nZamkeller              & 80  & Picat & 24,592 & 22,190 & 310,804 & 335,102 \\\\\n\\midrule\nEDA              & 50  & Industrial & 1,822 & 1,195 & 6,185 & 4207 \\\\\n\n\\bottomrule\n\\label{tab:bench}\n\\end{tabular}\n}\n\\end{center}\n\\vskip -0.08in\n\\end{table*}", "caption": "\\caption{\\textbf{Dataset information}.  Datasets used in this paper  are taken  from the SAT Competition 2023, 2024 (SC 2023, SC 2024 for short), Picat (a language tool for problem generation), and the industrial EDA scenario. The size of each dataset and statistics on the number of variables and clauses are provided, which clearly show the diversity of the problem instances. More details are provided in Supplementary.}", "label": null, "tabular": "\\begin{tabular}{lcc|cc|cc}\n\\toprule\ndataset            & size & source & variables mean & variables std & clauses mean & clauses std \\\\\n\\midrule\ncryptography-ascon           & 20 & SC 2023 & 146,636 & 15,010 & 342,940 & 37,315 \\\\\nregister-allocation       & 20  & SC 2023 & 381 & 193 & 5,813 & 5,622 \\\\\nsocial-golfer          & 20 & SC 2023 & 15,540 & 12,157 & 131,517 & 79,751\\\\\nhashtable-safety              & 20  & SC 2023 & 11,712,548 & 4,874,397 & 53,644,509 & 22,032,387 \\\\\nargumentation 2023             & 20  & SC 2023 & 962 & 190 & 27,960 & 23,034 \\\\ \nargumentation 2024           & 21  & SC 2024 & 909 & 187 & 35,110 & 29,989  \\\\\nhamiltonian              & 40  & SC 2024 & 511 & 60 & 4,062 & 533 \\\\\n\\midrule\nMineSweeper              & 88  & Picat & 618,801 & 531,657 & 9,065,224 & 7,909,645  \\\\\nKnightTour           & 56  & Picat & 223,697 & 313,704 & 10,692,883 & 17,482,123  \\\\\nZamkeller              & 80  & Picat & 24,592 & 22,190 & 310,804 & 335,102 \\\\\n\\midrule\nEDA              & 50  & Industrial & 1,822 & 1,195 & 6,185 & 4207 \\\\\n\n\\bottomrule\n\\label{tab:bench}\n\\end{tabular}", "subtables": []}, {"original": "\\begin{table*}[t]\n\\label{PAR-2result}\n\\belowrulesep=0pt\n\\aboverulesep=0pt\n\\begin{center}\n\\caption{\\textbf{PAR-2 over different datasets}. This table compares the PAR-2 scores (lower is better) and the number of solved instances (in brackets, higher is better) across 11 datasets for eight SAT solvers: MiniSat, ModSAT, ModSAT-para, Kissat, Kissat-para, Cadical, Cadical-para, and our proposed AutoModSAT. The results highlight AutoModSAT\u2019s superior performance, achieving the lowest PAR-2 in 8/11 datasets while matching or exceeding the solved instance counts of competitors. While parameter optimization improves baseline solvers in most cases, AutoModSAT consistently demonstrates broader efficiency gains, particularly in resource-intensive domains like system verification (hashtable-safety) and graph problems (hamiltonian). Note that we perform the calculations three times and present the mean values here.}\n\\vskip 0.04in\n\\resizebox{\\textwidth}{!}{\n\\begin{tabular}{lcccccccc}\n\\toprule\nDataset & MiniSat & ModSAT & ModSAT para &  Kissat & Kissat para & Cadical & Cadical para & AutoModSAT \\\\\n\\midrule\ncryptography-ascon & 193.14 (20) & 208.6 (20) & 208.6 (20) & 189.85 (20) & 155.85 (20) & 231.37 (20) & 204.78 (20) & \\textbf{140.72 (20)}  \\\\\nregister-allocation & 8808.35(3) &7213.23 (5) & 6854.54 (6) & 8553.9 (5) & 6321.95 (8) & 8813.81 (3) & 8774.00 (3) &\\textbf{ 1177.8 (18) }   \\\\\nsocial-golfer & 8193.50(4) & 7836.3 (5) & 7641.23 (5) & 7536.35 (5) & 7536.35 (5) & 7573.55 (5) & 7506.52 (5) & \\textbf{7265.45 (6)} \\\\\nhashtable-safety & 92.14(20) &83.25 (20) & 67.25 (20) & 456.8 (20) & 456.8 (20) & 252.29 (20) & 252.29 (20) & \\textbf{60.82 (20)} \\\\\nargumentation 2023 & 8685.5(3) &4695.25 (13) & 3618.75 (14) & 3330.05 (14) & \\textbf{3099.95 (14)} & 3450.97 (13) & 3289.25 (14) & 3229.65 (14)\\\\\nargumentation 2024 &2876.23 (17) &2745.57 (17) & 1392.36 (19) & 542.48 (21) & \\textbf{170.1 (21)} & 549.436 (21) & 321.23 (21) & 232.14 (21) \\\\\nhamiltonian & 653.23(36) & 577.48 (37)& 227.75 (39) & 457.32 (38) & 296.75 (39) & 937.35 (35) & 444.00(38) & \\textbf{133.13 (40)}\\\\\n\\midrule\nMineSweeper & 9.87 (88) &9.12 (88) & 7.8 (88) & 145.98 (88) & 47.31 (88) & 54.78 (88) & 43.43 (88) & \\textbf{7.36 (88)} \\\\\nKnightTour & 9135.0 (5) & 8769.77 (7) & 8105.79 (11) & 8753.77 (7) & 8577.7 (8) & 8358.88 (9) & 8284 (10) & \\textbf{7815.68 (13) }\\\\\nZamkeller & 5694.84 (37) & 3485.35 (54) & 2854.14 (62) & 2229.9 (65) & \\textbf{486.5 (75)} & 1946.70 (67) & 724.65 (72) & 2053.21 (66) \\\\\n\\midrule\n\nEDA & 1098.22 (45) &825.36 (46) & 643.16 (48) & 628.3 (48) & 416.42 (49) & 522.04 (49) & 491.64 (49) & \\textbf{376.01 (49)} \\\\\n\n\\bottomrule\n\\label{tab:PAR-2}\n\\end{tabular}\n}\n\\end{center}\n\\end{table*}", "caption": "\\caption{\\textbf{PAR-2 over different datasets}. This table compares the PAR-2 scores (lower is better) and the number of solved instances (in brackets, higher is better) across 11 datasets for eight SAT solvers: MiniSat, ModSAT, ModSAT-para, Kissat, Kissat-para, Cadical, Cadical-para, and our proposed AutoModSAT. The results highlight AutoModSAT\u2019s superior performance, achieving the lowest PAR-2 in 8/11 datasets while matching or exceeding the solved instance counts of competitors. While parameter optimization improves baseline solvers in most cases, AutoModSAT consistently demonstrates broader efficiency gains, particularly in resource-intensive domains like system verification (hashtable-safety) and graph problems (hamiltonian). Note that we perform the calculations three times and present the mean values here.}", "label": "\\label{PAR-2result}", "tabular": "\\begin{tabular}{lcccccccc}\n\\toprule\nDataset & MiniSat & ModSAT & ModSAT para &  Kissat & Kissat para & Cadical & Cadical para & AutoModSAT \\\\\n\\midrule\ncryptography-ascon & 193.14 (20) & 208.6 (20) & 208.6 (20) & 189.85 (20) & 155.85 (20) & 231.37 (20) & 204.78 (20) & \\textbf{140.72 (20)}  \\\\\nregister-allocation & 8808.35(3) &7213.23 (5) & 6854.54 (6) & 8553.9 (5) & 6321.95 (8) & 8813.81 (3) & 8774.00 (3) &\\textbf{ 1177.8 (18) }   \\\\\nsocial-golfer & 8193.50(4) & 7836.3 (5) & 7641.23 (5) & 7536.35 (5) & 7536.35 (5) & 7573.55 (5) & 7506.52 (5) & \\textbf{7265.45 (6)} \\\\\nhashtable-safety & 92.14(20) &83.25 (20) & 67.25 (20) & 456.8 (20) & 456.8 (20) & 252.29 (20) & 252.29 (20) & \\textbf{60.82 (20)} \\\\\nargumentation 2023 & 8685.5(3) &4695.25 (13) & 3618.75 (14) & 3330.05 (14) & \\textbf{3099.95 (14)} & 3450.97 (13) & 3289.25 (14) & 3229.65 (14)\\\\\nargumentation 2024 &2876.23 (17) &2745.57 (17) & 1392.36 (19) & 542.48 (21) & \\textbf{170.1 (21)} & 549.436 (21) & 321.23 (21) & 232.14 (21) \\\\\nhamiltonian & 653.23(36) & 577.48 (37)& 227.75 (39) & 457.32 (38) & 296.75 (39) & 937.35 (35) & 444.00(38) & \\textbf{133.13 (40)}\\\\\n\\midrule\nMineSweeper & 9.87 (88) &9.12 (88) & 7.8 (88) & 145.98 (88) & 47.31 (88) & 54.78 (88) & 43.43 (88) & \\textbf{7.36 (88)} \\\\\nKnightTour & 9135.0 (5) & 8769.77 (7) & 8105.79 (11) & 8753.77 (7) & 8577.7 (8) & 8358.88 (9) & 8284 (10) & \\textbf{7815.68 (13) }\\\\\nZamkeller & 5694.84 (37) & 3485.35 (54) & 2854.14 (62) & 2229.9 (65) & \\textbf{486.5 (75)} & 1946.70 (67) & 724.65 (72) & 2053.21 (66) \\\\\n\\midrule\n\nEDA & 1098.22 (45) &825.36 (46) & 643.16 (48) & 628.3 (48) & 416.42 (49) & 522.04 (49) & 491.64 (49) & \\textbf{376.01 (49)} \\\\\n\n\\bottomrule\n\\label{tab:PAR-2}\n\\end{tabular}", "subtables": []}, {"original": "\\begin{table}[ht!]\n\\centering\n\\caption{Configuration of training set, where the indices 1 to 7 represent the following function candidates in order: rephase\\_condition, rephase\\_function, reduce\\_condition, restart\\_condition, restart\\_function, varBumpActivity, claBumpActivity.}\n\\label{tab:training-params}\n\\begin{tabular}{llp{3.5cm}}\n\\toprule\n\\textbf{Dataset} & \\textbf{Training Timeout} & \\textbf{Function candidate}\\\\\n\\midrule\ncryptography-ascon  & 800 & $1,2,3,6$ \\\\\nregister-allocation  & 5000 & $2,3,5,6$ \\\\\nsocial-golfer    & 2000 & $1,4,5,6$ \\\\\nhashtable-safety   & 500 & $2,4,5,7$ \\\\\nargumentation 2023      & 2000 & $1,2,3,6$ \\\\\nargumentation 2024    & 2000 &  $1,2,3,5$ \\\\\nhamiltonian     & 800 & $3,4,5,6$ \\\\\nMineSweeper    & 500 & $2,4,3,7$ \\\\\nKnightTour & 2000    & $1,3,4,7$ \\\\\nZamkeller   & 2000 & $1,3,4,6$ \\\\\nEDA & 800    & $2,5,6,7$ \\\\\n% 'rephase_condition', 'rephase_function','reduce_condition', 'restart_condition', 'restart_function', 'varBumpActivity', 'claBumpActivity'\n\n\\bottomrule\n\\end{tabular}\n\\end{table}", "caption": "\\caption{Configuration of training set, where the indices 1 to 7 represent the following function candidates in order: rephase\\_condition, rephase\\_function, reduce\\_condition, restart\\_condition, restart\\_function, varBumpActivity, claBumpActivity.}", "label": "\\label{tab:training-params}", "tabular": "\\begin{tabular}{llp{3.5cm}}\n\\toprule\n\\textbf{Dataset} & \\textbf{Training Timeout} & \\textbf{Function candidate}\\\\\n\\midrule\ncryptography-ascon  & 800 & $1,2,3,6$ \\\\\nregister-allocation  & 5000 & $2,3,5,6$ \\\\\nsocial-golfer    & 2000 & $1,4,5,6$ \\\\\nhashtable-safety   & 500 & $2,4,5,7$ \\\\\nargumentation 2023      & 2000 & $1,2,3,6$ \\\\\nargumentation 2024    & 2000 &  $1,2,3,5$ \\\\\nhamiltonian     & 800 & $3,4,5,6$ \\\\\nMineSweeper    & 500 & $2,4,3,7$ \\\\\nKnightTour & 2000    & $1,3,4,7$ \\\\\nZamkeller   & 2000 & $1,3,4,6$ \\\\\nEDA & 800    & $2,5,6,7$ \\\\\n% 'rephase_condition', 'rephase_function','reduce_condition', 'restart_condition', 'restart_function', 'varBumpActivity', 'claBumpActivity'\n\n\\bottomrule\n\\end{tabular}", "subtables": []}, {"original": "\\begin{table}[ht!]\n\\centering\n\\caption{ModSAT configuration parameters}\n\\label{tab:modsat-params}\n\\begin{tabular}{llp{7cm}l}\n\\toprule\n\\textbf{Parameter} & \\textbf{Type} & \\textbf{Description} & \\textbf{Search Space} \\\\\n\\midrule\n\\texttt{var-decay}    & double & Variable activity decay factor & $(0, 1)$ \\\\\n\\texttt{cla-decay}    & double & Clause activity decay factor & $(0, 1)$ \\\\\n\\texttt{rnd-freq}     & double & Frequency for random variable selection & $[0, 1]$ \\\\\n\\texttt{rnd-init}     & bool   & Randomize initial activities & $\\{\\text{true}, \\text{false}\\}$ \\\\\n\\texttt{rfirst}       & int    & Base restart interval & $[1, 1e4]$ \\\\\n\\texttt{rinc}         & double & Restart interval increase factor & $(1.5, 4)$ \\\\\n\\texttt{gc-frac}      & double & Wasted memory fraction triggering garbage collection & $(0, 1)$ \\\\\n\\texttt{min-learnts} & int    & Minimum learnt clause limit & $[0, 1e6]$ \\\\\n\\bottomrule\n\\end{tabular}\n\\end{table}", "caption": "\\caption{ModSAT configuration parameters}", "label": "\\label{tab:modsat-params}", "tabular": "\\begin{tabular}{llp{7cm}l}\n\\toprule\n\\textbf{Parameter} & \\textbf{Type} & \\textbf{Description} & \\textbf{Search Space} \\\\\n\\midrule\n\\texttt{var-decay}    & double & Variable activity decay factor & $(0, 1)$ \\\\\n\\texttt{cla-decay}    & double & Clause activity decay factor & $(0, 1)$ \\\\\n\\texttt{rnd-freq}     & double & Frequency for random variable selection & $[0, 1]$ \\\\\n\\texttt{rnd-init}     & bool   & Randomize initial activities & $\\{\\text{true}, \\text{false}\\}$ \\\\\n\\texttt{rfirst}       & int    & Base restart interval & $[1, 1e4]$ \\\\\n\\texttt{rinc}         & double & Restart interval increase factor & $(1.5, 4)$ \\\\\n\\texttt{gc-frac}      & double & Wasted memory fraction triggering garbage collection & $(0, 1)$ \\\\\n\\texttt{min-learnts} & int    & Minimum learnt clause limit & $[0, 1e6]$ \\\\\n\\bottomrule\n\\end{tabular}", "subtables": []}, {"original": "\\begin{table}[ht!]\n\\centering\n\\caption{Kissat configuration parameters}\n\\label{tab:kissat-params}\n\\begin{tabular}{llp{7.5cm}l}\n\\toprule\n\\textbf{Parameter} & \\textbf{Type} & \\textbf{Description} & \\textbf{Search Space} \\\\\n\\midrule\n\\texttt{chrono}        & bool   & Enable chronological backtracking & $\\{0, 1\\}$ \\\\\n\\texttt{eliminate}     & bool   & Enable variable elimination & $\\{0, 1\\}$ \\\\\n\\texttt{forcephase}    & bool   & Force initial phase assignment & $\\{0, 1\\}$ \\\\\n\\texttt{minimize}      & bool   & Enable clause minimization & $\\{0, 1\\}$ \\\\\n\\texttt{phase}         & bool   & Set initial decision phase & $\\{0, 1\\}$ \\\\\n\\texttt{phasesaving}   & bool   & Enable phase saving during restarts & $\\{0, 1\\}$ \\\\\n\\texttt{probe}         & bool   & Enable failed literal probing & $\\{0, 1\\}$ \\\\\n\\texttt{reduceint}     & int    & Conflict interval for clause DB reduction & $\\{10^1, 10^2, 10^3, 10^4, 10^5\\}$ \\\\\n\\texttt{rephaseint}    & int    & Conflict interval for phase resetting & $\\{10^1, 10^2, 10^3, 10^4, 10^5\\}$ \\\\\n\\texttt{restartint}    & int    & Base restart interval (conflicts) & $\\{1, 10^2, 10^3, 10^4\\}$ \\\\\n\\texttt{restartmargin} & int    & Rapid restart margin threshold & $\\{0, 5, 10, 15, 20, 25\\}$ \\\\\n\\texttt{simplify}      & bool   & Enable periodic simplification & $\\{0, 1\\}$ \\\\\n\\texttt{stable}        & int    & Search stability mode (0=focused, 1=stable, 2=switching) & $\\{0, 1, 2\\}$ \\\\\n\\texttt{target}        & int    & Target phase selection strategy (0=negative, 1=positive, 2=best) & $\\{0, 1, 2\\}$ \\\\\n\\texttt{tier1}         & int    & Tier 1 glue limit for learned clauses & $\\{2, 3, 4, 5\\}$ \\\\\n\\texttt{tier2}         & int    & Tier 2 glue limit for learned clauses & $\\{6, 7, 8, 9, 10, 20, 50\\}$ \\\\\n\\bottomrule\n\\end{tabular}\n\\end{table}", "caption": "\\caption{Kissat configuration parameters}", "label": "\\label{tab:kissat-params}", "tabular": "\\begin{tabular}{llp{7.5cm}l}\n\\toprule\n\\textbf{Parameter} & \\textbf{Type} & \\textbf{Description} & \\textbf{Search Space} \\\\\n\\midrule\n\\texttt{chrono}        & bool   & Enable chronological backtracking & $\\{0, 1\\}$ \\\\\n\\texttt{eliminate}     & bool   & Enable variable elimination & $\\{0, 1\\}$ \\\\\n\\texttt{forcephase}    & bool   & Force initial phase assignment & $\\{0, 1\\}$ \\\\\n\\texttt{minimize}      & bool   & Enable clause minimization & $\\{0, 1\\}$ \\\\\n\\texttt{phase}         & bool   & Set initial decision phase & $\\{0, 1\\}$ \\\\\n\\texttt{phasesaving}   & bool   & Enable phase saving during restarts & $\\{0, 1\\}$ \\\\\n\\texttt{probe}         & bool   & Enable failed literal probing & $\\{0, 1\\}$ \\\\\n\\texttt{reduceint}     & int    & Conflict interval for clause DB reduction & $\\{10^1, 10^2, 10^3, 10^4, 10^5\\}$ \\\\\n\\texttt{rephaseint}    & int    & Conflict interval for phase resetting & $\\{10^1, 10^2, 10^3, 10^4, 10^5\\}$ \\\\\n\\texttt{restartint}    & int    & Base restart interval (conflicts) & $\\{1, 10^2, 10^3, 10^4\\}$ \\\\\n\\texttt{restartmargin} & int    & Rapid restart margin threshold & $\\{0, 5, 10, 15, 20, 25\\}$ \\\\\n\\texttt{simplify}      & bool   & Enable periodic simplification & $\\{0, 1\\}$ \\\\\n\\texttt{stable}        & int    & Search stability mode (0=focused, 1=stable, 2=switching) & $\\{0, 1, 2\\}$ \\\\\n\\texttt{target}        & int    & Target phase selection strategy (0=negative, 1=positive, 2=best) & $\\{0, 1, 2\\}$ \\\\\n\\texttt{tier1}         & int    & Tier 1 glue limit for learned clauses & $\\{2, 3, 4, 5\\}$ \\\\\n\\texttt{tier2}         & int    & Tier 2 glue limit for learned clauses & $\\{6, 7, 8, 9, 10, 20, 50\\}$ \\\\\n\\bottomrule\n\\end{tabular}", "subtables": []}, {"original": "\\begin{table}[ht!]\n\\centering\n\\caption{CaDiCaL configuration parameters}\n\\label{tab:cadical-params}\n\\begin{tabular}{llp{7cm}l}\n\\toprule\n\\textbf{Parameter} & \\textbf{Type} & \\textbf{Description} & \\textbf{Search Space} \\\\\n\\midrule\n\\texttt{chrono}       & int    & Chronological backtracking mode (0: none, 1: limited, 2: always) & $\\{0, 1, 2\\}$ \\\\\n\\texttt{elim}         & bool   & Enables variable elimination during simplification & $\\{0, 1\\}$ \\\\\n\\texttt{forcephase}   & bool   & Forces phase saving for decision variables & $\\{0, 1\\}$ \\\\\n\\texttt{minimize}     & bool   & Enables clause minimization during conflict analysis & $\\{0, 1\\}$ \\\\\n\\texttt{phase}        & bool   & Initial decision phase assignment (0: negative, 1: positive) & $\\{0, 1\\}$ \\\\\n\\texttt{probe}        & bool   & Enables probing (failed literal detection) & $\\{0, 1\\}$ \\\\\n\\texttt{reduceint}    & int    & Conflict interval for clause database reduction & $\\{10^2, 10^3, 10^4, 10^5\\}$ \\\\\n\\texttt{rephaseint}   & int    & Conflict interval for resetting variable phases & $\\{10^1, 10^2, 10^3, 10^4, 10^5\\}$ \\\\\n\\texttt{restartint}   & int    & Base restart interval (conflicts between restarts) & $\\{2, 10^2, 10^3, 10^4\\}$ \\\\\n\\texttt{restartmargin}& int    & Restart margin percentage (Luby sequence scaling) & $\\{0, 5, 10, 15, 20, 25\\}$ \\\\\n\\texttt{stabilize}    & bool   & Stabilizes search by limiting activity updates & $\\{0, 1\\}$ \\\\\n\\texttt{target}       & int    & Search target (0: SAT, 1: UNSAT, 2: balanced) & $\\{0, 1, 2\\}$ \\\\\n\\bottomrule\n\\end{tabular}\n\\end{table}", "caption": "\\caption{CaDiCaL configuration parameters}", "label": "\\label{tab:cadical-params}", "tabular": "\\begin{tabular}{llp{7cm}l}\n\\toprule\n\\textbf{Parameter} & \\textbf{Type} & \\textbf{Description} & \\textbf{Search Space} \\\\\n\\midrule\n\\texttt{chrono}       & int    & Chronological backtracking mode (0: none, 1: limited, 2: always) & $\\{0, 1, 2\\}$ \\\\\n\\texttt{elim}         & bool   & Enables variable elimination during simplification & $\\{0, 1\\}$ \\\\\n\\texttt{forcephase}   & bool   & Forces phase saving for decision variables & $\\{0, 1\\}$ \\\\\n\\texttt{minimize}     & bool   & Enables clause minimization during conflict analysis & $\\{0, 1\\}$ \\\\\n\\texttt{phase}        & bool   & Initial decision phase assignment (0: negative, 1: positive) & $\\{0, 1\\}$ \\\\\n\\texttt{probe}        & bool   & Enables probing (failed literal detection) & $\\{0, 1\\}$ \\\\\n\\texttt{reduceint}    & int    & Conflict interval for clause database reduction & $\\{10^2, 10^3, 10^4, 10^5\\}$ \\\\\n\\texttt{rephaseint}   & int    & Conflict interval for resetting variable phases & $\\{10^1, 10^2, 10^3, 10^4, 10^5\\}$ \\\\\n\\texttt{restartint}   & int    & Base restart interval (conflicts between restarts) & $\\{2, 10^2, 10^3, 10^4\\}$ \\\\\n\\texttt{restartmargin}& int    & Restart margin percentage (Luby sequence scaling) & $\\{0, 5, 10, 15, 20, 25\\}$ \\\\\n\\texttt{stabilize}    & bool   & Stabilizes search by limiting activity updates & $\\{0, 1\\}$ \\\\\n\\texttt{target}       & int    & Search target (0: SAT, 1: UNSAT, 2: balanced) & $\\{0, 1, 2\\}$ \\\\\n\\bottomrule\n\\end{tabular}", "subtables": []}], "figure": [{"original": "\\begin{figure*}[t]\n    \\centering\n        \\includegraphics[width=1.05\\textwidth]{Architecture.png}\n\\caption{\\textbf{Overview of AutoModSAT}.\n% \\textbf{a.} This figure illustrates the paradigm shift in solver code development methodologies. The traditional Human Craft approach requires SAT experts to manually rewrite solver functions for different scenarios, demanding extensive expertise and time investment. The second paradigm, Automatic Tune, employs algorithm selection or predefined search spaces for optimization but suffers from limited search capabilities and suboptimal efficiency. The latest paradigm, LLM Generation, leverages generative AI to autonomously produce heuristic rules, enabling efficient creation of human-unreachable heuristics while significantly enhancing solver performance.\nThis figure displays the workflow of AutoModSAT, which distinguishes itself from existing LLMs methods for algorithm design on challenges in large-scale, structurally complex solver codes. The whole process requires a basic SAT  algorithm (CDCL), initial prompt, and datasets in different scenarios as input, then involves four core components: (1) modularizing SAT solvers (ModSAT) based on CDCL algorithm; (2)  prompt optimization based on entropy; (3)  a presearch strategy to identifies function candidates for each datasets; and (4) iterative heuristics discovery. After selecting the function to be optimized, we use LLMs to generate code, and evaluate it on specific dataset if it is executed successfully. Better heuristics are then iteratively updated into the solver. This iterative refinement process continues until the final iteration, leading to systematic and adaptive code evolution.}\n\n\\label{fig:architecture}\n\\end{figure*}", "caption": "\\caption{\\textbf{Overview of AutoModSAT}.\n% \\textbf{a.} This figure illustrates the paradigm shift in solver code development methodologies. The traditional Human Craft approach requires SAT experts to manually rewrite solver functions for different scenarios, demanding extensive expertise and time investment. The second paradigm, Automatic Tune, employs algorithm selection or predefined search spaces for optimization but suffers from limited search capabilities and suboptimal efficiency. The latest paradigm, LLM Generation, leverages generative AI to autonomously produce heuristic rules, enabling efficient creation of human-unreachable heuristics while significantly enhancing solver performance.\nThis figure displays the workflow of AutoModSAT, which distinguishes itself from existing LLMs methods for algorithm design on challenges in large-scale, structurally complex solver codes. The whole process requires a basic SAT  algorithm (CDCL), initial prompt, and datasets in different scenarios as input, then involves four core components: (1) modularizing SAT solvers (ModSAT) based on CDCL algorithm; (2)  prompt optimization based on entropy; (3)  a presearch strategy to identifies function candidates for each datasets; and (4) iterative heuristics discovery. After selecting the function to be optimized, we use LLMs to generate code, and evaluate it on specific dataset if it is executed successfully. Better heuristics are then iteratively updated into the solver. This iterative refinement process continues until the final iteration, leading to systematic and adaptive code evolution.}", "label": "\\label{fig:architecture}", "subfigures": [], "figure_paths": ["Architecture.png"]}, {"original": "\\begin{figure*}[ht!] % Use figure* for spanning the width of the page in a two-column format\n    \\centering\n    \\begin{minipage}{0.5\\textwidth}\n        \\includegraphics[width=\\textwidth]{ModSAT_radar_chart0.png}\n        \\label{fig:radar}\n    \\end{minipage}\\hfill\n    \\begin{minipage}{0.5\\textwidth}\n        \\includegraphics[width=\\textwidth]{ModSAT_bar_chart.png}\n        \\label{fig:bar}\n    \\end{minipage}\n    \\vspace{0.5cm}\n\n    \\begin{minipage}{\\textwidth}\n        \\includegraphics[width=\\textwidth]{ModSAT_line_chart.png}\n        \\label{fig:line}\n    \\end{minipage}\n    % \\hfill\n    % \\begin{minipage}{0.5\\textwidth}\n    %     \\includegraphics[width=\\textwidth]{ModSAT_bar_chart.png}\n    % \\end{minipage}\n\\caption{\\textbf{PAR-2 over Different Datasets} \\textbf{a.} This figure provides a visualization of the PAR-2 values in Table~\\ref{tab:PAR-2}, which shows the overall superior performance of AutoModSAT across a wide range of datasets. More precisely, the plotted values are normalized for each dataset by $1 - \\frac{curr - min}{2*(max - min)} $, where $curr$ is the PAR-2 corresponding to a solver, and $min$ and $max$ correspond to the minimum and maximum PAR-2 values over all the tested solvers. Larger shadow area indicates better performance. \\textbf{b.} This figure provides a performance comparison between AutoModSAT and parameter-tuned ModSAT on improving the original ModSAT solver, where the vertical axis is the PAR-2 improvement ratio. \\textbf{c.} This figure illustrates the search process of AutoModSAT with three experiments for each dataset. The horizontal axis is the number of iterations, and the vertical axis is PAR-2 values.}\n\n\\label{fig:compare}\n\\end{figure*}", "caption": "\\caption{\\textbf{PAR-2 over Different Datasets} \\textbf{a.} This figure provides a visualization of the PAR-2 values in Table~\\ref{tab:PAR-2}, which shows the overall superior performance of AutoModSAT across a wide range of datasets. More precisely, the plotted values are normalized for each dataset by $1 - \\frac{curr - min}{2*(max - min)} $, where $curr$ is the PAR-2 corresponding to a solver, and $min$ and $max$ correspond to the minimum and maximum PAR-2 values over all the tested solvers. Larger shadow area indicates better performance. \\textbf{b.} This figure provides a performance comparison between AutoModSAT and parameter-tuned ModSAT on improving the original ModSAT solver, where the vertical axis is the PAR-2 improvement ratio. \\textbf{c.} This figure illustrates the search process of AutoModSAT with three experiments for each dataset. The horizontal axis is the number of iterations, and the vertical axis is PAR-2 values.}", "label": "\\label{fig:compare}", "subfigures": [], "figure_paths": ["ModSAT_radar_chart0.png", "ModSAT_bar_chart.png", "ModSAT_line_chart.png"]}, {"original": "\\begin{figure*}[ht!] % Use figure* for spanning the width of the page in a two-column format\n    \\centering\n    \\begin{minipage}{0.5\\textwidth}\n        \\includegraphics[width=\\textwidth]{code_example.png}\n        \\label{fig:left_image}\n    \\end{minipage}\\hfill\n    \\begin{minipage}{0.5\\textwidth}\n        \\includegraphics[width=\\textwidth]{code_example2.png}\n        \\label{fig:right_image}\n    \\end{minipage}\n\n\\caption{This figure shows two novel LLM-generated heuristic functions for SAT solvers and their original counterparts. (Left) The restart function implements a dynamic restart strategy using moving averages of Literal Block Distance (LBD) scores, enhancing traditional approaches. (Right) The varbump function innovatively scales activity increments based on the solver's current decision level. Both functions introduce unprecedented heuristic rules not previously proposed in existing solvers, demonstrating exceptional performance on EDA datasets.}\n\\label{fig:code}\n\\end{figure*}", "caption": "\\caption{This figure shows two novel LLM-generated heuristic functions for SAT solvers and their original counterparts. (Left) The restart function implements a dynamic restart strategy using moving averages of Literal Block Distance (LBD) scores, enhancing traditional approaches. (Right) The varbump function innovatively scales activity increments based on the solver's current decision level. Both functions introduce unprecedented heuristic rules not previously proposed in existing solvers, demonstrating exceptional performance on EDA datasets.}", "label": "\\label{fig:code}", "subfigures": [], "figure_paths": ["code_example.png", "code_example2.png"]}, {"original": "\\begin{figure}[ht!]\n\\begin{cppcode}{Maintain functions simple: Original function to modify}\nlbool Solver::search(int nof_conflicts){\n    // if there is a conflict\n    ...... ......\n    // if there is no conflict\n    if ((lbd_queue_size == 50 && 0.8 * fast_lbd_sum / lbd_queue_size > slow_lbd_sum / conflicts) || !withinBudget())\n        restart_function();\n\n    // Simplify the set of problem clauses:\n    if (decisionLevel() == 0 && !simplify())\n        return l_False;\n            \n    // Reduce the set of learnt clauses:\n        if (learnts.size()-nAssigns() >= max_learnts)\n                reduceDB();\n    if (rephase_condition())\n        rephase_function();\n        \n    Lit next = lit_Undef;\n    while (decisionLevel() < assumptions.size()){\n        // Perform user provided assumption:\n        Lit p = assumptions[decisionLevel()];\n        if (value(p) == l_True){\n            // Dummy decision level:\n            newDecisionLevel();\n            }else if (value(p) == l_False){\n                analyzeFinal(~p, conflict);\n                return l_False;\n            }else{\n                next = p;\n                break;\n            }\n        }\n\n    if (next == lit_Undef){\n        // New variable decision:\n        decisions++;\n        next = pickBranchLit();\n\n        if (next == lit_Undef)\n            // Model found:\n            return l_True;\n    }\n    newDecisionLevel();\n    uncheckedEnqueue(next);\n}\n\\end{cppcode}\n    \\caption{Illustration of principle {\\em Maintain functions simple and focus.}}\n    \\label{fig:rule1-1}\n\\end{figure}", "caption": "\\caption{Illustration of principle {\\em Maintain functions simple and focus.}}", "label": "\\label{fig:rule1-1}", "subfigures": [], "figure_paths": []}, {"original": "\\begin{figure}[ht!]\n\\begin{cppcode}{Maintain functions simple: modularized function to modify}\n// original function which has been modularized\nlbool Solver::search(int nof_conflicts){\n    ...... ......\n\n    if (restart_condition())\n        restart_function();\n    if (reduce_condition())\n        reduceDB();\n\n    if (rephase_condition())\n        rephase_function();\n        \n    ...... ......\n}\n\n// functions to modify\nbool Solver::rephase_condition() {\n    if (rephases >= rephase_limit) \n        return true;\n    else \n        return false;\n}\n\nbool Solver::reduce_condition() {\n    if (rephases >= rephase_limit) \n        return true;\n    else \n        return false;\n}\n\nbool Solver::restart_condition(){\n    if ((lbd_queue_size == 50 && 0.8 * fast_lbd_sum / lbd_queue_size > slow_lbd_sum / conflicts) || !withinBudget())\n        return true;\n    else\n        return false;\n}\n\\end{cppcode}\n    \\caption{Illustration of principle {\\em Maintain functions simple and focus}.}\n    \\label{fig:rule1-2}\n\\end{figure}", "caption": "\\caption{Illustration of principle {\\em Maintain functions simple and focus}.}", "label": "\\label{fig:rule1-2}", "subfigures": [], "figure_paths": []}, {"original": "\\begin{figure}[ht!]\n\\begin{cppcode}{Add class member variables}\n    // LBD heuristics\n    int lbd_queue[500],   // circled queue saved the recent 500 LBDs.\n        lbd_queue_size,   // The number of LBDs in this queue\n        lbd_queue_pos;  \n    double fast_lbd_sum, slow_lbd_sum;   \n\n    // rephase heuristics\n    int rephases, rephase_limit, rephase_count, threshold;\n    double last_rephase_progress;\n\n    // restart heuristics\n    int curr_restarts;\n    double last_restart_progress;\n\\end{cppcode}\n    \\caption{Illustration of principle {\\em Utilize class variables for shared information}}\n    \\label{fig:rule2-1}\n\\end{figure}", "caption": "\\caption{Illustration of principle {\\em Utilize class variables for shared information}}", "label": "\\label{fig:rule2-1}", "subfigures": [], "figure_paths": []}, {"original": "\\begin{figure}[ht!]\n\\begin{cppcode}{Prevent bugs: add more packages}\n#include <math.h>\n#include <unordered_set>\n#include <algorithm>\nusing namespace std;\n\\end{cppcode}\n    \\caption{Illustration of principle {\\em Proactively prevent bugs during heuristics discovery}}\n    \\label{fig:rule3-1}\n\\end{figure}", "caption": "\\caption{Illustration of principle {\\em Proactively prevent bugs during heuristics discovery}}", "label": "\\label{fig:rule3-1}", "subfigures": [], "figure_paths": []}, {"original": "\\begin{figure}[ht!]\n\\begin{cppcode}{Prevent Bugs: overloading functions}\n#include <type_traits>\n\ntemplate <typename T1, typename T2>\ntypename std::common_type<T1, T2>::type max(T1 a, T2 b) {\n    static_assert(std::is_integral<T1>::value && std::is_integral<T2>::value,\n                  \"max: Both types must be integers (int or long int)\");\n    return (a < b) ? b : a;\n}\n\ntemplate <typename T1, typename T2>\ntypename std::common_type<T1, T2>::type min(T1 a, T2 b) {\n    static_assert(std::is_integral<T1>::value && std::is_integral<T2>::value,\n                  \"min: Both types must be integers (int or long int)\");\n    return (a < b) ? a : b;\n}\n\ntemplate <typename T1, typename T2>\ntypename std::common_type<T1, T2>::type max(T1 a, T2 b) {\n    static_assert(std::is_floating_point<T1>::value && std::is_floating_point<T2>::value,\n                  \"max: Both types must be floating-point (float or double)\");\n    return (a < b) ? b : a;\n}\n\ntemplate <typename T1, typename T2>\ntypename std::common_type<T1, T2>::type min(T1 a, T2 b) {\n    static_assert(std::is_floating_point<T1>::value && std::is_floating_point<T2>::value,\n                  \"min: Both types must be floating-point (float or double)\");\n    return (a < b) ? a : b;\n}\n\\end{cppcode}\n    \\caption{Illustration of principle {\\em Proactively prevent bugs during heuristics discovery.}}\n    \\label{fig:rule3-2}\n\\end{figure}", "caption": "\\caption{Illustration of principle {\\em Proactively prevent bugs during heuristics discovery.}}", "label": "\\label{fig:rule3-2}", "subfigures": [], "figure_paths": []}, {"original": "\\begin{figure*}[htbp!]\n    \\centering\n        \\includegraphics[width=0.8\\textwidth]{ModSAT_bar_chart_prompt.png}\n\n\\caption{\\textbf{Comparison over Different Prompts}.  This figure shows the performance  of AutoModSAT using different prompts. The vertical axis shows the PAR-2 improvement ratio compared to the original solver, while the two coordinates in the horizontal axis correspond to the original prompt (Original) and optimized prompt (Updated), respectively.}\n\\label{fig:prompt}\n\\end{figure*}", "caption": "\\caption{\\textbf{Comparison over Different Prompts}.  This figure shows the performance  of AutoModSAT using different prompts. The vertical axis shows the PAR-2 improvement ratio compared to the original solver, while the two coordinates in the horizontal axis correspond to the original prompt (Original) and optimized prompt (Updated), respectively.}", "label": "\\label{fig:prompt}", "subfigures": [], "figure_paths": ["ModSAT_bar_chart_prompt.png"]}, {"original": "\\begin{figure}[ht!]\n\\begin{tcolorbox}[colback=gray!10!white, colframe=gray!50!black, title=Original Prompt]\n(Role) You are a SAT solver researcher trying to rewrite the \\{\\{ func\\_name \\}\\}  function(s). \\\\\n\n(Goal) Your goal is to improve the SAT solver by rewriting the \\{\\{ func\\_name \\}\\}  function(s), after reading and understanding the <key code> of SAT solver below.\\\\\n\n(Tips) Tips:\\\\\n1) Your rewrited function code must start with '''// start {function name}''' and end with '''// end {function name}''' \\\\\n2) Your rewrited function(s) code must be different from original code, not just rewrite code synonymous! \\\\\n3) You are not allowed to create your own new function(s) in the rewrited function(s).  You are not allowed to create your own new global variables, but you can use the global variables existing in the <key code>. \\\\\n4) Make sure the rewrited function(s) code can be executed correctly. \\\\\n\n<key code> of SAT solver is:\\\\\n\\{\\{ replace\\_key\\_code \\}\\}\n\n\\end{tcolorbox}\n\n\\begin{tcolorbox}[colback=gray!10!white, colframe=gray!50!black, title=Updated Prompt]\n(Role) You are a SAT solver researcher trying to improve the \\{\\{ func\\_name \\}\\} function. \\\\\n\n(Goal) Objective:\\\\\nYour goal is to improve the SAT solver by rewriting the \\{\\{ func\\_name \\}\\}  function. \\\\\n\nInstructions: \\\\\n1. Carefully read and comprehend the <key code> of the SAT solver provided below. \\\\\n2. Analyze potential improvements and devise a strategy for optimizing the heuristics of function. \\\\\n3. Deliver your improved function(s) with the following format:\\\\\n   - Begin with: `// start {function name}`\\\\\n   - End with: `// end {function name}`\\\\\n\n(Tips) Tips:\\\\\n1. Ensure that your rewritten function(s) are substantially different from the original, beyond mere synonym replacements.\\\\\n2. You may utilize existing global variables from the <key code>, but refrain from introducing new global variables.\\\\\n3. Verify that the rewritten function(s) execute correctly.\\\\\n\n\nTake a deep breath and think it step by step. \\\\\n\n<key code> of SAT solver is: \\\\\n\"\"\"\n\\{\\{ replace\\_key\\_code \\}\\}\n\"\"\"\n...\n\\end{tcolorbox}\n    \\caption{Comparison of original prompt and optimized prompt}\n    \\label{fig:coder_prompt}\n\\end{figure}", "caption": "\\caption{Comparison of original prompt and optimized prompt}", "label": "\\label{fig:coder_prompt}", "subfigures": [], "figure_paths": []}, {"original": "\\begin{figure*}[t]\n    \\centering\n        \\includegraphics[width=\\textwidth]{function_contribution.png}\n\\caption{Function Contribution: where the vertical axis lists different function candidates  and the horizontal axis denotes the frequency of contributions.}\n\n\\label{fig:functioncontribution}\n\\end{figure*}", "caption": "\\caption{Function Contribution: where the vertical axis lists different function candidates  and the horizontal axis denotes the frequency of contributions.}", "label": "\\label{fig:functioncontribution}", "subfigures": [], "figure_paths": ["function_contribution.png"]}, {"original": "\\begin{figure}[ht!]\n    \\centering\n        \\includegraphics[width=1.1\\textwidth]{HeuristicsDiscovery.png}\n        \\vspace{-2cm}\n\\caption{Details about heuristics discovery}\n\\label{fig:discovery}\n\\end{figure}", "caption": "\\caption{Details about heuristics discovery}", "label": "\\label{fig:discovery}", "subfigures": [], "figure_paths": ["HeuristicsDiscovery.png"]}, {"original": "\\begin{figure}\n\\begin{cppcode}{original claBumpActivity}\ninline void Solver::claBumpActivity (Clause& c) {\n        if ( (c.activity() += cla_inc) > 1e20 ) {\n            // Rescale:\n            for (int i = 0; i < learnts.size(); i++)\n                ca[learnts[i]].activity() *= 1e-20;\n            cla_inc *= 1e-20; } \n        }\n\\end{cppcode}\n\n\\begin{cppcode}{discovered claBumpActivity}\ninline void Solver::claBumpActivity (Clause& c) {\n    // Adaptive scaling based on clause length and conflict participation\n    if ((c.activity() += cla_inc) > 1e20) {\n        // Maintain minimum activity while scaling to preserve relevance\n        double scale_factor = 1e-20;\n        double min_activity = 1e-20;\n        for (int i = 0; i < learnts.size(); i++) {\n            ca[learnts[i]].activity() *= scale_factor;\n            if (ca[learnts[i]].activity() < min_activity)\n                ca[learnts[i]].activity() = min_activity;\n        }\n        cla_inc *= scale_factor;\n        \n        // Stabilize scaling by maintaining lower bound on clause activity\n        if (cla_inc < min_activity)\n            cla_inc = min_activity;\n    }\n    // Dynamic decay adjustment based on recent conflict rate\n    if (conflicts > 1000 && lbd_queue_size > 50) {\n        double conflict_scale = 1.0 - 0.01 * (lbd_queue_size / 50.0);\n        cla_inc *= conflict_scale > 0.8 ? conflict_scale : 0.8;\n    }\n}\n\\end{cppcode}\n    \\caption{Example of LLM discovered heuristics of claBumpActivity}\n    \\label{fig:claBumpActivity}\n\\end{figure}", "caption": "\\caption{Example of LLM discovered heuristics of claBumpActivity}", "label": "\\label{fig:claBumpActivity}", "subfigures": [], "figure_paths": []}, {"original": "\\begin{figure}\n\\begin{cppcode}{original varBumpActivity}\ninline void Solver::varBumpActivity(Var v, double inc) {\n    activity[v] += inc;\n    // Rescale condition to prevent floating-point overflow earlier\n    if (activity[v] > 1e50) {\n        for (int i = 0; i < nVars(); i++)\n            activity[i] *= 1e-50;\n        var_inc *= 1e-50;\n        }\n    }\n\\end{cppcode}\n\n\\begin{cppcode}{discoverd varBumpActivity}\ninline void Solver::varBumpActivity(Var v, double inc) {\n    // Scale the increment based on decision level to prioritize recent variables\n    double scaled_inc = inc * (1.0 + 0.1 * decisionLevel());\n    activity[v] += scaled_inc;\n    // More gradual rescaling that preserves relative ordering better\n    if (activity[v] > 1e100) {\n        double scale_factor = 1e-100;\n        for (int i = 0; i < nVars(); i++) {\n            activity[i] *= scale_factor;\n            // Prevent variables from becoming completely inactive\n            if (activity[i] < 1e-100) activity[i] = 1e-100;\n        }\n        var_inc *= scale_factor;\n    }\n    // Optimized heap update with early exit for common case\n    if (order_heap.inHeap(v)) {\n        if (activity[v] > activity[order_heap[0]]) {\n            order_heap.decrease(v);\n        }\n    } else if (decision[v] && value(v) == l_Undef) {\n        order_heap.insert(v);\n    }\n}\n\\end{cppcode}\n    \\caption{Example of LLM discovered heuristics of varBumpActivity}\n    \\label{fig:varBumpActivity}\n\\end{figure}", "caption": "\\caption{Example of LLM discovered heuristics of varBumpActivity}", "label": "\\label{fig:varBumpActivity}", "subfigures": [], "figure_paths": []}, {"original": "\\begin{figure}\n\\begin{cppcode}{original restart\\_condition}\nbool Solver::restart_condition(){\n    if ((lbd_queue_size == 50 && 0.8 * fast_lbd_sum / lbd_queue_size > slow_lbd_sum / conflicts) || !withinBudget())\n        return true;\n    else\n        return false;\n\n}\n\\end{cppcode}\n\n\\begin{cppcode}{discoverd restart\\_condition}\nbool Solver::restart_condition() {\n    // Base restart condition on conflict count\n    if (conflicts <= 0) return false;\n    \n    // Dynamic restart threshold based on recent solver performance\n    double restart_threshold;\n    \n    if (lbd_queue_size > 0) {\n        // Use both average LBD and conflict rate for adaptive restart\n        double avg_lbd = fast_lbd_sum / lbd_queue_size;\n        double conflict_rate = (double)conflictR / (double)conflicts;\n        \n        // Adjust threshold based on problem difficulty (higher LBD = harder problem)\n        restart_threshold = restart_first * (0.8 + 0.4 * avg_lbd) * (1.0 + 0.5 * conflict_rate);\n        \n        // More aggressive restart if we're making little progress\n        if (progressEstimate() - last_rephase_progress < 0.01) {\n            restart_threshold *= 0.7;\n        }\n    } else {\n        // Default threshold for initial phase\n        restart_threshold = restart_first;\n    }\n    \n    // Check if we've reached the threshold\n    if (conflictR >= restart_threshold) {\n        conflictR = 0;\n        return true;\n    }   \n    return false;\n}\n\\end{cppcode}\n    \\caption{Example of LLM discovered heuristics of restart condition}\n    \\label{fig:restartcondition}\n\\end{figure}", "caption": "\\caption{Example of LLM discovered heuristics of restart condition}", "label": "\\label{fig:restartcondition}", "subfigures": [], "figure_paths": []}, {"original": "\\begin{figure}\n\\begin{cppcode}{original restart\\_function}\nvoid Solver::restart_function(){\n    fast_lbd_sum = lbd_queue_size = lbd_queue_pos = 0;\n    int level = 0;\n    cancelUntil(level);\n}\n\\end{cppcode}\n\n\\begin{cppcode}{discovered restart\\_function}\nvoid Solver::restart_function() {\n\n    // Update restart statistics\n    static double fast_avg = 0, slow_avg = 0;\n    static int restart_count = 0;\n    \n    // Calculate moving averages of LBD scores\n    if (lbd_queue_size > 0) {\n        double curr_fast = fast_lbd_sum / lbd_queue_size;\n        fast_avg = 0.9 * fast_avg + 0.1 * curr_fast;\n        slow_avg = 0.99 * slow_avg + 0.01 * curr_fast;\n    }\n\n    // Determine restart level based on recent performance\n    int restart_level = 0;\n    if (fast_avg > 0 && slow_avg > 0) {\n        double ratio = fast_avg / slow_avg;\n        if (ratio > 1.2) {\n            // Recent conflicts are harder - do a full restart\n            restart_level = 0;\n        } else if (ratio > 1.0) {\n            // Partial restart - keep some learned clauses\n            restart_level = std::max(0, decisionLevel() / 2);\n        } else {\n            // Recent conflicts are easier - minimal restart\n            restart_level = std::max(0, decisionLevel() - 1);\n        }\n    }\n\n    // Reset LBD statistics\n    fast_lbd_sum = lbd_queue_size = lbd_queue_pos = 0;\n    \n    // Perform the restart\n    cancelUntil(restart_level);\n    \n    // Occasionally reduce the clause database after restarts\n    if (restart_count++ \\% 16 == 15) {\n        reduceDB();\n    }\n\n    // Rebuild the order heap to reflect any activity changes\n    rebuildOrderHeap();\n}\n\\end{cppcode}\n    \\caption{Example of LLM discovered heuristics of restart function}\n    \\label{fig:restartfunction}\n\\end{figure}", "caption": "\\caption{Example of LLM discovered heuristics of restart function}", "label": "\\label{fig:restartfunction}", "subfigures": [], "figure_paths": []}, {"original": "\\begin{figure}[ht!]\n\\begin{cppcode}{original rephase\\_condition}\nbool Solver::rephase_condition() {\n    if (rephases >= rephase_limit) return true;\n    else return false;\n}\n\\end{cppcode}\n\n\\begin{cppcode}{discovered rephase\\_condition}\nbool Solver::rephase_condition() {\n    // Adaptive rephasing based on progress and conflict density\n    const int base_rephase_limit = 1024;\n    const double progress_factor = 0.02;  // 2% of total variables\n    \n    if (conflictR < rephase_limit) \n        return false;\n\n    // Calculate normalized progress since last rephase\n    int progress = trail.size() - last_rephase_progress;\n    int progress_threshold = std::max(50, (int)(nVars() * progress_factor));\n    \n    // Dynamic limit adjustment based on search progress\n    if (progress < progress_threshold) {\n        // Stagnation detected - reduce next rephase interval\n        rephase_limit = std::max(base_rephase_limit, rephase_limit * 2/3);\n    } else {\n        // Good progress - expand next rephase interval\n        rephase_limit = std::min(base_rephase_limit * 16, rephase_limit * 3/2);\n    }\n\n    // Reset conflict counter and update progress tracker in rephase_function\n    return true;\n}\n\\end{cppcode}\n    \\caption{Example of LLM discovered heuristics of rephase condition}\n    \\label{fig:rephasecondition}\n\\end{figure}", "caption": "\\caption{Example of LLM discovered heuristics of rephase condition}", "label": "\\label{fig:rephasecondition}", "subfigures": [], "figure_paths": []}, {"original": "\\begin{figure}[ht!]\n\\begin{cppcode}{original rephase\\_function}\nvoid Solver::rephase_function() {\n    int var_nums = nVars();\n    conflictR = 0, rephases = 0, threshold *= 0.9, rephase_limit += 8192;Add commentMore actions\n    int phase_rand = rand() \\% 100;      \n    if ((phase_rand -= 40) < 0){\n        for (int i = 0; i < var_nums; i++){\n            polarity[i] = local_best[i];\n        }\n    }\n    else if ((phase_rand -= 25) < 0){\n        for (int i = 0; i < var_nums; i++){\n            polarity[i] = 1-local_best[i];\n        }\n    }\n    else if ((phase_rand -= 15) < 0){\n        for (int i = 0; i < var_nums; i++){\n            polarity[i] = !polarity[i];\n        }\n    }\n    else {\n        for (int i = 0; i < var_nums; i++){\n            polarity[i] = saved[i];\n        }\n    }\n}\n\\end{cppcode}\n    \\caption{Example of LLM discovered heuristics of rephase function}\n\\end{figure}", "caption": "\\caption{Example of LLM discovered heuristics of rephase function}", "label": null, "subfigures": [], "figure_paths": []}, {"original": "\\begin{figure}[ht!]\n\\begin{cppcode}{discovered rephase\\_function}\nvoid Solver::rephase_function() {\n    // Adaptive rephase limit adjustment\n    if (rephases > 0 && conflictR > last_rephase_progress) {\n        // Progress was made - be more aggressive with rephasing\n        rephase_limit = rephase_limit * 1.5;\n    } else {\n        // No progress - be more conservative\n        rephase_limit = rephase_limit * 0.9;\n        if (rephase_limit < 512) rephase_limit = 512;\n    }\n    last_rephase_progress = conflictR;\n    rephase_count++;\n\n    // Dynamic phase selection strategy\n    double rand_val = drand(random_seed);\n    if (rand_val < 0.4) {\n        // 40\\% chance: Use local best phases\n        for (int v = 0; v < nVars(); v++) {\n            polarity[v] = local_best[v];\n        }\n        if (verbosity >= 1) printf(\"| Rephase: Local best phases |\\n\");\n    } else if (rand_val < 0.7) {\n        // 30\\% chance: Invert all phases\n        for (int v = 0; v < nVars(); v++) {\n            polarity[v] = !polarity[v];\n        }\n        if (verbosity >= 1) printf(\"| Rephase: Inverted all phases |\\n\");\n    } else if (rand_val < 0.9) {\n        // 20\\% chance: Random phases for variables with low activity\n        double activity_threshold = 0.2 * var_inc;\n        for (int v = 0; v < nVars(); v++) {\n            if (activity[v] < activity_threshold) {\n                polarity[v] = drand(random_seed) < 0.5;\n            }\n        }\n        if (verbosity >= 1) printf(\"| Rephase: Randomized low-activity phases |\\n\");\n    } else {\n        // 10\\% chance: Original user phases\n        for (int v = 0; v < nVars(); v++) {\n            if (user_pol[v] != l_Undef) {\n                polarity[v] = (user_pol[v] == l_True);\n            }\n        }Add commentMore actions\n        if (verbosity >= 1) printf(\"| Rephase: Reset to user phases |\\n\");\n    }\n\n    // Reset the threshold for next local best phase tracking\n    threshold = trail.size() * 0.8;\n    cancelUntil(0);\n}\n\\end{cppcode}\n    \\caption{Example of LLM discovered heuristics of rephase function}\n    \\label{fig:rephasefunction}\n\\end{figure}", "caption": "\\caption{Example of LLM discovered heuristics of rephase function}", "label": "\\label{fig:rephasefunction}", "subfigures": [], "figure_paths": []}, {"original": "\\begin{figure}[ht!]\n\\begin{cppcode}{original reduce\\_condition}\nbool Solver::reduce_condition()\n{   \n    if (learnts.size() >= max_learnts)  return true;\n    else return false;\n}\n\\end{cppcode}\n\n\\begin{cppcode}{discovered reduce\\_condition}\nbool Solver::reduce_condition()\n{\n    // Check if we've reached the absolute limit of learnt clausesAdd commentMore actions\n    if (learnts.size() >= max_learnts) return true;\n    \n    // Consider memory pressure and garbage collection needs\n    if (ca.wasted() > ca.size() * garbage_frac * 0.8) return true;\n    \n    // Consider the ratio between learnt and original clauses\n    if (learnts.size() > 0 && learnts.size() > 2 * nClauses()) return true;\n    \n    // Consider recent solver performance (conflict rate)\n    if (conflictR > 1000 && learnts.size() > max_learnts * 0.8) return true;\n    \n    return false;\n}\n\\end{cppcode}\n    \\caption{Example of LLM discovered heuristics of reduce condition}\n    \\label{fig:reducecondition}\n\\end{figure}", "caption": "\\caption{Example of LLM discovered heuristics of reduce condition}", "label": "\\label{fig:reducecondition}", "subfigures": [], "figure_paths": []}], "equations": [], "algorithm": ["\\begin{algorithm2e}[t]\n\\caption{CDCL Framework}\n\\label{alg:CDCL}\n\\textbf{Input:} A CNF $F$ of SAT instance\\;\n\\textbf{Initialization: } decision level $d \\leftarrow 0$, current assignment of variables $\\mathcal{X} \\leftarrow \\emptyset$\\;\n\n\\While{\\textbf{True}}{\n$\\mathcal{X} \\leftarrow \\textbf{Unit Propagation}(F,\\mathcal{X})$\\;\n\\eIf{Conflicts are detected in $\\mathcal{X}$}{\n\\eIf{$d == 0$}{return \\textsc{UNSAT}}\n{$\\mathcal{C}_{conflict}, d_{backtrack} \\leftarrow \\textbf{Analyze Conflict}(F,\\mathcal{X})$ \\;\n$C_{learned} \\leftarrow \\textbf{Learn Clause}(\\mathcal{C}_{conflict},\\mathcal{X})$ \\;\n$F \\leftarrow F \\land C_{learned}$\\;\n$\\mathcal{X} \\leftarrow \\textbf{Backtrack}(\\mathcal{X},d_{backtrack})$\\;\n$d \\leftarrow d_{backtrack}$\\;\n}\n}\n{\n\\eIf{All variables are assigned with a value}{return \\textsc{SAT}}\n{\n$d \\leftarrow d + 1$\\;\n$\\mathcal{X} \\leftarrow \\textbf{Make Decision}(\\mathcal{X})$\n}\n}\n}\n\\end{algorithm2e}", "\\begin{algorithm2e}[ht!]\n\\caption{ModSAT}\n\\label{alg:modsat}\n\\textbf{Input:} A CNF $F$ of SAT instance\\;\n\\textbf{Initialization: } decision level $d \\leftarrow 0$, current assignment of variables $\\mathcal{X} \\leftarrow \\emptyset$\\;\n\n\\While{\\textbf{True}}{\n$\\mathcal{X} \\leftarrow \\textbf{Unit Propagation}(F,\\mathcal{X})$\\;\n\\eIf{Conflicts are detected in $\\mathcal{X}$}{\n\\eIf{$d == 0$}{return \\textsc{UNSAT}}\n{$\\mathcal{C}_{conflict}, d_{backtrack} \\leftarrow \\textbf{Analyze Conflict}(F,\\mathcal{X})$ \\;\n$C_{learned} \\leftarrow \\textbf{Learn Clause}(\\mathcal{C}_{conflict},\\mathcal{X})$ \\;\n$F \\leftarrow F \\land C_{learned}$\\;\n$\\mathcal{X} \\leftarrow \\textbf{Backtrack}(\\mathcal{X},d_{backtrack})$\\;\n$d \\leftarrow d_{backtrack}$\\;\n}\n\n\\eIf{Restart condition}{$d \\leftarrow \\textbf{Restart}(d)$}{ continue }\n\\eIf{Rephase condition}{$\\mathcal{X} \\leftarrow \\textbf{Rephase}(\\mathcal{X})$}{ continue }\n\\eIf{Reduce condition}{$C_{learned} \\leftarrow \\textbf{Reduce}(C_{learned})$}{ continue }\n}\n{\n\\eIf{All variables are assigned with a value}{return \\textsc{SAT}}\n{\n$d \\leftarrow d + 1$\\;\n$\\mathcal{X} \\leftarrow \\textbf{Make Decision}(\\mathcal{X})$\n}\n}\n}\n\\end{algorithm2e}", "\\begin{algorithm2e}[t]\n\\caption{Automatic Prompt Optimization}\n\\label{alg:prompt}\n\\SetAlgoLined\n\\DontPrintSemicolon\n\\KwIn{initial prompt template $P$, solver codebase $S$, max\\_iterations $i$, prompt optimized part $R =\\{ Role, Goal, Tips \\}$}\n\\KwOut{optimized prompt template $P^*$}\n$i \\gets 10$ \\tcp*{prompt optimization iterations}\n$j \\gets 20$ \\tcp*{number of code generation in each iteration}\n\\While{$i \\ge 0$}{\n    select prompt part $r$ from $R$ uniformly at random \\\\\n     $P' \\gets$ refine\\_prompt($r, P$) \\tcp*{LLMs refine the prompt template}\n    \\While{$j \\ge 0$}{\n    generated code $c \\gets \\text{call\\_llm}(\\textit{current\\_prompt})$ \\\\\n    compilation error $e \\gets$ compile($c$, $S$) \\\\\n    \\eIf{$\\neg e $}{\n            $C \\gets C \\cup c$\n            }\n    {\n        \n        $\\text{execute\\_code}(\\textit{corrected\\_code})$\\;\n    }\n    $j \\gets j - 1$\\;\n    }\n            \n    diversity $ d_i \\gets \\text{compute\\_code\\_diversity}(C)$\\;\n    success rate $ s_i \\gets \\text{compute\\_code\\_success}(C)$\\;\n\n    \\eIf{$d_i > d$ and $s_i > threshold $}{\n        $d \\gets d_i $\\\\\n    $P \\gets \\text{update\\_prompt}(S, P')$\\;\n    }\n\n    $i \\gets i - 1$\\;\n}\n\\end{algorithm2e}", "\\begin{algorithm2e}[ht!]\n\\caption{PreSearch Strategy in AutoModSAT}\\label{alg:autosat-pre}\n\\textbf{Input:} Datasets $P$, modularized SAT solver with seven functions $\\{h_1,\\ldots,h_7\\}$, prompt template, baseline functions $\\{b_1,\\ldots,b_7\\}$ \\\\\n\\textbf{Phase 1: PreSearch Function Candidate}\n$P_{\\text{compact}} \\leftarrow$ 50\\% representative instances from $P$ \\\\\n$R \\leftarrow \\emptyset$  \\tcp*{Retained function set}\n\\For{each function $h_i \\in \\{h_1,\\ldots,h_7\\}$}{\n    $A_{\\text{test}} \\leftarrow$ build solver replacing $h_i$ with baseline $b_i$ \\\\\n    $f_i, s_i \\leftarrow$ evaluate($A_{\\text{test}}$, $P_{\\text{compact}}$) \\tcp*{Get PAR-2 metric} \n}\n$F \\leftarrow $ sort($f_1, ..., f_7$) \\tcp*{Sort PAR-2 metric in different functions}\nGet top 4 function index $R$ from $F$ \\\\\n\n\\textbf{Phase 2: Evolutionary Algorithm Optimization} \n$A \\leftarrow$ solver with functions: $(\\forall i \\in R: h_i) \\cup (\\forall i \\notin R: b_i)$ \\\\\n$f^* \\leftarrow$ evaluate($A$, $P$)  \\tcp*{Full dataset evaluation}\n\n$\\text{evalBudget} \\leftarrow 50$  \\tcp*{Maximum evaluations}\n\n\\While{evalBudget $>0$}{\n    $M \\leftarrow \\emptyset$ \\\\\n    $\\ell \\sim \\text{Bin}(|R|,\\frac{1}{|R|})$  \\tcp*{Sample modification count}\n    chosen $\\ell$ distinct values $M \\leftarrow \\{m_0, \\ldots, m_\\ell\\}$ from $R$ uniformly at random\\;\n    Generate new functions $\\{h'_m\\}_{m\\in M}$ via LLM using $A$ and $M$ \\\\\n    $A' \\leftarrow$ update $A$ with $\\{h'_m\\}_{m\\in M}$ \\\\\n    $f(A') \\leftarrow$ evaluate($A'$, $P$) \\\\\n    \\If{$f(A') \\leq f^*$}{\n        $A \\leftarrow A'$ \\\\\n        $f^* \\leftarrow f(A')$\n    }\n    $\\text{evalBudget} \\leftarrow \\text{evalBudget} - 1$\n}\n\\end{algorithm2e}"], "sections": {"Introduction": {"content": "\n\nSatisfiability problem (SAT), a fundamental question in logic and computer science, seeks whether there exists an assignment to variables in a given Boolean formula to make it true. As the first proven NP-complete problem\\cite{npc}, SAT holds immense theoretical significance, and serves as a cornerstone of the computational complexity theory. Efficient solutions to SAT would imply efficient solutions for all the problems in the NP class. Moreover, SAT arises from a wide range of applications, such as software verification, artificial intelligence, automated reasoning, cryptography, and scheduling~\\cite{satsurvey17}. Modern SAT solvers, driven by cutting-edge algorithms and heuristics, serve as a backbone for mission-critical industrial applications, enabling breakthroughs in semiconductor manufacturing, cybersecurity, and mission-critical software development~\\cite{satsurvey19}.\n\n\n\n\n\n\nAfter decades of development and refinement, modern SAT solvers are equipped with complex heuristics and have largely resisted theoretical average-case analysis. However, industry users still need to devote massive efforts to customize different SAT solvers for different real-world applications, which requires labor-intensive modifications by experts. For example, the Electronic Design Automation (EDA) task requires SAT solvers to handle various complex problem instances ~\\cite{edasurvey}. To address this requirement, hyperparameter optimization approaches, which also refer to as algorithm configuration, have been developed for automated SAT solver improvement\\cite{satautomation, satparameter, satparameter2} such that they can automatically choose well-performing settings for the given problem instance. Whereas, these frameworks suffer from inherent limitations of manually-defined search spaces and suboptimal performance improvements.\n\n\nLarge Language Models (LLMs), the recent fascinating advance in generative artificial intelligence (AI)~\\cite{gpt4, deepseekv3, deepseekr1, qwen, qwen3, llama, gemini}, provide new opportunities to surpass the limitations of manually designed frameworks~\\cite{algorithmdesign}. After DeepMind's pioneering work on complex mathematical and bin-packing problems~\\cite{FunSearch}, LLMs have demonstrated promising applications in automated algorithm design\\cite{eoh, reevo, autosat, droc, hsevo, extracting, alphaevolve}.  \nHowever, few studies have been successfully done on optimizing complex programs such as modern SAT solvers, due to challenges of the intricate data structures and excessive codebase scales. These complex solvers often employ carefully customized data structures to improve computational efficiency, but meanwhile bring significant adaptation barriers for automated optimization~\\cite{autosat}. In addition, while the conventional token length limit for large language models (LLMs) is around $200k$200k tokens~\\cite{longcontext, longcontext2}, the SOTA SAT solvers, such as Kissat~\\cite{kissat} and Cadical~\\cite{cadical},  have been refined over decades and thus have more than $250k$250k tokens. This fact raises the obstacle of utilizing LLMs to enhance the performance of SAT solvers. \n\n\\begin{figure*}[t]\n    \\centering\n        \\includegraphics[width=1.05\\textwidth]{Architecture.png}\n\\caption{\\textbf{Overview of AutoModSAT}.\n% \\textbf{a.} This figure illustrates the paradigm shift in solver code development methodologies. The traditional Human Craft approach requires SAT experts to manually rewrite solver functions for different scenarios, demanding extensive expertise and time investment. The second paradigm, Automatic Tune, employs algorithm selection or predefined search spaces for optimization but suffers from limited search capabilities and suboptimal efficiency. The latest paradigm, LLM Generation, leverages generative AI to autonomously produce heuristic rules, enabling efficient creation of human-unreachable heuristics while significantly enhancing solver performance.\nThis figure displays the workflow of AutoModSAT, which distinguishes itself from existing LLMs methods for algorithm design on challenges in large-scale, structurally complex solver codes. The whole process requires a basic SAT  algorithm (CDCL), initial prompt, and datasets in different scenarios as input, then involves four core components: (1) modularizing SAT solvers (ModSAT) based on CDCL algorithm; (2)  prompt optimization based on entropy; (3)  a presearch strategy to identifies function candidates for each datasets; and (4) iterative heuristics discovery. After selecting the function to be optimized, we use LLMs to generate code, and evaluate it on specific dataset if it is executed successfully. Better heuristics are then iteratively updated into the solver. This iterative refinement process continues until the final iteration, leading to systematic and adaptive code evolution.}\n\n\\label{fig:architecture}\n\\end{figure*}\n    \\centering\n        \\includegraphics[width=1.05\\textwidth]{Architecture.png}\n\\caption{\\textbf{Overview of AutoModSAT}.\n% \\textbf{a.} This figure illustrates the paradigm shift in solver code development methodologies. The traditional Human Craft approach requires SAT experts to manually rewrite solver functions for different scenarios, demanding extensive expertise and time investment. The second paradigm, Automatic Tune, employs algorithm selection or predefined search spaces for optimization but suffers from limited search capabilities and suboptimal efficiency. The latest paradigm, LLM Generation, leverages generative AI to autonomously produce heuristic rules, enabling efficient creation of human-unreachable heuristics while significantly enhancing solver performance.\nThis figure displays the workflow of AutoModSAT, which distinguishes itself from existing LLMs methods for algorithm design on challenges in large-scale, structurally complex solver codes. The whole process requires a basic SAT  algorithm (CDCL), initial prompt, and datasets in different scenarios as input, then involves four core components: (1) modularizing SAT solvers (ModSAT) based on CDCL algorithm; (2)  prompt optimization based on entropy; (3)  a presearch strategy to identifies function candidates for each datasets; and (4) iterative heuristics discovery. After selecting the function to be optimized, we use LLMs to generate code, and evaluate it on specific dataset if it is executed successfully. Better heuristics are then iteratively updated into the solver. This iterative refinement process continues until the final iteration, leading to systematic and adaptive code evolution.}\n\n\\label{fig:architecture}\n\n\nTo tackle the challenges mentioned above, we propose AutoModSAT, an LLM-based automated SAT solver that is capable of generating competitive heuristics {\\em tailored to specific problem instances}\\em tailored to specific problem instances and thus \\emph{eliminates repetitive manual tunings across different application scenarios}. By leveraging LLM models, AutoModSAT is able to \\emph{discover competitive heuristics programs beyond the human-designed search space} in traditional hyperparameter optimization methods. Furthermore, we develop a well-defined modularized architecture \\emph{to overcome the token length limitations} of LLMs when working on complex solvers.\nExperimental results show that AutoModSAT achieves significant performance improvements across multiple datasets compared to commonly used SOTA SAT solvers such as Kissat and Cadical. Moreover, AutoModSAT generally outperforms traditional hyperparameter optimization techniques in terms of both solution quality and computational efficiency.\n\nThis paper is structured as follows. Firstly, we outline the key components of AutoModSAT, including the newly developed modularized SAT solver to optimize, automatic prompt optimization, the presearch strategy, and heuristics discovery. Secondly, we evaluate the performance of AutoModSAT across diverse scenario datasets, demonstrating its outstanding performance compared to current SOTA SAT solvers. Then we discuss the insights obtained from AutoModSAT, potential limitations and future research directions. Finally, we provide a detailed description of each component within AutoModSAT, elaborating on its design principles and implementation details.\n\n\n\n\n\n\n\n", "appendix": false}, "Results": {"content": "\n \n\\subsection*{AutoModSAT: An automatic SAT solver optimization framework}\n\n\n\n\n\n\nAutoModSAT is an LLM-powered framework designed to optimize complex solvers for SAT problems. The whole framework is shown in Figure~\\ref{fig:architecture}, which comprises four core components. \n\n\n\\begin{itemize}\n    \\item \\emph{Modularized SAT Solver.}\n   In order to meet the token length limit and compatability of LLMs, we introduce ModSAT, a modularized SAT solver with well-designed functions. ModSAT is developed based on three principles,as detailed in the Methods section, with its pseudocode provided in Supplementary Algorithm ~\\ref{alg:modsat}. Rather than asking LLMs to generate the complete implementations from scratch, we define {\\em seven} critical heuristics in ModSAT that can significantly affect the performance of SAT solvers as a search space for LLMs to explore. Therefore, AutoModSAT can be expressed as a mapping from a search space of heuristics to a solver, given by $ \\{h_1, h_2, \\ldots, h_7\\} \\mapsto A$, where each $h_i$ represents a heuristic associated with a function. \n   The modularized solver enables LLMs to modify heuristics locally without disrupting components in other unrelated functions, facilitating reliable and efficient program generation. \n    % \\item \\emph{Search Space Formulation.} Rather than asking LLMs to generate the complete implementations from scratch, we define a structured search space of SAT solvers. Practically, we extract seven critical heuristics that can significantly affect the performance of SAT solvers and leverage LLMs to explore competitive implementations for these heuristics particularly.\n    \\item \\emph{Automatic Prompt Optimization.} Diverse prompts can enhance the output of LLMs, which enable AutoModSAT to discover more effective heuristics.\n  To this end, we adopt an unsupervised automatic prompt optimization method to increase the diversity of LLMs' output, which can enhance the performance of discovered heuristics  while minimize labor costs of prompt engineering.\n    \\item \\emph{Presearch Strategy.} The formulated search space should not only enable us to generate competitive solvers but also enhance our understanding of the LLM-based searching process itself. This insight motivates us to identify an appropriate search strategy, tailored to the landscape of searching SAT solvers. Specifically, A presearch strategy incorporating preliminary candidate pruning and evolutionary refinement using $(1+\\lambda)EA$ is introduced in this paper to guide LLMs to obtain competitive SAT solvers automatically.\n    \\item \\emph{Heuristics Discovery.} After  function candidates and prompts are obtained, we input them to LLMs to discover promising heuristics in different scenarios, leading to the final form of AutoModSAT. Extensive experiments across multiple benchmark datasets demonstrate significant improvements of AutoModSAT in efficiency and effectiveness, and provide a valuable guidance for future SAT research.\n\n\\end{itemize}\\begin{itemize}\n    \\item \\emph{Modularized SAT Solver.}\n   In order to meet the token length limit and compatability of LLMs, we introduce ModSAT, a modularized SAT solver with well-designed functions. ModSAT is developed based on three principles,as detailed in the Methods section, with its pseudocode provided in Supplementary Algorithm ~\\ref{alg:modsat}. Rather than asking LLMs to generate the complete implementations from scratch, we define {\\em seven} critical heuristics in ModSAT that can significantly affect the performance of SAT solvers as a search space for LLMs to explore. Therefore, AutoModSAT can be expressed as a mapping from a search space of heuristics to a solver, given by $ \\{h_1, h_2, \\ldots, h_7\\} \\mapsto A$, where each $h_i$ represents a heuristic associated with a function. \n   The modularized solver enables LLMs to modify heuristics locally without disrupting components in other unrelated functions, facilitating reliable and efficient program generation. \n    % \\item \\emph{Search Space Formulation.} Rather than asking LLMs to generate the complete implementations from scratch, we define a structured search space of SAT solvers. Practically, we extract seven critical heuristics that can significantly affect the performance of SAT solvers and leverage LLMs to explore competitive implementations for these heuristics particularly.\n    \\item \\emph{Automatic Prompt Optimization.} Diverse prompts can enhance the output of LLMs, which enable AutoModSAT to discover more effective heuristics.\n  To this end, we adopt an unsupervised automatic prompt optimization method to increase the diversity of LLMs' output, which can enhance the performance of discovered heuristics  while minimize labor costs of prompt engineering.\n    \\item \\emph{Presearch Strategy.} The formulated search space should not only enable us to generate competitive solvers but also enhance our understanding of the LLM-based searching process itself. This insight motivates us to identify an appropriate search strategy, tailored to the landscape of searching SAT solvers. Specifically, A presearch strategy incorporating preliminary candidate pruning and evolutionary refinement using $(1+\\lambda)EA$ is introduced in this paper to guide LLMs to obtain competitive SAT solvers automatically.\n    \\item \\emph{Heuristics Discovery.} After  function candidates and prompts are obtained, we input them to LLMs to discover promising heuristics in different scenarios, leading to the final form of AutoModSAT. Extensive experiments across multiple benchmark datasets demonstrate significant improvements of AutoModSAT in efficiency and effectiveness, and provide a valuable guidance for future SAT research.\n\n\\end{itemize}\n    \\item \\emph{Modularized SAT Solver.}\n   In order to meet the token length limit and compatability of LLMs, we introduce ModSAT, a modularized SAT solver with well-designed functions. ModSAT is developed based on three principles,as detailed in the Methods section, with its pseudocode provided in Supplementary Algorithm ~\\ref{alg:modsat}. Rather than asking LLMs to generate the complete implementations from scratch, we define {\\em seven}\\em seven critical heuristics in ModSAT that can significantly affect the performance of SAT solvers as a search space for LLMs to explore. Therefore, AutoModSAT can be expressed as a mapping from a search space of heuristics to a solver, given by $ \\{h_1, h_2, \\ldots, h_7\\} \\mapsto A$ \\{h_1, h_2, \\ldots, h_7\\} \\mapsto A, where each $h_i$h_i represents a heuristic associated with a function. \n   The modularized solver enables LLMs to modify heuristics locally without disrupting components in other unrelated functions, facilitating reliable and efficient program generation. \n    \\item \\emph{Automatic Prompt Optimization.} Diverse prompts can enhance the output of LLMs, which enable AutoModSAT to discover more effective heuristics.\n  To this end, we adopt an unsupervised automatic prompt optimization method to increase the diversity of LLMs' output, which can enhance the performance of discovered heuristics  while minimize labor costs of prompt engineering.\n    \\item \\emph{Presearch Strategy.} The formulated search space should not only enable us to generate competitive solvers but also enhance our understanding of the LLM-based searching process itself. This insight motivates us to identify an appropriate search strategy, tailored to the landscape of searching SAT solvers. Specifically, A presearch strategy incorporating preliminary candidate pruning and evolutionary refinement using $(1+\\lambda)EA$(1+\\lambda)EA is introduced in this paper to guide LLMs to obtain competitive SAT solvers automatically.\n    \\item \\emph{Heuristics Discovery.} After  function candidates and prompts are obtained, we input them to LLMs to discover promising heuristics in different scenarios, leading to the final form of AutoModSAT. Extensive experiments across multiple benchmark datasets demonstrate significant improvements of AutoModSAT in efficiency and effectiveness, and provide a valuable guidance for future SAT research.\n\n\n\nOverall, AutoModSAT can deliver superior performance without requiring additional instance-specific fine-tuning workload, which can significantly reduces both time and labor costs in real-world applications. To our best knowledge, this is the first successful attempt to utilize LLMs to optimize large-scale solvers that have complex customized data structures and long-text codes. Based on the insights obtained from our practice in this work, this LLM-based automation framework has the potential to be extended to optimize other complex solvers.\n\\begin{figure*}[ht!] % Use figure* for spanning the width of the page in a two-column format\n    \\centering\n    \\begin{minipage}{0.5\\textwidth}\n        \\includegraphics[width=\\textwidth]{ModSAT_radar_chart0.png}\n        \\label{fig:radar}\n    \\end{minipage}\\hfill\n    \\begin{minipage}{0.5\\textwidth}\n        \\includegraphics[width=\\textwidth]{ModSAT_bar_chart.png}\n        \\label{fig:bar}\n    \\end{minipage}\n    \\vspace{0.5cm}\n\n    \\begin{minipage}{\\textwidth}\n        \\includegraphics[width=\\textwidth]{ModSAT_line_chart.png}\n        \\label{fig:line}\n    \\end{minipage}\n    % \\hfill\n    % \\begin{minipage}{0.5\\textwidth}\n    %     \\includegraphics[width=\\textwidth]{ModSAT_bar_chart.png}\n    % \\end{minipage}\n\\caption{\\textbf{PAR-2 over Different Datasets} \\textbf{a.} This figure provides a visualization of the PAR-2 values in Table~\\ref{tab:PAR-2}, which shows the overall superior performance of AutoModSAT across a wide range of datasets. More precisely, the plotted values are normalized for each dataset by $1 - \\frac{curr - min}{2*(max - min)} $, where $curr$ is the PAR-2 corresponding to a solver, and $min$ and $max$ correspond to the minimum and maximum PAR-2 values over all the tested solvers. Larger shadow area indicates better performance. \\textbf{b.} This figure provides a performance comparison between AutoModSAT and parameter-tuned ModSAT on improving the original ModSAT solver, where the vertical axis is the PAR-2 improvement ratio. \\textbf{c.} This figure illustrates the search process of AutoModSAT with three experiments for each dataset. The horizontal axis is the number of iterations, and the vertical axis is PAR-2 values.}\n\n\\label{fig:compare}\n\\end{figure*} \\centering\n    {0.5\\textwidth}0.5\\textwidth\n        \\includegraphics[width=\\textwidth]{ModSAT_radar_chart0.png}\n        \\label{fig:radar}\n    \\hfill\n    {0.5\\textwidth}0.5\\textwidth\n        \\includegraphics[width=\\textwidth]{ModSAT_bar_chart.png}\n        \\label{fig:bar}\n    \n    \\vspace{0.5cm}\n\n    {\\textwidth}\\textwidth\n        \\includegraphics[width=\\textwidth]{ModSAT_line_chart.png}\n        \\label{fig:line}\n    \n    \\caption{\\textbf{PAR-2 over Different Datasets} \\textbf{a.} This figure provides a visualization of the PAR-2 values in Table~\\ref{tab:PAR-2}, which shows the overall superior performance of AutoModSAT across a wide range of datasets. More precisely, the plotted values are normalized for each dataset by $1 - \\frac{curr - min}{2*(max - min)} $, where $curr$ is the PAR-2 corresponding to a solver, and $min$ and $max$ correspond to the minimum and maximum PAR-2 values over all the tested solvers. Larger shadow area indicates better performance. \\textbf{b.} This figure provides a performance comparison between AutoModSAT and parameter-tuned ModSAT on improving the original ModSAT solver, where the vertical axis is the PAR-2 improvement ratio. \\textbf{c.} This figure illustrates the search process of AutoModSAT with three experiments for each dataset. The horizontal axis is the number of iterations, and the vertical axis is PAR-2 values.}\n\n\\label{fig:compare}\n\n\n\n\n\n\n\n\n\n\n\n\n\\subsection*{Discovery of promising heuristics}\n\\paragraph{Datasets}Datasets We selected $11$11 datasets to test the capabilities of AutoModSAT, consisting of $7$7 datasets from the SAT Competition 2023 and 2024 ~\\cite{sat2023, sat2024}, $3$3 datasets generated by Picat~\\cite{picat}, and another dataset from real industrial EDA scenarios. \nFor the selection of SAT Competition datasets, we filter out families with fewer than twenty instances, and select datasets with substaintial variations in average solving times which proves beneficial for comprehensively evaluating a solver's performance across diverse data types.  This results in a total of $7$7 families of instances: argumentation\\_2023, argumentatio\\_2024, cryptography-ascon, register-allocation, social-golfer, hashtable-safety. \nAnother $3$3 datasets are manually generated by the Picat tool, including KnightTour, MineSweeper, and Zamkeller, which can formulate constrained satisfied problems into Conjunctive Normal Form (CNF) formulas~\\cite{picat}. \nThe remaining dataset is from an industrial EDA scenario, which contains 50 industrial instances derived from combinational equivalence checking problems. Each instance originates from converting a miter circuit structure into CNF. We summarize the sources and characteristics of all datasets in Table~\\ref{tab:bench}, and more details are presented in Supplementary.\n\n\\paragraph{Baselines}Baselines Apart from the classic CDCL-based SAT solver MiniSat~\\cite{minisat}, we also compare with SOTA SAT solvers Kissat~\\cite{kissat} and Cadical~\\cite{cadical}, whose performance are fully optimized through hybrid heuristics and complex data structures. Even though Kissat and Cadical have demonstrated superior performance compared to ModSAT, the code complexity and opaque low-level data structures currently prevent effective modifications via LLMs. In addition to the original solvers, we also compare with their parameter-tuning versions in order to fully explore their abilities for different problem instances. More precisely,  we employed SMAC3 (Sequential Model-based Algorithm Configuration) ~\\cite{smac3} to optimize the parameters of the aforementioned SAT solvers. SMAC3 leverages its Bayesian optimization framework to efficiently navigate complex parameter spaces. The process involved three key steps: firstly, define the configuration space, solver-specific parameters and their feasible ranges; secondly,  configure SMAC3 using a performance metric (e.g., PAR-2 or solved instances) and execute multiple optimization trials with instance-specific training datasets; lastly, the best-found configuration is validated on the testing dataset. This approach systematically addresses parameter interdependencies while mitigating overfitting, resulting in performance improvements over default settings. Note that PAR-2 is an evaluation metric that measures SAT solver performance by averaging the runtime for solved instances while penalizing unsolved instances with a double timeout penalty. Further details about PAR-2 are provided in the Supplementary.\n\n\\paragraph{Experimental setup}Experimental setup All SAT solvers are implemented in C++, the interface to LLMs and parameter-tuning methods are implemented in Python. The budget, denoted $\\mathcal{B}$\\mathcal{B}, refers to the number of times requesting new heuristics from LLMs or new parameters from SMAC3, is set to $50$50. Owing to the superior performance of AutoModSAT when utilizing DeepSeek-V3, we only report results obtained from it in this paper. Due to the standard $5000$5000 seconds timeout bound in the SAT competition is excessively long, we use  half the median solving time reported from the original solvers as the timeout threshold in training, which can also ensure evaluation of the generalization capabilities. After getting the optimized solver,  the original $5000$5000 seconds timeout is used for the final evaluation (testing). This approach significantly reduces the computational overhead while maintaining meaningful performance assessment.  \n\n\n\n\\begin{table*}[t]\n\\belowrulesep=0pt\n\\aboverulesep=0pt\n\\begin{center}\n\\caption{\\textbf{Dataset information}.  Datasets used in this paper  are taken  from the SAT Competition 2023, 2024 (SC 2023, SC 2024 for short), Picat (a language tool for problem generation), and the industrial EDA scenario. The size of each dataset and statistics on the number of variables and clauses are provided, which clearly show the diversity of the problem instances. More details are provided in Supplementary.}\n\\vskip 0.04in\n\\resizebox{0.8\\textwidth}{!}{\n\\begin{tabular}{lcc|cc|cc}\n\\toprule\ndataset            & size & source & variables mean & variables std & clauses mean & clauses std \\\\\n\\midrule\ncryptography-ascon           & 20 & SC 2023 & 146,636 & 15,010 & 342,940 & 37,315 \\\\\nregister-allocation       & 20  & SC 2023 & 381 & 193 & 5,813 & 5,622 \\\\\nsocial-golfer          & 20 & SC 2023 & 15,540 & 12,157 & 131,517 & 79,751\\\\\nhashtable-safety              & 20  & SC 2023 & 11,712,548 & 4,874,397 & 53,644,509 & 22,032,387 \\\\\nargumentation 2023             & 20  & SC 2023 & 962 & 190 & 27,960 & 23,034 \\\\ \nargumentation 2024           & 21  & SC 2024 & 909 & 187 & 35,110 & 29,989  \\\\\nhamiltonian              & 40  & SC 2024 & 511 & 60 & 4,062 & 533 \\\\\n\\midrule\nMineSweeper              & 88  & Picat & 618,801 & 531,657 & 9,065,224 & 7,909,645  \\\\\nKnightTour           & 56  & Picat & 223,697 & 313,704 & 10,692,883 & 17,482,123  \\\\\nZamkeller              & 80  & Picat & 24,592 & 22,190 & 310,804 & 335,102 \\\\\n\\midrule\nEDA              & 50  & Industrial & 1,822 & 1,195 & 6,185 & 4207 \\\\\n\n\\bottomrule\n\\label{tab:bench}\n\\end{tabular}\n}\n\\end{center}\n\\vskip -0.08in\n\\end{table*}\n\\belowrulesep=0pt\n\\aboverulesep=0pt\n\n\\caption{\\textbf{Dataset information}.  Datasets used in this paper  are taken  from the SAT Competition 2023, 2024 (SC 2023, SC 2024 for short), Picat (a language tool for problem generation), and the industrial EDA scenario. The size of each dataset and statistics on the number of variables and clauses are provided, which clearly show the diversity of the problem instances. More details are provided in Supplementary.}\n\\vskip 0.04in\n\\resizebox{0.8\\textwidth}0.8\\textwidth{!}!{\n\\begin{tabular}{lcc|cc|cc}\n\\toprule\ndataset            & size & source & variables mean & variables std & clauses mean & clauses std \\\\\n\\midrule\ncryptography-ascon           & 20 & SC 2023 & 146,636 & 15,010 & 342,940 & 37,315 \\\\\nregister-allocation       & 20  & SC 2023 & 381 & 193 & 5,813 & 5,622 \\\\\nsocial-golfer          & 20 & SC 2023 & 15,540 & 12,157 & 131,517 & 79,751\\\\\nhashtable-safety              & 20  & SC 2023 & 11,712,548 & 4,874,397 & 53,644,509 & 22,032,387 \\\\\nargumentation 2023             & 20  & SC 2023 & 962 & 190 & 27,960 & 23,034 \\\\ \nargumentation 2024           & 21  & SC 2024 & 909 & 187 & 35,110 & 29,989  \\\\\nhamiltonian              & 40  & SC 2024 & 511 & 60 & 4,062 & 533 \\\\\n\\midrule\nMineSweeper              & 88  & Picat & 618,801 & 531,657 & 9,065,224 & 7,909,645  \\\\\nKnightTour           & 56  & Picat & 223,697 & 313,704 & 10,692,883 & 17,482,123  \\\\\nZamkeller              & 80  & Picat & 24,592 & 22,190 & 310,804 & 335,102 \\\\\n\\midrule\nEDA              & 50  & Industrial & 1,822 & 1,195 & 6,185 & 4207 \\\\\n\n\\bottomrule\n\\label{tab:bench}\n\\end{tabular}\n}\n\n\\toprule\ndataset            & size & source & variables mean & variables std & clauses mean & clauses std \\\\\n\\midrule\ncryptography-ascon           & 20 & SC 2023 & 146,636 & 15,010 & 342,940 & 37,315 \\\\\nregister-allocation       & 20  & SC 2023 & 381 & 193 & 5,813 & 5,622 \\\\\nsocial-golfer          & 20 & SC 2023 & 15,540 & 12,157 & 131,517 & 79,751\\\\\nhashtable-safety              & 20  & SC 2023 & 11,712,548 & 4,874,397 & 53,644,509 & 22,032,387 \\\\\nargumentation 2023             & 20  & SC 2023 & 962 & 190 & 27,960 & 23,034 \\\\ \nargumentation 2024           & 21  & SC 2024 & 909 & 187 & 35,110 & 29,989  \\\\\nhamiltonian              & 40  & SC 2024 & 511 & 60 & 4,062 & 533 \\\\\n\\midrule\nMineSweeper              & 88  & Picat & 618,801 & 531,657 & 9,065,224 & 7,909,645  \\\\\nKnightTour           & 56  & Picat & 223,697 & 313,704 & 10,692,883 & 17,482,123  \\\\\nZamkeller              & 80  & Picat & 24,592 & 22,190 & 310,804 & 335,102 \\\\\n\\midrule\nEDA              & 50  & Industrial & 1,822 & 1,195 & 6,185 & 4207 \\\\\n\n\\bottomrule\n\\label{tab:bench}\n\n\n\n\\vskip -0.08in\n\n\n\n\n\\begin{table*}[t]\n\\label{PAR-2result}\n\\belowrulesep=0pt\n\\aboverulesep=0pt\n\\begin{center}\n\\caption{\\textbf{PAR-2 over different datasets}. This table compares the PAR-2 scores (lower is better) and the number of solved instances (in brackets, higher is better) across 11 datasets for eight SAT solvers: MiniSat, ModSAT, ModSAT-para, Kissat, Kissat-para, Cadical, Cadical-para, and our proposed AutoModSAT. The results highlight AutoModSAT\u2019s superior performance, achieving the lowest PAR-2 in 8/11 datasets while matching or exceeding the solved instance counts of competitors. While parameter optimization improves baseline solvers in most cases, AutoModSAT consistently demonstrates broader efficiency gains, particularly in resource-intensive domains like system verification (hashtable-safety) and graph problems (hamiltonian). Note that we perform the calculations three times and present the mean values here.}\n\\vskip 0.04in\n\\resizebox{\\textwidth}{!}{\n\\begin{tabular}{lcccccccc}\n\\toprule\nDataset & MiniSat & ModSAT & ModSAT para &  Kissat & Kissat para & Cadical & Cadical para & AutoModSAT \\\\\n\\midrule\ncryptography-ascon & 193.14 (20) & 208.6 (20) & 208.6 (20) & 189.85 (20) & 155.85 (20) & 231.37 (20) & 204.78 (20) & \\textbf{140.72 (20)}  \\\\\nregister-allocation & 8808.35(3) &7213.23 (5) & 6854.54 (6) & 8553.9 (5) & 6321.95 (8) & 8813.81 (3) & 8774.00 (3) &\\textbf{ 1177.8 (18) }   \\\\\nsocial-golfer & 8193.50(4) & 7836.3 (5) & 7641.23 (5) & 7536.35 (5) & 7536.35 (5) & 7573.55 (5) & 7506.52 (5) & \\textbf{7265.45 (6)} \\\\\nhashtable-safety & 92.14(20) &83.25 (20) & 67.25 (20) & 456.8 (20) & 456.8 (20) & 252.29 (20) & 252.29 (20) & \\textbf{60.82 (20)} \\\\\nargumentation 2023 & 8685.5(3) &4695.25 (13) & 3618.75 (14) & 3330.05 (14) & \\textbf{3099.95 (14)} & 3450.97 (13) & 3289.25 (14) & 3229.65 (14)\\\\\nargumentation 2024 &2876.23 (17) &2745.57 (17) & 1392.36 (19) & 542.48 (21) & \\textbf{170.1 (21)} & 549.436 (21) & 321.23 (21) & 232.14 (21) \\\\\nhamiltonian & 653.23(36) & 577.48 (37)& 227.75 (39) & 457.32 (38) & 296.75 (39) & 937.35 (35) & 444.00(38) & \\textbf{133.13 (40)}\\\\\n\\midrule\nMineSweeper & 9.87 (88) &9.12 (88) & 7.8 (88) & 145.98 (88) & 47.31 (88) & 54.78 (88) & 43.43 (88) & \\textbf{7.36 (88)} \\\\\nKnightTour & 9135.0 (5) & 8769.77 (7) & 8105.79 (11) & 8753.77 (7) & 8577.7 (8) & 8358.88 (9) & 8284 (10) & \\textbf{7815.68 (13) }\\\\\nZamkeller & 5694.84 (37) & 3485.35 (54) & 2854.14 (62) & 2229.9 (65) & \\textbf{486.5 (75)} & 1946.70 (67) & 724.65 (72) & 2053.21 (66) \\\\\n\\midrule\n\nEDA & 1098.22 (45) &825.36 (46) & 643.16 (48) & 628.3 (48) & 416.42 (49) & 522.04 (49) & 491.64 (49) & \\textbf{376.01 (49)} \\\\\n\n\\bottomrule\n\\label{tab:PAR-2}\n\\end{tabular}\n}\n\\end{center}\n\\end{table*}\n\\label{PAR-2result}\n\\belowrulesep=0pt\n\\aboverulesep=0pt\n\n\\caption{\\textbf{PAR-2 over different datasets}. This table compares the PAR-2 scores (lower is better) and the number of solved instances (in brackets, higher is better) across 11 datasets for eight SAT solvers: MiniSat, ModSAT, ModSAT-para, Kissat, Kissat-para, Cadical, Cadical-para, and our proposed AutoModSAT. The results highlight AutoModSAT\u2019s superior performance, achieving the lowest PAR-2 in 8/11 datasets while matching or exceeding the solved instance counts of competitors. While parameter optimization improves baseline solvers in most cases, AutoModSAT consistently demonstrates broader efficiency gains, particularly in resource-intensive domains like system verification (hashtable-safety) and graph problems (hamiltonian). Note that we perform the calculations three times and present the mean values here.}\n\\vskip 0.04in\n\\resizebox{\\textwidth}\\textwidth{!}!{\n\\begin{tabular}{lcccccccc}\n\\toprule\nDataset & MiniSat & ModSAT & ModSAT para &  Kissat & Kissat para & Cadical & Cadical para & AutoModSAT \\\\\n\\midrule\ncryptography-ascon & 193.14 (20) & 208.6 (20) & 208.6 (20) & 189.85 (20) & 155.85 (20) & 231.37 (20) & 204.78 (20) & \\textbf{140.72 (20)}  \\\\\nregister-allocation & 8808.35(3) &7213.23 (5) & 6854.54 (6) & 8553.9 (5) & 6321.95 (8) & 8813.81 (3) & 8774.00 (3) &\\textbf{ 1177.8 (18) }   \\\\\nsocial-golfer & 8193.50(4) & 7836.3 (5) & 7641.23 (5) & 7536.35 (5) & 7536.35 (5) & 7573.55 (5) & 7506.52 (5) & \\textbf{7265.45 (6)} \\\\\nhashtable-safety & 92.14(20) &83.25 (20) & 67.25 (20) & 456.8 (20) & 456.8 (20) & 252.29 (20) & 252.29 (20) & \\textbf{60.82 (20)} \\\\\nargumentation 2023 & 8685.5(3) &4695.25 (13) & 3618.75 (14) & 3330.05 (14) & \\textbf{3099.95 (14)} & 3450.97 (13) & 3289.25 (14) & 3229.65 (14)\\\\\nargumentation 2024 &2876.23 (17) &2745.57 (17) & 1392.36 (19) & 542.48 (21) & \\textbf{170.1 (21)} & 549.436 (21) & 321.23 (21) & 232.14 (21) \\\\\nhamiltonian & 653.23(36) & 577.48 (37)& 227.75 (39) & 457.32 (38) & 296.75 (39) & 937.35 (35) & 444.00(38) & \\textbf{133.13 (40)}\\\\\n\\midrule\nMineSweeper & 9.87 (88) &9.12 (88) & 7.8 (88) & 145.98 (88) & 47.31 (88) & 54.78 (88) & 43.43 (88) & \\textbf{7.36 (88)} \\\\\nKnightTour & 9135.0 (5) & 8769.77 (7) & 8105.79 (11) & 8753.77 (7) & 8577.7 (8) & 8358.88 (9) & 8284 (10) & \\textbf{7815.68 (13) }\\\\\nZamkeller & 5694.84 (37) & 3485.35 (54) & 2854.14 (62) & 2229.9 (65) & \\textbf{486.5 (75)} & 1946.70 (67) & 724.65 (72) & 2053.21 (66) \\\\\n\\midrule\n\nEDA & 1098.22 (45) &825.36 (46) & 643.16 (48) & 628.3 (48) & 416.42 (49) & 522.04 (49) & 491.64 (49) & \\textbf{376.01 (49)} \\\\\n\n\\bottomrule\n\\label{tab:PAR-2}\n\\end{tabular}\n}\n\n\\toprule\nDataset & MiniSat & ModSAT & ModSAT para &  Kissat & Kissat para & Cadical & Cadical para & AutoModSAT \\\\\n\\midrule\ncryptography-ascon & 193.14 (20) & 208.6 (20) & 208.6 (20) & 189.85 (20) & 155.85 (20) & 231.37 (20) & 204.78 (20) & \\textbf{140.72 (20)}  \\\\\nregister-allocation & 8808.35(3) &7213.23 (5) & 6854.54 (6) & 8553.9 (5) & 6321.95 (8) & 8813.81 (3) & 8774.00 (3) &\\textbf{ 1177.8 (18) }   \\\\\nsocial-golfer & 8193.50(4) & 7836.3 (5) & 7641.23 (5) & 7536.35 (5) & 7536.35 (5) & 7573.55 (5) & 7506.52 (5) & \\textbf{7265.45 (6)} \\\\\nhashtable-safety & 92.14(20) &83.25 (20) & 67.25 (20) & 456.8 (20) & 456.8 (20) & 252.29 (20) & 252.29 (20) & \\textbf{60.82 (20)} \\\\\nargumentation 2023 & 8685.5(3) &4695.25 (13) & 3618.75 (14) & 3330.05 (14) & \\textbf{3099.95 (14)} & 3450.97 (13) & 3289.25 (14) & 3229.65 (14)\\\\\nargumentation 2024 &2876.23 (17) &2745.57 (17) & 1392.36 (19) & 542.48 (21) & \\textbf{170.1 (21)} & 549.436 (21) & 321.23 (21) & 232.14 (21) \\\\\nhamiltonian & 653.23(36) & 577.48 (37)& 227.75 (39) & 457.32 (38) & 296.75 (39) & 937.35 (35) & 444.00(38) & \\textbf{133.13 (40)}\\\\\n\\midrule\nMineSweeper & 9.87 (88) &9.12 (88) & 7.8 (88) & 145.98 (88) & 47.31 (88) & 54.78 (88) & 43.43 (88) & \\textbf{7.36 (88)} \\\\\nKnightTour & 9135.0 (5) & 8769.77 (7) & 8105.79 (11) & 8753.77 (7) & 8577.7 (8) & 8358.88 (9) & 8284 (10) & \\textbf{7815.68 (13) }\\\\\nZamkeller & 5694.84 (37) & 3485.35 (54) & 2854.14 (62) & 2229.9 (65) & \\textbf{486.5 (75)} & 1946.70 (67) & 724.65 (72) & 2053.21 (66) \\\\\n\\midrule\n\nEDA & 1098.22 (45) &825.36 (46) & 643.16 (48) & 628.3 (48) & 416.42 (49) & 522.04 (49) & 491.64 (49) & \\textbf{376.01 (49)} \\\\\n\n\\bottomrule\n\\label{tab:PAR-2}\n\n\n\n\n\n\\paragraph{Performance}Performance The experimental results demonstrate that AutoModSAT significantly outperforms existing SAT solvers across all evaluated datasets. As visualized in Figure~\\ref{fig:compare}, AutoModSAT achieved over 50\\% performance improvement relative to ModSAT, which is a substantial advancement. Furthermore, AutoModSAT exhibits substantial improvements over other SOTA solvers on each dataset, achieving an average performance gain exceeding 30\\%. Meanwhile, we also apply parameter tuning to ModSAT and compare the resulting solvers for different scenarios with AutoModSAT. The parameter-tuned baseline solvers (denoted as \"para\") generally show improved performance over their original counterparts across all datasets. Nevertheless, AutoModSAT consistently outperforms the parameter-tuned ModSAT solvers in a 30\\% speedup,  and attains a 20\\% speedup on average compared to parameter-tuned alternatives of the SOTA\nsolvers (Kissat and CadiCal). The speedup between two methods is calculated as: $\\text{speedup} = \\frac{v_a - v_b}{\\max(v_a, v_b)}$\\text{speedup} = \\frac{v_a - v_b}{\\max(v_a, v_b)}, where $v_a$v_a is the value of method A, $v_b$v_b is the value of method B.\n\nAs already mentioned, we also fine-tune the SOTA SAT solvers on each dataset in order to rigorously evaluate the absolute performance of AutoModSAT. The experimental results (see Figure~\\ref{fig:compare} and Table~\\ref{tab:PAR-2}) reveal that AutoModSAT achieves the shortest PAR-2 score while matching or exceeding the solved instance count in 8 out of 11 datasets: cryptography-ascon, register-allocation, social-golfer, hashtable-safety, Hamiltonian, EDA, and Minesweeper. This demonstrates that AutoModSAT is able to discover highly efficient heuristics that overall outperform existing SOTA solvers and their fine-tuned counterparts.\n\nOverall, AutoModSAT establishes itself as a robust and efficient solver, particularly excelling in cryptographic, system verification, and graph-based problems. Its ability of consistently outperforming both default and parameter-optimized versions of SOTA solvers highlights the effectiveness of our optimization framework.  Moreover, Figure~\\ref{fig:compare} also displays the search process of AutoModSAT. For each dataset, we ran three heuristics discovery experiments. In each run, the LLMs generated multiple useful heuristics across different functions, collectively contributing to the final outcome. This demonstrates that AutoModSAT gradually produces the effective heuristics for each dataset. \n\n\\subsection*{Analysis of discovered heuristics}\nAutoModSAT is capable of discovering novel heuristics, and we analyze two of them here: restart function and varBumpActivity as presented in Figure~\\ref{fig:code}. More analysis is shown in Supplementary. \n\n\n\nThe  heuristic restart\\_function can help the solver escape the local minimum. The generated restart\\_function introduces several key enhancements over the original implementation. For example, it implements a dynamic restart strategy using moving averages of Literal Block Distance (LBD) scores, maintaining both fast ($90\\%$90\\% historical weight) and slow ($99\\%$99\\% historical weight) averages. This enables adaptive decision-making: when recent conflicts become more complex (fast\\_avg/slow\\_avg ratio > 1.2), it performs a full restart; for moderate difficulty (ratio >1.0), it preserves some learned clauses through partial restart; and for easier conflicts, it minimizes backtracking. Moreover, it also introduces a periodic database reduction to help maintain memory efficiency. These improvements create a restart strategy that adapts to problem difficulty, and balances exploration and exploitation of learned clauses. Compared to the original's fixed-level restart, the updated version demonstrates better clause management and computational efficiency.\n\nThe heuristic varBumpActivity  increases a variable's activity score to prioritize it for future branching decisions. The generated varBumpActivity function introduces several key enhancements over the original one. For example, it scales the activity increments based on the current decision level of the solver ($1.0 + 0.1 * decisionLevel()$1.0 + 0.1 * decisionLevel()), prioritizing variables involved in recent conflicts. This improves search efficiency by dynamically focusing heuristic guidance on newer decisions. Then, the rescaling mechanism uses a larger threshold ($1e100$1e100 vs. $1e50$1e50) and a smaller scaling factor ($1e-100$1e-100), which preserves relative activity differences more effectively while preventing floating-point overflow. Additionally, a minimum activity floor ($1e-100$1e-100) ensures no variable becomes entirely inactive, maintaining heuristic relevance. Finally, the heap update logic is optimized to avoid redundant operations by only triggering a decrease when the variable\u2019s activity surpasses the top elements of the heap. These changes reduce computational overhead while maintaining the solver\u2019s ability to adaptively prioritize variables.\n\nThe above analysis demonstrates that AutoModSAT can discover new heuristics that transcend conventional implementation in existing SAT solvers. By intelligently synthesizing various member variables in SAT solvers, the system dynamically constructs sophisticated heuristics with practical effectiveness. It is  worth noting that a systematic analysis of these LLM-generated heuristics can also  offer valuable insights and  new patterns in the heuristic design. Therefore, AutoModSAT can not only improve the solver's performance but is also a useful exploratory tool for heuristic discovery. \n\n\n\n\n\\begin{figure*}[ht!] % Use figure* for spanning the width of the page in a two-column format\n    \\centering\n    \\begin{minipage}{0.5\\textwidth}\n        \\includegraphics[width=\\textwidth]{code_example.png}\n        \\label{fig:left_image}\n    \\end{minipage}\\hfill\n    \\begin{minipage}{0.5\\textwidth}\n        \\includegraphics[width=\\textwidth]{code_example2.png}\n        \\label{fig:right_image}\n    \\end{minipage}\n\n\\caption{This figure shows two novel LLM-generated heuristic functions for SAT solvers and their original counterparts. (Left) The restart function implements a dynamic restart strategy using moving averages of Literal Block Distance (LBD) scores, enhancing traditional approaches. (Right) The varbump function innovatively scales activity increments based on the solver's current decision level. Both functions introduce unprecedented heuristic rules not previously proposed in existing solvers, demonstrating exceptional performance on EDA datasets.}\n\\label{fig:code}\n\\end{figure*} \\centering\n    {0.5\\textwidth}0.5\\textwidth\n        \\includegraphics[width=\\textwidth]{code_example.png}\n        \\label{fig:left_image}\n    \\hfill\n    {0.5\\textwidth}0.5\\textwidth\n        \\includegraphics[width=\\textwidth]{code_example2.png}\n        \\label{fig:right_image}\n    \n\n\\caption{This figure shows two novel LLM-generated heuristic functions for SAT solvers and their original counterparts. (Left) The restart function implements a dynamic restart strategy using moving averages of Literal Block Distance (LBD) scores, enhancing traditional approaches. (Right) The varbump function innovatively scales activity increments based on the solver's current decision level. Both functions introduce unprecedented heuristic rules not previously proposed in existing solvers, demonstrating exceptional performance on EDA datasets.}\n\\label{fig:code}\n\n\n\n", "appendix": false}, "Discussion": {"content": "\nIn this paper we have introduced a new paradigm to automatically optimize complex SAT solvers through LLMs. To the best of our knowledge, it is the first systematic framework for optimizing complex solvers, with performance leaps from sub-SOTA baselines to surpassing SOTA results across multiple datasets. This is a transferable research paradigm also applicable to other kinds of complex solvers, and thus open new avenues for automatic solver optimization. \n\nAutomatically optimizing complex solvers often suffers from their intricate data structures, extensive codebases, and poor readability. Although LLMs have shown utility in simple algorithm design, their current limitations in long-context comprehension and code generation hinder their ability to improve complex solvers. Thus, a necessary and effective approach is to modularize the solver and create an LLM-friendly version that is easy to understand and modify. Even though the modularized solver does not match the SOTA performance, it shows the potential to surpass SOTA solver through heuristics discovery of LLMs, which also offer a promising methodology for future solver development. Three general principles have been introduced for modularizing solvers, which can be potentially extended to other complex solvers.\n\nThe goal of AutoModSAT is to tackle real-world complex problems. It goes beyond the conventional comfort zone of current trend of artificial intelligence research for algorithm design, which is only applied in simple algorithms that may not be extended to large-scale solvers. In contrast, AutoModSAT is designed to directly confront the real-world problems, and seek to make a contribution to practical applications.\nMoreover, AutoModSAT can automatically optimize complex SAT solvers for different datasets. Even though the theoretical analysis under the $P\\neq NP$P\\neq NP assumption suggests that general solvers can face inherent time complexity barriers, modern solvers can empirically outperform the theoretical limit by  working in specialized domains. Since industrial practices  prioritize domain-specific dataset optimization,  developing LLM-driven heuristic optimization method like AutoModSAT for specialized solvers is a highly promising direction.\n\n\n\nLast but not least, current LLM-based optimization methods still face some challenges: (1) performance of the baseline modularized solvers needs to be enhanced; (2) long-context capability of LLMs needs to be improved to generate more complex and high-quality codes; (3) feedback of search process needs to be more effectively leveraged to guide the next search. Addressing these limitations could enable LLMs to develop solvers that significantly outperform current SOTA solvers. Our work provides a foundational framework with methodological advancements for applying LLMs to complex solver optimization, and bridges the gap between theoretical potential and practical implementations in the applications of artificial intelligence.\n\n", "appendix": false}, "Method": {"content": "\n\\subsection* {Principles for Developing Complex SAT Solvers}\n\\label{principles}\n\n\nThe current architecture of complex solvers often have extensive functions, resulting in poor modularity and intricate data structures. This hinders the direct implementation of LLMs for solver optimization. For instance, complex SAT solvers frequently employ customized low-level data structures such as watch lists for unit propagation and clause databases with lazy deletion schemes~\\cite{watch}, which are optimized for memory locality and cache efficiency. Consequently, all related context must be included in prompts to ensure accurate code generation. Furthermore, due to weak modularity, modifying a single variable may require changes across multiple locations, making it difficult for LLMs to generate correct code. Finally, to enable localized heuristic modifications without disrupting unrelated components, adequate error tolerance must be allowed, which requires comprehensive variable context sharing for the modularized solver. To address these challenges, we have formulated three guiding principles, including:\n\\begin{itemize}\n    \\item Maintain functions simple and focus;\n    \\item use class variables for shared information;\n    \\item proactively prevent bugs during heuristics discovery.\n\\end{itemize}\\begin{itemize}\n    \\item Maintain functions simple and focus;\n    \\item use class variables for shared information;\n    \\item proactively prevent bugs during heuristics discovery.\n\\end{itemize}\n    \\item Maintain functions simple and focus;\n    \\item use class variables for shared information;\n    \\item proactively prevent bugs during heuristics discovery.\n\n\n\\textbf{Maintain functions simple and focus} means that the function optimized by LLMs should be simple and explicit, which is uncommon in complex solvers. Contemporary solvers, typically implemented in C/C++, often employ complex data structures coupled with poorly modularized functions. This structural deficiency frequently leads LLMs to misunderstand variable scopes and generate erroneous code when optimizing the solvers. \n\n\\textbf{Use class variables for shared information} means that class member variables are more friendly than global variables for LLMs to access. Although functions typically utilize only a few variables in the original solver implementations, LLMs tend to coordinate with additional variables to strengthen the diversity of heuristics. Therefore, instead of providing the information on all possible variables in the prompt to LLMS, we provide only relevant class member variables as contextual information. This allows LLMs to autonomously determine which variables to utilize.\n\n\n\\textbf{Proactively prevent bugs during heuristics discovery} means that we should fix the bugs written by LLMs proactively, so that the solver can compile correctly with the same heuristics. Many compilation errors admit straightforward resolutions, particularly those arising from common issues such as missing inclusions or variable scope misinterpretations. Fixing the bug proactively is helpful for LLMs to generate more diverse and correct code.\n\n\n\n\n\n\\subsection*{Automatic Prompt Optimization}\nPrompt engineering remains a significant challenge in LLMs applications~\\cite{promptengineering}.  Traditional approaches require extensive trial-and-error by experts to identify effective prompts, a process further complicated by the dynamic nature of optimal prompts as LLMs evolve. While conventional prompt optimization leverages supervised learning when label can be obtained easily~\\cite{ape, zhou2022large, pryzant2023automatic}, our task faces two critical constraints: prohibitive execution time ($5000$5000 seconds timeout per instance), and the absence of definitive labels due to the performance variance across different datasets. \n\nIn contrast, a novel unsupervised method that utilizes Shannon entropy as an evaluation metric is adopted for automatic prompt optimization here. This metric quantifies the population diversity at each time step based on clusters of all the individuals. Firstly, we employ the CodeT5+ embedding model~\\cite{codet5+} to generate embeddings for the synthesized code, which is preprocessed according to the Google C++ style guide~\\cite{googlestyle} (e.g., removing comments and ensuring uniform indentation). The resulting embeddings form the set $\\mathbf{X}$\\mathbf{X}, where each code sample $x \\in \\mathbf{X}$x \\in \\mathbf{X} is represented by an $m$m-dimensional vector. Then, we use an unsupervised learning method to cluster the $N$N distinct code embeddings generated by the same prompt. Specifically, we apply the K-Means++~\\cite{kmeans++} to partition the embeddings into $K$K clusters. More precisely, given the embeddings $\\mathbf{X} = \\{x_1, \\dots, x_N\\} \\subset \\mathbb{R}^m$\\mathbf{X} = \\{x_1, \\dots, x_N\\} \\subset \\mathbb{R}^m, K-Means++ consists of the following three steps:\n\\begin{enumerate}\n    \\item[(1)] \nInitialize centroids: Select the first centroid $c_1$ uniformly at random from $\\mathbf{X}$. For each subsequent centroid $c_j$ ($j=2,\\dots,N$), choose it as $x \\in \\mathbf{X}$ with probability proportional to $\\min_{k=1}^{j-1} |x - c_k|^2$;\n\\item[(2)] Assign clusters: Assign each embedding $x_i$ to the nearest centroid $c_j$ using Euclidean distance.\n\\item [(3)]Update centroids: Recompute the centroids as the mean of all embeddings in each cluster, and then repeat step (2).\n\\end{enumerate}\\begin{enumerate}\n    \\item[(1)] \nInitialize centroids: Select the first centroid $c_1$ uniformly at random from $\\mathbf{X}$. For each subsequent centroid $c_j$ ($j=2,\\dots,N$), choose it as $x \\in \\mathbf{X}$ with probability proportional to $\\min_{k=1}^{j-1} |x - c_k|^2$;\n\\item[(2)] Assign clusters: Assign each embedding $x_i$ to the nearest centroid $c_j$ using Euclidean distance.\n\\item [(3)]Update centroids: Recompute the centroids as the mean of all embeddings in each cluster, and then repeat step (2).\n\\end{enumerate}\n    \\item[(1)] \nInitialize centroids: Select the first centroid $c_1$c_1 uniformly at random from $\\mathbf{X}$\\mathbf{X}. For each subsequent centroid $c_j$c_j ($j=2,\\dots,N$j=2,\\dots,N), choose it as $x \\in \\mathbf{X}$x \\in \\mathbf{X} with probability proportional to $\\min_{k=1}^{j-1} |x - c_k|^2$\\min_{k=1}k=1^{j-1}j-1 |x - c_k|^2;\n\\item[(2)] Assign clusters: Assign each embedding $x_i$x_i to the nearest centroid $c_j$c_j using Euclidean distance.\n\\item [(3)]Update centroids: Recompute the centroids as the mean of all embeddings in each cluster, and then repeat step (2).\n\n\nAfter the clustering is completed, we calculate the probability distribution of each cluster, denoted $p_i = \\frac{|C_i|}{N}$p_i = \\frac{|C_i|}{N} ($i=1,\\cdots K$i=1,\\cdots K), where \\( |C_i| \\) |C_i|  is the number of individuals of the $i$i-th cluster. Then the entropy, \\( H(X) \\) H(X) is given by $H(X) = -\\sum_{i=1}^{K} p_i \\log(p_i)$H(X) = -\\sum_{i=1}i=1^{K}K p_i \\log(p_i)\n\n\n\nThis proposed approach is able to eliminate the dependency on explicit labels while maintaining adaptability to the evolvement of LLMs, particularly suitable for compute-intensive optimization tasks with ambiguous success criteria.\n\n\\subsection*{Presearch Strategy}\n\nPrevious work~\\cite{autosat} usually utilizes strategy such as evolutionary algorithms (EA) and greedy hill climbers to optimize different functions, and faces scalability issues when optimizing multiple functions with numerous candidates. For instance, in optimizing heuristic functions as a pseudo-Boolean optimization problem (e.g., LLMs provide merely two candidates for each function) with sequential dependency, EAs require approximately $0.54n^2$0.54n^2 ($n$n is the number of functions need to be optimized) trials of generating new heuristics functions as illustrated in recent empirical studies\\cite{doerr2018towards, ye2020benchmarking}. However, the number of candidates for each function that LLMs can provide is more than two in practice, and the performance contribution of each function may depend on complex dependencies. These facts indicate that significant optimization time is required for achieving the optimal results~\\cite{doerr2018static, doerr2019theory}. Since evaluating a SAT solver is a time-consuming task with a budget of $5,000$5,000 seconds, searching for the optimal combination of SAT heuristic functions is computationally prohibitive.  \n\nHowever, our empirical analysis reveals that certain functions consistently degrade performance for certain datasets, and this finding provides us with an intuitive approach, dimensionality reduction, to accelerate the search process toward the optimal heuristic functions. We therefore propose a presearch strategy to mitigate the combinatorial explosion:  prune function candidates through small-scale preliminary tests (single-function evaluation on compact datasets), and then execute $(1+\\lambda)$(1+\\lambda) EA search on the refined subset of functions. This two-phase approach significantly reduces the iteration counts while preserving optimization effectiveness.\n\nMore precisely, the presearch strategy operates in two phases. Firstly, we construct a representative subset comprising $50\\%$50\\% of the problem instances from the original dataset. On this compact subset, each candidate function's standalone impact based on the PAR-2 metric (where lower values indicate better solver performance) is evaluated. Typically, this phase retains about four high-impact functions that consistently improve the PAR-2 score. Subsequently, we execute a $(1+\\lambda)$(1+\\lambda) EA on the full dataset using this refined function set. Under the assumption used in AutoSAT\\cite{autosat} on the heuristic function optimization, the $(1+\\lambda)$(1+\\lambda) EA variants require a budget of $O(n^2+n\\lambda)$O(n^2+n\\lambda)~\\cite{jansen2005choice}. Accordingly, we can lower this bound by $75\\%$75\\% with the presearch strategy.\nMore details about the presearch are shown in Supplementary Algorithm ~\\ref{alg:autosat-pre}. \n\n\\subsection*{Heuristics discovery}\nAfter obtaining the optimized prompt, the modularized SAT solver, and the presearch function candidates, AutoModSAT starts to discover heuristics in different datasets. This phase involves the heuristics generation, executable code integration, and solver evaluation. See  Supplementary Figure ~\\ref{fig:discovery} for a detailed illustration of this process. \n\nWithin each iteration of this process, a specific function candidate is selected from the function candidates. An LLM is then called to generate the corresponding implementation code based on the optimized prompt. The generated code will be evaluated whether it is synonymous. The generated code passed the synonymous evaluation will undergo immediate execution validation against a predefined dataset. Successful execution triggers a performance evaluation phase to assess the heuristic's efficacy.\n\nIf the code execution fails, the code along with the error output are sent back to LLMs. LLMs utilize this feedback to generate revised code and  attempt to repair the bug. However, if the repair attempt fails, then the current iteration for the selected function candidate is terminated and the process restarts with a new iteration, possibly selecting a different function candidate to generate heuristics. On the other hand, when the code execution succeeds, it will be evaluated and compared with existing heuristics. If the new heuristic demonstrates a superior performance, it is dynamically integrated into the modularized solver to enhance the capabilities. \n\nIn summary, the entire process consists of candidate selection, LLM-driven code generation, execution validation, bug repair, performance evaluation, and solver update, which will be terminated when  a maximum number of iterations is reached. This structured framework facilitates systematic and adaptive code generation, and can successively  refine the solver's heuristic space through successive iterations.\n\n\\bibliography{main}\n\n\n\n\n\n\n\\newpage\n\\begin{center}\n{\\Large\\textbf{Supplementary Materials}}\n\\end{center}\\begin{center}\n{\\Large\\textbf{Supplementary Materials}}\n\\end{center}\n{\\Large\\textbf{Supplementary Materials}}\\Large\\textbf{Supplementary Materials}\n\n\n", "appendix": false}, "Preliminaries": {"content": "\n\n\n\\subsection{Background of SAT}\n\\label{pre:sat}\nLet $V = \\{x_1, x_2, \\dots, x_n\\}$V = \\{x_1, x_2, \\dots, x_n\\} be a set of Boolean variables. A \\textit{literal} is either a variable $x$x or its negation $\\neg x$\\neg x. A \\textit{clause} is a disjunction of literals. A \\textit{conjunctive normal form} (CNF) formula $F = C_1 \\land C_2 \\land \\dots \\land C_m$F = C_1 \\land C_2 \\land \\dots \\land C_m is a conjunction of clauses. For simplicity we assume all clauses are non-tautological. In other words, no variable $x$x occurs positively $(x \\in C)$(x \\in C) and negatively $(\\neg x \\in C)$(\\neg x \\in C) in the same clause.\n\nA (partial) mapping $\\alpha : V \\to \\{0, 1\\}$\\alpha : V \\to \\{0, 1\\} is called an \\textit{assignment}. If $\\alpha$\\alpha maps all variables to a boolean value, it is termed a \\textit{complete} assignment; otherwise, it is referred to as a \\textit{partial} assignment. The value of a variable $x$x under an assignment $\\alpha$\\alpha is denoted as $\\alpha[x]$\\alpha[x]. An assignment $\\alpha$\\alpha satisfies a clause if at least one literal evaluates to true under $\\alpha$\\alpha, and satisfies a CNF formula if it satisfies all its clauses. A CNF formula $F$F is satisfiable if there is at least one satisfying assignment. The empty clause $\\bot$\\bot is always unsatisfiable and represents a \\textit{conflict}. SAT is the problem of deciding whether a given CNF formula is satisfiable.\n\nTo solve such the SAT problem, a straightforward approach is to conduct exhaustively search over all possible truth assignments to the variables in $V$V. A complete SAT solver implements this idea by exploring all possible assignments to determine if at least one satisfies $F$F (proving $F$F is satisfiable). If no satisfying assignment exists, the solver conclusively proves $F$F is unsatisfiable. Within this framework, the strategies for branching (for choosing which variable to assign next and what value to assign it) are crucial. Key techniques to enhance the search efficiency include restart strategies, restart strategies, and activity-based heuristics (often implemented by \"bumping\" variable or clause activity scores).\n\n\n\\subsection{CDCL solver}\n\nConflict-Driven Clause Learning (CDCL)~\\cite{cdcl} is the most common approach and plays a dominant role in modern high-performance SAT solvers. The core innovation is conflict analysis: when a conflict occurs, the solver analyzes it and derives a new clause that explains the inconsistency. These derived clauses, called learned clauses, enable the solver to prune large portions of the search space, which significantly improve the computational efficiency. However, an excessive number of learnt clauses can degrade unit propagation speed and thus consume excessive memory. Consequently, identifying high-quality learne clauses and reducing their quantity are essential for maintaining a solver's performance.\n\nSpecifically, CDCL solvers operate on a propagation and learning mechanism, complemented by decision heuristics. The implementation of propagation and learning is a standard practice and overall similar in different solvers. In contrast, the decision policies (for variable selection) and restart policies (for search restarts) which are crucial for performance vary significantly. Due to the need of manual design and the absence of rigorous mathematical proofs for their optimality, these policies are referred to as important heuristics.\n\n\nThere is a long history of research on these heuristics in SAT solvers, among which branching heuristics play a crucial role and continue to  impact the performance of CDCL solvers. For example, Variable State Independent Decaying Sum (VSIDS)~\\cite{vsids} is a family of branching heuristics that seek to assign a value to the most promising variable  in the Make Decision phase. Another important branching heuristic is Learning-Rate Branching (LRB)~\\cite{lrb}, which frames branching as an optimization problem that picks a variable to maximize a metric called learning rate.\n\nRestart heuristics is also essential for enhancing the performance of CDCL solvers. It allows the solver to abandon the current search path and backtrack to a specific decision level. In this process, the learnt clauses are usually maintained for the next search. Fast restart~\\cite{ramos2011between} is a widely used method, and Luby restarts~\\cite{luby} is also heavily used because they represent a prior optimal strategy. However, most implementations are now switched to Glucose-style restarts~\\cite{glucose}, which are widely used in the SAT Competition. For more details, see the extensive overview given by Armin Biere~\\cite{biere2015evaluating}.\n\nRephase is another technique in CDCL solvers. The primary objective is to reset or adjust the current partial assignment, thereby enabling the solver to explore a diverse search space. PrecoSAT and PicoSAT~\\cite{precosat} utilize a Jeroslow-Wang score~\\cite{jeroslow1990solving} to adjust the saved phases either on all or only on irreundant clauses in regular intervals following a luby sequence. StrangeNight~\\cite{Strangenight} employs a strategy of flipping values with a certain probability that depends on the depth of the assignment. The motivation is to avoid the heavy-tail phenomenon.  These rephasing heuristics have been used and compared in the SAT solver Riss~\\cite{balint2015overview}. \n\n\n\\begin{algorithm2e}[t]\n\\caption{CDCL Framework}\n\\label{alg:CDCL}\n\\textbf{Input:} A CNF $F$ of SAT instance\\;\n\\textbf{Initialization: } decision level $d \\leftarrow 0$, current assignment of variables $\\mathcal{X} \\leftarrow \\emptyset$\\;\n\n\\While{\\textbf{True}}{\n$\\mathcal{X} \\leftarrow \\textbf{Unit Propagation}(F,\\mathcal{X})$\\;\n\\eIf{Conflicts are detected in $\\mathcal{X}$}{\n\\eIf{$d == 0$}{return \\textsc{UNSAT}}\n{$\\mathcal{C}_{conflict}, d_{backtrack} \\leftarrow \\textbf{Analyze Conflict}(F,\\mathcal{X})$ \\;\n$C_{learned} \\leftarrow \\textbf{Learn Clause}(\\mathcal{C}_{conflict},\\mathcal{X})$ \\;\n$F \\leftarrow F \\land C_{learned}$\\;\n$\\mathcal{X} \\leftarrow \\textbf{Backtrack}(\\mathcal{X},d_{backtrack})$\\;\n$d \\leftarrow d_{backtrack}$\\;\n}\n}\n{\n\\eIf{All variables are assigned with a value}{return \\textsc{SAT}}\n{\n$d \\leftarrow d + 1$\\;\n$\\mathcal{X} \\leftarrow \\textbf{Make Decision}(\\mathcal{X})$\n}\n}\n}\n\\end{algorithm2e}\\begin{algorithm2e}[t]\n\\caption{CDCL Framework}\n\\label{alg:CDCL}\n\\textbf{Input:} A CNF $F$ of SAT instance\\;\n\\textbf{Initialization: } decision level $d \\leftarrow 0$, current assignment of variables $\\mathcal{X} \\leftarrow \\emptyset$\\;\n\n\\While{\\textbf{True}}{\n$\\mathcal{X} \\leftarrow \\textbf{Unit Propagation}(F,\\mathcal{X})$\\;\n\\eIf{Conflicts are detected in $\\mathcal{X}$}{\n\\eIf{$d == 0$}{return \\textsc{UNSAT}}\n{$\\mathcal{C}_{conflict}, d_{backtrack} \\leftarrow \\textbf{Analyze Conflict}(F,\\mathcal{X})$ \\;\n$C_{learned} \\leftarrow \\textbf{Learn Clause}(\\mathcal{C}_{conflict},\\mathcal{X})$ \\;\n$F \\leftarrow F \\land C_{learned}$\\;\n$\\mathcal{X} \\leftarrow \\textbf{Backtrack}(\\mathcal{X},d_{backtrack})$\\;\n$d \\leftarrow d_{backtrack}$\\;\n}\n}\n{\n\\eIf{All variables are assigned with a value}{return \\textsc{SAT}}\n{\n$d \\leftarrow d + 1$\\;\n$\\mathcal{X} \\leftarrow \\textbf{Make Decision}(\\mathcal{X})$\n}\n}\n}\n\\end{algorithm2e}[t]\n\\caption{CDCL Framework}\n\\label{alg:CDCL}\n\\textbf{Input:} A CNF $F$F of SAT instance\\;\n\\textbf{Initialization: } decision level $d \\leftarrow 0$d \\leftarrow 0, current assignment of variables $\\mathcal{X} \\leftarrow \\emptyset$\\mathcal{X} \\leftarrow \\emptyset\\;\n\n\\While{\\textbf{True}}\\textbf{True}{\n$\\mathcal{X} \\leftarrow \\textbf{Unit Propagation}(F,\\mathcal{X})$\\;\n\\eIf{Conflicts are detected in $\\mathcal{X}$}{\n\\eIf{$d == 0$}{return \\textsc{UNSAT}}\n{$\\mathcal{C}_{conflict}, d_{backtrack} \\leftarrow \\textbf{Analyze Conflict}(F,\\mathcal{X})$ \\;\n$C_{learned} \\leftarrow \\textbf{Learn Clause}(\\mathcal{C}_{conflict},\\mathcal{X})$ \\;\n$F \\leftarrow F \\land C_{learned}$\\;\n$\\mathcal{X} \\leftarrow \\textbf{Backtrack}(\\mathcal{X},d_{backtrack})$\\;\n$d \\leftarrow d_{backtrack}$\\;\n}\n}\n{\n\\eIf{All variables are assigned with a value}{return \\textsc{SAT}}\n{\n$d \\leftarrow d + 1$\\;\n$\\mathcal{X} \\leftarrow \\textbf{Make Decision}(\\mathcal{X})$\n}\n}\n}\n$\\mathcal{X} \\leftarrow \\textbf{Unit Propagation}(F,\\mathcal{X})$\\mathcal{X} \\leftarrow \\textbf{Unit Propagation}(F,\\mathcal{X})\\;\n\\eIf{Conflicts are detected in $\\mathcal{X}$}Conflicts are detected in $\\mathcal{X}$\\mathcal{X}{\n\\eIf{$d == 0$}{return \\textsc{UNSAT}}\n{$\\mathcal{C}_{conflict}, d_{backtrack} \\leftarrow \\textbf{Analyze Conflict}(F,\\mathcal{X})$ \\;\n$C_{learned} \\leftarrow \\textbf{Learn Clause}(\\mathcal{C}_{conflict},\\mathcal{X})$ \\;\n$F \\leftarrow F \\land C_{learned}$\\;\n$\\mathcal{X} \\leftarrow \\textbf{Backtrack}(\\mathcal{X},d_{backtrack})$\\;\n$d \\leftarrow d_{backtrack}$\\;\n}\n}\n\\eIf{$d == 0$}$d == 0$d == 0{return \\textsc{UNSAT}}return \\textsc{UNSAT}\n{$\\mathcal{C}_{conflict}, d_{backtrack} \\leftarrow \\textbf{Analyze Conflict}(F,\\mathcal{X})$ \\;\n$C_{learned} \\leftarrow \\textbf{Learn Clause}(\\mathcal{C}_{conflict},\\mathcal{X})$ \\;\n$F \\leftarrow F \\land C_{learned}$\\;\n$\\mathcal{X} \\leftarrow \\textbf{Backtrack}(\\mathcal{X},d_{backtrack})$\\;\n$d \\leftarrow d_{backtrack}$\\;\n}$\\mathcal{C}_{conflict}, d_{backtrack} \\leftarrow \\textbf{Analyze Conflict}(F,\\mathcal{X})$\\mathcal{C}_{conflict}conflict, d_{backtrack}backtrack \\leftarrow \\textbf{Analyze Conflict}(F,\\mathcal{X}) \\;\n$C_{learned} \\leftarrow \\textbf{Learn Clause}(\\mathcal{C}_{conflict},\\mathcal{X})$C_{learned}learned \\leftarrow \\textbf{Learn Clause}(\\mathcal{C}_{conflict}conflict,\\mathcal{X}) \\;\n$F \\leftarrow F \\land C_{learned}$F \\leftarrow F \\land C_{learned}learned\\;\n$\\mathcal{X} \\leftarrow \\textbf{Backtrack}(\\mathcal{X},d_{backtrack})$\\mathcal{X} \\leftarrow \\textbf{Backtrack}(\\mathcal{X},d_{backtrack}backtrack)\\;\n$d \\leftarrow d_{backtrack}$d \\leftarrow d_{backtrack}backtrack\\;\n\n\n{\n\\eIf{All variables are assigned with a value}{return \\textsc{SAT}}\n{\n$d \\leftarrow d + 1$\\;\n$\\mathcal{X} \\leftarrow \\textbf{Make Decision}(\\mathcal{X})$\n}\n}\n\\eIf{All variables are assigned with a value}All variables are assigned with a value{return \\textsc{SAT}}return \\textsc{SAT}\n{\n$d \\leftarrow d + 1$\\;\n$\\mathcal{X} \\leftarrow \\textbf{Make Decision}(\\mathcal{X})$\n}\n$d \\leftarrow d + 1$d \\leftarrow d + 1\\;\n$\\mathcal{X} \\leftarrow \\textbf{Make Decision}(\\mathcal{X})$\\mathcal{X} \\leftarrow \\textbf{Make Decision}(\\mathcal{X})\n\n\n\n\n\n\n\\begin{algorithm2e}[ht!]\n\\caption{ModSAT}\n\\label{alg:modsat}\n\\textbf{Input:} A CNF $F$ of SAT instance\\;\n\\textbf{Initialization: } decision level $d \\leftarrow 0$, current assignment of variables $\\mathcal{X} \\leftarrow \\emptyset$\\;\n\n\\While{\\textbf{True}}{\n$\\mathcal{X} \\leftarrow \\textbf{Unit Propagation}(F,\\mathcal{X})$\\;\n\\eIf{Conflicts are detected in $\\mathcal{X}$}{\n\\eIf{$d == 0$}{return \\textsc{UNSAT}}\n{$\\mathcal{C}_{conflict}, d_{backtrack} \\leftarrow \\textbf{Analyze Conflict}(F,\\mathcal{X})$ \\;\n$C_{learned} \\leftarrow \\textbf{Learn Clause}(\\mathcal{C}_{conflict},\\mathcal{X})$ \\;\n$F \\leftarrow F \\land C_{learned}$\\;\n$\\mathcal{X} \\leftarrow \\textbf{Backtrack}(\\mathcal{X},d_{backtrack})$\\;\n$d \\leftarrow d_{backtrack}$\\;\n}\n\n\\eIf{Restart condition}{$d \\leftarrow \\textbf{Restart}(d)$}{ continue }\n\\eIf{Rephase condition}{$\\mathcal{X} \\leftarrow \\textbf{Rephase}(\\mathcal{X})$}{ continue }\n\\eIf{Reduce condition}{$C_{learned} \\leftarrow \\textbf{Reduce}(C_{learned})$}{ continue }\n}\n{\n\\eIf{All variables are assigned with a value}{return \\textsc{SAT}}\n{\n$d \\leftarrow d + 1$\\;\n$\\mathcal{X} \\leftarrow \\textbf{Make Decision}(\\mathcal{X})$\n}\n}\n}\n\\end{algorithm2e}\\begin{algorithm2e}[ht!]\n\\caption{ModSAT}\n\\label{alg:modsat}\n\\textbf{Input:} A CNF $F$ of SAT instance\\;\n\\textbf{Initialization: } decision level $d \\leftarrow 0$, current assignment of variables $\\mathcal{X} \\leftarrow \\emptyset$\\;\n\n\\While{\\textbf{True}}{\n$\\mathcal{X} \\leftarrow \\textbf{Unit Propagation}(F,\\mathcal{X})$\\;\n\\eIf{Conflicts are detected in $\\mathcal{X}$}{\n\\eIf{$d == 0$}{return \\textsc{UNSAT}}\n{$\\mathcal{C}_{conflict}, d_{backtrack} \\leftarrow \\textbf{Analyze Conflict}(F,\\mathcal{X})$ \\;\n$C_{learned} \\leftarrow \\textbf{Learn Clause}(\\mathcal{C}_{conflict},\\mathcal{X})$ \\;\n$F \\leftarrow F \\land C_{learned}$\\;\n$\\mathcal{X} \\leftarrow \\textbf{Backtrack}(\\mathcal{X},d_{backtrack})$\\;\n$d \\leftarrow d_{backtrack}$\\;\n}\n\n\\eIf{Restart condition}{$d \\leftarrow \\textbf{Restart}(d)$}{ continue }\n\\eIf{Rephase condition}{$\\mathcal{X} \\leftarrow \\textbf{Rephase}(\\mathcal{X})$}{ continue }\n\\eIf{Reduce condition}{$C_{learned} \\leftarrow \\textbf{Reduce}(C_{learned})$}{ continue }\n}\n{\n\\eIf{All variables are assigned with a value}{return \\textsc{SAT}}\n{\n$d \\leftarrow d + 1$\\;\n$\\mathcal{X} \\leftarrow \\textbf{Make Decision}(\\mathcal{X})$\n}\n}\n}\n\\end{algorithm2e}[ht!]\n\\caption{ModSAT}\n\\label{alg:modsat}\n\\textbf{Input:} A CNF $F$F of SAT instance\\;\n\\textbf{Initialization: } decision level $d \\leftarrow 0$d \\leftarrow 0, current assignment of variables $\\mathcal{X} \\leftarrow \\emptyset$\\mathcal{X} \\leftarrow \\emptyset\\;\n\n\\While{\\textbf{True}}\\textbf{True}{\n$\\mathcal{X} \\leftarrow \\textbf{Unit Propagation}(F,\\mathcal{X})$\\;\n\\eIf{Conflicts are detected in $\\mathcal{X}$}{\n\\eIf{$d == 0$}{return \\textsc{UNSAT}}\n{$\\mathcal{C}_{conflict}, d_{backtrack} \\leftarrow \\textbf{Analyze Conflict}(F,\\mathcal{X})$ \\;\n$C_{learned} \\leftarrow \\textbf{Learn Clause}(\\mathcal{C}_{conflict},\\mathcal{X})$ \\;\n$F \\leftarrow F \\land C_{learned}$\\;\n$\\mathcal{X} \\leftarrow \\textbf{Backtrack}(\\mathcal{X},d_{backtrack})$\\;\n$d \\leftarrow d_{backtrack}$\\;\n}\n\n\\eIf{Restart condition}{$d \\leftarrow \\textbf{Restart}(d)$}{ continue }\n\\eIf{Rephase condition}{$\\mathcal{X} \\leftarrow \\textbf{Rephase}(\\mathcal{X})$}{ continue }\n\\eIf{Reduce condition}{$C_{learned} \\leftarrow \\textbf{Reduce}(C_{learned})$}{ continue }\n}\n{\n\\eIf{All variables are assigned with a value}{return \\textsc{SAT}}\n{\n$d \\leftarrow d + 1$\\;\n$\\mathcal{X} \\leftarrow \\textbf{Make Decision}(\\mathcal{X})$\n}\n}\n}\n$\\mathcal{X} \\leftarrow \\textbf{Unit Propagation}(F,\\mathcal{X})$\\mathcal{X} \\leftarrow \\textbf{Unit Propagation}(F,\\mathcal{X})\\;\n\\eIf{Conflicts are detected in $\\mathcal{X}$}Conflicts are detected in $\\mathcal{X}$\\mathcal{X}{\n\\eIf{$d == 0$}{return \\textsc{UNSAT}}\n{$\\mathcal{C}_{conflict}, d_{backtrack} \\leftarrow \\textbf{Analyze Conflict}(F,\\mathcal{X})$ \\;\n$C_{learned} \\leftarrow \\textbf{Learn Clause}(\\mathcal{C}_{conflict},\\mathcal{X})$ \\;\n$F \\leftarrow F \\land C_{learned}$\\;\n$\\mathcal{X} \\leftarrow \\textbf{Backtrack}(\\mathcal{X},d_{backtrack})$\\;\n$d \\leftarrow d_{backtrack}$\\;\n}\n\n\\eIf{Restart condition}{$d \\leftarrow \\textbf{Restart}(d)$}{ continue }\n\\eIf{Rephase condition}{$\\mathcal{X} \\leftarrow \\textbf{Rephase}(\\mathcal{X})$}{ continue }\n\\eIf{Reduce condition}{$C_{learned} \\leftarrow \\textbf{Reduce}(C_{learned})$}{ continue }\n}\n\\eIf{$d == 0$}$d == 0$d == 0{return \\textsc{UNSAT}}return \\textsc{UNSAT}\n{$\\mathcal{C}_{conflict}, d_{backtrack} \\leftarrow \\textbf{Analyze Conflict}(F,\\mathcal{X})$ \\;\n$C_{learned} \\leftarrow \\textbf{Learn Clause}(\\mathcal{C}_{conflict},\\mathcal{X})$ \\;\n$F \\leftarrow F \\land C_{learned}$\\;\n$\\mathcal{X} \\leftarrow \\textbf{Backtrack}(\\mathcal{X},d_{backtrack})$\\;\n$d \\leftarrow d_{backtrack}$\\;\n}$\\mathcal{C}_{conflict}, d_{backtrack} \\leftarrow \\textbf{Analyze Conflict}(F,\\mathcal{X})$\\mathcal{C}_{conflict}conflict, d_{backtrack}backtrack \\leftarrow \\textbf{Analyze Conflict}(F,\\mathcal{X}) \\;\n$C_{learned} \\leftarrow \\textbf{Learn Clause}(\\mathcal{C}_{conflict},\\mathcal{X})$C_{learned}learned \\leftarrow \\textbf{Learn Clause}(\\mathcal{C}_{conflict}conflict,\\mathcal{X}) \\;\n$F \\leftarrow F \\land C_{learned}$F \\leftarrow F \\land C_{learned}learned\\;\n$\\mathcal{X} \\leftarrow \\textbf{Backtrack}(\\mathcal{X},d_{backtrack})$\\mathcal{X} \\leftarrow \\textbf{Backtrack}(\\mathcal{X},d_{backtrack}backtrack)\\;\n$d \\leftarrow d_{backtrack}$d \\leftarrow d_{backtrack}backtrack\\;\n\n\n\\eIf{Restart condition}Restart condition{$d \\leftarrow \\textbf{Restart}(d)$}$d \\leftarrow \\textbf{Restart}(d)$d \\leftarrow \\textbf{Restart}(d){ continue } continue \n\\eIf{Rephase condition}Rephase condition{$\\mathcal{X} \\leftarrow \\textbf{Rephase}(\\mathcal{X})$}$\\mathcal{X} \\leftarrow \\textbf{Rephase}(\\mathcal{X})$\\mathcal{X} \\leftarrow \\textbf{Rephase}(\\mathcal{X}){ continue } continue \n\\eIf{Reduce condition}Reduce condition{$C_{learned} \\leftarrow \\textbf{Reduce}(C_{learned})$}$C_{learned} \\leftarrow \\textbf{Reduce}(C_{learned})$C_{learned}learned \\leftarrow \\textbf{Reduce}(C_{learned}learned){ continue } continue \n\n{\n\\eIf{All variables are assigned with a value}{return \\textsc{SAT}}\n{\n$d \\leftarrow d + 1$\\;\n$\\mathcal{X} \\leftarrow \\textbf{Make Decision}(\\mathcal{X})$\n}\n}\n\\eIf{All variables are assigned with a value}All variables are assigned with a value{return \\textsc{SAT}}return \\textsc{SAT}\n{\n$d \\leftarrow d + 1$\\;\n$\\mathcal{X} \\leftarrow \\textbf{Make Decision}(\\mathcal{X})$\n}\n$d \\leftarrow d + 1$d \\leftarrow d + 1\\;\n$\\mathcal{X} \\leftarrow \\textbf{Make Decision}(\\mathcal{X})$\\mathcal{X} \\leftarrow \\textbf{Make Decision}(\\mathcal{X})\n\n\n\n\n\n\n", "appendix": false}, "ModSAT: A Modularized SAT solver": {"content": "\n\\subsection{Overview of ModSAT}\nIn this section, details of the proposed modularized SAT solver are provided. ModSAT obeys the basic CDCL framework~\\cite{cdcl} in Algorithm~\\ref{alg:CDCL},\nwhich usually initiates with an empty set of partial assignments (line 2). The Unit Propagation (UP), also called Boolean Constraint Propagation, assigns values to variable in clauses which has only one variable. UP can always make a clause satisfied, and this operation will repeat until no more UP is possible (line 4). If no conflicts are detected in $\\mathcal{X}$\\mathcal{X} during the Decision Detection phase, the algorithm will select a variable to assign a value (line 19). This Make Decision step usually contains a few heuristics. When conflicts are detected (line 5), Analyze Conflict will identify the conflicted clauses (line 9), and a newly learnt clause will be derived based on the clause (i.e., the current partial assignment) of conflicts (line 10). Afterwards, the algorithm backtracks to an earlier decision level (lines 12-13). Once all variables are assigned and no conflict is detected, the algorithm obtains a satisfied assignment (line 16); otherwise, detecting conflicts at the decision level $0$0 indicates that the given CNF is unsatisfiable (line 7).\n\n\nVarious heuristics have been  proposed in ModSAT to enhance its performance. For instance, \\emph{reduce} heuristics identify and remove the learnt clauses by controlling the size of the tracking list. In addition, \\emph{bump var heuristics} are usually incorporated in the Analyze Conflict step, which affect the choice of variables in the Make Decision function. While the order of choosing variables can determine the search path of branching, \n\\emph{rephase} heuristics can control the polarity in variales to be selected. Also, \\emph{restart} heuristics may abandon the current search path, allowing algorithms to explore possibly easier search regions.\n\n\n\nMore precisely, in ModSAT, we have defined {\\em seven}\\em seven functions which are independently implemented: \\textbf{restart function}, which manages restart heuristics; \\textbf{restart condition}, which determines when to execute restart; \\textbf{reduce condition}, which determines when to reduce; \\textbf{rephase function}, which manages rephase heuristics; \\textbf{rephase condition}, which determines when to rephase; \\textbf{bump var activity}, which governs the order of variables selection in Make Decision; and \\textbf{bump cla activity} that govern the order of clauses being removed during reduce. \nThese functions collectively improve the solver's ability to handle large and complex SAT instances by balancing exploration, exploitation, and resource management.  The combination of conflict-driven learning, backtracking, and heuristic enhancements makes ModSAT an efficient and robust SAT solver.\n\n\\subsection {Three principles behind ModSAT}\nAs already mentioned in the paper,  we follow three principles when developing ModSAT to ensure it is LLM-friendly:\n\n\\begin{itemize}\n    \\item \\textbf{Maintain functions simple and focus.} The function optimized by LLMs should be simple and explicit, unlike common implementation in complex solvers.\n    \\item \\textbf{Utilize class variables for shared information.} Local variables should be declared as class member variables to give LLMs access to them.\n    \\item \\textbf{Proactively prevent bugs during heuristics discovery.} The bugs written by LLMs should be fixed proactively, so that the solver could compile correctly with the same heuristics, which helps LLMs to generate more diverse correct codes.\n\\end{itemize}\\begin{itemize}\n    \\item \\textbf{Maintain functions simple and focus.} The function optimized by LLMs should be simple and explicit, unlike common implementation in complex solvers.\n    \\item \\textbf{Utilize class variables for shared information.} Local variables should be declared as class member variables to give LLMs access to them.\n    \\item \\textbf{Proactively prevent bugs during heuristics discovery.} The bugs written by LLMs should be fixed proactively, so that the solver could compile correctly with the same heuristics, which helps LLMs to generate more diverse correct codes.\n\\end{itemize}\n    \\item \\textbf{Maintain functions simple and focus.} The function optimized by LLMs should be simple and explicit, unlike common implementation in complex solvers.\n    \\item \\textbf{Utilize class variables for shared information.} Local variables should be declared as class member variables to give LLMs access to them.\n    \\item \\textbf{Proactively prevent bugs during heuristics discovery.} The bugs written by LLMs should be fixed proactively, so that the solver could compile correctly with the same heuristics, which helps LLMs to generate more diverse correct codes.\n\n\nThe following example demonstrates the application of the principle \\emph{Maintain functions simple and focus},  with the original function given in Figure~\\ref{fig:rule1-1}. Instead of modifying the whole search function by LLMs, we modularize it into three distinct functions by isolating the components  that significantly impact the performance and are suitable for LLM to modify, see Figure~\\ref{fig:rule1-2}. The decomposition also enables LLMs to focus on refining one kind of heuristic at a time, thereby enhancing the code generation capability.\n\n\n\n\\begin{figure}[ht!]\n\\begin{cppcode}{Maintain functions simple: Original function to modify}\nlbool Solver::search(int nof_conflicts){\n    // if there is a conflict\n    ...... ......\n    // if there is no conflict\n    if ((lbd_queue_size == 50 && 0.8 * fast_lbd_sum / lbd_queue_size > slow_lbd_sum / conflicts) || !withinBudget())\n        restart_function();\n\n    // Simplify the set of problem clauses:\n    if (decisionLevel() == 0 && !simplify())\n        return l_False;\n            \n    // Reduce the set of learnt clauses:\n        if (learnts.size()-nAssigns() >= max_learnts)\n                reduceDB();\n    if (rephase_condition())\n        rephase_function();\n        \n    Lit next = lit_Undef;\n    while (decisionLevel() < assumptions.size()){\n        // Perform user provided assumption:\n        Lit p = assumptions[decisionLevel()];\n        if (value(p) == l_True){\n            // Dummy decision level:\n            newDecisionLevel();\n            }else if (value(p) == l_False){\n                analyzeFinal(~p, conflict);\n                return l_False;\n            }else{\n                next = p;\n                break;\n            }\n        }\n\n    if (next == lit_Undef){\n        // New variable decision:\n        decisions++;\n        next = pickBranchLit();\n\n        if (next == lit_Undef)\n            // Model found:\n            return l_True;\n    }\n    newDecisionLevel();\n    uncheckedEnqueue(next);\n}\n\\end{cppcode}\n    \\caption{Illustration of principle {\\em Maintain functions simple and focus.}}\n    \\label{fig:rule1-1}\n\\end{figure}\n{Maintain functions simple: Original function to modify}Maintain functions simple: Original function to modify\nlbool Solver::search(int nof_conflicts){\n    // if there is a conflict\n    ...... ......\n    // if there is no conflict\n    if ((lbd_queue_size == 50 && 0.8 * fast_lbd_sum / lbd_queue_size > slow_lbd_sum / conflicts) || !withinBudget())\n        restart_function();\n\n    // Simplify the set of problem clauses:\n    if (decisionLevel() == 0 && !simplify())\n        return l_False;\n            \n    // Reduce the set of learnt clauses:\n        if (learnts.size()-nAssigns() >= max_learnts)\n                reduceDB();\n    if (rephase_condition())\n        rephase_function();\n        \n    Lit next = lit_Undef;\n    while (decisionLevel() < assumptions.size()){\n        // Perform user provided assumption:\n        Lit p = assumptions[decisionLevel()];\n        if (value(p) == l_True){\n            // Dummy decision level:\n            newDecisionLevel();\n            }else if (value(p) == l_False){\n                analyzeFinal(~p, conflict);\n                return l_False;\n            }else{\n                next = p;\n                break;\n            }\n        }\n\n    if (next == lit_Undef){\n        // New variable decision:\n        decisions++;\n        next = pickBranchLit();\n\n        if (next == lit_Undef)\n            // Model found:\n            return l_True;\n    }\n    newDecisionLevel();\n    uncheckedEnqueue(next);\n}\n    // if there is a conflict\n    ...... ......\n    // if there is no conflict\n    if ((lbd_queue_size == 50 && 0.8 * fast_lbd_sum / lbd_queue_size > slow_lbd_sum / conflicts) || !withinBudget())\n        restart_function();\n\n    // Simplify the set of problem clauses:\n    if (decisionLevel() == 0 && !simplify())\n        return l_False;\n            \n    // Reduce the set of learnt clauses:\n        if (learnts.size()-nAssigns() >= max_learnts)\n                reduceDB();\n    if (rephase_condition())\n        rephase_function();\n        \n    Lit next = lit_Undef;\n    while (decisionLevel() < assumptions.size()){\n        // Perform user provided assumption:\n        Lit p = assumptions[decisionLevel()];\n        if (value(p) == l_True){\n            // Dummy decision level:\n            newDecisionLevel();\n            }else if (value(p) == l_False){\n                analyzeFinal(~p, conflict);\n                return l_False;\n            }else{\n                next = p;\n                break;\n            }\n        }\n        // Perform user provided assumption:\n        Lit p = assumptions[decisionLevel()];\n        if (value(p) == l_True){\n            // Dummy decision level:\n            newDecisionLevel();\n            }\n            // Dummy decision level:\n            newDecisionLevel();\n            else if (value(p) == l_False){\n                analyzeFinal(~p, conflict);\n                return l_False;\n            }\n                analyzeFinal(~p, conflict);\n                return l_False;\n            else{\n                next = p;\n                break;\n            }\n                next = p;\n                break;\n            \n        \n\n    if (next == lit_Undef){\n        // New variable decision:\n        decisions++;\n        next = pickBranchLit();\n\n        if (next == lit_Undef)\n            // Model found:\n            return l_True;\n    }\n        // New variable decision:\n        decisions++;\n        next = pickBranchLit();\n\n        if (next == lit_Undef)\n            // Model found:\n            return l_True;\n    \n    newDecisionLevel();\n    uncheckedEnqueue(next);\n\n\n    \\caption{Illustration of principle {\\em Maintain functions simple and focus.}}\n    \\label{fig:rule1-1}\n\n\n\\begin{figure}[ht!]\n\\begin{cppcode}{Maintain functions simple: modularized function to modify}\n// original function which has been modularized\nlbool Solver::search(int nof_conflicts){\n    ...... ......\n\n    if (restart_condition())\n        restart_function();\n    if (reduce_condition())\n        reduceDB();\n\n    if (rephase_condition())\n        rephase_function();\n        \n    ...... ......\n}\n\n// functions to modify\nbool Solver::rephase_condition() {\n    if (rephases >= rephase_limit) \n        return true;\n    else \n        return false;\n}\n\nbool Solver::reduce_condition() {\n    if (rephases >= rephase_limit) \n        return true;\n    else \n        return false;\n}\n\nbool Solver::restart_condition(){\n    if ((lbd_queue_size == 50 && 0.8 * fast_lbd_sum / lbd_queue_size > slow_lbd_sum / conflicts) || !withinBudget())\n        return true;\n    else\n        return false;\n}\n\\end{cppcode}\n    \\caption{Illustration of principle {\\em Maintain functions simple and focus}.}\n    \\label{fig:rule1-2}\n\\end{figure}\n{Maintain functions simple: modularized function to modify}Maintain functions simple: modularized function to modify\n// original function which has been modularized\nlbool Solver::search(int nof_conflicts){\n    ...... ......\n\n    if (restart_condition())\n        restart_function();\n    if (reduce_condition())\n        reduceDB();\n\n    if (rephase_condition())\n        rephase_function();\n        \n    ...... ......\n}\n    ...... ......\n\n    if (restart_condition())\n        restart_function();\n    if (reduce_condition())\n        reduceDB();\n\n    if (rephase_condition())\n        rephase_function();\n        \n    ...... ......\n\n\n// functions to modify\nbool Solver::rephase_condition() {\n    if (rephases >= rephase_limit) \n        return true;\n    else \n        return false;\n}\n    if (rephases >= rephase_limit) \n        return true;\n    else \n        return false;\n\n\nbool Solver::reduce_condition() {\n    if (rephases >= rephase_limit) \n        return true;\n    else \n        return false;\n}\n    if (rephases >= rephase_limit) \n        return true;\n    else \n        return false;\n\n\nbool Solver::restart_condition(){\n    if ((lbd_queue_size == 50 && 0.8 * fast_lbd_sum / lbd_queue_size > slow_lbd_sum / conflicts) || !withinBudget())\n        return true;\n    else\n        return false;\n}\n    if ((lbd_queue_size == 50 && 0.8 * fast_lbd_sum / lbd_queue_size > slow_lbd_sum / conflicts) || !withinBudget())\n        return true;\n    else\n        return false;\n\n\n    \\caption{Illustration of principle {\\em Maintain functions simple and focus}.}\n    \\label{fig:rule1-2}\n\n\n\nFor the principle \\emph{use Class Variables for Shared information}, we move variables that may reside in local scope into class members to ensure that LLMs can access this shared information, see Figure~\\ref{fig:rule2-1}.\n\n\\begin{figure}[ht!]\n\\begin{cppcode}{Add class member variables}\n    // LBD heuristics\n    int lbd_queue[500],   // circled queue saved the recent 500 LBDs.\n        lbd_queue_size,   // The number of LBDs in this queue\n        lbd_queue_pos;  \n    double fast_lbd_sum, slow_lbd_sum;   \n\n    // rephase heuristics\n    int rephases, rephase_limit, rephase_count, threshold;\n    double last_rephase_progress;\n\n    // restart heuristics\n    int curr_restarts;\n    double last_restart_progress;\n\\end{cppcode}\n    \\caption{Illustration of principle {\\em Utilize class variables for shared information}}\n    \\label{fig:rule2-1}\n\\end{figure}\n{Add class member variables}Add class member variables\n    // LBD heuristics\n    int lbd_queue[500],   // circled queue saved the recent 500 LBDs.\n        lbd_queue_size,   // The number of LBDs in this queue\n        lbd_queue_pos;  \n    double fast_lbd_sum, slow_lbd_sum;   \n\n    // rephase heuristics\n    int rephases, rephase_limit, rephase_count, threshold;\n    double last_rephase_progress;\n\n    // restart heuristics\n    int curr_restarts;\n    double last_restart_progress;\n\n    \\caption{Illustration of principle {\\em Utilize class variables for shared information}}\n    \\label{fig:rule2-1}\n\n\n\nFigures~\\ref{fig:rule3-1} and \\ref{fig:rule3-2} provide two example on how to {\\em prevent bugs during heuristics discovery proactively}\\em prevent bugs during heuristics discovery proactively. The first one is to include some extra packages to prevent LLMs from implementing extra functions, while the second one is to overload common functions to prevent LLMs from incorrectly implementing simple functions because of a misunderstanding of data structures.\n\n\\begin{figure}[ht!]\n\\begin{cppcode}{Prevent bugs: add more packages}\n#include <math.h>\n#include <unordered_set>\n#include <algorithm>\nusing namespace std;\n\\end{cppcode}\n    \\caption{Illustration of principle {\\em Proactively prevent bugs during heuristics discovery}}\n    \\label{fig:rule3-1}\n\\end{figure}\n{Prevent bugs: add more packages}Prevent bugs: add more packages\n#include <math.h>\n#include <unordered_set>\n#include <algorithm>\nusing namespace std;\n\n    \\caption{Illustration of principle {\\em Proactively prevent bugs during heuristics discovery}}\n    \\label{fig:rule3-1}\n\n\n\\begin{figure}[ht!]\n\\begin{cppcode}{Prevent Bugs: overloading functions}\n#include <type_traits>\n\ntemplate <typename T1, typename T2>\ntypename std::common_type<T1, T2>::type max(T1 a, T2 b) {\n    static_assert(std::is_integral<T1>::value && std::is_integral<T2>::value,\n                  \"max: Both types must be integers (int or long int)\");\n    return (a < b) ? b : a;\n}\n\ntemplate <typename T1, typename T2>\ntypename std::common_type<T1, T2>::type min(T1 a, T2 b) {\n    static_assert(std::is_integral<T1>::value && std::is_integral<T2>::value,\n                  \"min: Both types must be integers (int or long int)\");\n    return (a < b) ? a : b;\n}\n\ntemplate <typename T1, typename T2>\ntypename std::common_type<T1, T2>::type max(T1 a, T2 b) {\n    static_assert(std::is_floating_point<T1>::value && std::is_floating_point<T2>::value,\n                  \"max: Both types must be floating-point (float or double)\");\n    return (a < b) ? b : a;\n}\n\ntemplate <typename T1, typename T2>\ntypename std::common_type<T1, T2>::type min(T1 a, T2 b) {\n    static_assert(std::is_floating_point<T1>::value && std::is_floating_point<T2>::value,\n                  \"min: Both types must be floating-point (float or double)\");\n    return (a < b) ? a : b;\n}\n\\end{cppcode}\n    \\caption{Illustration of principle {\\em Proactively prevent bugs during heuristics discovery.}}\n    \\label{fig:rule3-2}\n\\end{figure}\n{Prevent Bugs: overloading functions}Prevent Bugs: overloading functions\n#include <type_traits>\n\ntemplate <typename T1, typename T2>\ntypename std::common_type<T1, T2>::type max(T1 a, T2 b) {\n    static_assert(std::is_integral<T1>::value && std::is_integral<T2>::value,\n                  \"max: Both types must be integers (int or long int)\");\n    return (a < b) ? b : a;\n}\n    static_assert(std::is_integral<T1>::value && std::is_integral<T2>::value,\n                  \"max: Both types must be integers (int or long int)\");\n    return (a < b) ? b : a;\n\n\ntemplate <typename T1, typename T2>\ntypename std::common_type<T1, T2>::type min(T1 a, T2 b) {\n    static_assert(std::is_integral<T1>::value && std::is_integral<T2>::value,\n                  \"min: Both types must be integers (int or long int)\");\n    return (a < b) ? a : b;\n}\n    static_assert(std::is_integral<T1>::value && std::is_integral<T2>::value,\n                  \"min: Both types must be integers (int or long int)\");\n    return (a < b) ? a : b;\n\n\ntemplate <typename T1, typename T2>\ntypename std::common_type<T1, T2>::type max(T1 a, T2 b) {\n    static_assert(std::is_floating_point<T1>::value && std::is_floating_point<T2>::value,\n                  \"max: Both types must be floating-point (float or double)\");\n    return (a < b) ? b : a;\n}\n    static_assert(std::is_floating_point<T1>::value && std::is_floating_point<T2>::value,\n                  \"max: Both types must be floating-point (float or double)\");\n    return (a < b) ? b : a;\n\n\ntemplate <typename T1, typename T2>\ntypename std::common_type<T1, T2>::type min(T1 a, T2 b) {\n    static_assert(std::is_floating_point<T1>::value && std::is_floating_point<T2>::value,\n                  \"min: Both types must be floating-point (float or double)\");\n    return (a < b) ? a : b;\n}\n    static_assert(std::is_floating_point<T1>::value && std::is_floating_point<T2>::value,\n                  \"min: Both types must be floating-point (float or double)\");\n    return (a < b) ? a : b;\n\n\n    \\caption{Illustration of principle {\\em Proactively prevent bugs during heuristics discovery.}}\n    \\label{fig:rule3-2}\n\n\n\\begin{algorithm2e}[t]\n\\caption{Automatic Prompt Optimization}\n\\label{alg:prompt}\n\\SetAlgoLined\n\\DontPrintSemicolon\n\\KwIn{initial prompt template $P$, solver codebase $S$, max\\_iterations $i$, prompt optimized part $R =\\{ Role, Goal, Tips \\}$}\n\\KwOut{optimized prompt template $P^*$}\n$i \\gets 10$ \\tcp*{prompt optimization iterations}\n$j \\gets 20$ \\tcp*{number of code generation in each iteration}\n\\While{$i \\ge 0$}{\n    select prompt part $r$ from $R$ uniformly at random \\\\\n     $P' \\gets$ refine\\_prompt($r, P$) \\tcp*{LLMs refine the prompt template}\n    \\While{$j \\ge 0$}{\n    generated code $c \\gets \\text{call\\_llm}(\\textit{current\\_prompt})$ \\\\\n    compilation error $e \\gets$ compile($c$, $S$) \\\\\n    \\eIf{$\\neg e $}{\n            $C \\gets C \\cup c$\n            }\n    {\n        \n        $\\text{execute\\_code}(\\textit{corrected\\_code})$\\;\n    }\n    $j \\gets j - 1$\\;\n    }\n            \n    diversity $ d_i \\gets \\text{compute\\_code\\_diversity}(C)$\\;\n    success rate $ s_i \\gets \\text{compute\\_code\\_success}(C)$\\;\n\n    \\eIf{$d_i > d$ and $s_i > threshold $}{\n        $d \\gets d_i $\\\\\n    $P \\gets \\text{update\\_prompt}(S, P')$\\;\n    }\n\n    $i \\gets i - 1$\\;\n}\n\\end{algorithm2e}\\begin{algorithm2e}[t]\n\\caption{Automatic Prompt Optimization}\n\\label{alg:prompt}\n\\SetAlgoLined\n\\DontPrintSemicolon\n\\KwIn{initial prompt template $P$, solver codebase $S$, max\\_iterations $i$, prompt optimized part $R =\\{ Role, Goal, Tips \\}$}\n\\KwOut{optimized prompt template $P^*$}\n$i \\gets 10$ \\tcp*{prompt optimization iterations}\n$j \\gets 20$ \\tcp*{number of code generation in each iteration}\n\\While{$i \\ge 0$}{\n    select prompt part $r$ from $R$ uniformly at random \\\\\n     $P' \\gets$ refine\\_prompt($r, P$) \\tcp*{LLMs refine the prompt template}\n    \\While{$j \\ge 0$}{\n    generated code $c \\gets \\text{call\\_llm}(\\textit{current\\_prompt})$ \\\\\n    compilation error $e \\gets$ compile($c$, $S$) \\\\\n    \\eIf{$\\neg e $}{\n            $C \\gets C \\cup c$\n            }\n    {\n        \n        $\\text{execute\\_code}(\\textit{corrected\\_code})$\\;\n    }\n    $j \\gets j - 1$\\;\n    }\n            \n    diversity $ d_i \\gets \\text{compute\\_code\\_diversity}(C)$\\;\n    success rate $ s_i \\gets \\text{compute\\_code\\_success}(C)$\\;\n\n    \\eIf{$d_i > d$ and $s_i > threshold $}{\n        $d \\gets d_i $\\\\\n    $P \\gets \\text{update\\_prompt}(S, P')$\\;\n    }\n\n    $i \\gets i - 1$\\;\n}\n\\end{algorithm2e}[t]\n\\caption{Automatic Prompt Optimization}\n\\label{alg:prompt}\n\\SetAlgoLined\n\\DontPrintSemicolon\n\\KwIn{initial prompt template $P$, solver codebase $S$, max\\_iterations $i$, prompt optimized part $R =\\{ Role, Goal, Tips \\}$}initial prompt template $P$P, solver codebase $S$S, max\\_iterations $i$i, prompt optimized part $R =\\{ Role, Goal, Tips \\}$R =\\{ Role, Goal, Tips \\}\n\\KwOut{optimized prompt template $P^*$}optimized prompt template $P^*$P^*\n$i \\gets 10$i \\gets 10 \\tcp*{prompt optimization iterations}prompt optimization iterations\n$j \\gets 20$j \\gets 20 \\tcp*{number of code generation in each iteration}number of code generation in each iteration\n\\While{$i \\ge 0$}$i \\ge 0$i \\ge 0{\n    select prompt part $r$ from $R$ uniformly at random \\\\\n     $P' \\gets$ refine\\_prompt($r, P$) \\tcp*{LLMs refine the prompt template}\n    \\While{$j \\ge 0$}{\n    generated code $c \\gets \\text{call\\_llm}(\\textit{current\\_prompt})$ \\\\\n    compilation error $e \\gets$ compile($c$, $S$) \\\\\n    \\eIf{$\\neg e $}{\n            $C \\gets C \\cup c$\n            }\n    {\n        \n        $\\text{execute\\_code}(\\textit{corrected\\_code})$\\;\n    }\n    $j \\gets j - 1$\\;\n    }\n            \n    diversity $ d_i \\gets \\text{compute\\_code\\_diversity}(C)$\\;\n    success rate $ s_i \\gets \\text{compute\\_code\\_success}(C)$\\;\n\n    \\eIf{$d_i > d$ and $s_i > threshold $}{\n        $d \\gets d_i $\\\\\n    $P \\gets \\text{update\\_prompt}(S, P')$\\;\n    }\n\n    $i \\gets i - 1$\\;\n}\n    select prompt part $r$r from $R$R uniformly at random \\\\\n     $P' \\gets$P' \\gets refine\\_prompt($r, P$r, P) \\tcp*{LLMs refine the prompt template}LLMs refine the prompt template\n    \\While{$j \\ge 0$}$j \\ge 0$j \\ge 0{\n    generated code $c \\gets \\text{call\\_llm}(\\textit{current\\_prompt})$ \\\\\n    compilation error $e \\gets$ compile($c$, $S$) \\\\\n    \\eIf{$\\neg e $}{\n            $C \\gets C \\cup c$\n            }\n    {\n        \n        $\\text{execute\\_code}(\\textit{corrected\\_code})$\\;\n    }\n    $j \\gets j - 1$\\;\n    }\n    generated code $c \\gets \\text{call\\_llm}(\\textit{current\\_prompt})$c \\gets \\text{call\\_llm}(\\textit{current\\_prompt}) \\\\\n    compilation error $e \\gets$e \\gets compile($c$c, $S$S) \\\\\n    \\eIf{$\\neg e $}$\\neg e $\\neg e {\n            $C \\gets C \\cup c$\n            }\n            $C \\gets C \\cup c$C \\gets C \\cup c\n            \n    {\n        \n        $\\text{execute\\_code}(\\textit{corrected\\_code})$\\;\n    }\n        \n        $\\text{execute\\_code}(\\textit{corrected\\_code})$\\text{execute\\_code}(\\textit{corrected\\_code})\\;\n    \n    $j \\gets j - 1$j \\gets j - 1\\;\n    \n            \n    diversity $ d_i \\gets \\text{compute\\_code\\_diversity}(C)$ d_i \\gets \\text{compute\\_code\\_diversity}(C)\\;\n    success rate $ s_i \\gets \\text{compute\\_code\\_success}(C)$ s_i \\gets \\text{compute\\_code\\_success}(C)\\;\n\n    \\eIf{$d_i > d$ and $s_i > threshold $}$d_i > d$d_i > d and $s_i > threshold $s_i > threshold {\n        $d \\gets d_i $\\\\\n    $P \\gets \\text{update\\_prompt}(S, P')$\\;\n    }\n        $d \\gets d_i $d \\gets d_i \\\\\n    $P \\gets \\text{update\\_prompt}(S, P')$P \\gets \\text{update\\_prompt}(S, P')\\;\n    \n\n    $i \\gets i - 1$i \\gets i - 1\\;\n\n\n\n\n\n", "appendix": false}, "Automatic Prompt Optimization": {"content": "\nTo tackle the problem of prohibitive execution time (5000s timeout per instance) and with large performance variance across different datasets, we propose an unsupervised automatic prompt optimization method using Shannon entropy as the evaluation metric. This approach eliminates the dependency on explicit labels while maintaining the adaptability to the evolvement of LLMs, particularly suitable for compute-intensive optimization tasks with ambiguous success criteria. \n\nThe basic prompt template follows the instructions in OpenAI framework docs~\\cite{openai_docs}, which obeys the following format:\n\\begin{itemize}\n    \\item Define the \\textbf{Role} of an agent as a solver expert who needs to assess and improve the heuristics function in the SAT solver.\n    \\item Clearly state the \\textbf{Goal}, such as providing optimization suggestions, writing code, or feedback.\n    \\item Enhance the agents' capabilities by inserting optional \\textbf{Tips} that guide them to avoid common mistakes during code generation. Additionally, through this flexible interface, agents can effectively utilize external codes and results and can be instructed to specify the types of modification directions such as changing parameters, modifying heuristics, or adding new heuristics.\n    \\item Key code of SAT solver is appended at the end of each prompt to ensure all agents are in the same context. Note that the key code includes member parameters in cpp class of the solver (LLMs may utilize), along with the main loop function, and all corresponding functions LLMs may need to understand (e.g. such as the functions call the  target optimized function).\n\\end{itemize}\\begin{itemize}\n    \\item Define the \\textbf{Role} of an agent as a solver expert who needs to assess and improve the heuristics function in the SAT solver.\n    \\item Clearly state the \\textbf{Goal}, such as providing optimization suggestions, writing code, or feedback.\n    \\item Enhance the agents' capabilities by inserting optional \\textbf{Tips} that guide them to avoid common mistakes during code generation. Additionally, through this flexible interface, agents can effectively utilize external codes and results and can be instructed to specify the types of modification directions such as changing parameters, modifying heuristics, or adding new heuristics.\n    \\item Key code of SAT solver is appended at the end of each prompt to ensure all agents are in the same context. Note that the key code includes member parameters in cpp class of the solver (LLMs may utilize), along with the main loop function, and all corresponding functions LLMs may need to understand (e.g. such as the functions call the  target optimized function).\n\\end{itemize}\n    \\item Define the \\textbf{Role} of an agent as a solver expert who needs to assess and improve the heuristics function in the SAT solver.\n    \\item Clearly state the \\textbf{Goal}, such as providing optimization suggestions, writing code, or feedback.\n    \\item Enhance the agents' capabilities by inserting optional \\textbf{Tips} that guide them to avoid common mistakes during code generation. Additionally, through this flexible interface, agents can effectively utilize external codes and results and can be instructed to specify the types of modification directions such as changing parameters, modifying heuristics, or adding new heuristics.\n    \\item Key code of SAT solver is appended at the end of each prompt to ensure all agents are in the same context. Note that the key code includes member parameters in cpp class of the solver (LLMs may utilize), along with the main loop function, and all corresponding functions LLMs may need to understand (e.g. such as the functions call the  target optimized function).\n\n\n\\begin{figure*}[htbp!]\n    \\centering\n        \\includegraphics[width=0.8\\textwidth]{ModSAT_bar_chart_prompt.png}\n\n\\caption{\\textbf{Comparison over Different Prompts}.  This figure shows the performance  of AutoModSAT using different prompts. The vertical axis shows the PAR-2 improvement ratio compared to the original solver, while the two coordinates in the horizontal axis correspond to the original prompt (Original) and optimized prompt (Updated), respectively.}\n\\label{fig:prompt}\n\\end{figure*}\n    \\centering\n        \\includegraphics[width=0.8\\textwidth]{ModSAT_bar_chart_prompt.png}\n\n\\caption{\\textbf{Comparison over Different Prompts}.  This figure shows the performance  of AutoModSAT using different prompts. The vertical axis shows the PAR-2 improvement ratio compared to the original solver, while the two coordinates in the horizontal axis correspond to the original prompt (Original) and optimized prompt (Updated), respectively.}\n\\label{fig:prompt}\n\n\nThe previous three components, role, goal and tips can be automatically optimized by LLMs. In each iteration, we randomly select one component to optimize by LLMs, compute the correctness and diversity (entropy) of the generated codes, and update the component in prompt with better performance in both correctness and diversity. This loop will iterate until the stopping criteria is met, see Algorithm~\\ref{alg:prompt} for details.\nAn empirical evaluation of the original and optimized prompts   is presented in Figure~\\ref{fig:prompt}. It is clear that optimized prompt achieves better performance than the original one. \n\n\n\\begin{figure}[ht!]\n\\begin{tcolorbox}[colback=gray!10!white, colframe=gray!50!black, title=Original Prompt]\n(Role) You are a SAT solver researcher trying to rewrite the \\{\\{ func\\_name \\}\\}  function(s). \\\\\n\n(Goal) Your goal is to improve the SAT solver by rewriting the \\{\\{ func\\_name \\}\\}  function(s), after reading and understanding the <key code> of SAT solver below.\\\\\n\n(Tips) Tips:\\\\\n1) Your rewrited function code must start with '''// start {function name}''' and end with '''// end {function name}''' \\\\\n2) Your rewrited function(s) code must be different from original code, not just rewrite code synonymous! \\\\\n3) You are not allowed to create your own new function(s) in the rewrited function(s).  You are not allowed to create your own new global variables, but you can use the global variables existing in the <key code>. \\\\\n4) Make sure the rewrited function(s) code can be executed correctly. \\\\\n\n<key code> of SAT solver is:\\\\\n\\{\\{ replace\\_key\\_code \\}\\}\n\n\\end{tcolorbox}\n\n\\begin{tcolorbox}[colback=gray!10!white, colframe=gray!50!black, title=Updated Prompt]\n(Role) You are a SAT solver researcher trying to improve the \\{\\{ func\\_name \\}\\} function. \\\\\n\n(Goal) Objective:\\\\\nYour goal is to improve the SAT solver by rewriting the \\{\\{ func\\_name \\}\\}  function. \\\\\n\nInstructions: \\\\\n1. Carefully read and comprehend the <key code> of the SAT solver provided below. \\\\\n2. Analyze potential improvements and devise a strategy for optimizing the heuristics of function. \\\\\n3. Deliver your improved function(s) with the following format:\\\\\n   - Begin with: `// start {function name}`\\\\\n   - End with: `// end {function name}`\\\\\n\n(Tips) Tips:\\\\\n1. Ensure that your rewritten function(s) are substantially different from the original, beyond mere synonym replacements.\\\\\n2. You may utilize existing global variables from the <key code>, but refrain from introducing new global variables.\\\\\n3. Verify that the rewritten function(s) execute correctly.\\\\\n\n\nTake a deep breath and think it step by step. \\\\\n\n<key code> of SAT solver is: \\\\\n\"\"\"\n\\{\\{ replace\\_key\\_code \\}\\}\n\"\"\"\n...\n\\end{tcolorbox}\n    \\caption{Comparison of original prompt and optimized prompt}\n    \\label{fig:coder_prompt}\n\\end{figure}\n[colback=gray!10!white, colframe=gray!50!black, title=Original Prompt]\n(Role) You are a SAT solver researcher trying to rewrite the \\{\\{ func\\_name \\}\\}  function(s). \\\\\n\n(Goal) Your goal is to improve the SAT solver by rewriting the \\{\\{ func\\_name \\}\\}  function(s), after reading and understanding the <key code> of SAT solver below.\\\\\n\n(Tips) Tips:\\\\\n1) Your rewrited function code must start with '''// start {function name}function name''' and end with '''// end {function name}function name''' \\\\\n2) Your rewrited function(s) code must be different from original code, not just rewrite code synonymous! \\\\\n3) You are not allowed to create your own new function(s) in the rewrited function(s).  You are not allowed to create your own new global variables, but you can use the global variables existing in the <key code>. \\\\\n4) Make sure the rewrited function(s) code can be executed correctly. \\\\\n\n<key code> of SAT solver is:\\\\\n\\{\\{ replace\\_key\\_code \\}\\}\n\n\n\n[colback=gray!10!white, colframe=gray!50!black, title=Updated Prompt]\n(Role) You are a SAT solver researcher trying to improve the \\{\\{ func\\_name \\}\\} function. \\\\\n\n(Goal) Objective:\\\\\nYour goal is to improve the SAT solver by rewriting the \\{\\{ func\\_name \\}\\}  function. \\\\\n\nInstructions: \\\\\n1. Carefully read and comprehend the <key code> of the SAT solver provided below. \\\\\n2. Analyze potential improvements and devise a strategy for optimizing the heuristics of function. \\\\\n3. Deliver your improved function(s) with the following format:\\\\\n   - Begin with: `// start {function name}function name`\\\\\n   - End with: `// end {function name}function name`\\\\\n\n(Tips) Tips:\\\\\n1. Ensure that your rewritten function(s) are substantially different from the original, beyond mere synonym replacements.\\\\\n2. You may utilize existing global variables from the <key code>, but refrain from introducing new global variables.\\\\\n3. Verify that the rewritten function(s) execute correctly.\\\\\n\n\nTake a deep breath and think it step by step. \\\\\n\n<key code> of SAT solver is: \\\\\n\"\"\"\n\\{\\{ replace\\_key\\_code \\}\\}\n\"\"\"\n...\n\n    \\caption{Comparison of original prompt and optimized prompt}\n    \\label{fig:coder_prompt}\n\n\n\n", "appendix": false}, "Presearch strategy": {"content": "\n\n\n\\begin{algorithm2e}[ht!]\n\\caption{PreSearch Strategy in AutoModSAT}\\label{alg:autosat-pre}\n\\textbf{Input:} Datasets $P$, modularized SAT solver with seven functions $\\{h_1,\\ldots,h_7\\}$, prompt template, baseline functions $\\{b_1,\\ldots,b_7\\}$ \\\\\n\\textbf{Phase 1: PreSearch Function Candidate}\n$P_{\\text{compact}} \\leftarrow$ 50\\% representative instances from $P$ \\\\\n$R \\leftarrow \\emptyset$  \\tcp*{Retained function set}\n\\For{each function $h_i \\in \\{h_1,\\ldots,h_7\\}$}{\n    $A_{\\text{test}} \\leftarrow$ build solver replacing $h_i$ with baseline $b_i$ \\\\\n    $f_i, s_i \\leftarrow$ evaluate($A_{\\text{test}}$, $P_{\\text{compact}}$) \\tcp*{Get PAR-2 metric} \n}\n$F \\leftarrow $ sort($f_1, ..., f_7$) \\tcp*{Sort PAR-2 metric in different functions}\nGet top 4 function index $R$ from $F$ \\\\\n\n\\textbf{Phase 2: Evolutionary Algorithm Optimization} \n$A \\leftarrow$ solver with functions: $(\\forall i \\in R: h_i) \\cup (\\forall i \\notin R: b_i)$ \\\\\n$f^* \\leftarrow$ evaluate($A$, $P$)  \\tcp*{Full dataset evaluation}\n\n$\\text{evalBudget} \\leftarrow 50$  \\tcp*{Maximum evaluations}\n\n\\While{evalBudget $>0$}{\n    $M \\leftarrow \\emptyset$ \\\\\n    $\\ell \\sim \\text{Bin}(|R|,\\frac{1}{|R|})$  \\tcp*{Sample modification count}\n    chosen $\\ell$ distinct values $M \\leftarrow \\{m_0, \\ldots, m_\\ell\\}$ from $R$ uniformly at random\\;\n    Generate new functions $\\{h'_m\\}_{m\\in M}$ via LLM using $A$ and $M$ \\\\\n    $A' \\leftarrow$ update $A$ with $\\{h'_m\\}_{m\\in M}$ \\\\\n    $f(A') \\leftarrow$ evaluate($A'$, $P$) \\\\\n    \\If{$f(A') \\leq f^*$}{\n        $A \\leftarrow A'$ \\\\\n        $f^* \\leftarrow f(A')$\n    }\n    $\\text{evalBudget} \\leftarrow \\text{evalBudget} - 1$\n}\n\\end{algorithm2e}\\begin{algorithm2e}[ht!]\n\\caption{PreSearch Strategy in AutoModSAT}\\label{alg:autosat-pre}\n\\textbf{Input:} Datasets $P$, modularized SAT solver with seven functions $\\{h_1,\\ldots,h_7\\}$, prompt template, baseline functions $\\{b_1,\\ldots,b_7\\}$ \\\\\n\\textbf{Phase 1: PreSearch Function Candidate}\n$P_{\\text{compact}} \\leftarrow$ 50\\% representative instances from $P$ \\\\\n$R \\leftarrow \\emptyset$  \\tcp*{Retained function set}\n\\For{each function $h_i \\in \\{h_1,\\ldots,h_7\\}$}{\n    $A_{\\text{test}} \\leftarrow$ build solver replacing $h_i$ with baseline $b_i$ \\\\\n    $f_i, s_i \\leftarrow$ evaluate($A_{\\text{test}}$, $P_{\\text{compact}}$) \\tcp*{Get PAR-2 metric} \n}\n$F \\leftarrow $ sort($f_1, ..., f_7$) \\tcp*{Sort PAR-2 metric in different functions}\nGet top 4 function index $R$ from $F$ \\\\\n\n\\textbf{Phase 2: Evolutionary Algorithm Optimization} \n$A \\leftarrow$ solver with functions: $(\\forall i \\in R: h_i) \\cup (\\forall i \\notin R: b_i)$ \\\\\n$f^* \\leftarrow$ evaluate($A$, $P$)  \\tcp*{Full dataset evaluation}\n\n$\\text{evalBudget} \\leftarrow 50$  \\tcp*{Maximum evaluations}\n\n\\While{evalBudget $>0$}{\n    $M \\leftarrow \\emptyset$ \\\\\n    $\\ell \\sim \\text{Bin}(|R|,\\frac{1}{|R|})$  \\tcp*{Sample modification count}\n    chosen $\\ell$ distinct values $M \\leftarrow \\{m_0, \\ldots, m_\\ell\\}$ from $R$ uniformly at random\\;\n    Generate new functions $\\{h'_m\\}_{m\\in M}$ via LLM using $A$ and $M$ \\\\\n    $A' \\leftarrow$ update $A$ with $\\{h'_m\\}_{m\\in M}$ \\\\\n    $f(A') \\leftarrow$ evaluate($A'$, $P$) \\\\\n    \\If{$f(A') \\leq f^*$}{\n        $A \\leftarrow A'$ \\\\\n        $f^* \\leftarrow f(A')$\n    }\n    $\\text{evalBudget} \\leftarrow \\text{evalBudget} - 1$\n}\n\\end{algorithm2e}[ht!]\n\\caption{PreSearch Strategy in AutoModSAT}\\label{alg:autosat-pre}\n\\textbf{Input:} Datasets $P$P, modularized SAT solver with seven functions $\\{h_1,\\ldots,h_7\\}$\\{h_1,\\ldots,h_7\\}, prompt template, baseline functions $\\{b_1,\\ldots,b_7\\}$\\{b_1,\\ldots,b_7\\} \\\\\n\\textbf{Phase 1: PreSearch Function Candidate}\n$P_{\\text{compact}} \\leftarrow$P_{\\text{compact}}\\text{compact} \\leftarrow 50\\% representative instances from $P$P \\\\\n$R \\leftarrow \\emptyset$R \\leftarrow \\emptyset  \\tcp*{Retained function set}Retained function set\n\\For{each function $h_i \\in \\{h_1,\\ldots,h_7\\}$}each function $h_i \\in \\{h_1,\\ldots,h_7\\}$h_i \\in \\{h_1,\\ldots,h_7\\}{\n    $A_{\\text{test}} \\leftarrow$ build solver replacing $h_i$ with baseline $b_i$ \\\\\n    $f_i, s_i \\leftarrow$ evaluate($A_{\\text{test}}$, $P_{\\text{compact}}$) \\tcp*{Get PAR-2 metric} \n}\n    $A_{\\text{test}} \\leftarrow$A_{\\text{test}}\\text{test} \\leftarrow build solver replacing $h_i$h_i with baseline $b_i$b_i \\\\\n    $f_i, s_i \\leftarrow$f_i, s_i \\leftarrow evaluate($A_{\\text{test}}$A_{\\text{test}}\\text{test}, $P_{\\text{compact}}$P_{\\text{compact}}\\text{compact}) \\tcp*{Get PAR-2 metric}Get PAR-2 metric \n\n$F \\leftarrow $F \\leftarrow  sort($f_1, ..., f_7$f_1, ..., f_7) \\tcp*{Sort PAR-2 metric in different functions}Sort PAR-2 metric in different functions\nGet top 4 function index $R$R from $F$F \\\\\n\n\\textbf{Phase 2: Evolutionary Algorithm Optimization} \n$A \\leftarrow$A \\leftarrow solver with functions: $(\\forall i \\in R: h_i) \\cup (\\forall i \\notin R: b_i)$(\\forall i \\in R: h_i) \\cup (\\forall i \\notin R: b_i) \\\\\n$f^* \\leftarrow$f^* \\leftarrow evaluate($A$A, $P$P)  \\tcp*{Full dataset evaluation}Full dataset evaluation\n\n$\\text{evalBudget} \\leftarrow 50$\\text{evalBudget} \\leftarrow 50  \\tcp*{Maximum evaluations}Maximum evaluations\n\n\\While{evalBudget $>0$}evalBudget $>0$>0{\n    $M \\leftarrow \\emptyset$ \\\\\n    $\\ell \\sim \\text{Bin}(|R|,\\frac{1}{|R|})$  \\tcp*{Sample modification count}\n    chosen $\\ell$ distinct values $M \\leftarrow \\{m_0, \\ldots, m_\\ell\\}$ from $R$ uniformly at random\\;\n    Generate new functions $\\{h'_m\\}_{m\\in M}$ via LLM using $A$ and $M$ \\\\\n    $A' \\leftarrow$ update $A$ with $\\{h'_m\\}_{m\\in M}$ \\\\\n    $f(A') \\leftarrow$ evaluate($A'$, $P$) \\\\\n    \\If{$f(A') \\leq f^*$}{\n        $A \\leftarrow A'$ \\\\\n        $f^* \\leftarrow f(A')$\n    }\n    $\\text{evalBudget} \\leftarrow \\text{evalBudget} - 1$\n}\n    $M \\leftarrow \\emptyset$M \\leftarrow \\emptyset \\\\\n    $\\ell \\sim \\text{Bin}(|R|,\\frac{1}{|R|})$\\ell \\sim \\text{Bin}(|R|,\\frac{1}{|R|})  \\tcp*{Sample modification count}Sample modification count\n    chosen $\\ell$\\ell distinct values $M \\leftarrow \\{m_0, \\ldots, m_\\ell\\}$M \\leftarrow \\{m_0, \\ldots, m_\\ell\\} from $R$R uniformly at random\\;\n    Generate new functions $\\{h'_m\\}_{m\\in M}$\\{h'_m\\}_{m\\in M}m\\in M via LLM using $A$A and $M$M \\\\\n    $A' \\leftarrow$A' \\leftarrow update $A$A with $\\{h'_m\\}_{m\\in M}$\\{h'_m\\}_{m\\in M}m\\in M \\\\\n    $f(A') \\leftarrow$f(A') \\leftarrow evaluate($A'$A', $P$P) \\\\\n    \\If{$f(A') \\leq f^*$}$f(A') \\leq f^*$f(A') \\leq f^*{\n        $A \\leftarrow A'$ \\\\\n        $f^* \\leftarrow f(A')$\n    }\n        $A \\leftarrow A'$A \\leftarrow A' \\\\\n        $f^* \\leftarrow f(A')$f^* \\leftarrow f(A')\n    \n    $\\text{evalBudget} \\leftarrow \\text{evalBudget} - 1$\\text{evalBudget} \\leftarrow \\text{evalBudget} - 1\n\n\n\nTo overcome this combinatorial explosion when searching over all candidate functions, we propose a novel two-phase optimization strategy:\n\\begin{itemize}\n    \\item Presearh function candidate: Conduct small-scale preliminary testing to identify and eliminate functions that consistently degrade the performance.\n    \\item Refined evolutionary search: Execute a focused $(1+\\lambda)$ Evolutionary Algorithm (EA) search only on the high-impact candidate functions identified in the last phase.\n\\end{itemize}\\begin{itemize}\n    \\item Presearh function candidate: Conduct small-scale preliminary testing to identify and eliminate functions that consistently degrade the performance.\n    \\item Refined evolutionary search: Execute a focused $(1+\\lambda)$ Evolutionary Algorithm (EA) search only on the high-impact candidate functions identified in the last phase.\n\\end{itemize}\n    \\item Presearh function candidate: Conduct small-scale preliminary testing to identify and eliminate functions that consistently degrade the performance.\n    \\item Refined evolutionary search: Execute a focused $(1+\\lambda)$(1+\\lambda) Evolutionary Algorithm (EA) search only on the high-impact candidate functions identified in the last phase.\n\nA detailed description of this strategy  can be found in Algorithm~\\ref{alg:autosat-pre}. For the phase of presearh function candidate, we construct a compact and representative evaluation subset comprising the 50\\%  problem instances from the original dataset. This subset can capture the essential solver behavior while minimizing the evaluation cost. Each candidate function is evaluated separately on the sub-dataset for its impact on the solver's PAR-2 score (where lower values indicate better performance), which measures the standalone effect of adding the function to a baseline solver.\nThen functions that  degrade the PAR-2 score are identified and pruned. For each dataset, the pruned functions will be not be further considered for evolutionary search. This phase typically retains a small set of high-impact functions (e.g., 4 functions) that consistently show a positive or neutral effect on PAR-2 in the preliminary tests.\nFor the evolutionary optimization phase, we use the significantly refined function set (e.g., about 4 functions) to execute a standard $(1+\\lambda)$(1+\\lambda) Evolutionary Algorithm on the full target dataset to find optimal combinations.\n\nIt is also helpful to investigate the contribution of each function to the final results. To this end, we have calculated the number of times that a function contributes to the final performance improvement in each  experiment, see Figure~\\ref{fig:functioncontribution}, where each subfigure shows the results for one dataset. It can be observed that almost all functions we select could contribute substantially to the final performance,\n\n\\begin{figure*}[t]\n    \\centering\n        \\includegraphics[width=\\textwidth]{function_contribution.png}\n\\caption{Function Contribution: where the vertical axis lists different function candidates  and the horizontal axis denotes the frequency of contributions.}\n\n\\label{fig:functioncontribution}\n\\end{figure*}\n    \\centering\n        \\includegraphics[width=\\textwidth]{function_contribution.png}\n\\caption{Function Contribution: where the vertical axis lists different function candidates  and the horizontal axis denotes the frequency of contributions.}\n\n\\label{fig:functioncontribution}\n\n\n", "appendix": false}, "Heuristics discovery": {"content": "\nThe details of heuristics discovery in AutoModSAT in presented in Figure~\\ref{fig:discovery}, which contains three agents, LLMs coder, LLMs evaluator, LLMs repairer. Since  the LLM coder agent is already optimized in automatic prompt optimization, here we give a brief discussion of the LLMs evaluator and LLMs repairer.\n\nIn our experiments, we find that sometimes LLMs coder would generate synonymous code compared with original one, even though we have optimized the prompt. This will lead to redundant iterations in the evolutionary search. Thus, we develop an LLMs evaluator agent, which identifies whether the generated code is synonymous. If the code is synonymous, LLMs coder needs to regenerate a code; otherwise, the code will be sent to compile. \n\nIn addition, LLMs sometimes make mistakes, such as missing parentheses or utilizing incorrect data types. To address this issue, an LLM repairer agent is introduced. LLM repairer analyzes the LLM-generated code and the corresponding errors, and then seeks to fix the bug. This agent can successfully resolves some common errors. While there are some errors remaining uncorrectable,  LLM Coder will re-generate the code.\n\\begin{figure}[ht!]\n    \\centering\n        \\includegraphics[width=1.1\\textwidth]{HeuristicsDiscovery.png}\n        \\vspace{-2cm}\n\\caption{Details about heuristics discovery}\n\\label{fig:discovery}\n\\end{figure}\n    \\centering\n        \\includegraphics[width=1.1\\textwidth]{HeuristicsDiscovery.png}\n        \\vspace{-2cm}\n\\caption{Details about heuristics discovery}\n\\label{fig:discovery}\n\n\n", "appendix": false}, "Experimental details": {"content": "\n\n\\subsection{Dataset description}\nHere we give more details  about the datasets, including $7$7 datasets selected from SAT Competition 2023 and 2024, $3$3 generated ones by Picat, and another one from an industrial EDA scenario. \n\\begin{itemize}\n    \\item \\textbf{Argumentation problem} involves finding acceptable sets of arguments in a directed graph where attacks between arguments are represented by edges.\n    \n    \\item  \\textbf{Social Golfer problem} is a combinatorial problem that aims to assign golfers to groups over several weeks, ensuring no two golfers play in the same group more than once.\n    \n    \\item  \\textbf{Hashtable Safety problem} focuses on verifying the correctness of operations in a hash table to avoid collisions and ensure the integrity of the structure.\n\n    \\item \\textbf{Register Allocation problem} is a problem that arises in compiler optimization, where the goal is to assign a limited number of CPU registers to variables in a program. \n    \n    \\item \\textbf{Cryptography-Ascon problem} is a lightweight cryptographic algorithm challenge focused on implementing and verifying the Ascon cipher, a NIST-standardized authenticated encryption scheme, for resource-constrained IoT devices, balancing security against differential attacks with minimal computational overhead.\n    \n    \\item \\textbf{Hamiltonian problem} is a graph theory problem that involves determining whether a given graph contains a Hamiltonian cycle, a closed loop visiting each vertex exactly once, which is NP-complete and often applied to route optimization or circuit design verification.\n\n\n    \\item \\textbf{MineSweeper problem} is derived from the classic MineSweeper game, where the objective is to determine the placement of hidden mines on a grid based on numerical clues. \n    \n    \\item \\textbf{LangFord problem} is a combinatorial mathematics problem that involves finding a specific permutation of the sequence $1, 1, 2, 2, ..., n, n$ where the two copies of each number $k$ are exactly $k$ units apart.\n    \n    \\item \\textbf{KnightTour problem} aims to find a path for a knight on a chessboard that visits every square exactly once, with possible extensions to different board sizes and types.\n    \n    \\item \\textbf{Zamkeller problem} involves finding a permutation of integers from $1$ to $n$ that maximizes the number of differential alternations in subsequences divisible by integers from $1$ to $k$, where $(1 < k < n)$.\n\n    \\item \\textbf{EDA problem }involves formally proving whether two design specifications are functionally equivalent, which is one of the most essential techniques in Electronic Design Automation and digital IC design. It has a wide range of applications, such as functional equivalent logic removal, sequential equivalence checking, circuit-based method for symmetries detection, engineering change orders, among others.\n\n\\end{itemize}\\begin{itemize}\n    \\item \\textbf{Argumentation problem} involves finding acceptable sets of arguments in a directed graph where attacks between arguments are represented by edges.\n    \n    \\item  \\textbf{Social Golfer problem} is a combinatorial problem that aims to assign golfers to groups over several weeks, ensuring no two golfers play in the same group more than once.\n    \n    \\item  \\textbf{Hashtable Safety problem} focuses on verifying the correctness of operations in a hash table to avoid collisions and ensure the integrity of the structure.\n\n    \\item \\textbf{Register Allocation problem} is a problem that arises in compiler optimization, where the goal is to assign a limited number of CPU registers to variables in a program. \n    \n    \\item \\textbf{Cryptography-Ascon problem} is a lightweight cryptographic algorithm challenge focused on implementing and verifying the Ascon cipher, a NIST-standardized authenticated encryption scheme, for resource-constrained IoT devices, balancing security against differential attacks with minimal computational overhead.\n    \n    \\item \\textbf{Hamiltonian problem} is a graph theory problem that involves determining whether a given graph contains a Hamiltonian cycle, a closed loop visiting each vertex exactly once, which is NP-complete and often applied to route optimization or circuit design verification.\n\n\n    \\item \\textbf{MineSweeper problem} is derived from the classic MineSweeper game, where the objective is to determine the placement of hidden mines on a grid based on numerical clues. \n    \n    \\item \\textbf{LangFord problem} is a combinatorial mathematics problem that involves finding a specific permutation of the sequence $1, 1, 2, 2, ..., n, n$ where the two copies of each number $k$ are exactly $k$ units apart.\n    \n    \\item \\textbf{KnightTour problem} aims to find a path for a knight on a chessboard that visits every square exactly once, with possible extensions to different board sizes and types.\n    \n    \\item \\textbf{Zamkeller problem} involves finding a permutation of integers from $1$ to $n$ that maximizes the number of differential alternations in subsequences divisible by integers from $1$ to $k$, where $(1 < k < n)$.\n\n    \\item \\textbf{EDA problem }involves formally proving whether two design specifications are functionally equivalent, which is one of the most essential techniques in Electronic Design Automation and digital IC design. It has a wide range of applications, such as functional equivalent logic removal, sequential equivalence checking, circuit-based method for symmetries detection, engineering change orders, among others.\n\n\\end{itemize}\n    \\item \\textbf{Argumentation problem} involves finding acceptable sets of arguments in a directed graph where attacks between arguments are represented by edges.\n    \n    \\item  \\textbf{Social Golfer problem} is a combinatorial problem that aims to assign golfers to groups over several weeks, ensuring no two golfers play in the same group more than once.\n    \n    \\item  \\textbf{Hashtable Safety problem} focuses on verifying the correctness of operations in a hash table to avoid collisions and ensure the integrity of the structure.\n\n    \\item \\textbf{Register Allocation problem} is a problem that arises in compiler optimization, where the goal is to assign a limited number of CPU registers to variables in a program. \n    \n    \\item \\textbf{Cryptography-Ascon problem} is a lightweight cryptographic algorithm challenge focused on implementing and verifying the Ascon cipher, a NIST-standardized authenticated encryption scheme, for resource-constrained IoT devices, balancing security against differential attacks with minimal computational overhead.\n    \n    \\item \\textbf{Hamiltonian problem} is a graph theory problem that involves determining whether a given graph contains a Hamiltonian cycle, a closed loop visiting each vertex exactly once, which is NP-complete and often applied to route optimization or circuit design verification.\n\n\n    \\item \\textbf{MineSweeper problem} is derived from the classic MineSweeper game, where the objective is to determine the placement of hidden mines on a grid based on numerical clues. \n    \n    \\item \\textbf{LangFord problem} is a combinatorial mathematics problem that involves finding a specific permutation of the sequence $1, 1, 2, 2, ..., n, n$1, 1, 2, 2, ..., n, n where the two copies of each number $k$k are exactly $k$k units apart.\n    \n    \\item \\textbf{KnightTour problem} aims to find a path for a knight on a chessboard that visits every square exactly once, with possible extensions to different board sizes and types.\n    \n    \\item \\textbf{Zamkeller problem} involves finding a permutation of integers from $1$1 to $n$n that maximizes the number of differential alternations in subsequences divisible by integers from $1$1 to $k$k, where $(1 < k < n)$(1 < k < n).\n\n    \\item \\textbf{EDA problem }involves formally proving whether two design specifications are functionally equivalent, which is one of the most essential techniques in Electronic Design Automation and digital IC design. It has a wide range of applications, such as functional equivalent logic removal, sequential equivalence checking, circuit-based method for symmetries detection, engineering change orders, among others.\n\n\n\nFor the generated instances using Picat~\\cite{picat}, we adopt  the settings in Chapters 2 and 3 of the book by NengFa Zhou~\\cite{picat} and conduct grid sampling within a parameter space. Specifically, the parameter space  $\\Theta = \\{\\theta_1, \\theta_2, \\ldots\\}, \\theta^{L}_i \\le \\theta_i \\le \\theta^{U}_i$\\Theta = \\{\\theta_1, \\theta_2, \\ldots\\}, \\theta^{L}L_i \\le \\theta_i \\le \\theta^{U}U_i is defined to ensure that three baseline solvers including EasySAT, MiniSat and Kissat, can obtain a solution within proper cputime range, i.e., [$1$1s, $5000$5000s]. The we apply a space $\\Theta'$\\Theta' to generate the dataset by enlarging the upper bound of $\\Theta$\\Theta, e.g., $\\theta'^U_i = \\theta'^U_i * 1.2$\\theta'^U_i = \\theta'^U_i * 1.2, such that we can test whether AutoModSAT can solve the instances where the baseline solvers cannot.\n\n\\begin{itemize}\n    \\item \\textbf{MineSweeper problem} \\\\ \n    Parameter $\\Theta$: $\\{m, n, k, p\\}$\t\\\\\n    Parameter Space: $[500, 1,600] \\times [400, 3200] \\times [72,689, 1,572,118] \\times [0.32, 0.38]$ \\\\\t\n    Notes: $m, n$ represent the grid size of the Minesweeper game. $k$ is the total number of mines. $p$ is the probability that a given cell contains a mine (range: $0.32$ to $0.38$).\n\n    \\item \\textbf{KnightTour problem} \\\\\n    Parameter $\\Theta$: $\\{k\\}$ \\\\\n    Parameter Space: $[12, 75]$ \\\\\n    Notes: A $k \\times k$ chessboard where a knight's tour is attempted, covering all squares and returning to the start point. (A solution is not possible for odd-sized boards, i.e., they are unsatisfiable.)\n    \\item \\textbf{Zamkeller problem}: \\\\\n    Parameter $\\Theta$: $\\{k, n\\}$\\\\\n    Parameter Space: $[3, 34] \\times [25, 100]$ \\\\\n    Notes: $k$ represents the total sequence length, and $n$ represents the subsequence length. For all subsequences of length $k$, the goal is to change them into the minimum number of distinct sequences.\n\\end{itemize}\\begin{itemize}\n    \\item \\textbf{MineSweeper problem} \\\\ \n    Parameter $\\Theta$: $\\{m, n, k, p\\}$\t\\\\\n    Parameter Space: $[500, 1,600] \\times [400, 3200] \\times [72,689, 1,572,118] \\times [0.32, 0.38]$ \\\\\t\n    Notes: $m, n$ represent the grid size of the Minesweeper game. $k$ is the total number of mines. $p$ is the probability that a given cell contains a mine (range: $0.32$ to $0.38$).\n\n    \\item \\textbf{KnightTour problem} \\\\\n    Parameter $\\Theta$: $\\{k\\}$ \\\\\n    Parameter Space: $[12, 75]$ \\\\\n    Notes: A $k \\times k$ chessboard where a knight's tour is attempted, covering all squares and returning to the start point. (A solution is not possible for odd-sized boards, i.e., they are unsatisfiable.)\n    \\item \\textbf{Zamkeller problem}: \\\\\n    Parameter $\\Theta$: $\\{k, n\\}$\\\\\n    Parameter Space: $[3, 34] \\times [25, 100]$ \\\\\n    Notes: $k$ represents the total sequence length, and $n$ represents the subsequence length. For all subsequences of length $k$, the goal is to change them into the minimum number of distinct sequences.\n\\end{itemize}\n    \\item \\textbf{MineSweeper problem} \\\\ \n    Parameter $\\Theta$\\Theta: $\\{m, n, k, p\\}$\\{m, n, k, p\\}\t\\\\\n    Parameter Space: $[500, 1,600] \\times [400, 3200] \\times [72,689, 1,572,118] \\times [0.32, 0.38]$[500, 1,600] \\times [400, 3200] \\times [72,689, 1,572,118] \\times [0.32, 0.38] \\\\\t\n    Notes: $m, n$m, n represent the grid size of the Minesweeper game. $k$k is the total number of mines. $p$p is the probability that a given cell contains a mine (range: $0.32$0.32 to $0.38$0.38).\n\n    \\item \\textbf{KnightTour problem} \\\\\n    Parameter $\\Theta$\\Theta: $\\{k\\}$\\{k\\} \\\\\n    Parameter Space: $[12, 75]$[12, 75] \\\\\n    Notes: A $k \\times k$k \\times k chessboard where a knight's tour is attempted, covering all squares and returning to the start point. (A solution is not possible for odd-sized boards, i.e., they are unsatisfiable.)\n    \\item \\textbf{Zamkeller problem}: \\\\\n    Parameter $\\Theta$\\Theta: $\\{k, n\\}$\\{k, n\\}\\\\\n    Parameter Space: $[3, 34] \\times [25, 100]$[3, 34] \\times [25, 100] \\\\\n    Notes: $k$k represents the total sequence length, and $n$n represents the subsequence length. For all subsequences of length $k$k, the goal is to change them into the minimum number of distinct sequences.\n\n\nThe detailed configuration of the training dataset and the function candidates in heuristics discovery are presented in Table~\\ref{tab:training-params} . \n\n\\subsection{Evaluation Metric}\nWe consider two specific metrics for evaluation of a SAT solver: (1) the number of SAT instances solved within the given timeout bound, and (2) the Penalized Average Runtime with a factor of 2 score (PAR-2).  Both metrics are commonly used in the SAT Competitions.\n\n\n\nConsider a dataset of $n$n instances. Let $t_i$t_i be the runtime of the SAT solver on the instance $i$i. The PAR-2 score is formally defined as:\n\\[\n\\text{PAR-2} = \\frac{1}{n} \\sum_{i=1}^{n} \\tau_i\n\\quad\n\\text{where:} \n\\quad\n\\tau_i = \n\\begin{cases} \nt_i, & \\text{if } t_i \\leq \\mathcal{T} \\\\\n2\\mathcal{T}, & \\text{if } t_i > \\mathcal{T} \\text{ or the solver fails to return a result},\n\\end{cases}\n\\]\n\\text{PAR-2} = \\frac{1}{n} \\sum_{i=1}i=1^{n}n \\tau_i\n\\quad\n\\text{where:} \n\\quad\n\\tau_i = \n \nt_i, & \\text{if } t_i \\leq \\mathcal{T} \\\\\n2\\mathcal{T}, & \\text{if } t_i > \\mathcal{T} \\text{ or the solver fails to return a result},\n\n\nwhere \n$\\mathcal{T}$\\mathcal{T} is the predefined timeout bound. For example, consider a benchmark dataset with three instances and a timeout bound $\\mathcal{T} = 100$\\mathcal{T} = 100 seconds. The runtimes (in seconds) for the three instances are: $t_1 = 80$t_1 = 80 for instance 1, $t_2 = 120$t_2 = 120 for instance 2, the solver fails to return a result\nfor instance 3. Then\n\\begin{itemize}\n\\item since $t_1 \\leq \\mathcal{B}$, we have $\\tau_1 = 80$;\n\\item\nsince $t_2 > \\mathcal{B}$, we have $\\tau_2 = 200$ (penalized);\n\\item\nsince the solver fails for instance 3, we have $\\tau_3 = 200$ (penalized).\n\\end{itemize}\\begin{itemize}\n\\item since $t_1 \\leq \\mathcal{B}$, we have $\\tau_1 = 80$;\n\\item\nsince $t_2 > \\mathcal{B}$, we have $\\tau_2 = 200$ (penalized);\n\\item\nsince the solver fails for instance 3, we have $\\tau_3 = 200$ (penalized).\n\\end{itemize}\n\\item since $t_1 \\leq \\mathcal{B}$t_1 \\leq \\mathcal{B}, we have $\\tau_1 = 80$\\tau_1 = 80;\n\\item\nsince $t_2 > \\mathcal{B}$t_2 > \\mathcal{B}, we have $\\tau_2 = 200$\\tau_2 = 200 (penalized);\n\\item\nsince the solver fails for instance 3, we have $\\tau_3 = 200$\\tau_3 = 200 (penalized).\n\nTherefore,\nThe PAR-2 score is given by\n\\[\n\\text{PAR-2} = \\frac{1}{3} (80 + 200 + 200) = \\frac{480}{3} = 160.\n\\]\n\\text{PAR-2} = \\frac{1}{3} (80 + 200 + 200) = \\frac{480}{3} = 160.\n\n\n\n\n\\begin{table}[ht!]\n\\centering\n\\caption{Configuration of training set, where the indices 1 to 7 represent the following function candidates in order: rephase\\_condition, rephase\\_function, reduce\\_condition, restart\\_condition, restart\\_function, varBumpActivity, claBumpActivity.}\n\\label{tab:training-params}\n\\begin{tabular}{llp{3.5cm}}\n\\toprule\n\\textbf{Dataset} & \\textbf{Training Timeout} & \\textbf{Function candidate}\\\\\n\\midrule\ncryptography-ascon  & 800 & $1,2,3,6$ \\\\\nregister-allocation  & 5000 & $2,3,5,6$ \\\\\nsocial-golfer    & 2000 & $1,4,5,6$ \\\\\nhashtable-safety   & 500 & $2,4,5,7$ \\\\\nargumentation 2023      & 2000 & $1,2,3,6$ \\\\\nargumentation 2024    & 2000 &  $1,2,3,5$ \\\\\nhamiltonian     & 800 & $3,4,5,6$ \\\\\nMineSweeper    & 500 & $2,4,3,7$ \\\\\nKnightTour & 2000    & $1,3,4,7$ \\\\\nZamkeller   & 2000 & $1,3,4,6$ \\\\\nEDA & 800    & $2,5,6,7$ \\\\\n% 'rephase_condition', 'rephase_function','reduce_condition', 'restart_condition', 'restart_function', 'varBumpActivity', 'claBumpActivity'\n\n\\bottomrule\n\\end{tabular}\n\\end{table}\n\\centering\n\\caption{Configuration of training set, where the indices 1 to 7 represent the following function candidates in order: rephase\\_condition, rephase\\_function, reduce\\_condition, restart\\_condition, restart\\_function, varBumpActivity, claBumpActivity.}\n\\label{tab:training-params}\n\n\\toprule\n\\textbf{Dataset} & \\textbf{Training Timeout} & \\textbf{Function candidate}\\\\\n\\midrule\ncryptography-ascon  & 800 & $1,2,3,6$1,2,3,6 \\\\\nregister-allocation  & 5000 & $2,3,5,6$2,3,5,6 \\\\\nsocial-golfer    & 2000 & $1,4,5,6$1,4,5,6 \\\\\nhashtable-safety   & 500 & $2,4,5,7$2,4,5,7 \\\\\nargumentation 2023      & 2000 & $1,2,3,6$1,2,3,6 \\\\\nargumentation 2024    & 2000 &  $1,2,3,5$1,2,3,5 \\\\\nhamiltonian     & 800 & $3,4,5,6$3,4,5,6 \\\\\nMineSweeper    & 500 & $2,4,3,7$2,4,3,7 \\\\\nKnightTour & 2000    & $1,3,4,7$1,3,4,7 \\\\\nZamkeller   & 2000 & $1,3,4,6$1,3,4,6 \\\\\nEDA & 800    & $2,5,6,7$2,5,6,7 \\\\\n\n\n\\bottomrule\n\n\n\n\n\n\\subsection{Search Space for Parameter Tuning}\nIn this paper, we adopt SMAC3 to optimize the baseline SAT solver parameters across different datasets. The search space for each solver, including the parameter name, type, description and range, are presented in Tables~\\ref{tab:modsat-params},~\\ref{tab:kissat-params}, and~\\ref{tab:cadical-params}.\n\n\\begin{table}[ht!]\n\\centering\n\\caption{ModSAT configuration parameters}\n\\label{tab:modsat-params}\n\\begin{tabular}{llp{7cm}l}\n\\toprule\n\\textbf{Parameter} & \\textbf{Type} & \\textbf{Description} & \\textbf{Search Space} \\\\\n\\midrule\n\\texttt{var-decay}    & double & Variable activity decay factor & $(0, 1)$ \\\\\n\\texttt{cla-decay}    & double & Clause activity decay factor & $(0, 1)$ \\\\\n\\texttt{rnd-freq}     & double & Frequency for random variable selection & $[0, 1]$ \\\\\n\\texttt{rnd-init}     & bool   & Randomize initial activities & $\\{\\text{true}, \\text{false}\\}$ \\\\\n\\texttt{rfirst}       & int    & Base restart interval & $[1, 1e4]$ \\\\\n\\texttt{rinc}         & double & Restart interval increase factor & $(1.5, 4)$ \\\\\n\\texttt{gc-frac}      & double & Wasted memory fraction triggering garbage collection & $(0, 1)$ \\\\\n\\texttt{min-learnts} & int    & Minimum learnt clause limit & $[0, 1e6]$ \\\\\n\\bottomrule\n\\end{tabular}\n\\end{table}\n\\centering\n\\caption{ModSAT configuration parameters}\n\\label{tab:modsat-params}\n\n\\toprule\n\\textbf{Parameter} & \\textbf{Type} & \\textbf{Description} & \\textbf{Search Space} \\\\\n\\midrule\n\\texttt{var-decay}    & double & Variable activity decay factor & $(0, 1)$(0, 1) \\\\\n\\texttt{cla-decay}    & double & Clause activity decay factor & $(0, 1)$(0, 1) \\\\\n\\texttt{rnd-freq}     & double & Frequency for random variable selection & $[0, 1]$[0, 1] \\\\\n\\texttt{rnd-init}     & bool   & Randomize initial activities & $\\{\\text{true}, \\text{false}\\}$\\{\\text{true}, \\text{false}\\} \\\\\n\\texttt{rfirst}       & int    & Base restart interval & $[1, 1e4]$[1, 1e4] \\\\\n\\texttt{rinc}         & double & Restart interval increase factor & $(1.5, 4)$(1.5, 4) \\\\\n\\texttt{gc-frac}      & double & Wasted memory fraction triggering garbage collection & $(0, 1)$(0, 1) \\\\\n\\texttt{min-learnts} & int    & Minimum learnt clause limit & $[0, 1e6]$[0, 1e6] \\\\\n\\bottomrule\n\n\n\n\\begin{table}[ht!]\n\\centering\n\\caption{Kissat configuration parameters}\n\\label{tab:kissat-params}\n\\begin{tabular}{llp{7.5cm}l}\n\\toprule\n\\textbf{Parameter} & \\textbf{Type} & \\textbf{Description} & \\textbf{Search Space} \\\\\n\\midrule\n\\texttt{chrono}        & bool   & Enable chronological backtracking & $\\{0, 1\\}$ \\\\\n\\texttt{eliminate}     & bool   & Enable variable elimination & $\\{0, 1\\}$ \\\\\n\\texttt{forcephase}    & bool   & Force initial phase assignment & $\\{0, 1\\}$ \\\\\n\\texttt{minimize}      & bool   & Enable clause minimization & $\\{0, 1\\}$ \\\\\n\\texttt{phase}         & bool   & Set initial decision phase & $\\{0, 1\\}$ \\\\\n\\texttt{phasesaving}   & bool   & Enable phase saving during restarts & $\\{0, 1\\}$ \\\\\n\\texttt{probe}         & bool   & Enable failed literal probing & $\\{0, 1\\}$ \\\\\n\\texttt{reduceint}     & int    & Conflict interval for clause DB reduction & $\\{10^1, 10^2, 10^3, 10^4, 10^5\\}$ \\\\\n\\texttt{rephaseint}    & int    & Conflict interval for phase resetting & $\\{10^1, 10^2, 10^3, 10^4, 10^5\\}$ \\\\\n\\texttt{restartint}    & int    & Base restart interval (conflicts) & $\\{1, 10^2, 10^3, 10^4\\}$ \\\\\n\\texttt{restartmargin} & int    & Rapid restart margin threshold & $\\{0, 5, 10, 15, 20, 25\\}$ \\\\\n\\texttt{simplify}      & bool   & Enable periodic simplification & $\\{0, 1\\}$ \\\\\n\\texttt{stable}        & int    & Search stability mode (0=focused, 1=stable, 2=switching) & $\\{0, 1, 2\\}$ \\\\\n\\texttt{target}        & int    & Target phase selection strategy (0=negative, 1=positive, 2=best) & $\\{0, 1, 2\\}$ \\\\\n\\texttt{tier1}         & int    & Tier 1 glue limit for learned clauses & $\\{2, 3, 4, 5\\}$ \\\\\n\\texttt{tier2}         & int    & Tier 2 glue limit for learned clauses & $\\{6, 7, 8, 9, 10, 20, 50\\}$ \\\\\n\\bottomrule\n\\end{tabular}\n\\end{table}\n\\centering\n\\caption{Kissat configuration parameters}\n\\label{tab:kissat-params}\n\n\\toprule\n\\textbf{Parameter} & \\textbf{Type} & \\textbf{Description} & \\textbf{Search Space} \\\\\n\\midrule\n\\texttt{chrono}        & bool   & Enable chronological backtracking & $\\{0, 1\\}$\\{0, 1\\} \\\\\n\\texttt{eliminate}     & bool   & Enable variable elimination & $\\{0, 1\\}$\\{0, 1\\} \\\\\n\\texttt{forcephase}    & bool   & Force initial phase assignment & $\\{0, 1\\}$\\{0, 1\\} \\\\\n\\texttt{minimize}      & bool   & Enable clause minimization & $\\{0, 1\\}$\\{0, 1\\} \\\\\n\\texttt{phase}         & bool   & Set initial decision phase & $\\{0, 1\\}$\\{0, 1\\} \\\\\n\\texttt{phasesaving}   & bool   & Enable phase saving during restarts & $\\{0, 1\\}$\\{0, 1\\} \\\\\n\\texttt{probe}         & bool   & Enable failed literal probing & $\\{0, 1\\}$\\{0, 1\\} \\\\\n\\texttt{reduceint}     & int    & Conflict interval for clause DB reduction & $\\{10^1, 10^2, 10^3, 10^4, 10^5\\}$\\{10^1, 10^2, 10^3, 10^4, 10^5\\} \\\\\n\\texttt{rephaseint}    & int    & Conflict interval for phase resetting & $\\{10^1, 10^2, 10^3, 10^4, 10^5\\}$\\{10^1, 10^2, 10^3, 10^4, 10^5\\} \\\\\n\\texttt{restartint}    & int    & Base restart interval (conflicts) & $\\{1, 10^2, 10^3, 10^4\\}$\\{1, 10^2, 10^3, 10^4\\} \\\\\n\\texttt{restartmargin} & int    & Rapid restart margin threshold & $\\{0, 5, 10, 15, 20, 25\\}$\\{0, 5, 10, 15, 20, 25\\} \\\\\n\\texttt{simplify}      & bool   & Enable periodic simplification & $\\{0, 1\\}$\\{0, 1\\} \\\\\n\\texttt{stable}        & int    & Search stability mode (0=focused, 1=stable, 2=switching) & $\\{0, 1, 2\\}$\\{0, 1, 2\\} \\\\\n\\texttt{target}        & int    & Target phase selection strategy (0=negative, 1=positive, 2=best) & $\\{0, 1, 2\\}$\\{0, 1, 2\\} \\\\\n\\texttt{tier1}         & int    & Tier 1 glue limit for learned clauses & $\\{2, 3, 4, 5\\}$\\{2, 3, 4, 5\\} \\\\\n\\texttt{tier2}         & int    & Tier 2 glue limit for learned clauses & $\\{6, 7, 8, 9, 10, 20, 50\\}$\\{6, 7, 8, 9, 10, 20, 50\\} \\\\\n\\bottomrule\n\n\n\n\\begin{table}[ht!]\n\\centering\n\\caption{CaDiCaL configuration parameters}\n\\label{tab:cadical-params}\n\\begin{tabular}{llp{7cm}l}\n\\toprule\n\\textbf{Parameter} & \\textbf{Type} & \\textbf{Description} & \\textbf{Search Space} \\\\\n\\midrule\n\\texttt{chrono}       & int    & Chronological backtracking mode (0: none, 1: limited, 2: always) & $\\{0, 1, 2\\}$ \\\\\n\\texttt{elim}         & bool   & Enables variable elimination during simplification & $\\{0, 1\\}$ \\\\\n\\texttt{forcephase}   & bool   & Forces phase saving for decision variables & $\\{0, 1\\}$ \\\\\n\\texttt{minimize}     & bool   & Enables clause minimization during conflict analysis & $\\{0, 1\\}$ \\\\\n\\texttt{phase}        & bool   & Initial decision phase assignment (0: negative, 1: positive) & $\\{0, 1\\}$ \\\\\n\\texttt{probe}        & bool   & Enables probing (failed literal detection) & $\\{0, 1\\}$ \\\\\n\\texttt{reduceint}    & int    & Conflict interval for clause database reduction & $\\{10^2, 10^3, 10^4, 10^5\\}$ \\\\\n\\texttt{rephaseint}   & int    & Conflict interval for resetting variable phases & $\\{10^1, 10^2, 10^3, 10^4, 10^5\\}$ \\\\\n\\texttt{restartint}   & int    & Base restart interval (conflicts between restarts) & $\\{2, 10^2, 10^3, 10^4\\}$ \\\\\n\\texttt{restartmargin}& int    & Restart margin percentage (Luby sequence scaling) & $\\{0, 5, 10, 15, 20, 25\\}$ \\\\\n\\texttt{stabilize}    & bool   & Stabilizes search by limiting activity updates & $\\{0, 1\\}$ \\\\\n\\texttt{target}       & int    & Search target (0: SAT, 1: UNSAT, 2: balanced) & $\\{0, 1, 2\\}$ \\\\\n\\bottomrule\n\\end{tabular}\n\\end{table}\n\\centering\n\\caption{CaDiCaL configuration parameters}\n\\label{tab:cadical-params}\n\n\\toprule\n\\textbf{Parameter} & \\textbf{Type} & \\textbf{Description} & \\textbf{Search Space} \\\\\n\\midrule\n\\texttt{chrono}       & int    & Chronological backtracking mode (0: none, 1: limited, 2: always) & $\\{0, 1, 2\\}$\\{0, 1, 2\\} \\\\\n\\texttt{elim}         & bool   & Enables variable elimination during simplification & $\\{0, 1\\}$\\{0, 1\\} \\\\\n\\texttt{forcephase}   & bool   & Forces phase saving for decision variables & $\\{0, 1\\}$\\{0, 1\\} \\\\\n\\texttt{minimize}     & bool   & Enables clause minimization during conflict analysis & $\\{0, 1\\}$\\{0, 1\\} \\\\\n\\texttt{phase}        & bool   & Initial decision phase assignment (0: negative, 1: positive) & $\\{0, 1\\}$\\{0, 1\\} \\\\\n\\texttt{probe}        & bool   & Enables probing (failed literal detection) & $\\{0, 1\\}$\\{0, 1\\} \\\\\n\\texttt{reduceint}    & int    & Conflict interval for clause database reduction & $\\{10^2, 10^3, 10^4, 10^5\\}$\\{10^2, 10^3, 10^4, 10^5\\} \\\\\n\\texttt{rephaseint}   & int    & Conflict interval for resetting variable phases & $\\{10^1, 10^2, 10^3, 10^4, 10^5\\}$\\{10^1, 10^2, 10^3, 10^4, 10^5\\} \\\\\n\\texttt{restartint}   & int    & Base restart interval (conflicts between restarts) & $\\{2, 10^2, 10^3, 10^4\\}$\\{2, 10^2, 10^3, 10^4\\} \\\\\n\\texttt{restartmargin}& int    & Restart margin percentage (Luby sequence scaling) & $\\{0, 5, 10, 15, 20, 25\\}$\\{0, 5, 10, 15, 20, 25\\} \\\\\n\\texttt{stabilize}    & bool   & Stabilizes search by limiting activity updates & $\\{0, 1\\}$\\{0, 1\\} \\\\\n\\texttt{target}       & int    & Search target (0: SAT, 1: UNSAT, 2: balanced) & $\\{0, 1, 2\\}$\\{0, 1, 2\\} \\\\\n\\bottomrule\n\n\n\n\n", "appendix": false}, "More Examples of Discovered Heuristics": {"content": "\nIn this section, to demonstrate LLMs' ability of generating effective heuristics, we provide more contrastive examples (one for each function candidate), along with the explanations for the changes.\n\n\nFigure~\\ref{fig:claBumpActivity} provides an example for the updated claBumpActivity function, which introduces two key enhancements in contrast to the original implementation. First, during activity rescaling, it enforces a minimum activity threshold ($min\\_activity = 1e-20$min\\_activity = 1e-20) to prevent clauses from becoming numerically insignificant after scaling. This preserves the relevance of historically important clauses and avoids premature elimination from the learning process. Second, it incorporates dynamic decay adjustment based on recent conflict rates: when conflicts exceed 1000 and the LBD queue surpasses 50 entries, $cla\\_inc$cla\\_inc is scaled down proportionally to the conflict density (with a floor of $0.8$0.8). This adaptively moderates activity growth during high-conflict phases, prioritizing recent impactful clauses while maintaining stability. Together, these refinements yield a more balanced clause management strategy\u2014preventing underutilization of valuable learned clauses while dynamically optimizing activity decay for solver efficiency.\n\n\nFigure~\\ref{fig:varBumpActivity} provides an example of the updated varBumpActivity function, which introduces three key improvements over the original. First, it scales the increment by (1.0 + 0.1 * decisionLevel()), prioritizing variables involved in recent decisions to accelerate conflict-driven learning. Second, the rescaling mechanism uses a larger threshold (1e100) and finer scale factor (1e-100), while preserving variable relevance by enforcing a minimum activity floor (1e-100) to maintain relative ordering and prevent premature underflow. Third, it optimizes heap management through conditional updates: dynamically adjusting the variable's heap position only when its activity exceeds the current maximum, or inserting undefined decision variables lazily. These enhancements collectively improve search guidance, reduce floating-point stability issues, and minimize unnecessary data structure operations.\n\nFigure~\\ref{fig:restartcondition} provides an example of the updated restart\\_condition function significantly improves upon the original by replacing its static threshold approach with a dynamic, performance-driven restart strategy that adapts to real-time solver behavior. Instead of relying on fixed queue sizes and hardcoded multipliers, the new version intelligently calculates restart thresholds using multiple runtime metrics: it combines average LBD (measuring clause quality) with conflict rates (tracking solver progress) to dynamically adjust restart timing based on problem difficulty. Crucially, it introduces a progress-sensitive mechanism that aggressively lowers thresholds when stagnation is detected (progressEstimate changes < 0.01), enabling proactive recovery from plateaus\u2014a capability absent in the original. This multi-factor approach yields more precise restart decisions, reduces wasteful recomputations, and enhances solver adaptability across diverse SAT instances while maintaining robustness during initialization through default thresholds.\n\nFigure~\\ref{fig:restartfunction} provide an example of the updated restart\\_function, which introduces significant improvements over the original implementation by incorporating adaptive restart strategies based on real-time solver performance metrics. Unlike the original version, which always resets to decision level 0 (a full restart), the enhanced function dynamically calculates two exponential moving averages of conflict difficulty (fast\\_avg and slow\\_avg) using Literal Block Distance (LBD) scores. By analyzing the ratio between these averages, it intelligently selects one of three restart depths: full restart (level 0) for deteriorating conflict quality, partial restart (mid-level) for moderately harder conflicts, or minimal restart (current level -1) for stable conditions. This adaptability preserves useful learned clauses during partial/minimal restarts, reducing redundant recomputation. Additionally, periodic clause database reduction (every 16 restarts) curbs memory growth, while rebuilding the variable order heap ensures branching decisions reflect updated activity scores. Collectively, these optimizations balance exploration and exploitation, enhancing solver efficiency through context-aware restarts and resource management.\n\nFigure~\\ref{fig:rephasecondition} provides and examples of the updated rephase\\_condition function, which introduces an adaptive rephasing mechanism that significantly enhances the original static threshold approach. Unlike the prior version which solely relied on a fixed rephase limit, the new implementation dynamically adjusts rephasing intervals based on real-time search progress and conflict density. By calculating normalized progress through trail size changes and setting variable-driven thresholds (e.g., $2\\%$2\\% of total variables), it detects stagnation when progress falls below expectations and responds by reducing subsequent rephase intervals exponentially. Conversely, substantial progress triggers gradual interval expansion. This self-tuning capability optimizes computational efficiency: it minimizes unnecessary rephasing during productive search phases while aggressively countering stagnation, thereby improving solution convergence without compromising robustness.\n\nFigure~\\ref{fig:rephasefunction} provides an example of the updated rephase\\_function, which introduces several key improvements over the original implementation, enhancing adaptability and search efficiency. First, it implements dynamic rephase limit adjustment by scaling rephase\\_limit based on progress measured through conflict resolution (conflictR). If progress occurs, the limit increases by $50\\%$50\\% to exploit productive phases more aggressively; otherwise, it decays by $10\\%$10\\% (with a lower bound of 512) to conserve resources during stagnation. This replaces the original\u2019s static increment (+= 8192) and fixed decay (threshold *= 0.9), enabling context-sensitive resource allocation. Second, the refined phase selection strategy uses weighted probabilities with four distinct policies: local-best phases ($40\\%$40\\%), global phase inversion ($30\\%$30\\%), randomized phases for low-activity variables ($20\\%$20\\%), and user-specified phases ($10\\%$10\\%). This replaces the original\u2019s rigid three-policy cascade, adding targeted randomization for less-active variables\u2014which helps escape local optima\u2014and reintroducing user phases for domain-specific guidance. Finally, adaptive threshold reset (threshold = trail.size() * 0.8) dynamically scales with the solver\u2019s state, replacing the fixed decay, while verbosity-controlled logging aids debugging. These changes collectively improve the solver\u2019s ability to balance exploration versus exploitation, mitigate stagnation, and leverage problem-specific knowledge.\n\nFigure~\\ref{fig:reducecondition} provides an example of the updated reduce\\_condition function, which significantly enhances the original version through four key improvements that collectively the optimize memory management and solver adaptability. First, it retains the core check for absolute learnt clause limits (learnts.size() >= max\\_learnts), ensuring baseline constraint adherence. Second, it introduces memory pressure awareness by triggering reduction when wasted clause memory exceeds $80\\%$80\\% of the garbage collection threshold (ca.wasted() > ca.size() * garbage\\_frac * 0.8). This proactively mitigates memory bloat and improves cache efficiency. Third, a learnt-to-original clause ratio check (learnts.size() > 2 * nClauses()) prevents learnt clauses from disproportionately dominating the formula, maintaining balanced reasoning. Finally, a conflict-driven heuristic (conflictR > 1000 \\&\\& learnts.size() > max\\_learnts * 0.8) adapts to high-conflict phases by initiating earlier reduction, thus accelerating recovery from solver stagnation. These layered criteria synergistically boost robustness: they minimize redundant computation through memory-sensitive garbage collection, preserve clause quality via ratio controls, and dynamically respond to runtime behavior\u2014ultimately yielding faster, more memory-efficient SAT solving.\n\n\n\\begin{figure}\n\\begin{cppcode}{original claBumpActivity}\ninline void Solver::claBumpActivity (Clause& c) {\n        if ( (c.activity() += cla_inc) > 1e20 ) {\n            // Rescale:\n            for (int i = 0; i < learnts.size(); i++)\n                ca[learnts[i]].activity() *= 1e-20;\n            cla_inc *= 1e-20; } \n        }\n\\end{cppcode}\n\n\\begin{cppcode}{discovered claBumpActivity}\ninline void Solver::claBumpActivity (Clause& c) {\n    // Adaptive scaling based on clause length and conflict participation\n    if ((c.activity() += cla_inc) > 1e20) {\n        // Maintain minimum activity while scaling to preserve relevance\n        double scale_factor = 1e-20;\n        double min_activity = 1e-20;\n        for (int i = 0; i < learnts.size(); i++) {\n            ca[learnts[i]].activity() *= scale_factor;\n            if (ca[learnts[i]].activity() < min_activity)\n                ca[learnts[i]].activity() = min_activity;\n        }\n        cla_inc *= scale_factor;\n        \n        // Stabilize scaling by maintaining lower bound on clause activity\n        if (cla_inc < min_activity)\n            cla_inc = min_activity;\n    }\n    // Dynamic decay adjustment based on recent conflict rate\n    if (conflicts > 1000 && lbd_queue_size > 50) {\n        double conflict_scale = 1.0 - 0.01 * (lbd_queue_size / 50.0);\n        cla_inc *= conflict_scale > 0.8 ? conflict_scale : 0.8;\n    }\n}\n\\end{cppcode}\n    \\caption{Example of LLM discovered heuristics of claBumpActivity}\n    \\label{fig:claBumpActivity}\n\\end{figure}\n{original claBumpActivity}original claBumpActivity\ninline void Solver::claBumpActivity (Clause& c) {\n        if ( (c.activity() += cla_inc) > 1e20 ) {\n            // Rescale:\n            for (int i = 0; i < learnts.size(); i++)\n                ca[learnts[i]].activity() *= 1e-20;\n            cla_inc *= 1e-20; } \n        }\n        if ( (c.activity() += cla_inc) > 1e20 ) {\n            // Rescale:\n            for (int i = 0; i < learnts.size(); i++)\n                ca[learnts[i]].activity() *= 1e-20;\n            cla_inc *= 1e-20; }\n            // Rescale:\n            for (int i = 0; i < learnts.size(); i++)\n                ca[learnts[i]].activity() *= 1e-20;\n            cla_inc *= 1e-20;  \n        \n\n\n{discovered claBumpActivity}discovered claBumpActivity\ninline void Solver::claBumpActivity (Clause& c) {\n    // Adaptive scaling based on clause length and conflict participation\n    if ((c.activity() += cla_inc) > 1e20) {\n        // Maintain minimum activity while scaling to preserve relevance\n        double scale_factor = 1e-20;\n        double min_activity = 1e-20;\n        for (int i = 0; i < learnts.size(); i++) {\n            ca[learnts[i]].activity() *= scale_factor;\n            if (ca[learnts[i]].activity() < min_activity)\n                ca[learnts[i]].activity() = min_activity;\n        }\n        cla_inc *= scale_factor;\n        \n        // Stabilize scaling by maintaining lower bound on clause activity\n        if (cla_inc < min_activity)\n            cla_inc = min_activity;\n    }\n    // Dynamic decay adjustment based on recent conflict rate\n    if (conflicts > 1000 && lbd_queue_size > 50) {\n        double conflict_scale = 1.0 - 0.01 * (lbd_queue_size / 50.0);\n        cla_inc *= conflict_scale > 0.8 ? conflict_scale : 0.8;\n    }\n}\n    // Adaptive scaling based on clause length and conflict participation\n    if ((c.activity() += cla_inc) > 1e20) {\n        // Maintain minimum activity while scaling to preserve relevance\n        double scale_factor = 1e-20;\n        double min_activity = 1e-20;\n        for (int i = 0; i < learnts.size(); i++) {\n            ca[learnts[i]].activity() *= scale_factor;\n            if (ca[learnts[i]].activity() < min_activity)\n                ca[learnts[i]].activity() = min_activity;\n        }\n        cla_inc *= scale_factor;\n        \n        // Stabilize scaling by maintaining lower bound on clause activity\n        if (cla_inc < min_activity)\n            cla_inc = min_activity;\n    }\n        // Maintain minimum activity while scaling to preserve relevance\n        double scale_factor = 1e-20;\n        double min_activity = 1e-20;\n        for (int i = 0; i < learnts.size(); i++) {\n            ca[learnts[i]].activity() *= scale_factor;\n            if (ca[learnts[i]].activity() < min_activity)\n                ca[learnts[i]].activity() = min_activity;\n        }\n            ca[learnts[i]].activity() *= scale_factor;\n            if (ca[learnts[i]].activity() < min_activity)\n                ca[learnts[i]].activity() = min_activity;\n        \n        cla_inc *= scale_factor;\n        \n        // Stabilize scaling by maintaining lower bound on clause activity\n        if (cla_inc < min_activity)\n            cla_inc = min_activity;\n    \n    // Dynamic decay adjustment based on recent conflict rate\n    if (conflicts > 1000 && lbd_queue_size > 50) {\n        double conflict_scale = 1.0 - 0.01 * (lbd_queue_size / 50.0);\n        cla_inc *= conflict_scale > 0.8 ? conflict_scale : 0.8;\n    }\n        double conflict_scale = 1.0 - 0.01 * (lbd_queue_size / 50.0);\n        cla_inc *= conflict_scale > 0.8 ? conflict_scale : 0.8;\n    \n\n\n    \\caption{Example of LLM discovered heuristics of claBumpActivity}\n    \\label{fig:claBumpActivity}\n\n\n\\begin{figure}\n\\begin{cppcode}{original varBumpActivity}\ninline void Solver::varBumpActivity(Var v, double inc) {\n    activity[v] += inc;\n    // Rescale condition to prevent floating-point overflow earlier\n    if (activity[v] > 1e50) {\n        for (int i = 0; i < nVars(); i++)\n            activity[i] *= 1e-50;\n        var_inc *= 1e-50;\n        }\n    }\n\\end{cppcode}\n\n\\begin{cppcode}{discoverd varBumpActivity}\ninline void Solver::varBumpActivity(Var v, double inc) {\n    // Scale the increment based on decision level to prioritize recent variables\n    double scaled_inc = inc * (1.0 + 0.1 * decisionLevel());\n    activity[v] += scaled_inc;\n    // More gradual rescaling that preserves relative ordering better\n    if (activity[v] > 1e100) {\n        double scale_factor = 1e-100;\n        for (int i = 0; i < nVars(); i++) {\n            activity[i] *= scale_factor;\n            // Prevent variables from becoming completely inactive\n            if (activity[i] < 1e-100) activity[i] = 1e-100;\n        }\n        var_inc *= scale_factor;\n    }\n    // Optimized heap update with early exit for common case\n    if (order_heap.inHeap(v)) {\n        if (activity[v] > activity[order_heap[0]]) {\n            order_heap.decrease(v);\n        }\n    } else if (decision[v] && value(v) == l_Undef) {\n        order_heap.insert(v);\n    }\n}\n\\end{cppcode}\n    \\caption{Example of LLM discovered heuristics of varBumpActivity}\n    \\label{fig:varBumpActivity}\n\\end{figure}\n{original varBumpActivity}original varBumpActivity\ninline void Solver::varBumpActivity(Var v, double inc) {\n    activity[v] += inc;\n    // Rescale condition to prevent floating-point overflow earlier\n    if (activity[v] > 1e50) {\n        for (int i = 0; i < nVars(); i++)\n            activity[i] *= 1e-50;\n        var_inc *= 1e-50;\n        }\n    }\n    activity[v] += inc;\n    // Rescale condition to prevent floating-point overflow earlier\n    if (activity[v] > 1e50) {\n        for (int i = 0; i < nVars(); i++)\n            activity[i] *= 1e-50;\n        var_inc *= 1e-50;\n        }\n        for (int i = 0; i < nVars(); i++)\n            activity[i] *= 1e-50;\n        var_inc *= 1e-50;\n        \n    \n\n\n{discoverd varBumpActivity}discoverd varBumpActivity\ninline void Solver::varBumpActivity(Var v, double inc) {\n    // Scale the increment based on decision level to prioritize recent variables\n    double scaled_inc = inc * (1.0 + 0.1 * decisionLevel());\n    activity[v] += scaled_inc;\n    // More gradual rescaling that preserves relative ordering better\n    if (activity[v] > 1e100) {\n        double scale_factor = 1e-100;\n        for (int i = 0; i < nVars(); i++) {\n            activity[i] *= scale_factor;\n            // Prevent variables from becoming completely inactive\n            if (activity[i] < 1e-100) activity[i] = 1e-100;\n        }\n        var_inc *= scale_factor;\n    }\n    // Optimized heap update with early exit for common case\n    if (order_heap.inHeap(v)) {\n        if (activity[v] > activity[order_heap[0]]) {\n            order_heap.decrease(v);\n        }\n    } else if (decision[v] && value(v) == l_Undef) {\n        order_heap.insert(v);\n    }\n}\n    // Scale the increment based on decision level to prioritize recent variables\n    double scaled_inc = inc * (1.0 + 0.1 * decisionLevel());\n    activity[v] += scaled_inc;\n    // More gradual rescaling that preserves relative ordering better\n    if (activity[v] > 1e100) {\n        double scale_factor = 1e-100;\n        for (int i = 0; i < nVars(); i++) {\n            activity[i] *= scale_factor;\n            // Prevent variables from becoming completely inactive\n            if (activity[i] < 1e-100) activity[i] = 1e-100;\n        }\n        var_inc *= scale_factor;\n    }\n        double scale_factor = 1e-100;\n        for (int i = 0; i < nVars(); i++) {\n            activity[i] *= scale_factor;\n            // Prevent variables from becoming completely inactive\n            if (activity[i] < 1e-100) activity[i] = 1e-100;\n        }\n            activity[i] *= scale_factor;\n            // Prevent variables from becoming completely inactive\n            if (activity[i] < 1e-100) activity[i] = 1e-100;\n        \n        var_inc *= scale_factor;\n    \n    // Optimized heap update with early exit for common case\n    if (order_heap.inHeap(v)) {\n        if (activity[v] > activity[order_heap[0]]) {\n            order_heap.decrease(v);\n        }\n    }\n        if (activity[v] > activity[order_heap[0]]) {\n            order_heap.decrease(v);\n        }\n            order_heap.decrease(v);\n        \n     else if (decision[v] && value(v) == l_Undef) {\n        order_heap.insert(v);\n    }\n        order_heap.insert(v);\n    \n\n\n    \\caption{Example of LLM discovered heuristics of varBumpActivity}\n    \\label{fig:varBumpActivity}\n\n\n\n\n\\begin{figure}\n\\begin{cppcode}{original restart\\_condition}\nbool Solver::restart_condition(){\n    if ((lbd_queue_size == 50 && 0.8 * fast_lbd_sum / lbd_queue_size > slow_lbd_sum / conflicts) || !withinBudget())\n        return true;\n    else\n        return false;\n\n}\n\\end{cppcode}\n\n\\begin{cppcode}{discoverd restart\\_condition}\nbool Solver::restart_condition() {\n    // Base restart condition on conflict count\n    if (conflicts <= 0) return false;\n    \n    // Dynamic restart threshold based on recent solver performance\n    double restart_threshold;\n    \n    if (lbd_queue_size > 0) {\n        // Use both average LBD and conflict rate for adaptive restart\n        double avg_lbd = fast_lbd_sum / lbd_queue_size;\n        double conflict_rate = (double)conflictR / (double)conflicts;\n        \n        // Adjust threshold based on problem difficulty (higher LBD = harder problem)\n        restart_threshold = restart_first * (0.8 + 0.4 * avg_lbd) * (1.0 + 0.5 * conflict_rate);\n        \n        // More aggressive restart if we're making little progress\n        if (progressEstimate() - last_rephase_progress < 0.01) {\n            restart_threshold *= 0.7;\n        }\n    } else {\n        // Default threshold for initial phase\n        restart_threshold = restart_first;\n    }\n    \n    // Check if we've reached the threshold\n    if (conflictR >= restart_threshold) {\n        conflictR = 0;\n        return true;\n    }   \n    return false;\n}\n\\end{cppcode}\n    \\caption{Example of LLM discovered heuristics of restart condition}\n    \\label{fig:restartcondition}\n\\end{figure}\n{original restart\\_condition}original restart\\_condition\nbool Solver::restart_condition(){\n    if ((lbd_queue_size == 50 && 0.8 * fast_lbd_sum / lbd_queue_size > slow_lbd_sum / conflicts) || !withinBudget())\n        return true;\n    else\n        return false;\n\n}\n    if ((lbd_queue_size == 50 && 0.8 * fast_lbd_sum / lbd_queue_size > slow_lbd_sum / conflicts) || !withinBudget())\n        return true;\n    else\n        return false;\n\n\n\n\n{discoverd restart\\_condition}discoverd restart\\_condition\nbool Solver::restart_condition() {\n    // Base restart condition on conflict count\n    if (conflicts <= 0) return false;\n    \n    // Dynamic restart threshold based on recent solver performance\n    double restart_threshold;\n    \n    if (lbd_queue_size > 0) {\n        // Use both average LBD and conflict rate for adaptive restart\n        double avg_lbd = fast_lbd_sum / lbd_queue_size;\n        double conflict_rate = (double)conflictR / (double)conflicts;\n        \n        // Adjust threshold based on problem difficulty (higher LBD = harder problem)\n        restart_threshold = restart_first * (0.8 + 0.4 * avg_lbd) * (1.0 + 0.5 * conflict_rate);\n        \n        // More aggressive restart if we're making little progress\n        if (progressEstimate() - last_rephase_progress < 0.01) {\n            restart_threshold *= 0.7;\n        }\n    } else {\n        // Default threshold for initial phase\n        restart_threshold = restart_first;\n    }\n    \n    // Check if we've reached the threshold\n    if (conflictR >= restart_threshold) {\n        conflictR = 0;\n        return true;\n    }   \n    return false;\n}\n    // Base restart condition on conflict count\n    if (conflicts <= 0) return false;\n    \n    // Dynamic restart threshold based on recent solver performance\n    double restart_threshold;\n    \n    if (lbd_queue_size > 0) {\n        // Use both average LBD and conflict rate for adaptive restart\n        double avg_lbd = fast_lbd_sum / lbd_queue_size;\n        double conflict_rate = (double)conflictR / (double)conflicts;\n        \n        // Adjust threshold based on problem difficulty (higher LBD = harder problem)\n        restart_threshold = restart_first * (0.8 + 0.4 * avg_lbd) * (1.0 + 0.5 * conflict_rate);\n        \n        // More aggressive restart if we're making little progress\n        if (progressEstimate() - last_rephase_progress < 0.01) {\n            restart_threshold *= 0.7;\n        }\n    }\n        // Use both average LBD and conflict rate for adaptive restart\n        double avg_lbd = fast_lbd_sum / lbd_queue_size;\n        double conflict_rate = (double)conflictR / (double)conflicts;\n        \n        // Adjust threshold based on problem difficulty (higher LBD = harder problem)\n        restart_threshold = restart_first * (0.8 + 0.4 * avg_lbd) * (1.0 + 0.5 * conflict_rate);\n        \n        // More aggressive restart if we're making little progress\n        if (progressEstimate() - last_rephase_progress < 0.01) {\n            restart_threshold *= 0.7;\n        }\n            restart_threshold *= 0.7;\n        \n     else {\n        // Default threshold for initial phase\n        restart_threshold = restart_first;\n    }\n        // Default threshold for initial phase\n        restart_threshold = restart_first;\n    \n    \n    // Check if we've reached the threshold\n    if (conflictR >= restart_threshold) {\n        conflictR = 0;\n        return true;\n    }\n        conflictR = 0;\n        return true;\n       \n    return false;\n\n\n    \\caption{Example of LLM discovered heuristics of restart condition}\n    \\label{fig:restartcondition}\n\n\n\n\n\\begin{figure}\n\\begin{cppcode}{original restart\\_function}\nvoid Solver::restart_function(){\n    fast_lbd_sum = lbd_queue_size = lbd_queue_pos = 0;\n    int level = 0;\n    cancelUntil(level);\n}\n\\end{cppcode}\n\n\\begin{cppcode}{discovered restart\\_function}\nvoid Solver::restart_function() {\n\n    // Update restart statistics\n    static double fast_avg = 0, slow_avg = 0;\n    static int restart_count = 0;\n    \n    // Calculate moving averages of LBD scores\n    if (lbd_queue_size > 0) {\n        double curr_fast = fast_lbd_sum / lbd_queue_size;\n        fast_avg = 0.9 * fast_avg + 0.1 * curr_fast;\n        slow_avg = 0.99 * slow_avg + 0.01 * curr_fast;\n    }\n\n    // Determine restart level based on recent performance\n    int restart_level = 0;\n    if (fast_avg > 0 && slow_avg > 0) {\n        double ratio = fast_avg / slow_avg;\n        if (ratio > 1.2) {\n            // Recent conflicts are harder - do a full restart\n            restart_level = 0;\n        } else if (ratio > 1.0) {\n            // Partial restart - keep some learned clauses\n            restart_level = std::max(0, decisionLevel() / 2);\n        } else {\n            // Recent conflicts are easier - minimal restart\n            restart_level = std::max(0, decisionLevel() - 1);\n        }\n    }\n\n    // Reset LBD statistics\n    fast_lbd_sum = lbd_queue_size = lbd_queue_pos = 0;\n    \n    // Perform the restart\n    cancelUntil(restart_level);\n    \n    // Occasionally reduce the clause database after restarts\n    if (restart_count++ \\% 16 == 15) {\n        reduceDB();\n    }\n\n    // Rebuild the order heap to reflect any activity changes\n    rebuildOrderHeap();\n}\n\\end{cppcode}\n    \\caption{Example of LLM discovered heuristics of restart function}\n    \\label{fig:restartfunction}\n\\end{figure}\n{original restart\\_function}original restart\\_function\nvoid Solver::restart_function(){\n    fast_lbd_sum = lbd_queue_size = lbd_queue_pos = 0;\n    int level = 0;\n    cancelUntil(level);\n}\n    fast_lbd_sum = lbd_queue_size = lbd_queue_pos = 0;\n    int level = 0;\n    cancelUntil(level);\n\n\n\n{discovered restart\\_function}discovered restart\\_function\nvoid Solver::restart_function() {\n\n    // Update restart statistics\n    static double fast_avg = 0, slow_avg = 0;\n    static int restart_count = 0;\n    \n    // Calculate moving averages of LBD scores\n    if (lbd_queue_size > 0) {\n        double curr_fast = fast_lbd_sum / lbd_queue_size;\n        fast_avg = 0.9 * fast_avg + 0.1 * curr_fast;\n        slow_avg = 0.99 * slow_avg + 0.01 * curr_fast;\n    }\n\n    // Determine restart level based on recent performance\n    int restart_level = 0;\n    if (fast_avg > 0 && slow_avg > 0) {\n        double ratio = fast_avg / slow_avg;\n        if (ratio > 1.2) {\n            // Recent conflicts are harder - do a full restart\n            restart_level = 0;\n        } else if (ratio > 1.0) {\n            // Partial restart - keep some learned clauses\n            restart_level = std::max(0, decisionLevel() / 2);\n        } else {\n            // Recent conflicts are easier - minimal restart\n            restart_level = std::max(0, decisionLevel() - 1);\n        }\n    }\n\n    // Reset LBD statistics\n    fast_lbd_sum = lbd_queue_size = lbd_queue_pos = 0;\n    \n    // Perform the restart\n    cancelUntil(restart_level);\n    \n    // Occasionally reduce the clause database after restarts\n    if (restart_count++ \\% 16 == 15) {\n        reduceDB();\n    }\n\n    // Rebuild the order heap to reflect any activity changes\n    rebuildOrderHeap();\n}\n\n    // Update restart statistics\n    static double fast_avg = 0, slow_avg = 0;\n    static int restart_count = 0;\n    \n    // Calculate moving averages of LBD scores\n    if (lbd_queue_size > 0) {\n        double curr_fast = fast_lbd_sum / lbd_queue_size;\n        fast_avg = 0.9 * fast_avg + 0.1 * curr_fast;\n        slow_avg = 0.99 * slow_avg + 0.01 * curr_fast;\n    }\n        double curr_fast = fast_lbd_sum / lbd_queue_size;\n        fast_avg = 0.9 * fast_avg + 0.1 * curr_fast;\n        slow_avg = 0.99 * slow_avg + 0.01 * curr_fast;\n    \n\n    // Determine restart level based on recent performance\n    int restart_level = 0;\n    if (fast_avg > 0 && slow_avg > 0) {\n        double ratio = fast_avg / slow_avg;\n        if (ratio > 1.2) {\n            // Recent conflicts are harder - do a full restart\n            restart_level = 0;\n        } else if (ratio > 1.0) {\n            // Partial restart - keep some learned clauses\n            restart_level = std::max(0, decisionLevel() / 2);\n        } else {\n            // Recent conflicts are easier - minimal restart\n            restart_level = std::max(0, decisionLevel() - 1);\n        }\n    }\n        double ratio = fast_avg / slow_avg;\n        if (ratio > 1.2) {\n            // Recent conflicts are harder - do a full restart\n            restart_level = 0;\n        }\n            // Recent conflicts are harder - do a full restart\n            restart_level = 0;\n         else if (ratio > 1.0) {\n            // Partial restart - keep some learned clauses\n            restart_level = std::max(0, decisionLevel() / 2);\n        }\n            // Partial restart - keep some learned clauses\n            restart_level = std::max(0, decisionLevel() / 2);\n         else {\n            // Recent conflicts are easier - minimal restart\n            restart_level = std::max(0, decisionLevel() - 1);\n        }\n            // Recent conflicts are easier - minimal restart\n            restart_level = std::max(0, decisionLevel() - 1);\n        \n    \n\n    // Reset LBD statistics\n    fast_lbd_sum = lbd_queue_size = lbd_queue_pos = 0;\n    \n    // Perform the restart\n    cancelUntil(restart_level);\n    \n    // Occasionally reduce the clause database after restarts\n    if (restart_count++ \\% 16 == 15) {\n        reduceDB();\n    }\n        reduceDB();\n    \n\n    // Rebuild the order heap to reflect any activity changes\n    rebuildOrderHeap();\n\n\n    \\caption{Example of LLM discovered heuristics of restart function}\n    \\label{fig:restartfunction}\n\n\n\n\\begin{figure}[ht!]\n\\begin{cppcode}{original rephase\\_condition}\nbool Solver::rephase_condition() {\n    if (rephases >= rephase_limit) return true;\n    else return false;\n}\n\\end{cppcode}\n\n\\begin{cppcode}{discovered rephase\\_condition}\nbool Solver::rephase_condition() {\n    // Adaptive rephasing based on progress and conflict density\n    const int base_rephase_limit = 1024;\n    const double progress_factor = 0.02;  // 2% of total variables\n    \n    if (conflictR < rephase_limit) \n        return false;\n\n    // Calculate normalized progress since last rephase\n    int progress = trail.size() - last_rephase_progress;\n    int progress_threshold = std::max(50, (int)(nVars() * progress_factor));\n    \n    // Dynamic limit adjustment based on search progress\n    if (progress < progress_threshold) {\n        // Stagnation detected - reduce next rephase interval\n        rephase_limit = std::max(base_rephase_limit, rephase_limit * 2/3);\n    } else {\n        // Good progress - expand next rephase interval\n        rephase_limit = std::min(base_rephase_limit * 16, rephase_limit * 3/2);\n    }\n\n    // Reset conflict counter and update progress tracker in rephase_function\n    return true;\n}\n\\end{cppcode}\n    \\caption{Example of LLM discovered heuristics of rephase condition}\n    \\label{fig:rephasecondition}\n\\end{figure}\n{original rephase\\_condition}original rephase\\_condition\nbool Solver::rephase_condition() {\n    if (rephases >= rephase_limit) return true;\n    else return false;\n}\n    if (rephases >= rephase_limit) return true;\n    else return false;\n\n\n\n{discovered rephase\\_condition}discovered rephase\\_condition\nbool Solver::rephase_condition() {\n    // Adaptive rephasing based on progress and conflict density\n    const int base_rephase_limit = 1024;\n    const double progress_factor = 0.02;  // 2% of total variables\n    \n    if (conflictR < rephase_limit) \n        return false;\n\n    // Calculate normalized progress since last rephase\n    int progress = trail.size() - last_rephase_progress;\n    int progress_threshold = std::max(50, (int)(nVars() * progress_factor));\n    \n    // Dynamic limit adjustment based on search progress\n    if (progress < progress_threshold) {\n        // Stagnation detected - reduce next rephase interval\n        rephase_limit = std::max(base_rephase_limit, rephase_limit * 2/3);\n    } else {\n        // Good progress - expand next rephase interval\n        rephase_limit = std::min(base_rephase_limit * 16, rephase_limit * 3/2);\n    }\n\n    // Reset conflict counter and update progress tracker in rephase_function\n    return true;\n}\n    // Adaptive rephasing based on progress and conflict density\n    const int base_rephase_limit = 1024;\n    const double progress_factor = 0.02;  // 2if (conflictR < rephase_limit) \n        return false;\n\n    // Calculate normalized progress since last rephase\n    int progress = trail.size() - last_rephase_progress;\n    int progress_threshold = std::max(50, (int)(nVars() * progress_factor));\n    \n    // Dynamic limit adjustment based on search progress\n    if (progress < progress_threshold) {\n        // Stagnation detected - reduce next rephase interval\n        rephase_limit = std::max(base_rephase_limit, rephase_limit * 2/3);\n    }\n        // Stagnation detected - reduce next rephase interval\n        rephase_limit = std::max(base_rephase_limit, rephase_limit * 2/3);\n     else {\n        // Good progress - expand next rephase interval\n        rephase_limit = std::min(base_rephase_limit * 16, rephase_limit * 3/2);\n    }\n        // Good progress - expand next rephase interval\n        rephase_limit = std::min(base_rephase_limit * 16, rephase_limit * 3/2);\n    \n\n    // Reset conflict counter and update progress tracker in rephase_function\n    return true;\n\n\n    \\caption{Example of LLM discovered heuristics of rephase condition}\n    \\label{fig:rephasecondition}\n\n\n\n\\begin{figure}[ht!]\n\\begin{cppcode}{original rephase\\_function}\nvoid Solver::rephase_function() {\n    int var_nums = nVars();\n    conflictR = 0, rephases = 0, threshold *= 0.9, rephase_limit += 8192;Add commentMore actions\n    int phase_rand = rand() \\% 100;      \n    if ((phase_rand -= 40) < 0){\n        for (int i = 0; i < var_nums; i++){\n            polarity[i] = local_best[i];\n        }\n    }\n    else if ((phase_rand -= 25) < 0){\n        for (int i = 0; i < var_nums; i++){\n            polarity[i] = 1-local_best[i];\n        }\n    }\n    else if ((phase_rand -= 15) < 0){\n        for (int i = 0; i < var_nums; i++){\n            polarity[i] = !polarity[i];\n        }\n    }\n    else {\n        for (int i = 0; i < var_nums; i++){\n            polarity[i] = saved[i];\n        }\n    }\n}\n\\end{cppcode}\n    \\caption{Example of LLM discovered heuristics of rephase function}\n\\end{figure}\n{original rephase\\_function}original rephase\\_function\nvoid Solver::rephase_function() {\n    int var_nums = nVars();\n    conflictR = 0, rephases = 0, threshold *= 0.9, rephase_limit += 8192;Add commentMore actions\n    int phase_rand = rand() \\% 100;      \n    if ((phase_rand -= 40) < 0){\n        for (int i = 0; i < var_nums; i++){\n            polarity[i] = local_best[i];\n        }\n    }\n    else if ((phase_rand -= 25) < 0){\n        for (int i = 0; i < var_nums; i++){\n            polarity[i] = 1-local_best[i];\n        }\n    }\n    else if ((phase_rand -= 15) < 0){\n        for (int i = 0; i < var_nums; i++){\n            polarity[i] = !polarity[i];\n        }\n    }\n    else {\n        for (int i = 0; i < var_nums; i++){\n            polarity[i] = saved[i];\n        }\n    }\n}\n    int var_nums = nVars();\n    conflictR = 0, rephases = 0, threshold *= 0.9, rephase_limit += 8192;Add commentMore actions\n    int phase_rand = rand() \\% 100;      \n    if ((phase_rand -= 40) < 0){\n        for (int i = 0; i < var_nums; i++){\n            polarity[i] = local_best[i];\n        }\n    }\n        for (int i = 0; i < var_nums; i++){\n            polarity[i] = local_best[i];\n        }\n            polarity[i] = local_best[i];\n        \n    \n    else if ((phase_rand -= 25) < 0){\n        for (int i = 0; i < var_nums; i++){\n            polarity[i] = 1-local_best[i];\n        }\n    }\n        for (int i = 0; i < var_nums; i++){\n            polarity[i] = 1-local_best[i];\n        }\n            polarity[i] = 1-local_best[i];\n        \n    \n    else if ((phase_rand -= 15) < 0){\n        for (int i = 0; i < var_nums; i++){\n            polarity[i] = !polarity[i];\n        }\n    }\n        for (int i = 0; i < var_nums; i++){\n            polarity[i] = !polarity[i];\n        }\n            polarity[i] = !polarity[i];\n        \n    \n    else {\n        for (int i = 0; i < var_nums; i++){\n            polarity[i] = saved[i];\n        }\n    }\n        for (int i = 0; i < var_nums; i++){\n            polarity[i] = saved[i];\n        }\n            polarity[i] = saved[i];\n        \n    \n\n\n    \\caption{Example of LLM discovered heuristics of rephase function}\n\n\n\\begin{figure}[ht!]\n\\begin{cppcode}{discovered rephase\\_function}\nvoid Solver::rephase_function() {\n    // Adaptive rephase limit adjustment\n    if (rephases > 0 && conflictR > last_rephase_progress) {\n        // Progress was made - be more aggressive with rephasing\n        rephase_limit = rephase_limit * 1.5;\n    } else {\n        // No progress - be more conservative\n        rephase_limit = rephase_limit * 0.9;\n        if (rephase_limit < 512) rephase_limit = 512;\n    }\n    last_rephase_progress = conflictR;\n    rephase_count++;\n\n    // Dynamic phase selection strategy\n    double rand_val = drand(random_seed);\n    if (rand_val < 0.4) {\n        // 40\\% chance: Use local best phases\n        for (int v = 0; v < nVars(); v++) {\n            polarity[v] = local_best[v];\n        }\n        if (verbosity >= 1) printf(\"| Rephase: Local best phases |\\n\");\n    } else if (rand_val < 0.7) {\n        // 30\\% chance: Invert all phases\n        for (int v = 0; v < nVars(); v++) {\n            polarity[v] = !polarity[v];\n        }\n        if (verbosity >= 1) printf(\"| Rephase: Inverted all phases |\\n\");\n    } else if (rand_val < 0.9) {\n        // 20\\% chance: Random phases for variables with low activity\n        double activity_threshold = 0.2 * var_inc;\n        for (int v = 0; v < nVars(); v++) {\n            if (activity[v] < activity_threshold) {\n                polarity[v] = drand(random_seed) < 0.5;\n            }\n        }\n        if (verbosity >= 1) printf(\"| Rephase: Randomized low-activity phases |\\n\");\n    } else {\n        // 10\\% chance: Original user phases\n        for (int v = 0; v < nVars(); v++) {\n            if (user_pol[v] != l_Undef) {\n                polarity[v] = (user_pol[v] == l_True);\n            }\n        }Add commentMore actions\n        if (verbosity >= 1) printf(\"| Rephase: Reset to user phases |\\n\");\n    }\n\n    // Reset the threshold for next local best phase tracking\n    threshold = trail.size() * 0.8;\n    cancelUntil(0);\n}\n\\end{cppcode}\n    \\caption{Example of LLM discovered heuristics of rephase function}\n    \\label{fig:rephasefunction}\n\\end{figure}\n{discovered rephase\\_function}discovered rephase\\_function\nvoid Solver::rephase_function() {\n    // Adaptive rephase limit adjustment\n    if (rephases > 0 && conflictR > last_rephase_progress) {\n        // Progress was made - be more aggressive with rephasing\n        rephase_limit = rephase_limit * 1.5;\n    } else {\n        // No progress - be more conservative\n        rephase_limit = rephase_limit * 0.9;\n        if (rephase_limit < 512) rephase_limit = 512;\n    }\n    last_rephase_progress = conflictR;\n    rephase_count++;\n\n    // Dynamic phase selection strategy\n    double rand_val = drand(random_seed);\n    if (rand_val < 0.4) {\n        // 40\\% chance: Use local best phases\n        for (int v = 0; v < nVars(); v++) {\n            polarity[v] = local_best[v];\n        }\n        if (verbosity >= 1) printf(\"| Rephase: Local best phases |\\n\");\n    } else if (rand_val < 0.7) {\n        // 30\\% chance: Invert all phases\n        for (int v = 0; v < nVars(); v++) {\n            polarity[v] = !polarity[v];\n        }\n        if (verbosity >= 1) printf(\"| Rephase: Inverted all phases |\\n\");\n    } else if (rand_val < 0.9) {\n        // 20\\% chance: Random phases for variables with low activity\n        double activity_threshold = 0.2 * var_inc;\n        for (int v = 0; v < nVars(); v++) {\n            if (activity[v] < activity_threshold) {\n                polarity[v] = drand(random_seed) < 0.5;\n            }\n        }\n        if (verbosity >= 1) printf(\"| Rephase: Randomized low-activity phases |\\n\");\n    } else {\n        // 10\\% chance: Original user phases\n        for (int v = 0; v < nVars(); v++) {\n            if (user_pol[v] != l_Undef) {\n                polarity[v] = (user_pol[v] == l_True);\n            }\n        }Add commentMore actions\n        if (verbosity >= 1) printf(\"| Rephase: Reset to user phases |\\n\");\n    }\n\n    // Reset the threshold for next local best phase tracking\n    threshold = trail.size() * 0.8;\n    cancelUntil(0);\n}\n    // Adaptive rephase limit adjustment\n    if (rephases > 0 && conflictR > last_rephase_progress) {\n        // Progress was made - be more aggressive with rephasing\n        rephase_limit = rephase_limit * 1.5;\n    }\n        // Progress was made - be more aggressive with rephasing\n        rephase_limit = rephase_limit * 1.5;\n     else {\n        // No progress - be more conservative\n        rephase_limit = rephase_limit * 0.9;\n        if (rephase_limit < 512) rephase_limit = 512;\n    }\n        // No progress - be more conservative\n        rephase_limit = rephase_limit * 0.9;\n        if (rephase_limit < 512) rephase_limit = 512;\n    \n    last_rephase_progress = conflictR;\n    rephase_count++;\n\n    // Dynamic phase selection strategy\n    double rand_val = drand(random_seed);\n    if (rand_val < 0.4) {\n        // 40\\% chance: Use local best phases\n        for (int v = 0; v < nVars(); v++) {\n            polarity[v] = local_best[v];\n        }\n        if (verbosity >= 1) printf(\"| Rephase: Local best phases |\\n\");\n    }\n        // 40\\% chance: Use local best phases\n        for (int v = 0; v < nVars(); v++) {\n            polarity[v] = local_best[v];\n        }\n            polarity[v] = local_best[v];\n        \n        if (verbosity >= 1) printf(\"| Rephase: Local best phases |\\n\");\n     else if (rand_val < 0.7) {\n        // 30\\% chance: Invert all phases\n        for (int v = 0; v < nVars(); v++) {\n            polarity[v] = !polarity[v];\n        }\n        if (verbosity >= 1) printf(\"| Rephase: Inverted all phases |\\n\");\n    }\n        // 30\\% chance: Invert all phases\n        for (int v = 0; v < nVars(); v++) {\n            polarity[v] = !polarity[v];\n        }\n            polarity[v] = !polarity[v];\n        \n        if (verbosity >= 1) printf(\"| Rephase: Inverted all phases |\\n\");\n     else if (rand_val < 0.9) {\n        // 20\\% chance: Random phases for variables with low activity\n        double activity_threshold = 0.2 * var_inc;\n        for (int v = 0; v < nVars(); v++) {\n            if (activity[v] < activity_threshold) {\n                polarity[v] = drand(random_seed) < 0.5;\n            }\n        }\n        if (verbosity >= 1) printf(\"| Rephase: Randomized low-activity phases |\\n\");\n    }\n        // 20\\% chance: Random phases for variables with low activity\n        double activity_threshold = 0.2 * var_inc;\n        for (int v = 0; v < nVars(); v++) {\n            if (activity[v] < activity_threshold) {\n                polarity[v] = drand(random_seed) < 0.5;\n            }\n        }\n            if (activity[v] < activity_threshold) {\n                polarity[v] = drand(random_seed) < 0.5;\n            }\n                polarity[v] = drand(random_seed) < 0.5;\n            \n        \n        if (verbosity >= 1) printf(\"| Rephase: Randomized low-activity phases |\\n\");\n     else {\n        // 10\\% chance: Original user phases\n        for (int v = 0; v < nVars(); v++) {\n            if (user_pol[v] != l_Undef) {\n                polarity[v] = (user_pol[v] == l_True);\n            }\n        }Add commentMore actions\n        if (verbosity >= 1) printf(\"| Rephase: Reset to user phases |\\n\");\n    }\n        // 10\\% chance: Original user phases\n        for (int v = 0; v < nVars(); v++) {\n            if (user_pol[v] != l_Undef) {\n                polarity[v] = (user_pol[v] == l_True);\n            }\n        }\n            if (user_pol[v] != l_Undef) {\n                polarity[v] = (user_pol[v] == l_True);\n            }\n                polarity[v] = (user_pol[v] == l_True);\n            \n        Add commentMore actions\n        if (verbosity >= 1) printf(\"| Rephase: Reset to user phases |\\n\");\n    \n\n    // Reset the threshold for next local best phase tracking\n    threshold = trail.size() * 0.8;\n    cancelUntil(0);\n\n\n    \\caption{Example of LLM discovered heuristics of rephase function}\n    \\label{fig:rephasefunction}\n\n\n\n\n\\begin{figure}[ht!]\n\\begin{cppcode}{original reduce\\_condition}\nbool Solver::reduce_condition()\n{   \n    if (learnts.size() >= max_learnts)  return true;\n    else return false;\n}\n\\end{cppcode}\n\n\\begin{cppcode}{discovered reduce\\_condition}\nbool Solver::reduce_condition()\n{\n    // Check if we've reached the absolute limit of learnt clausesAdd commentMore actions\n    if (learnts.size() >= max_learnts) return true;\n    \n    // Consider memory pressure and garbage collection needs\n    if (ca.wasted() > ca.size() * garbage_frac * 0.8) return true;\n    \n    // Consider the ratio between learnt and original clauses\n    if (learnts.size() > 0 && learnts.size() > 2 * nClauses()) return true;\n    \n    // Consider recent solver performance (conflict rate)\n    if (conflictR > 1000 && learnts.size() > max_learnts * 0.8) return true;\n    \n    return false;\n}\n\\end{cppcode}\n    \\caption{Example of LLM discovered heuristics of reduce condition}\n    \\label{fig:reducecondition}\n\\end{figure}\n{original reduce\\_condition}original reduce\\_condition\nbool Solver::reduce_condition()\n{   \n    if (learnts.size() >= max_learnts)  return true;\n    else return false;\n}   \n    if (learnts.size() >= max_learnts)  return true;\n    else return false;\n\n\n\n{discovered reduce\\_condition}discovered reduce\\_condition\nbool Solver::reduce_condition()\n{\n    // Check if we've reached the absolute limit of learnt clausesAdd commentMore actions\n    if (learnts.size() >= max_learnts) return true;\n    \n    // Consider memory pressure and garbage collection needs\n    if (ca.wasted() > ca.size() * garbage_frac * 0.8) return true;\n    \n    // Consider the ratio between learnt and original clauses\n    if (learnts.size() > 0 && learnts.size() > 2 * nClauses()) return true;\n    \n    // Consider recent solver performance (conflict rate)\n    if (conflictR > 1000 && learnts.size() > max_learnts * 0.8) return true;\n    \n    return false;\n}\n    // Check if we've reached the absolute limit of learnt clausesAdd commentMore actions\n    if (learnts.size() >= max_learnts) return true;\n    \n    // Consider memory pressure and garbage collection needs\n    if (ca.wasted() > ca.size() * garbage_frac * 0.8) return true;\n    \n    // Consider the ratio between learnt and original clauses\n    if (learnts.size() > 0 && learnts.size() > 2 * nClauses()) return true;\n    \n    // Consider recent solver performance (conflict rate)\n    if (conflictR > 1000 && learnts.size() > max_learnts * 0.8) return true;\n    \n    return false;\n\n\n    \\caption{Example of LLM discovered heuristics of reduce condition}\n    \\label{fig:reducecondition}\n\n\n\n", "appendix": false}}, "categories": ["cs.AI", "cs.LO"], "published": "2025-07-30 17:52:25+00:00", "primary_category": "cs.AI", "summary": "Satisfiability problem (SAT) is a cornerstone of computational complexity\nwith broad industrial applications, and it remains challenging to optimize\nmodern SAT solvers in real-world settings due to their intricate architectures.\nWhile automatic configuration frameworks have been developed, they rely on\nmanually constrained search spaces and yield limited performance gains. This\nwork introduces a novel paradigm which effectively optimizes complex SAT\nsolvers via Large Language Models (LLMs), and a tool called AutoModSAT is\ndeveloped. Three fundamental challenges are addressed in order to achieve\nsuperior performance: (1) LLM-friendly solver: Systematic guidelines are\nproposed for developing a modularized solver to meet LLMs' compatibility,\nemphasizing code simplification, information share and bug reduction; (2)\nAutomatic prompt optimization: An unsupervised automatic prompt optimization\nmethod is introduced to advance the diversity of LLMs' output; (3) Efficient\nsearch strategy: We design a presearch strategy and an EA evolutionary\nalgorithm for the final efficient and effective discovery of heuristics.\nExtensive experiments across a wide range of datasets demonstrate that\nAutoModSAT achieves 50% performance improvement over the baseline solver and\nachieves 30% superiority against the state-of-the-art (SOTA) solvers. Moreover,\nAutoModSAT attains a 20% speedup on average compared to parameter-tuned\nalternatives of the SOTA solvers, showcasing the enhanced capability in\nhandling complex problem instances. This work bridges the gap between AI-driven\nheuristics discovery and mission-critical system optimization, and provides\nboth methodological advancements and empirically validated results for\nnext-generation complex solver development."}