INFO 08-29 19:19:33 [__init__.py:241] Automatically detected platform cuda.
figure_block: Figure (optional):
- label: \label{fig:qualitative_faceid}; caption: \caption{Examples of the FaceID guidance generation with pre-trained CelebA-HQ models. }
Collected fig_labels: ['fig:qualitative_faceid']
CLIP image features: (1, 512)
INFO 08-29 19:22:28 [__init__.py:241] Automatically detected platform cuda.
figure_block: Figure (optional):
- label: \label{fig:qualitative_faceid}; caption: \caption{Examples of the FaceID guidance generation with pre-trained CelebA-HQ models. }
Collected fig_labels: ['fig:qualitative_faceid']
CLIP image features: (1, 512)
Top CLIP tags: ['contains scatter plot']
Image tag list: [['contains scatter plot']]
figure_block: Figure (optional):
- label: \label{fig:precond_a}; caption: \caption{}
- label: \label{fig:precond_b}; caption: \caption{}
Collected fig_labels: ['fig:precond_a', 'fig:precond_b']
[WARN] Path not found: download/output/figures/2310.07894v1/tex_figures_5c.png
[WARN] Path not found: download/output/figures/2310.07894v1/tex_figures_5d.png
Image tag list: [None, None]
figure_block: Figure (optional):
- label: \label{fig:cnn_c10_c100_trend}; caption: \caption{Prediction errors of base models and their weight averages (\fastswa and \swa) for CNN    on \textbf{(left)} CIFAR-10 with $4k$ labels,   \textbf{(middle)} CIFAR-100 with $10k$ labels,   and \textbf{(right)} CIFAR-100 $50k$ labels
Collected fig_labels: ['fig:cnn_c10_c100_trend']
[WARN] Path not found: download/output/figures/1806.05594v3/figs_exps_results_epochs_c10_cnn_MT_4k_wmodelTrue_nolegend
Image tag list: [None]
figure_block: Figure (optional):
- label: \label{fig:ai_use}; caption: \caption{The Adoption of Generative AI among Middlebury College Students}
- label: \label{fig:ai_use_time}; caption: \caption{The Evolution of Generative AI Adoption among Middlebury College Students}
- label: \label{fig:ai_models}; caption: \caption{Adoption of Generative AI Models Among College Students}
- label: \label{fig:ai_pays_dem}; caption: \caption{Percent of Students Who Pay for Generative AI Tools}
Collected fig_labels: ['fig:ai_use', 'fig:ai_use_time', 'fig:ai_models', 'fig:ai_pays_dem']
[WARN] Path not found: download/output/figures/2508.00717/results_ai_use_demog
[WARN] Path not found: download/output/figures/2508.00717/results_ai_use_time
[WARN] Path not found: download/output/figures/2508.00717/results_ai_use_model
[WARN] Path not found: download/output/figures/2508.00717/results_ai_pays_dem
Image tag list: [None, None, None, None]
figure_block: Figure (optional):
- label: \label{figure4}; caption: \caption{Graphical representation of the query types of the BetaE dataset considered in our experiment, where $p$, $i$, $u$, and $n$ represent projection, intersection, union, and negation, respectively. }
- label: \label{figure5}; caption: \caption{Graphical representation of the query types of the FIT dataset considered in our experiment, where $l$, $m$, and $c$ represent existential leaf, multi graph, and circle, respectively. }
Collected fig_labels: ['figure4', 'figure5']
INFO 08-29 19:23:19 [__init__.py:241] Automatically detected platform cuda.
figure_block: Figure (optional):
- label: \label{fig:qualitative_faceid}; caption: \caption{Examples of the FaceID guidance generation with pre-trained CelebA-HQ models. }
Collected fig_labels: ['fig:qualitative_faceid']
CLIP image features: (1, 512)
Top CLIP tags: ['contains scatter plot']
Image tag list: [['contains scatter plot']]
figure_block: Figure (optional):
- label: \label{fig:precond_a}; caption: \caption{}
- label: \label{fig:precond_b}; caption: \caption{}
Collected fig_labels: ['fig:precond_a', 'fig:precond_b']
[WARN] Path not found: download/output/figures/2310.07894v1/tex_figures_5c.png
[WARN] Path not found: download/output/figures/2310.07894v1/tex_figures_5d.png
Image tag list: [None, None]
figure_block: Figure (optional):
- label: \label{fig:cnn_c10_c100_trend}; caption: \caption{Prediction errors of base models and their weight averages (\fastswa and \swa) for CNN    on \textbf{(left)} CIFAR-10 with $4k$ labels,   \textbf{(middle)} CIFAR-100 with $10k$ labels,   and \textbf{(right)} CIFAR-100 $50k$ labels
Collected fig_labels: ['fig:cnn_c10_c100_trend']
[WARN] Path not found: download/output/figures/1806.05594v3/figs_exps_results_epochs_c10_cnn_MT_4k_wmodelTrue_nolegend
Image tag list: [None]
figure_block: Figure (optional):
- label: \label{fig:ai_use}; caption: \caption{The Adoption of Generative AI among Middlebury College Students}
- label: \label{fig:ai_use_time}; caption: \caption{The Evolution of Generative AI Adoption among Middlebury College Students}
- label: \label{fig:ai_models}; caption: \caption{Adoption of Generative AI Models Among College Students}
- label: \label{fig:ai_pays_dem}; caption: \caption{Percent of Students Who Pay for Generative AI Tools}
Collected fig_labels: ['fig:ai_use', 'fig:ai_use_time', 'fig:ai_models', 'fig:ai_pays_dem']
[WARN] Path not found: download/output/figures/2508.00717/results_ai_use_demog
[WARN] Path not found: download/output/figures/2508.00717/results_ai_use_time
[WARN] Path not found: download/output/figures/2508.00717/results_ai_use_model
[WARN] Path not found: download/output/figures/2508.00717/results_ai_pays_dem
Image tag list: [None, None, None, None]
figure_block: Figure (optional):
- label: \label{figure4}; caption: \caption{Graphical representation of the query types of the BetaE dataset considered in our experiment, where $p$, $i$, $u$, and $n$ represent projection, intersection, union, and negation, respectively. }
- label: \label{figure5}; caption: \caption{Graphical representation of the query types of the FIT dataset considered in our experiment, where $l$, $m$, and $c$ represent existential leaf, multi graph, and circle, respectively. }
Collected fig_labels: ['figure4', 'figure5']
CLIP image features: (1, 512)
Top CLIP tags: ['a figure showing network']
CLIP image features: (1, 512)
Top CLIP tags: ['a figure showing network']
Image tag list: [['a figure showing network'], ['a figure showing network']]
figure_block: Figure (optional):
- label: \label{fig:fwt_order8}; caption: \caption{Forward transfer score of different approaches on order 8. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:fwt_order9}; caption: \caption{Forward transfer score of different approaches on order 9. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:fwt_order10}; caption: \caption{Forward transfer score of different approaches on order 10. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:bwt_order8}; caption: \caption{Backward transfer score of different approaches on order 8. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:bwt_order9}; caption: \caption{Backward transfer score of different approaches on order 9. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:bwt_order10}; caption: \caption{Backward transfer score of different approaches on order 10. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:evolution}; caption: \caption{Evolution of average accuracy after learning new tasks.}
- label: \label{fig:fig_long_bars}; caption: \caption{Per-task improvement of Progressive Prompts verus per-task prompts in CL experiment with order 8 across different data limits (20, 200 and 1000 samples per class). X-axis shows the sequence of tasks, Y-axis shows percentage improve
Collected fig_labels: ['fig:fwt_order8', 'fig:fwt_order9', 'fig:fwt_order10', 'fig:bwt_order8', 'fig:bwt_order9', 'fig:bwt_order10', 'fig:evolution', 'fig:fig_long_bars']
CLIP image features: (1, 512)
Top CLIP tags: ['a chart about heatmap']
CLIP image features: (1, 512)
Top CLIP tags: ['a chart about heatmap']
CLIP image features: (1, 512)
Top CLIP tags: ['a chart about heatmap']
CLIP image features: (1, 512)
Top CLIP tags: ['a chart about heatmap']
CLIP image features: (1, 512)
Top CLIP tags: ['a chart about heatmap']
CLIP image features: (1, 512)
Top CLIP tags: ['a chart about heatmap']
CLIP image features: (1, 512)
Top CLIP tags: ['a chart about heatmap']
CLIP image features: (1, 512)
Top CLIP tags: ['a chart about bar chart']
Image tag list: [['a chart about heatmap'], ['a chart about heatmap'], ['a chart about heatmap'], ['a chart about heatmap'], ['a chart about heatmap'], ['a chart about heatmap'], ['a chart about heatmap'], ['a chart about bar chart']]
figure_block: Figure (optional):
- label: \label{fig:qualitative_faceid}; caption: \caption{Examples of the FaceID guidance generation with pre-trained CelebA-HQ models. }
Collected fig_labels: ['fig:qualitative_faceid']
figure_block: Figure (optional):
- label: \label{fig:precond_a}; caption: \caption{}
- label: \label{fig:precond_b}; caption: \caption{}
Collected fig_labels: ['fig:precond_a', 'fig:precond_b']
[WARN] Not a file: ./download/output/figures/2310.07894v1/tex_figures_5c.png
[WARN] Not a file: ./download/output/figures/2310.07894v1/tex_figures_5d.png
figure_block: Figure (optional):
- label: \label{fig:cnn_c10_c100_trend}; caption: \caption{Prediction errors of base models and their weight averages (\fastswa and \swa) for CNN    on \textbf{(left)} CIFAR-10 with $4k$ labels,   \textbf{(middle)} CIFAR-100 with $10k$ labels,   and \textbf{(right)} CIFAR-100 $50k$ labels
Collected fig_labels: ['fig:cnn_c10_c100_trend']
[WARN] Not a file: ./download/output/figures/1806.05594v3/figs_exps_results_epochs_c10_cnn_MT_4k_wmodelTrue_nolegend
figure_block: Figure (optional):
- label: \label{fig:ai_use}; caption: \caption{The Adoption of Generative AI among Middlebury College Students}
- label: \label{fig:ai_use_time}; caption: \caption{The Evolution of Generative AI Adoption among Middlebury College Students}
- label: \label{fig:ai_models}; caption: \caption{Adoption of Generative AI Models Among College Students}
- label: \label{fig:ai_pays_dem}; caption: \caption{Percent of Students Who Pay for Generative AI Tools}
Collected fig_labels: ['fig:ai_use', 'fig:ai_use_time', 'fig:ai_models', 'fig:ai_pays_dem']
[WARN] Not a file: ./download/output/figures/2508.00717/results_ai_use_demog
[WARN] Not a file: ./download/output/figures/2508.00717/results_ai_use_time
[WARN] Not a file: ./download/output/figures/2508.00717/results_ai_use_model
[WARN] Not a file: ./download/output/figures/2508.00717/results_ai_pays_dem
figure_block: Figure (optional):
- label: \label{figure4}; caption: \caption{Graphical representation of the query types of the BetaE dataset considered in our experiment, where $p$, $i$, $u$, and $n$ represent projection, intersection, union, and negation, respectively. }
- label: \label{figure5}; caption: \caption{Graphical representation of the query types of the FIT dataset considered in our experiment, where $l$, $m$, and $c$ represent existential leaf, multi graph, and circle, respectively. }
Collected fig_labels: ['figure4', 'figure5']
figure_block: Figure (optional):
- label: \label{fig:fwt_order8}; caption: \caption{Forward transfer score of different approaches on order 8. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:fwt_order9}; caption: \caption{Forward transfer score of different approaches on order 9. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:fwt_order10}; caption: \caption{Forward transfer score of different approaches on order 10. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:bwt_order8}; caption: \caption{Backward transfer score of different approaches on order 8. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:bwt_order9}; caption: \caption{Backward transfer score of different approaches on order 9. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:bwt_order10}; caption: \caption{Backward transfer score of different approaches on order 10. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:evolution}; caption: \caption{Evolution of average accuracy after learning new tasks.}
- label: \label{fig:fig_long_bars}; caption: \caption{Per-task improvement of Progressive Prompts verus per-task prompts in CL experiment with order 8 across different data limits (20, 200 and 1000 samples per class). X-axis shows the sequence of tasks, Y-axis shows percentage improve
Collected fig_labels: ['fig:fwt_order8', 'fig:fwt_order9', 'fig:fwt_order10', 'fig:bwt_order8', 'fig:bwt_order9', 'fig:bwt_order10', 'fig:evolution', 'fig:fig_long_bars']
figure_block: Figure (optional):
- label: \label{fig:qualitative_faceid}; caption: \caption{Examples of the FaceID guidance generation with pre-trained CelebA-HQ models. }
Collected fig_labels: ['fig:qualitative_faceid']
figure_block: Figure (optional):
- label: \label{fig:precond_a}; caption: \caption{}
- label: \label{fig:precond_b}; caption: \caption{}
Collected fig_labels: ['fig:precond_a', 'fig:precond_b']
[WARN] Not a file: ./download/output/figures/2310.07894v1/tex_figures_5c.png
[WARN] Not a file: ./download/output/figures/2310.07894v1/tex_figures_5d.png
figure_block: Figure (optional):
- label: \label{fig:cnn_c10_c100_trend}; caption: \caption{Prediction errors of base models and their weight averages (\fastswa and \swa) for CNN    on \textbf{(left)} CIFAR-10 with $4k$ labels,   \textbf{(middle)} CIFAR-100 with $10k$ labels,   and \textbf{(right)} CIFAR-100 $50k$ labels
Collected fig_labels: ['fig:cnn_c10_c100_trend']
[WARN] Not a file: ./download/output/figures/1806.05594v3/figs_exps_results_epochs_c10_cnn_MT_4k_wmodelTrue_nolegend
figure_block: Figure (optional):
- label: \label{fig:ai_use}; caption: \caption{The Adoption of Generative AI among Middlebury College Students}
- label: \label{fig:ai_use_time}; caption: \caption{The Evolution of Generative AI Adoption among Middlebury College Students}
- label: \label{fig:ai_models}; caption: \caption{Adoption of Generative AI Models Among College Students}
- label: \label{fig:ai_pays_dem}; caption: \caption{Percent of Students Who Pay for Generative AI Tools}
Collected fig_labels: ['fig:ai_use', 'fig:ai_use_time', 'fig:ai_models', 'fig:ai_pays_dem']
[WARN] Not a file: ./download/output/figures/2508.00717/results_ai_use_demog
[WARN] Not a file: ./download/output/figures/2508.00717/results_ai_use_time
[WARN] Not a file: ./download/output/figures/2508.00717/results_ai_use_model
[WARN] Not a file: ./download/output/figures/2508.00717/results_ai_pays_dem
figure_block: Figure (optional):
- label: \label{figure4}; caption: \caption{Graphical representation of the query types of the BetaE dataset considered in our experiment, where $p$, $i$, $u$, and $n$ represent projection, intersection, union, and negation, respectively. }
- label: \label{figure5}; caption: \caption{Graphical representation of the query types of the FIT dataset considered in our experiment, where $l$, $m$, and $c$ represent existential leaf, multi graph, and circle, respectively. }
Collected fig_labels: ['figure4', 'figure5']
figure_block: Figure (optional):
- label: \label{fig:fwt_order8}; caption: \caption{Forward transfer score of different approaches on order 8. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:fwt_order9}; caption: \caption{Forward transfer score of different approaches on order 9. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:fwt_order10}; caption: \caption{Forward transfer score of different approaches on order 10. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:bwt_order8}; caption: \caption{Backward transfer score of different approaches on order 8. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:bwt_order9}; caption: \caption{Backward transfer score of different approaches on order 9. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:bwt_order10}; caption: \caption{Backward transfer score of different approaches on order 10. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:evolution}; caption: \caption{Evolution of average accuracy after learning new tasks.}
- label: \label{fig:fig_long_bars}; caption: \caption{Per-task improvement of Progressive Prompts verus per-task prompts in CL experiment with order 8 across different data limits (20, 200 and 1000 samples per class). X-axis shows the sequence of tasks, Y-axis shows percentage improve
Collected fig_labels: ['fig:fwt_order8', 'fig:fwt_order9', 'fig:fwt_order10', 'fig:bwt_order8', 'fig:bwt_order9', 'fig:bwt_order10', 'fig:evolution', 'fig:fig_long_bars']
figure_block: Figure (optional):
- label: \label{fig:qualitative_faceid}; caption: \caption{Examples of the FaceID guidance generation with pre-trained CelebA-HQ models. }
Collected fig_labels: ['fig:qualitative_faceid']
figure_block: Figure (optional):
- label: \label{fig:precond_a}; caption: \caption{}
- label: \label{fig:precond_b}; caption: \caption{}
Collected fig_labels: ['fig:precond_a', 'fig:precond_b']
[WARN] Not a file: ./download/output/figures/2310.07894v1/tex_figures_5c.png
[WARN] Not a file: ./download/output/figures/2310.07894v1/tex_figures_5d.png
figure_block: Figure (optional):
- label: \label{fig:cnn_c10_c100_trend}; caption: \caption{Prediction errors of base models and their weight averages (\fastswa and \swa) for CNN    on \textbf{(left)} CIFAR-10 with $4k$ labels,   \textbf{(middle)} CIFAR-100 with $10k$ labels,   and \textbf{(right)} CIFAR-100 $50k$ labels
Collected fig_labels: ['fig:cnn_c10_c100_trend']
[WARN] Not a file: ./download/output/figures/1806.05594v3/figs_exps_results_epochs_c10_cnn_MT_4k_wmodelTrue_nolegend
figure_block: Figure (optional):
- label: \label{fig:ai_use}; caption: \caption{The Adoption of Generative AI among Middlebury College Students}
- label: \label{fig:ai_use_time}; caption: \caption{The Evolution of Generative AI Adoption among Middlebury College Students}
- label: \label{fig:ai_models}; caption: \caption{Adoption of Generative AI Models Among College Students}
- label: \label{fig:ai_pays_dem}; caption: \caption{Percent of Students Who Pay for Generative AI Tools}
Collected fig_labels: ['fig:ai_use', 'fig:ai_use_time', 'fig:ai_models', 'fig:ai_pays_dem']
[WARN] Not a file: ./download/output/figures/2508.00717/results_ai_use_demog
[WARN] Not a file: ./download/output/figures/2508.00717/results_ai_use_time
[WARN] Not a file: ./download/output/figures/2508.00717/results_ai_use_model
[WARN] Not a file: ./download/output/figures/2508.00717/results_ai_pays_dem
figure_block: Figure (optional):
- label: \label{figure4}; caption: \caption{Graphical representation of the query types of the BetaE dataset considered in our experiment, where $p$, $i$, $u$, and $n$ represent projection, intersection, union, and negation, respectively. }
- label: \label{figure5}; caption: \caption{Graphical representation of the query types of the FIT dataset considered in our experiment, where $l$, $m$, and $c$ represent existential leaf, multi graph, and circle, respectively. }
Collected fig_labels: ['figure4', 'figure5']
figure_block: Figure (optional):
- label: \label{fig:fwt_order8}; caption: \caption{Forward transfer score of different approaches on order 8. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:fwt_order9}; caption: \caption{Forward transfer score of different approaches on order 9. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:fwt_order10}; caption: \caption{Forward transfer score of different approaches on order 10. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:bwt_order8}; caption: \caption{Backward transfer score of different approaches on order 8. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:bwt_order9}; caption: \caption{Backward transfer score of different approaches on order 9. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:bwt_order10}; caption: \caption{Backward transfer score of different approaches on order 10. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:evolution}; caption: \caption{Evolution of average accuracy after learning new tasks.}
- label: \label{fig:fig_long_bars}; caption: \caption{Per-task improvement of Progressive Prompts verus per-task prompts in CL experiment with order 8 across different data limits (20, 200 and 1000 samples per class). X-axis shows the sequence of tasks, Y-axis shows percentage improve
Collected fig_labels: ['fig:fwt_order8', 'fig:fwt_order9', 'fig:fwt_order10', 'fig:bwt_order8', 'fig:bwt_order9', 'fig:bwt_order10', 'fig:evolution', 'fig:fig_long_bars']
figure_block: Figure (optional):
- label: \label{fig:qualitative_faceid}; caption: \caption{Examples of the FaceID guidance generation with pre-trained CelebA-HQ models. }
Collected fig_labels: ['fig:qualitative_faceid']
figure_block: Figure (optional):
- label: \label{fig:precond_a}; caption: \caption{}
- label: \label{fig:precond_b}; caption: \caption{}
Collected fig_labels: ['fig:precond_a', 'fig:precond_b']
[WARN] Not a file: ./download/output/figures/2310.07894v1/tex_figures_5c.png
[WARN] Not a file: ./download/output/figures/2310.07894v1/tex_figures_5d.png
figure_block: Figure (optional):
- label: \label{fig:cnn_c10_c100_trend}; caption: \caption{Prediction errors of base models and their weight averages (\fastswa and \swa) for CNN    on \textbf{(left)} CIFAR-10 with $4k$ labels,   \textbf{(middle)} CIFAR-100 with $10k$ labels,   and \textbf{(right)} CIFAR-100 $50k$ labels
Collected fig_labels: ['fig:cnn_c10_c100_trend']
[WARN] Not a file: ./download/output/figures/1806.05594v3/figs_exps_results_epochs_c10_cnn_MT_4k_wmodelTrue_nolegend
figure_block: Figure (optional):
- label: \label{fig:ai_use}; caption: \caption{The Adoption of Generative AI among Middlebury College Students}
- label: \label{fig:ai_use_time}; caption: \caption{The Evolution of Generative AI Adoption among Middlebury College Students}
- label: \label{fig:ai_models}; caption: \caption{Adoption of Generative AI Models Among College Students}
- label: \label{fig:ai_pays_dem}; caption: \caption{Percent of Students Who Pay for Generative AI Tools}
Collected fig_labels: ['fig:ai_use', 'fig:ai_use_time', 'fig:ai_models', 'fig:ai_pays_dem']
[WARN] Not a file: ./download/output/figures/2508.00717/results_ai_use_demog
[WARN] Not a file: ./download/output/figures/2508.00717/results_ai_use_time
[WARN] Not a file: ./download/output/figures/2508.00717/results_ai_use_model
[WARN] Not a file: ./download/output/figures/2508.00717/results_ai_pays_dem
figure_block: Figure (optional):
- label: \label{figure4}; caption: \caption{Graphical representation of the query types of the BetaE dataset considered in our experiment, where $p$, $i$, $u$, and $n$ represent projection, intersection, union, and negation, respectively. }
- label: \label{figure5}; caption: \caption{Graphical representation of the query types of the FIT dataset considered in our experiment, where $l$, $m$, and $c$ represent existential leaf, multi graph, and circle, respectively. }
Collected fig_labels: ['figure4', 'figure5']
figure_block: Figure (optional):
- label: \label{fig:fwt_order8}; caption: \caption{Forward transfer score of different approaches on order 8. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:fwt_order9}; caption: \caption{Forward transfer score of different approaches on order 9. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:fwt_order10}; caption: \caption{Forward transfer score of different approaches on order 10. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:bwt_order8}; caption: \caption{Backward transfer score of different approaches on order 8. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:bwt_order9}; caption: \caption{Backward transfer score of different approaches on order 9. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:bwt_order10}; caption: \caption{Backward transfer score of different approaches on order 10. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:evolution}; caption: \caption{Evolution of average accuracy after learning new tasks.}
- label: \label{fig:fig_long_bars}; caption: \caption{Per-task improvement of Progressive Prompts verus per-task prompts in CL experiment with order 8 across different data limits (20, 200 and 1000 samples per class). X-axis shows the sequence of tasks, Y-axis shows percentage improve
Collected fig_labels: ['fig:fwt_order8', 'fig:fwt_order9', 'fig:fwt_order10', 'fig:bwt_order8', 'fig:bwt_order9', 'fig:bwt_order10', 'fig:evolution', 'fig:fig_long_bars']
figure_block: Figure (optional):
- label: \label{fig:qualitative_faceid}; caption: \caption{Examples of the FaceID guidance generation with pre-trained CelebA-HQ models. }
Collected fig_labels: ['fig:qualitative_faceid']
figure_block: Figure (optional):
- label: \label{fig:precond_a}; caption: \caption{}
- label: \label{fig:precond_b}; caption: \caption{}
Collected fig_labels: ['fig:precond_a', 'fig:precond_b']
[WARN] Not a file: ./download/output/figures/2310.07894v1/tex_figures_5c.png
[WARN] Not a file: ./download/output/figures/2310.07894v1/tex_figures_5d.png
figure_block: Figure (optional):
- label: \label{fig:cnn_c10_c100_trend}; caption: \caption{Prediction errors of base models and their weight averages (\fastswa and \swa) for CNN    on \textbf{(left)} CIFAR-10 with $4k$ labels,   \textbf{(middle)} CIFAR-100 with $10k$ labels,   and \textbf{(right)} CIFAR-100 $50k$ labels
Collected fig_labels: ['fig:cnn_c10_c100_trend']
[WARN] Not a file: ./download/output/figures/1806.05594v3/figs_exps_results_epochs_c10_cnn_MT_4k_wmodelTrue_nolegend
figure_block: Figure (optional):
- label: \label{fig:ai_use}; caption: \caption{The Adoption of Generative AI among Middlebury College Students}
- label: \label{fig:ai_use_time}; caption: \caption{The Evolution of Generative AI Adoption among Middlebury College Students}
- label: \label{fig:ai_models}; caption: \caption{Adoption of Generative AI Models Among College Students}
- label: \label{fig:ai_pays_dem}; caption: \caption{Percent of Students Who Pay for Generative AI Tools}
Collected fig_labels: ['fig:ai_use', 'fig:ai_use_time', 'fig:ai_models', 'fig:ai_pays_dem']
[WARN] Not a file: ./download/output/figures/2508.00717/results_ai_use_demog
[WARN] Not a file: ./download/output/figures/2508.00717/results_ai_use_time
[WARN] Not a file: ./download/output/figures/2508.00717/results_ai_use_model
[WARN] Not a file: ./download/output/figures/2508.00717/results_ai_pays_dem
figure_block: Figure (optional):
- label: \label{figure4}; caption: \caption{Graphical representation of the query types of the BetaE dataset considered in our experiment, where $p$, $i$, $u$, and $n$ represent projection, intersection, union, and negation, respectively. }
- label: \label{figure5}; caption: \caption{Graphical representation of the query types of the FIT dataset considered in our experiment, where $l$, $m$, and $c$ represent existential leaf, multi graph, and circle, respectively. }
Collected fig_labels: ['figure4', 'figure5']
figure_block: Figure (optional):
- label: \label{fig:fwt_order8}; caption: \caption{Forward transfer score of different approaches on order 8. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:fwt_order9}; caption: \caption{Forward transfer score of different approaches on order 9. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:fwt_order10}; caption: \caption{Forward transfer score of different approaches on order 10. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:bwt_order8}; caption: \caption{Backward transfer score of different approaches on order 8. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:bwt_order9}; caption: \caption{Backward transfer score of different approaches on order 9. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:bwt_order10}; caption: \caption{Backward transfer score of different approaches on order 10. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:evolution}; caption: \caption{Evolution of average accuracy after learning new tasks.}
- label: \label{fig:fig_long_bars}; caption: \caption{Per-task improvement of Progressive Prompts verus per-task prompts in CL experiment with order 8 across different data limits (20, 200 and 1000 samples per class). X-axis shows the sequence of tasks, Y-axis shows percentage improve
Collected fig_labels: ['fig:fwt_order8', 'fig:fwt_order9', 'fig:fwt_order10', 'fig:bwt_order8', 'fig:bwt_order9', 'fig:bwt_order10', 'fig:evolution', 'fig:fig_long_bars']
figure_block: Figure (optional):
- label: \label{fig:qualitative_faceid}; caption: \caption{Examples of the FaceID guidance generation with pre-trained CelebA-HQ models. }
Collected fig_labels: ['fig:qualitative_faceid']
figure_block: Figure (optional):
- label: \label{fig:precond_a}; caption: \caption{}
- label: \label{fig:precond_b}; caption: \caption{}
Collected fig_labels: ['fig:precond_a', 'fig:precond_b']
[WARN] Not a file: ./download/output/figures/2310.07894v1/tex_figures_5c.png
[WARN] Not a file: ./download/output/figures/2310.07894v1/tex_figures_5d.png
figure_block: Figure (optional):
- label: \label{fig:cnn_c10_c100_trend}; caption: \caption{Prediction errors of base models and their weight averages (\fastswa and \swa) for CNN    on \textbf{(left)} CIFAR-10 with $4k$ labels,   \textbf{(middle)} CIFAR-100 with $10k$ labels,   and \textbf{(right)} CIFAR-100 $50k$ labels
Collected fig_labels: ['fig:cnn_c10_c100_trend']
[WARN] Not a file: ./download/output/figures/1806.05594v3/figs_exps_results_epochs_c10_cnn_MT_4k_wmodelTrue_nolegend
figure_block: Figure (optional):
- label: \label{fig:ai_use}; caption: \caption{The Adoption of Generative AI among Middlebury College Students}
- label: \label{fig:ai_use_time}; caption: \caption{The Evolution of Generative AI Adoption among Middlebury College Students}
- label: \label{fig:ai_models}; caption: \caption{Adoption of Generative AI Models Among College Students}
- label: \label{fig:ai_pays_dem}; caption: \caption{Percent of Students Who Pay for Generative AI Tools}
Collected fig_labels: ['fig:ai_use', 'fig:ai_use_time', 'fig:ai_models', 'fig:ai_pays_dem']
[WARN] Not a file: ./download/output/figures/2508.00717/results_ai_use_demog
[WARN] Not a file: ./download/output/figures/2508.00717/results_ai_use_time
[WARN] Not a file: ./download/output/figures/2508.00717/results_ai_use_model
[WARN] Not a file: ./download/output/figures/2508.00717/results_ai_pays_dem
figure_block: Figure (optional):
- label: \label{figure4}; caption: \caption{Graphical representation of the query types of the BetaE dataset considered in our experiment, where $p$, $i$, $u$, and $n$ represent projection, intersection, union, and negation, respectively. }
- label: \label{figure5}; caption: \caption{Graphical representation of the query types of the FIT dataset considered in our experiment, where $l$, $m$, and $c$ represent existential leaf, multi graph, and circle, respectively. }
Collected fig_labels: ['figure4', 'figure5']
figure_block: Figure (optional):
- label: \label{fig:fwt_order8}; caption: \caption{Forward transfer score of different approaches on order 8. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:fwt_order9}; caption: \caption{Forward transfer score of different approaches on order 9. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:fwt_order10}; caption: \caption{Forward transfer score of different approaches on order 10. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:bwt_order8}; caption: \caption{Backward transfer score of different approaches on order 8. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:bwt_order9}; caption: \caption{Backward transfer score of different approaches on order 9. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:bwt_order10}; caption: \caption{Backward transfer score of different approaches on order 10. Different data limits are shown (20, 200 and 1000 samples per class).}
- label: \label{fig:evolution}; caption: \caption{Evolution of average accuracy after learning new tasks.}
- label: \label{fig:fig_long_bars}; caption: \caption{Per-task improvement of Progressive Prompts verus per-task prompts in CL experiment with order 8 across different data limits (20, 200 and 1000 samples per class). X-axis shows the sequence of tasks, Y-axis shows percentage improve
Collected fig_labels: ['fig:fwt_order8', 'fig:fwt_order9', 'fig:fwt_order10', 'fig:bwt_order8', 'fig:bwt_order9', 'fig:bwt_order10', 'fig:evolution', 'fig:fig_long_bars']
Prompt list: ['You are given the following inputs for reconstructing a missing paragraph in a research paper.\n\n    Title: Manifold Preserving Guided Diffusion\n    Abstract: \n    Section name: Experiments\n\n    Figure block (optional): Figure (optional):\n- label: \\label{fig:qualitative_faceid}; caption: \\caption{Examples of the FaceID guidance generation with pre-trained CelebA-HQ models. }\n    Table block (optional): Table (optional):\n- label: \\label{tab:faceid}; text: \\begin{tabular}{@{}l|ccc@{}} \\toprule \\textbf{Method} & \\textbf{KID}$\\downarrow$        & \\textbf{FaceID}$\\downarrow$ & \\textbf{Time}$\\downarrow$ \\\\ \\midrule DDIM            & 0.0442          & 1.3914               & 3.41s             \\\\ \\m\n    Cited paper titles/abstracts (optional): Abstract(s) of cited paper(s):\n- [lgd] Loss-guided diffusion models for plug-and-play controllable generation.: \n- [freedom] FreeDoM: Training-free energy-guided conditional diffusion model.:\n\n    k-most adjacent paragraphs (context): Previous:\n1. \\vspace{-5pt}\n\\subsection{Pixel space diffusion models}\nIn this section, we evaluate the performance of our proposed pixel domain methods (i.e. \\textbf{MPGD w/o Proj.}, \\textbf{MPGD-AE} and \\textbf{MPGD-Z}) with two different sets of conditional image generation tasks: solving liner inverse problems and human face generation guided by face recognition loss, which we refer to as FaceID guidance generation. For MPGD-AE and MPGD-Z, we use the pre-trained VQGAN models provided by~\\citet{rombach2021highresolution}.\n\\subsubsection{Noisy Linear Inverse Problem}\n2. For linear tasks, we use noisy super-resolution and noisy Gaussian deblurring as the test bed. We choose DPS~\\citep{dps}, LGD-MC~\\citep{lgd}, and MCG~\\citep{mcg} as the basleines. We test each method with two pre-trained diffusion models provided by~\\citet{dps}: one trained on FFHQ dataset~\\citep{karras2019style} and another on ImageNet~\\citep{deng2009imagenet}, both with $256 \\times 256$256 \\times 256 resolution. \nFor super-resolution, we down-sample ground truth images to $64 \\times 64$64 \\times 64. In the Gaussian deblurring task, we apply a $61\\times 61$61\\times 61 sized Gaussian blur with kernel intensity $3.0$3.0. to original images, Measurements in both tasks have a random noise with a variance of $\\sigma^{2}=0.05^{2}$\\sigma^{2}2=0.05^{2}2. We evaluate each task on a set of 1000~samples. We use the Kernel Inception distance (KID)~\\citep{binkowski2018demystifying} to assess the fidelity, Learned Perceptual Image Patch Similarity (LPIPS)~\\citep{zhang2018unreasonable} to evaluate the guidance quality, and the inference time to test the efficiency of the methods. All experiments are conducted on a single NVIDIA GeForce RTX 2080 Ti GPU . Figure~\\ref{fig:linear_main} shows the generated examples for qualitative comparison, and Figure~\\ref{fig:ffhq_sr} presents the quantitative results for the super-resolution task on FFHQ. All three of our methods significantly outperform the baselines with all metrics tested across a variety of different numbers of DDIM steps, and we can observe manifold projection improves the sample fidelity by a large margin.\nNext:\n1. \\hfill\n    [t]{0.53\\textwidth}0.53\\textwidth\n        \\centering\n        \\caption{Quantitative results for style guidance with Stable Diffusion experiment. Our method finds the sweet spot between following the prompt and following the style guidance.}\n        \\label{tab:style}\n2. \\vspace{-7pt}\n\\subsection{Latent diffusion models}\nTo evaluate \\textbf{MPGD-LDM}, we test our methods against the same baselines as the pixel-space FaceID experiments with text-to-image style guided generation task. The goal of this task is to generate images that fit both the text input prompts and the style of the reference images.\nWe use Stable Diffusion~\\citep{rombach2021highresolution} as the pre-trained text-to-image model and deploy the guided sampling methods to incorporate a style loss, which is calculated by the Frobenius norm between the Gram matrices of the reference images and the generated images.\nFor reference style images and text prompts, we randomly created 1000 conditioning pairs, using images from WikiArt~\\citep{saleh2015large} and prompts from PartiPrompts~\\citep{yu2022scaling} dataset. \nFigure~\\ref{fig:style_main} and Table~\\ref{tab:style} show qualitative and quantitative results for this experiment respectively. All the samples are generated on a single NVIDIA A100 GPU with 100 DDIM steps.\nOur method finds the sweet spot between following the text prompts, which usually instruct the generation to generate photo realistic images that do not suit the given style, and following the style guidance, which deviate from the prompts. Notably, because MPGD does not require propagation through the diffusion model, our method can provide significant speedup and can be fitted into a 16GB GPU while all the other methods cannot.\n3. \\vspace{-7pt}\n    Target length (characters): 1212\n    \n    # Canonicalized metadata for enforcement (already cleaned)\n    fig_labels = [\'fig:qualitative_faceid\']          # e.g., ["fig:framework","fig:sd_latents"]; [] if none\n    table_labels = [\'tab:faceid\']      # e.g., ["tab:results"]; [] if none\n    bib_keys = [\'freedom\', \'lgd\', \'freedom\']              # e.g., ["smith2024", "lee2023"]; [] if none\n\n    # Task\n    Write exactly one LaTeX-formatted paragraph that naturally fits between the adjacent paragraphs.\n\n    # HARD REQUIREMENTS (must all be satisfied)\n    1) If fig_labels is non-empty, include each label **exactly once** using \\ref{<label>} in the paragraph text (e.g., "see Fig.~\\ref{fig:framework}").\n    2) If table_labels is non-empty, include each label **exactly once** using \\ref{<label>}.\n    3) If bib_keys is non-empty, **cite all of them** (you may group keys in a single \\cite{...}).\n    - If allow_derived_bib_keys=true and a cited item lacks a key, derive a stable placeholder from its title: lowercase, keep a-z0-9 and hyphens only.\n    - Do not invent any other keys.\n    4) Maintain objective, concise academic tone; ensure logical continuity with the provided context.\n    5) Length approximately equals to 1212 (plus or minus 15%). Produce exactly one paragraph (no lists/headers/environments).\n\n    # ORDERING\n    - When mentioning multiple figures/tables, follow the order in fig_labels/table_labels.\n\n    # SILENT SELF-CHECK (do not print this checklist)\n    - Verify every l in fig_labels and table_labels appears exactly once as the substring "\\ref{" + l + "}".\n    - Verify every key in bib_keys (plus any allowed derived keys) appears in a \\cite{...}.\n    - Verify the output is a single paragraph (no blank lines).\n\n    # Output\n    Return only the LaTeX paragraph text. No explanations, no markdown, no extra lines.', 'You are given the following inputs for reconstructing a missing paragraph in a research paper.\n\n    Title: Efficient Integrators for Diffusion Generative Models\n    Abstract: \n    Section name: Additional Experimental Results\n\n    Figure block (optional): Figure (optional):\n- label: \\label{fig:precond_a}; caption: \\caption{}\n- label: \\label{fig:precond_b}; caption: \\caption{}\n    Table block (optional): Table (optional):\n- label: \\label{table:main}; text: \\begin{tabular}{@{}clcccc@{}} \\toprule                                         &               &                                                             &           & \\multicolumn{2}{c}{NFE (FID@50k $\\downarrow$)} \\\\ \\midrule\n    Cited paper titles/abstracts (optional): Abstract(s) of cited paper(s):\n- [songdenoising] Denoising diffusion implicit models.: \n- [lu2022dpm] Dpm-solver: A fast ode solver for diffusion probabilistic model   sampling in around 10 steps.: \n- [zhang2023fast] Fast sampling of diffusion models with exponential integrator.: \n- [karraselucidating] Elucidating the design space of diffusion-based generative models.: \n- [liupseudo] Pseudo numerical methods for diffusion models on manifolds.: \n- [bao2022analyticdpm] Analytic-DPM: an analytic estimate of the optimal reverse variance   in diffusion probabilistic models.: \n- [xue2023sasolver] Sa-solver: Stochastic adams solver for fast sampling of diffusion   models, 2023:\n\n    k-most adjacent paragraphs (context): Previous:\n1. \\textbf{Notation.} For simplicity, we denote our best-performing Reduced Splitting and Conjugate Splitting integrators as \\textit{\\gls{SPS}} and \\textit{\\gls{CSPS}}, respectively. Consequently, we refer to the \\underline{D}eterministic \\gls{RVV}RVV and \\underline{S}tochastic \\gls{ROBA}ROBA samplers as \\gls{SPS}SPS-D and \\gls{SPS}SPS-S, and their conjugate variants as \\gls{CSPS}CSPS-D and \\gls{CSPS}CSPS-S, respectively.\n2. \\textbf{Datasets and Evaluation Metrics.} We use the CIFAR-10, CelebA-64 \\citep{liu2015faceattributes} and the AFHQ-v2 \\citep{choi2020stargan} datasets for comparisons. Unless specified otherwise, we report FID for 50k generated samples for all datasets and quantify sampling efficiency using \\gls{NFE}NFE. We include full experimental details in Appendix \\ref{app:exp_setup}.\nNext:\n1. \\textbf{Empirical Observations:} For CIFAR-10, our ODE sampler performs comparably or outperforms all other baselines for \\gls{NFE}NFE $\\geq$\\geq 50 (Fig. \\ref{fig:sota_all}, Top Left). Similarly, our SDE sampler outperforms all other baselines for \\gls{NFE}NFE $\\geq$\\geq 40 (Fig. \\ref{fig:sota_all}, Top Right). We make similar observations for the CelebA-64 and AFHQv2-64 datasets, where our proposed samplers can obtain significant gains over prior methods for \\gls{NFE}NFE $\\geq$\\geq 70 (See Fig. \\ref{fig:sota_all}, Bottom Left). Therefore, our proposed samplers for \\gls{PSLD}PSLD are competitive with recent work. Moreover, for all datasets, our stochastic sampler achieves better sample quality for low sampling budgets (\\gls{NFE}NFE $<$< 50) as compared to our deterministic sampler. \nLastly, in contrast to CIFAR-10, we find that the \\gls{CSPS}CSPS-S sampler works better than the \\gls{SPS}SPS-S sampler for the CelebA-64 and AFHQv2-64 datasets, indicating its effectiveness for higher-resolution sampling.\n    Target length (characters): 1323\n    \n    # Canonicalized metadata for enforcement (already cleaned)\n    fig_labels = [\'fig:precond_a\', \'fig:precond_b\']          # e.g., ["fig:framework","fig:sd_latents"]; [] if none\n    table_labels = [\'table:main\']      # e.g., ["tab:results"]; [] if none\n    bib_keys = [\'songdenoising\', \'zhang2023fast\', \'lu2022dpm\', \'liupseudo\', \'karraselucidating\', \'xue2023sasolver\', \'bao2022analyticdpm\', \'karraselucidating\']              # e.g., ["smith2024", "lee2023"]; [] if none\n\n    # Task\n    Write exactly one LaTeX-formatted paragraph that naturally fits between the adjacent paragraphs.\n\n    # HARD REQUIREMENTS (must all be satisfied)\n    1) If fig_labels is non-empty, include each label **exactly once** using \\ref{<label>} in the paragraph text (e.g., "see Fig.~\\ref{fig:framework}").\n    2) If table_labels is non-empty, include each label **exactly once** using \\ref{<label>}.\n    3) If bib_keys is non-empty, **cite all of them** (you may group keys in a single \\cite{...}).\n    - If allow_derived_bib_keys=true and a cited item lacks a key, derive a stable placeholder from its title: lowercase, keep a-z0-9 and hyphens only.\n    - Do not invent any other keys.\n    4) Maintain objective, concise academic tone; ensure logical continuity with the provided context.\n    5) Length approximately equals to 1323 (plus or minus 15%). Produce exactly one paragraph (no lists/headers/environments).\n\n    # ORDERING\n    - When mentioning multiple figures/tables, follow the order in fig_labels/table_labels.\n\n    # SILENT SELF-CHECK (do not print this checklist)\n    - Verify every l in fig_labels and table_labels appears exactly once as the substring "\\ref{" + l + "}".\n    - Verify every key in bib_keys (plus any allowed derived keys) appears in a \\cite{...}.\n    - Verify the output is a single paragraph (no blank lines).\n\n    # Output\n    Return only the LaTeX paragraph text. No explanations, no markdown, no extra lines.', 'You are given the following inputs for reconstructing a missing paragraph in a research paper.\n\n    Title: There Are Many Consistent Explanations of Unlabeled Data: Why You Should Average\n    Abstract: \n    Section name: Experiments\n\n    Figure block (optional): Figure (optional):\n- label: \\label{fig:cnn_c10_c100_trend}; caption: \\caption{Prediction errors of base models and their weight averages (\\fastswa and \\swa) for CNN    on \\textbf{(left)} CIFAR-10 with $4k$ labels,   \\textbf{(middle)} CIFAR-100 with $10k$ labels,   and \\textbf{(right)} CIFAR-100 $50k$ labels\n    Table block (optional): Table (optional):\n- label: \\label{table:cifar100_shakeshake}; text: \\begin{tabular}{l c c c c c l l l l l } Number of labels\t\t\t& \t10k \t\t& \t50k \t\t& \t50k + 500k \t\t& 50k +   237k$^*$ \t\\\\  \\midrule TE (CNN) \\citep{te}  & \t38.65 \\tpm 0.51\t\t&\t26.30 \\tpm 0.15\t\t&\t23.62 \\tpm 0.17  \t&\t 23.79 \\tpm 0.17  \t\\\\  \\midrule\n    Cited paper titles/abstracts (optional): Abstract(s) of cited paper(s):\n- [te] Temporal Ensembling for Semi-Supervised Learning.:\n\n    k-most adjacent paragraphs (context): Previous:\n1. In Figure \\ref{fig:cnn_c10_c100_trend} (left), we visualize the test\nerror as a function of iteration using the CNN.\nWe observe that when the cyclical learning rate starts after epoch $\\ell=180$\\ell=180, \nthe base models drop in performance due to the sudden increase in learning rate (see Figure \\ref{fig:swa_model} left).\nHowever, \\fastswa continues to improve while collecting the weights corresponding to high learning rates for averaging.\nIn general, we also find that the cyclical learning rate improves the base models beyond the usual cosine annealing \nschedule and increases the performance of \\fastswa as training progresses. \nCompared to \\swa, we also observe that \\fastswa converges substantially faster, \nfor instance, reducing the error to $10.5\\%$10.5\\%  at epoch $200$200 while \\swa attains \nsimilar error at epoch $350$350 for CIFAR-10 $4k$4k labels (Figure \n\\ref{fig:cnn_c10_c100_trend} left). We provide additional plots in Section \\ref{sec:add_results} \nshowing the convergence of the \\pi and MT models in all label \nsettings, where we observe similar trends that \\fastswa results in faster error reduction.\n2. We also find that the performance gains of \\fastswa over base models are higher for the \\pi model compared to the MT model, which is consistent with the convexity observation in Section \\ref{sec:empirical_convexity} \nand Figure \\ref{fig:convexity}.\nIn the previous evaluations \\citep[see e.g.][]{ssl-eval, mt}, the \\pi model was shown to be inferior to the MT model.\nHowever, with weight averaging, \\fastswa reduces the gap between \\pi and MT performance. \nSurprisingly, we find that the \\pi model can outperform MT after applying \\fastswa  \nwith moderate to large numbers of labeled points. \nIn particular, the $\\Pi$\\Pi+fast-SWA model outperforms MT+\\fastswa on CIFAR-10 with $4k$4k, $10k$10k, and $50k$50k labeled\ndata points for the Shake-Shake  architecture.\n3. \\vspace{-0.8\\baselineskip}\n4. \\subsection{CIFAR-100 and Extra Unlabeled Data} \\label{sec:cifar100_cnn} \\label{sec:cifar100}\n5. We evaluate the \\pi and MT models with \\fastswa on \nCIFAR-100.\nWe train our models using $50000$50000 images with $10k$10k and $50k$50k labels using the $13$13-layer CNN. \nWe also analyze the effect of using the Tiny Images dataset \\citep{tiny_images} as an additional source of unlabeled data.\nNext:\n1. \\subsection{Advancing State-of-the-Art} \\label{sec:soa}\n2. We have shown that \\fastswa can significantly improve the performance of both the \\pi and \nMT models. We provide a summary comparing our results with the previous best results in the literature in Table  \\ref{table:soa}, using the $13$13-layer CNN and\nthe Shake-Shake architecture that had been applied previously. We also provide detailed results the Appendix \\ref{sec:add_results}.\n3. \\subsection{Preliminary Results on Domain Adaptation}\n\\label{sec:domain_adaptation}\nDomain adaptation problems involve learning using a source domain $X_s$X_s \nequipped with labels $Y_s$Y_s and performing classification on the target \ndomain $X_t$X_t while having no access to the target labels at training time. \nA recent model by \\citet{da_mt} applies the consistency enforcing principle for \ndomain adaptation and achieves state-of-the-art results on many datasets. \nApplying \\fastswa to this model on domain adaptation from CIFAR-10 to STL we \nwere able to improve the best results reported in the literature from\n$19.9\\%$19.9\\% to $16.8\\%$16.8\\%. \nSee Section \\ref{sec:exp_da} for more details on the domain adaptation experiments.\n    Target length (characters): 1438\n    \n    # Canonicalized metadata for enforcement (already cleaned)\n    fig_labels = [\'fig:cnn_c10_c100_trend\']          # e.g., ["fig:framework","fig:sd_latents"]; [] if none\n    table_labels = [\'table:cifar100_shakeshake\']      # e.g., ["tab:results"]; [] if none\n    bib_keys = [\'te\']              # e.g., ["smith2024", "lee2023"]; [] if none\n\n    # Task\n    Write exactly one LaTeX-formatted paragraph that naturally fits between the adjacent paragraphs.\n\n    # HARD REQUIREMENTS (must all be satisfied)\n    1) If fig_labels is non-empty, include each label **exactly once** using \\ref{<label>} in the paragraph text (e.g., "see Fig.~\\ref{fig:framework}").\n    2) If table_labels is non-empty, include each label **exactly once** using \\ref{<label>}.\n    3) If bib_keys is non-empty, **cite all of them** (you may group keys in a single \\cite{...}).\n    - If allow_derived_bib_keys=true and a cited item lacks a key, derive a stable placeholder from its title: lowercase, keep a-z0-9 and hyphens only.\n    - Do not invent any other keys.\n    4) Maintain objective, concise academic tone; ensure logical continuity with the provided context.\n    5) Length approximately equals to 1438 (plus or minus 15%). Produce exactly one paragraph (no lists/headers/environments).\n\n    # ORDERING\n    - When mentioning multiple figures/tables, follow the order in fig_labels/table_labels.\n\n    # SILENT SELF-CHECK (do not print this checklist)\n    - Verify every l in fig_labels and table_labels appears exactly once as the substring "\\ref{" + l + "}".\n    - Verify every key in bib_keys (plus any allowed derived keys) appears in a \\cite{...}.\n    - Verify the output is a single paragraph (no blank lines).\n\n    # Output\n    Return only the LaTeX paragraph text. No explanations, no markdown, no extra lines.', 'You are given the following inputs for reconstructing a missing paragraph in a research paper.\n\n    Title: Generative AI in Higher Education: Evidence from an Elite College\n    Abstract: \n    Section name: Generative AI Usage Patterns Among Students\n\n    Figure block (optional): Figure (optional):\n- label: \\label{fig:ai_use}; caption: \\caption{The Adoption of Generative AI among Middlebury College Students}\n- label: \\label{fig:ai_use_time}; caption: \\caption{The Evolution of Generative AI Adoption among Middlebury College Students}\n- label: \\label{fig:ai_models}; caption: \\caption{Adoption of Generative AI Models Among College Students}\n- label: \\label{fig:ai_pays_dem}; caption: \\caption{Percent of Students Who Pay for Generative AI Tools}\n    Table block (optional): Table (optional):\n- label: \\label{tab:ai_usage_correlates}; text: \\begin{tabular}{l@{}lR{\\w cm}@{}L{0.45cm}R{\\w cm}@{}L{0.45cm}R{\\w cm}@{}L{0.45cm}R{\\w cm}@{}L{0.45cm}} \t\t\t\t\t\\midrule \t\t\t\t\t&& \\multicolumn{8}{c}{Outcome: Uses AI during the semester with frequency of at least...}  \\\\\\cmidrule{3-10}  \t\t\t\t\t%\n- label: \\label{tab:ai_adopt_correlates}; text: \\begin{tabular}{l@{}lR{\\w cm}@{}L{0.45cm}R{\\w cm}@{}L{0.45cm}R{\\w cm}@{}L{0.45cm}R{\\w cm}@{}L{0.45cm}R{\\w cm}@{}L{0.45cm}} \t\t\t\t\t\\midrule \t\t\t\t\t&& \\multicolumn{10}{c}{Outcome: Started using generative AI...}  \\\\\\cmidrule{3-12}  \t\t\t\t\t&& Before\n- label: \\label{tab:ai_freq_het}; text: \\begin{tabular}{lccccc} \t\t\t\t\t\t\\toprule \t\t\t\t\t\t&& \\multicolumn{4}{c}{By Usage Frequency} \\\\ \\cmidrule{3-6} \t\t\t\t\t\t& Any use & Rarely & Occasionally & Frequently & Very Frequently \\\\ \t\t\t\t\t\t& (1) & (2) & (3) & (4) & (5) \\\\ \\midrule\t\t\t\t\t\t \t\t\t\t\t\t\\\n- label: \\label{tab:ai_model_correlates}; text: \\begin{tabular}{l@{}lR{\\w cm}@{}L{0.45cm}R{\\w cm}@{}L{0.45cm}R{\\w cm}@{}L{0.45cm}R{\\w cm}@{}L{0.45cm}R{\\w cm}@{}L{0.45cm}} \t\t\t\t\t\\midrule \t\t\t\t\t&& \\multicolumn{10}{c}{Outcome: =1 if student uses}  \\\\\\cmidrule{3-12}  \t\t\t\t\t&& OpenAI\'s && Google\n    Cited paper titles/abstracts (optional): Abstract(s) of cited paper(s):\n- [bick.etal2025] The rapid adoption of generative AI.: \n- [mcclain2024] Americans\' use of ChatGPT is ticking up, but few trust its   election information: \n- [nam2023ai] 56\\% of college students have used ai on assignments or exams.: \n- [stohr.etal2024] \\"o: \n- [ravselj.etal2025] s: \n- [otis2024global] Global Evidence on Gender Gaps and Generative AI.: \n- [hartley.etal2025] The Labor Market Effects of Generative Artificial   Intelligence: \n- [humlum.vestergaard2025] Large Language Models, Small Labor Market Effects: \n- [carvajal2024] Will artificial intelligence get in the way of achieving gender   equality?: \n- [david1990dynamo] The dynamo and the computer: an historical perspective on the modern   productivity paradox.: \n- [gallup2024] AI in the Workplace: Answering 3 Big Questions: \n- [hall2003adoption] Adoption of new technology: \n- [stokey2021technology] Technology diffusion.: \n- [world2016world] World Bank: \n- [bick.etal2025] The rapid adoption of generative AI.: \n- [mcclain2024] Americans\' use of ChatGPT is ticking up, but few trust its   election information: \n- [nam2023ai] 56\\% of college students have used ai on assignments or exams.: \n- [stohr.etal2024] \\"o: \n- [ravselj.etal2025] s: \n- [otis2024global] Global Evidence on Gender Gaps and Generative AI.: \n- [hartley.etal2025] The Labor Market Effects of Generative Artificial   Intelligence: \n- [humlum.vestergaard2025] Large Language Models, Small Labor Market Effects: \n- [carvajal2024] Will artificial intelligence get in the way of achieving gender   equality?: \n- [david1990dynamo] The dynamo and the computer: an historical perspective on the modern   productivity paradox.: \n- [gallup2024] AI in the Workplace: Answering 3 Big Questions: \n- [hall2003adoption] Adoption of new technology: \n- [stokey2021technology] Technology diffusion.: \n- [world2016world] World Bank:\n\n    k-most adjacent paragraphs (context): \n    Target length (characters): 13653\n    \n    # Canonicalized metadata for enforcement (already cleaned)\n    fig_labels = [\'fig:ai_use\', \'fig:ai_use_time\', \'fig:ai_models\', \'fig:ai_pays_dem\']          # e.g., ["fig:framework","fig:sd_latents"]; [] if none\n    table_labels = [\'tab:ai_usage_correlates\', \'tab:ai_adopt_correlates\', \'tab:ai_freq_het\', \'tab:ai_model_correlates\']      # e.g., ["tab:results"]; [] if none\n    bib_keys = [\'nam2023ai\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'nam2023ai\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'nam2023ai\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'nam2023ai\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'nam2023ai\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'nam2023ai\', \'nam2023ai\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'nam2023ai\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'nam2023ai\', \'ravselj.etal2025\', \'nam2023ai\', \'stohr.etal2024\', \'carvajal2024\', \'ravselj.etal2025\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'david1990dynamo\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'hall2003adoption\', \'otis2024global\', \'nam2023ai\', \'stokey2021technology\', \'carvajal2024\', \'stohr.etal2024\', \'world2016world\', \'ravselj.etal2025\', \'carvajal2024\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'nam2023ai\', \'nam2023ai\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'nam2023ai\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'nam2023ai\', \'nam2023ai\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'nam2023ai\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'nam2023ai\', \'nam2023ai\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'nam2023ai\', \'nam2023ai\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'nam2023ai\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'nam2023ai\', \'nam2023ai\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'nam2023ai\', \'nam2023ai\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'nam2023ai\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'nam2023ai\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'ravselj.etal2025\', \'nam2023ai\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'nam2023ai\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'nam2023ai\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'nam2023ai\', \'nam2023ai\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'nam2023ai\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\', \'nam2023ai\', \'ravselj.etal2025\', \'stohr.etal2024\', \'carvajal2024\', \'mcclain2024\', \'gallup2024\', \'bick.etal2025\', \'hartley.etal2025\', \'humlum.vestergaard2025\', \'mcclain2024\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'otis2024global\', \'nam2023ai\', \'carvajal2024\', \'stohr.etal2024\', \'ravselj.etal2025\', \'carvajal2024\', \'stohr.etal2024\', \'nam2023ai\', \'ravselj.etal2025\', \'bick.etal2025\', \'humlum.vestergaard2025\', \'david1990dynamo\', \'hall2003adoption\', \'stokey2021technology\', \'world2016world\', \'mcclain2024\', \'stohr.etal2024\', \'bick.etal2025\', \'bick.etal2025\', \'ravselj.etal2025\']              # e.g., ["smith2024", "lee2023"]; [] if none\n\n    # Task\n    Write exactly one LaTeX-formatted paragraph that naturally fits between the adjacent paragraphs.\n\n    # HARD REQUIREMENTS (must all be satisfied)\n    1) If fig_labels is non-empty, include each label **exactly once** using \\ref{<label>} in the paragraph text (e.g., "see Fig.~\\ref{fig:framework}").\n    2) If table_labels is non-empty, include each label **exactly once** using \\ref{<label>}.\n    3) If bib_keys is non-empty, **cite all of them** (you may group keys in a single \\cite{...}).\n    - If allow_derived_bib_keys=true and a cited item lacks a key, derive a stable placeholder from its title: lowercase, keep a-z0-9 and hyphens only.\n    - Do not invent any other keys.\n    4) Maintain objective, concise academic tone; ensure logical continuity with the provided context.\n    5) Length approximately equals to 13653 (plus or minus 15%). Produce exactly one paragraph (no lists/headers/environments).\n\n    # ORDERING\n    - When mentioning multiple figures/tables, follow the order in fig_labels/table_labels.\n\n    # SILENT SELF-CHECK (do not print this checklist)\n    - Verify every l in fig_labels and table_labels appears exactly once as the substring "\\ref{" + l + "}".\n    - Verify every key in bib_keys (plus any allowed derived keys) appears in a \\cite{...}.\n    - Verify the output is a single paragraph (no blank lines).\n\n    # Output\n    Return only the LaTeX paragraph text. No explanations, no markdown, no extra lines.', 'You are given the following inputs for reconstructing a missing paragraph in a research paper.\n\n    Title: Neural-Symbolic Message Passing with Dynamic Pruning\n    Abstract: \n    Section name: More Details about the Datasets\n\n    Figure block (optional): Figure (optional):\n- label: \\label{figure4}; caption: \\caption{Graphical representation of the query types of the BetaE dataset considered in our experiment, where $p$, $i$, $u$, and $n$ represent projection, intersection, union, and negation, respectively. }\n- label: \\label{figure5}; caption: \\caption{Graphical representation of the query types of the FIT dataset considered in our experiment, where $l$, $m$, and $c$ represent existential leaf, multi graph, and circle, respectively. }\n    Table block (optional): Table (optional):\n- label: \\label{KG stat}; text: \\begin{tabular}{ccccccc}     \\toprule     \\textbf{Knowledge Graph} & \\textbf{Entities} & \\textbf{Relations} & \\textbf{Training Edges} & \\textbf{Val Edges} & \\textbf{Test Edges} & \\textbf{Total Edges} \\\\     \\midrule     FB15k-237 & 14,505 &\n- label: \\label{BetaE stat}; text: \\begin{tabular}{ccccccc}     \\toprule     \\multirow{2}{*}{\\textbf{Knowledge Graph}} & \\multicolumn{2}{c}{\\textbf{Training Queries}} & \\multicolumn{2}{c}{\\textbf{Validation Queries}} & \\multicolumn{2}{c}{\\textbf{Test Queries}} \\\\     \\cmidru\n- label: \\label{FIT stat}; text: \\begin{tabular}{ccccccccccc}     \\toprule     \\textbf{Knowledge Graph} & \\textbf{pni} & \\textbf{2il} & \\textbf{3il} & \\textbf{2m} & \\textbf{2nm} & \\textbf{3mp} & \\textbf{3pm} & \\textbf{im} & \\textbf{3c} & \\textbf{3cm} \\\\     \\midrule     FB\n    Cited paper titles/abstracts (optional): Abstract(s) of cited paper(s):\n- [ren2020beta] Beta embeddings for multi-hop logical reasoning in knowledge graphs: \n- [yin2024rethinking] Rethinking Complex Queries on Knowledge Graphs with Neural Link Predictors:\n\n    k-most adjacent paragraphs (context): \n    Target length (characters): 973\n    \n    # Canonicalized metadata for enforcement (already cleaned)\n    fig_labels = [\'figure4\', \'figure5\']          # e.g., ["fig:framework","fig:sd_latents"]; [] if none\n    table_labels = [\'KG stat\', \'BetaE stat\', \'FIT stat\']      # e.g., ["tab:results"]; [] if none\n    bib_keys = [\'ren2020beta\', \'yin2024rethinking\', \'ren2020beta\', \'ren2020beta\', \'yin2024rethinking\', \'ren2020beta\', \'yin2024rethinking\', \'ren2020beta\', \'yin2024rethinking\', \'ren2020beta\', \'yin2024rethinking\', \'yin2024rethinking\', \'ren2020beta\', \'yin2024rethinking\', \'ren2020beta\', \'yin2024rethinking\', \'ren2020beta\', \'yin2024rethinking\', \'ren2020beta\', \'ren2020beta\', \'yin2024rethinking\', \'yin2024rethinking\', \'ren2020beta\', \'yin2024rethinking\', \'ren2020beta\', \'yin2024rethinking\', \'ren2020beta\', \'ren2020beta\', \'yin2024rethinking\', \'ren2020beta\', \'yin2024rethinking\', \'yin2024rethinking\', \'ren2020beta\', \'yin2024rethinking\', \'ren2020beta\', \'yin2024rethinking\', \'ren2020beta\', \'yin2024rethinking\']              # e.g., ["smith2024", "lee2023"]; [] if none\n\n    # Task\n    Write exactly one LaTeX-formatted paragraph that naturally fits between the adjacent paragraphs.\n\n    # HARD REQUIREMENTS (must all be satisfied)\n    1) If fig_labels is non-empty, include each label **exactly once** using \\ref{<label>} in the paragraph text (e.g., "see Fig.~\\ref{fig:framework}").\n    2) If table_labels is non-empty, include each label **exactly once** using \\ref{<label>}.\n    3) If bib_keys is non-empty, **cite all of them** (you may group keys in a single \\cite{...}).\n    - If allow_derived_bib_keys=true and a cited item lacks a key, derive a stable placeholder from its title: lowercase, keep a-z0-9 and hyphens only.\n    - Do not invent any other keys.\n    4) Maintain objective, concise academic tone; ensure logical continuity with the provided context.\n    5) Length approximately equals to 973 (plus or minus 15%). Produce exactly one paragraph (no lists/headers/environments).\n\n    # ORDERING\n    - When mentioning multiple figures/tables, follow the order in fig_labels/table_labels.\n\n    # SILENT SELF-CHECK (do not print this checklist)\n    - Verify every l in fig_labels and table_labels appears exactly once as the substring "\\ref{" + l + "}".\n    - Verify every key in bib_keys (plus any allowed derived keys) appears in a \\cite{...}.\n    - Verify the output is a single paragraph (no blank lines).\n\n    # Output\n    Return only the LaTeX paragraph text. No explanations, no markdown, no extra lines.', 'You are given the following inputs for reconstructing a missing paragraph in a research paper.\n\n    Title: Progressive Prompts: Continual Learning for Language Models\n    Abstract: \n    Section name: Further experimental results\n\n    Figure block (optional): Figure (optional):\n- label: \\label{fig:fwt_order8}; caption: \\caption{Forward transfer score of different approaches on order 8. Different data limits are shown (20, 200 and 1000 samples per class).}\n- label: \\label{fig:fwt_order9}; caption: \\caption{Forward transfer score of different approaches on order 9. Different data limits are shown (20, 200 and 1000 samples per class).}\n- label: \\label{fig:fwt_order10}; caption: \\caption{Forward transfer score of different approaches on order 10. Different data limits are shown (20, 200 and 1000 samples per class).}\n- label: \\label{fig:bwt_order8}; caption: \\caption{Backward transfer score of different approaches on order 8. Different data limits are shown (20, 200 and 1000 samples per class).}\n- label: \\label{fig:bwt_order9}; caption: \\caption{Backward transfer score of different approaches on order 9. Different data limits are shown (20, 200 and 1000 samples per class).}\n- label: \\label{fig:bwt_order10}; caption: \\caption{Backward transfer score of different approaches on order 10. Different data limits are shown (20, 200 and 1000 samples per class).}\n- label: \\label{fig:evolution}; caption: \\caption{Evolution of average accuracy after learning new tasks.}\n- label: \\label{fig:fig_long_bars}; caption: \\caption{Per-task improvement of Progressive Prompts verus per-task prompts in CL experiment with order 8 across different data limits (20, 200 and 1000 samples per class). X-axis shows the sequence of tasks, Y-axis shows percentage improve\n    Table block (optional): Table (optional):\n- label: \\label{wrap-tab:init}; text: \\begin{tabular}{lcc}\\\\\\toprule   Method & Few-shot & Full-shot \\\\\\midrule PT + Prev. Init. & 48.2 & 50.0 \\\\  ProgPrompt & \\textbf{53.5} & \\textbf{69.3} \\\\ \\bottomrule \\end{tabular}\n- label: \\label{tab:table_appendix_long}; text: \\begin{tabular}{lccc|ccc|ccc|ccc} % <-- Alignments: 1st column left & 2nd middle and 3rd right & with vertical lines in between     \\toprule       \\textbf{Method} $\\downarrow$ & \\multicolumn{3}{c}{\\textbf{Order 8}}  & \\multicolumn{3}{c}{\\te\n    Cited paper titles/abstracts (optional): Abstract(s) of cited paper(s):\n- [lopez2017gradient] Gradient episodic memory for continual learning:\n\n    k-most adjacent paragraphs (context): Next:\n1. \\includegraphics[width=0.9\\textwidth]{images/long_exp_bars.png}\n\\caption{Per-task improvement of Progressive Prompts verus per-task prompts in CL experiment with order 8 across different data limits (20, 200 and 1000 samples per class). X-axis shows the sequence of tasks, Y-axis shows percentage improvement of Progressive Prompts test score compared to per-task prompt on the corresponding task.}\n\\label{fig:fig_long_bars}\n\\end{figure}\n2. \\includegraphics[width=0.9\\textwidth]{images/long_exp_bars.png}\n\\caption{Per-task improvement of Progressive Prompts verus per-task prompts in CL experiment with order 8 across different data limits (20, 200 and 1000 samples per class). X-axis shows the sequence of tasks, Y-axis shows percentage improvement of Progressive Prompts test score compared to per-task prompt on the corresponding task.}\n\\label{fig:fig_long_bars}\n3. \\includegraphics[width=0.7\\textwidth]{images/superglue_illustration.png}\n4. \\caption{Original prompt tuning versus Progressive Prompts on SuperGLUE datasets. For illustration, we show how SuperGLUE task WiC is leaned (we have similar scheme for other tasks). Prompt tuning trains a single prompt of 100 tokens for WiC task. Progressive Prompts method learns a prompt of 40 tokens, which is progressively appended to the six frozen prompts of 10 tokens learned on GLUE benchmark (with random task order). Total prompt length is equal in both approaches. }\n\\label{fig:fig_super_illustration}\n\\end{figure}\n5. \\includegraphics[width=0.7\\textwidth]{images/superglue_illustration.png}\n    Target length (characters): 1627\n    \n    # Canonicalized metadata for enforcement (already cleaned)\n    fig_labels = [\'fig:fwt_order8\', \'fig:fwt_order9\', \'fig:fwt_order10\', \'fig:bwt_order8\', \'fig:bwt_order9\', \'fig:bwt_order10\', \'fig:evolution\', \'fig:fig_long_bars\']          # e.g., ["fig:framework","fig:sd_latents"]; [] if none\n    table_labels = [\'wrap-tab:init\', \'tab:table_appendix_long\']      # e.g., ["tab:results"]; [] if none\n    bib_keys = [\'lopez2017gradient\']              # e.g., ["smith2024", "lee2023"]; [] if none\n\n    # Task\n    Write exactly one LaTeX-formatted paragraph that naturally fits between the adjacent paragraphs.\n\n    # HARD REQUIREMENTS (must all be satisfied)\n    1) If fig_labels is non-empty, include each label **exactly once** using \\ref{<label>} in the paragraph text (e.g., "see Fig.~\\ref{fig:framework}").\n    2) If table_labels is non-empty, include each label **exactly once** using \\ref{<label>}.\n    3) If bib_keys is non-empty, **cite all of them** (you may group keys in a single \\cite{...}).\n    - If allow_derived_bib_keys=true and a cited item lacks a key, derive a stable placeholder from its title: lowercase, keep a-z0-9 and hyphens only.\n    - Do not invent any other keys.\n    4) Maintain objective, concise academic tone; ensure logical continuity with the provided context.\n    5) Length approximately equals to 1627 (plus or minus 15%). Produce exactly one paragraph (no lists/headers/environments).\n\n    # ORDERING\n    - When mentioning multiple figures/tables, follow the order in fig_labels/table_labels.\n\n    # SILENT SELF-CHECK (do not print this checklist)\n    - Verify every l in fig_labels and table_labels appears exactly once as the substring "\\ref{" + l + "}".\n    - Verify every key in bib_keys (plus any allowed derived keys) appears in a \\cite{...}.\n    - Verify the output is a single paragraph (no blank lines).\n\n    # Output\n    Return only the LaTeX paragraph text. No explanations, no markdown, no extra lines.']
Number of prompts: 6
Image tag lists: [[['contains scatter plot']], [None, None], [None], [None, None, None, None], [['a figure showing network'], ['a figure showing network']], [['a chart about heatmap'], ['a chart about heatmap'], ['a chart about heatmap'], ['a chart about heatmap'], ['a chart about heatmap'], ['a chart about heatmap'], ['a chart about heatmap'], ['a chart about bar chart']]]
Number of Image tag lists: 6
INFO 08-29 19:24:03 [utils.py:326] non-default args: {'model': 'Qwen/Qwen3-8B', 'trust_remote_code': True, 'dtype': 'bfloat16', 'gpu_memory_utilization': 0.8, 'disable_log_stats': True, 'enforce_eager': True}
INFO 08-29 19:24:09 [__init__.py:711] Resolved architecture: Qwen3ForCausalLM
INFO 08-29 19:24:09 [__init__.py:1750] Using max model len 40960
INFO 08-29 19:24:09 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=8192.
INFO 08-29 19:24:09 [__init__.py:3565] Cudagraph is disabled under eager mode
WARNING 08-29 19:24:10 [__init__.py:2921] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reasons: CUDA is initialized
INFO 08-29 19:24:15 [__init__.py:241] Automatically detected platform cuda.
[1;36m(EngineCore_0 pid=2873480)[0;0m INFO 08-29 19:24:17 [core.py:636] Waiting for init message from front-end.
[1;36m(EngineCore_0 pid=2873480)[0;0m INFO 08-29 19:24:17 [core.py:74] Initializing a V1 LLM engine (v0.10.1.1) with config: model='Qwen/Qwen3-8B', speculative_config=None, tokenizer='Qwen/Qwen3-8B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=40960, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-8B, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":null,"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":0,"use_cudagraph":true,"cudagraph_num_of_warmups":0,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"pass_config":{},"max_capture_size":0,"local_cache_dir":null}
[1;36m(EngineCore_0 pid=2873480)[0;0m INFO 08-29 19:24:19 [parallel_state.py:1134] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0
[1;36m(EngineCore_0 pid=2873480)[0;0m WARNING 08-29 19:24:19 [topk_topp_sampler.py:61] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.
[1;36m(EngineCore_0 pid=2873480)[0;0m INFO 08-29 19:24:19 [gpu_model_runner.py:1953] Starting to load model Qwen/Qwen3-8B...
[1;36m(EngineCore_0 pid=2873480)[0;0m INFO 08-29 19:24:19 [gpu_model_runner.py:1985] Loading model from scratch...
[1;36m(EngineCore_0 pid=2873480)[0;0m INFO 08-29 19:24:19 [cuda.py:328] Using Flash Attention backend on V1 engine.
[1;36m(EngineCore_0 pid=2873480)[0;0m INFO 08-29 19:24:19 [weight_utils.py:296] Using model weights format ['*.safetensors']
[1;36m(EngineCore_0 pid=2873480)[0;0m INFO 08-29 19:24:22 [default_loader.py:262] Loading weights took 3.09 seconds
[1;36m(EngineCore_0 pid=2873480)[0;0m INFO 08-29 19:24:23 [gpu_model_runner.py:2007] Model loading took 15.2683 GiB and 3.481222 seconds
[1;36m(EngineCore_0 pid=2873480)[0;0m INFO 08-29 19:24:25 [gpu_worker.py:276] Available KV cache memory: 21.29 GiB
[1;36m(EngineCore_0 pid=2873480)[0;0m INFO 08-29 19:24:25 [kv_cache_utils.py:849] GPU KV cache size: 155,008 tokens
[1;36m(EngineCore_0 pid=2873480)[0;0m INFO 08-29 19:24:25 [kv_cache_utils.py:853] Maximum concurrency for 40,960 tokens per request: 3.78x
[1;36m(EngineCore_0 pid=2873480)[0;0m INFO 08-29 19:24:25 [core.py:214] init engine (profile, create kv cache, warmup model) took 2.28 seconds
[1;36m(EngineCore_0 pid=2873480)[0;0m INFO 08-29 19:24:26 [__init__.py:3565] Cudagraph is disabled under eager mode
INFO 08-29 19:24:26 [llm.py:298] Supported_tasks: ['generate']
[1;36m(EngineCore_0 pid=2873480)[0;0m WARNING 08-29 19:24:26 [cudagraph_dispatcher.py:101] cudagraph dispatching keys are not initialized. No cudagraph will be used.
Saved results to ./task_result/paragraph_generation_result2.csv
